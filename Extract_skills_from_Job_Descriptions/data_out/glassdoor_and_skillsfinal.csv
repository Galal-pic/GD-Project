,Unnamed: 0,Job Title,Job Description,mymodel_skills,Technology_skills,Technical_skills,business_skills
0,0,Data Scientist (Remote),"as a critical member of the stream systems team, the data scientist is responsible for acting as a subject matter expert when it comes to statistical analysis, machine learning , and deep learning. he or she will work with the development and bd teams to define end to end, ml based solutions to develop or enhance new or existing features. priority will be given to candidates with expertise in the following areas deep learning frameworks such as tensorflow and pytorch frameworks for in production ml code cloud computing such as amazon web services deploying machine learning models in production development and deployment using docker a strong command of sql and working with multiple relational databases and data warehouses strong programming skills in python with experience of libraries such as pandas, scikit learn, numpy and scipy tools such as git and jira data collection and data pipelines productization best practices for ml based solutions who we are stream systems is a privately owned, canadian software company headquartered in calgary, alberta. it enables companies to identify, assess, and reduce their system bottlenecks by providing complex models and simulation toolkits which can be tailored to a client s individual capital assets. each solution bridges engineering, operations, and finance thus creating a risk free virtual world to allow you to experiment with business rules, operating procedures, and asset configuration for brown and greenfield projects. stream systems is well positioned to fundamentally shift how a company makes business decisions. for more information, please visit open to contractors as well as full time employee placements. due to covid 19, we are currently working from home to keep our staff and clients safe. fortunately, we have the tools and infrastructure to set you up for a successful home based position. for this reason, we are accepting applications to work remotely from anywhere in canada. we thank all those who apply but only qualified applicants will be contacted. successful completion of a criminal background check will be required. indqce","['pytorch', 'tensorflow', 'statistical analysis', 'sql', 'python', 'scipy', 'software', 'pandas', 'programming', 'cloud computing', 'amazon web services', 'machine learning', 'data pipelines', 'relational databases', 'numpy', 'data collection', 'deep learning', 'jira', 'git']","['sql', 'python', 'amazon web services', 'jira', 'pytorch', 'sci', 'numpy', 'git', 'pandas', 'programming']","['deep learning', 'machine learning', 'data pipelines', 'relational databases', 'software', 'tensorflow', 'data collection', 'statistical analysis', 'cloud computing']","['capital', 'greenfield projects', 'finance', 'acting']"
1,2,Sr. Data Analyst,"numerator is a data and tech company bringing speed and scale to market research. headquartered in chicago, il, numerator has more than 2,000 employees worldwide. the company blends proprietary data with advanced technology to create unique insights for the market research industry that has been slow to change. the majority of fortune 100 companies are numerator clients. job description as our senior data analyst truview on our data science team, you will get the opportunity to build data products, drive actionable insights, and tackle high impact business problems. you will tell the story behind the data painting a picture to our cross functional partners, explaining what the numbers are telling us, and recommending new ways to leverage data. this role will focus on our new, innovative product called truview. as this is a small, entrepreneurial subteam, you ll be an ideal fit if you thrive being autonomous, delivering results despite ambiguity, and want to relish the opportunity to make an impact on a highly visible, fast growth team and product. you will have solid technical abilities to retrieve, manipulate, analyze, and visualize data and excellent communication capabilities to all levels. you enjoy leading and working with product, engineering, data science teams, client services, and other stakeholders to find the best solution to the problem at hand, iterate over it, and balance technical data complexity with delivering timely customer value. additionally, the ideal candidate will have experience managing analytical projects from conception to completion, being hands on throughout. if you seek an environment where you get to do meaningful work with a great, fun data science team, we want to hear from you what you get to do provide bespoke analysis and insights that influence our data product, business, and clients. partner with product, data science, and engineering teams to identify, investigate, and deliver analytics that leverages our data lake, warehouse, and data science models. lead analysis to discover new or improved methodologies support our data scientists in evaluating algorithms effectiveness, performance, and business impact. identify new areas of analytic opportunity and work collaboratively to implement them, such as designing kpis quality metrics to maximize the control of our data pipeline. provide analysis consulting support to both internal stakeholders and external clients. skills requirements what you bring 3 years of industry experience with granular data analysis, predictive analytics, or analytics technology products. 1 years of experience in a senior role or leading data analytic position where you executed technical business solutions for analytics deliverables. fluency in sql, querying databases, and intermediate data munging. experience with data visualization tools such as tableau mode a data storyteller who is comfortable communicating results in a crisp and effective manner to all audiences . flexible analytical skills and can evangelize the use of data for sound decision making across functions. experience launching metric dashboards and scorecards. strong oral and written communication skills with an ability to collaborate with and influence cross functional partners. self motivated, self directed, and able to thrive in a fast paced environment in an industry that constantly changes. a mindset of designing for the future but building for now. an eagerness to learn from others and help others grow with you. a love of data and finding interesting questions to ask of it. nice to haves hands on experience reading or writing code as data engineer, technical data analyst, or data scientist. previous experience working with purchase panel data, cpg data, marketing insights, or the retail industry. proficiency in at least one scripting or statistics or data analysis packages, such as python or r, or the demonstrated desire to grow and learn more. experience with understanding, analyzing, and modeling user data and granular behavioral trends. exposure to machine learning concepts. what we offer more data than you could imagine to play with data that matters and that is shaping the impact of billion dollar brands. brillant, motivated and passionate colleagues with whom to spend your time with. an inclusive and collaborative company culture we work in an open environment while working together to get things done and adapt to the changing needs as they come. market competitive total compensation package. an opportunity to have an impact in a technologically data driven company quarterly hack days. volunteer time off and charitable donation matching. strong support for career growth, including mentorship programs, leadership training, access to conferences, and employee resource groups. great benefits package including health or vision or dental, unlimited pto, flexible schedule, 401k matching, travel reimbursement and more. if this sounds like something you would like to be part of, we d love for you to apply don t worry if you think that you don t meet all the qualifications here. the tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience. while this position can be remote, numerator is only able to hire in many, but not all, states and provinces. in certain cases, if you are not located in a specific area where numerator is able to hire, you may not be eligible for employment. we are an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.","['sql', 'analytical skills', 'databases', 'statistics', 'python', 'tableau', 'machine learning', 'data products', 'scripting', 'data visualization', 'data science', 'dashboards', 'modeling', 'analytics', 'data analysis', 'bespoke', 'algorithms', 'r']","['sql', 'python', 'databases', 'tableau', 'predictive', 'r']","['analytical skills', 'machine learning', 'statistics', 'data products', 'scripting', 'data visualization', 'data science', 'dashboards', 'modeling', 'analytics', 'data analysis', 'bespoke', 'algorithms']","['law', 'environment', 'metrics', 'marketing', 'retail', 'customer value', 'client services', 'market research', 'quality', 'employee resource groups', 'consulting', 'compensation', 'external clients']"
2,3,Radar E/W Scientists,"radare or w scientists, ottawa canada remote work in canada is available permanent, full time with over 45,000 employees, leonardo is a global technology organisation and a key player in the international defence and security market. leonardo canada electronics is expanding and we have an immediate need for several key resources to support the next phase of our growth. we offer a competitive compensation package and a work environment that supports, encourages and challenges its employees to grow personally. for additional information on leonardo, please visit our website at or en we have exciting permanent opportunities for radar e or w scientists spectrum would be an asset to actively work on optical systems modelling, design, analysis and signal processing of sensor data. responsibilities developing physics based ecm and ircm design, testing and customer support of our products models to be integrated within our sea, air, and land simulators enhancing our software architecture products to meet current and future demands developing interfaces between our products and external applications test and develop equations and algorithms written in matlab, simulink, and c or c create and maintain documentation for in house and end user applications become subject matter experts in ew with a focus on eo or ir and uv algorithms, image exploitation processing and target tracking research military sensor, weapon and ecm systems and develop input data sets that will configure the corresponding product models to match those real world systems provide ew analysis services to defence related customers education bachelor s degree or higher, from an accredited university in an appropriate engineering field such as electrical engineering or engineering physics with courses in in control systems, radar systems or optical systems theory. general knowledge experience in order to be successful customer support technical documentation writing real system development and or or modeling and simulation real system development and or or hardware or software in the loop simulation and or or test and integration developing and testing software modules in matlab or simulink, work with c or c java chaff, flare, dircm, hyperspectral imagery, ircm data classification assets master s or phd degree in a related field of study ircm or ecm or threat system design and analysis advanced knowledge of image and signal processing guided weapon systems aerospace subsystems cyber warfare artificial intelligence or machine learning control theory target tracking electromagnetic wave propagation knowledge of verification and validation concepts practical experience with standard software test and evaluation tools. active canadian secret security clearance personal attributes excellent communication skills, team player with the drive and commitment toward maintaining high standards ability to produce clear concise documentation. security clearance it is a condition of employment that the successful candidate receive a secret level security clearance. to obtain such a clearance, the candidate must be either a canadian citizen or permanent resident of canada must have lived in canada continuously for the past 10 years not have a criminal record must be able to obtain a canadian industrial security clearance to nato secret level must be eligible for controlled goods regulations program government clearances. job type full time, permanent apply if your qualifications meet the job description and related requirements, we d love to hear from you please submit your application today special needs of candidates with disabilities will be accommodated. successful candidates must fulfil requirements for canadian controlled goods program and canadian security clearance. leonardo supports the principles of employment equity and is an equal opportunity employer. please apply to this position as indicated. visit us at https or or leonardocompany.ca or","['system development', 'https', 'data classification', 'c', 'documentation', 'simulink', 'electronics', 'java', 'interfaces', 'software', 'physics', 'integration', 'software architecture', 'electrical engineering', 'machine learning', 'testing', 'artificial intelligence', 'hardware', 'algorithms', 'matlab', 'radar', 'signal processing', 'technical', 'security', 'system', 'modeling']","['system development', 'https', 'c', 'documentation', 'simulink', 'hardware', 'electronics', 'control systems', 'java', 'matlab']","['software architecture', 'interfaces', 'electrical engineering', 'signal processing', 'radar', 'machine learning', 'software', 'physics', 'testing', 'security', 'artificial intelligence', 'technical documentation', 'integration', 'modeling', 'algorithms']","['validation', 'environment', 'subject matter experts', 'land', 'education', 'regulations', 'design', 'government', 'compensation', 'aerospace', 'customer support']"
3,5,Research & Analytical Director - Data Scientist,"pink triangle press is looking for a research analytics director to lead the newly created analytics team. as part of the growth team, the research analytics director supports the evaluation and improvement of profitability and customer satisfaction for ptp s products . they also align and direct the management, development and integration of data analytics and business intelligence necessary for supporting the mission, vision strategies, objectives and goals of ptp. as a newly created department the role will require to work partly on strategies and partly on day to day analytics. the role has one analyst as a direct report. due to covid 19 guidelines, this role is currently 100 remote or work from home until further notice. expectations are that this person will work from the toronto office when in office working is allowed. all interviews will be conducted virtually. provide management visibility into data driven, actionable insights that inform ptp s strategic direction and kpis provide thought leadership and act as a subject matter expert in the designing and recommending of appropriate analytical approaches and methodology in addressing key issues within the organization determine the adoption of suitable tools that drive innovation and create advantage for ptp support the slt in making strategic, data driven decisions in regard to existing, new products, customer segments, investments define the business intelligence needs and analytics tools requirements across ptp lead measurement framework development and defines the business kpis drive and oversee initiatives to meet and exceed performance expectations, key metrics and enable overall profitability of ptp assess risks of growth opportunities as well provide analytics that will position the organization for dynamic growth stay informed and keep up with the latest industry and customer trends and best practices to improve ptp s competitiveness in its markets proactively monitor market trends and inform the leaders of the specific areas that will impact the competitiveness of ptp s brands anticipate business and research trends, understand the big picture but also the nuances of the business and research oversee the research function utilizing a number of methods surveys, focus groups and usability research to collect and analyze customer behaviour and feedback, and provide recommendations based on the analysis analyze ptp products to maximize profits, audition growth and customer satisfaction work with the product owners to establish analytics framework to collect data regarding product usage, and come up with recommendations how the usage of the product can be improved establish user feedback loops to evaluate product updates and feature adoption work with the marketing team to establish analysis frameworks for media buying and traffic generation patterns to maximize product usage and profits evaluate customer behaviour and buying patterns or models use analysis to identify opportunities for revenue growth direct structured testing programmes of ux and persuasion for new and existing products to increase profitability oversee ptp s data collection and design strategy to improve on data collection and data management develop insights and analytics, marketing technology roadmaps, identify marketing technology relevant for insight, establish key milestones and deliverables improve data collection and build or maintain our source of truth ensure that data is organized in a way that is easy to access and understand work with departmental leaders to ensure consistent data collection strategies across ptp manage development of audience insight experience 5 10 years of analytics management experience in a digital environment bachelor s degree in statistics, mathematics or computer science ability to quickly understand the data needs of various departments knowledge of reporting tools or dashboards advanced knowledge in sql, python or r deep technical background in analytics, applied data science, and reporting spanning across areas such as marketing attribution, experimentation, optimization techniques, data engineering architecture, statistics modeling and behavioral analytics extensive experience in measuring online and offline marketing strategy using various methodologies such as incrementality, attribution and cross channel interaction strong understanding on how the data should be captured, stored and structured in data warehousing environment demonstrated track record of successful analysis of online customer behaviour note that the right person for this role will be comfortable working with and around sexually explicit products and material. if this job sounds like it s for you, please apply come work with us we re an awesome organization that makes a difference, works hard, and still knows how to have fun our company founded in 1971 to advance the struggle for sexual liberation, pink triangle press is canada s leading lgbt media organization. we publish xtramagazine.com, and we also operate the gay adult dating website squirt.org, the gay dating app guy spy and have produced a number of television projects, including the travel show bump and the gayest show ever. our culture we believe in flexibility, and the celebration of individuality here at ptp and we think our organizational culture reflects that we have a casual dress code, a friendly atmosphere, and where the position permits we have flexible hours. we believe in being good at what we do, and working hard but that fun can be had along the way. we have an attractive benefits package, an employee and family assistance program, and a company matched pension plan. you do not need to be a part of the lgbt community in order to work here allies are absolutely welcome to apply. ptp is committed to employment equity, and to providing a fair and equitable work environment. we encourage applications from women, aboriginal people, those living with disabilities, and people who are visible minorities. we are a trans inclusive organization. ptp is committed to ensuring accessible services and communications to individuals with disabilities. once an applicant has been selected for an interview, requests for accommodation can be made at any stage of the recruitment process. applicants should make their accommodation needs known when contacted. due to the volume of submissions, only applicants selected for the next step in our recruitment process will be contacted. job types full time, permanent benefits casual dress company events company pension dental care disability insurance employee assistance program extended health care flexible schedule life insurance paid time off vision care schedule 8 hour shift monday to friday application question bachelor s degree in statistics, mathematics or computer science education bachelor s degree experience analytics management 5 years work remotely temporarily due to covid 19","['dashboards', 'attribution', 'data analytics', 'sql', 'python', 'statistics', 'usability research', 'reporting', 'data science', 'analytics', 'integration', 'data engineering', 'data warehousing', 'testing', 'data collection', 'business intelligence', 'ux', 'computer science', 'mathematics', 'optimization', 'modeling', 'data management', 'r']","['sql', 'python', 'business intelligence', 'r']","['dashboards', 'usability', 'modeling', 'attribution', 'data analytics', 'statistics', 'reporting', 'data science', 'analytics', 'integration', 'data engineering', 'data warehousing', 'testing', 'data collection', 'ux', 'computer science', 'mathematics', 'optimization', 'methodology', 'data management']","['marketing strategy', 'environment', 'events', 'education', 'metrics', 'focus groups', 'marketing', 'material', 'design', 'insurance', 'customer satisfaction', 'surveys', 'adoption', 'investments', 'architecture']"
4,6,Bilingual Senior Data Scientist,"position summary the senior data scientist will serve as a technical reference for the core data science team in delivering analytically driven research projects for the group. the candidate will be able to demonstrate a proven track record in identifying and leading data science projects while delivering compelling business insights using cutting edge data science methods. the candidate will be instrumental to shaping air liquide r d data science perspectives on major business issues. your challenge at air liquide provide technical expertise to the team of data scientists and support end to end rigorous and creative analytics research process. ensure the flawless deployment and delivery of analytics solutions with demonstrated business performance and to the satisfaction of internal sponsors. lead the end to end development of scalable and production grade predictive models, artificial intelligence and machine learning solutions that can create proven business value for their respective entities. provide thought leadership to business executives and analytic leaders to develop a vision and roadmap for analytics across the air liquide group. build strong relationships with academic and business communities to build and maintain cutting edge expertise in analytics, artificial analytics and machine learning. present research findings to senior leadership both within and outside of air liquide who we are looking for required phd or master s degree in computer science, mathematics, physics, applied science, engineering or similar disciplines with demonstrated research capability. 8 years of relevant experience in an analytical function in the corporate world.. substantial experience with analytical tools and techniques and a proven track record on analytics projects solving business problems and or or improving bottom line. demonstrated ability to independently drive novel data driven research projects, from project ideation to full deployment. established network of thought leaders and recognized experts on leading edge tools and methods in artificial intelligence and machine learning. capacity to interface effectively with senior management and build business momentum around data analytics. programming experience in python. good communication skills in french and in english preferred understanding and or or past experience of the industrial or energy sectors is a plus. thank you for your interest in air liquide. please note that only shortlisted candidates will be contacted. for more information on our company, visit us online at scientifique senior des donn es r sum du poste le scientifique senior des donn es sera une r f rence technique pour l quipe core data science dans le cadre de la r alisation de projets de recherche pour le groupe ax s sur l analyse. vous serez en mesure de faire preuve d une exp rience av r e dans l identification et la direction de projets de science des donn es tout en fournissant des informations commerciales convaincantes l aide de m thodes de science des donn es de pointe. vous aurez un r le d terminant dans l laboration des perspectives de la science des donn es d air liquide r d sur des questions commerciales majeures. votre d fi chez air liquide fournir une expertise technique l quipe de scientifiques des donn es tout en soutenant un processus de recherche analytique rigoureux et cr atif de bout en bout. assurer le d ploiement et la livraison sans faille de solutions d analyse avec un rendement commercial d montr et la satisfaction des sponsors internes. diriger le d veloppement de bout en bout de mod les pr visionnels volutifs et de grande production, de solutions d intelligence artificielle et d apprentissage automatis qui peuvent cr er une valeur commerciale av r e pour leurs entit s respectives. fournir un leadership clair aux dirigeants d entreprise et aux leaders analytiques pour d velopper une vision et une feuille de route pour l analytique travers le groupe air liquide. construire de solides relations avec les communaut s acad miques et commerciales pour construire et maintenir une expertise de pointe en mati re d analytique, d analyse artificielle et d apprentissage automatis . pr senter les r sultats de recherches aux hauts dirigeants, tant l int rieur qu l ext rieur d air liquide. qui recherchons nous exigences doctorat or ma trise en informatique, math matiques, physique, sciences appliqu es, ing nierie ou dans des disciplines similaires avec une capacit de recherche av r e. minimum de 8 ans d exp rience pertinente dans une fonction analytique dans le monde de l entreprise. une bonne connaissance des outils et techniques d analyse et une exp rience av r e dans des projets d analyse visant r soudre des probl mes commerciaux et or ou am liorer les r sultats. capacit av r e g rer de mani re autonome des projets de recherche novateurs fond s sur des donn es, de l id ation du projet au d ploiement complet. r seau tabli de leaders d opinion et d experts reconnus sur les outils et m thodes de pointe en mati re d intelligence artificielle et d apprentissage automatis . capacit d interagir efficacement avec la haute direction et de cr er une dynamique commerciale autour de l analyse des donn es.. exp rience de la programmation sous python. bonne capacit de communication en fran ais et en anglais atout une compr hension et or ou une exp rience ant rieure des secteurs de l industrie ou de l nergie constitue un atout. merci de l int r t que vous portez air liquide. veuillez noter que seuls les candidats pr s lectionn s seront contact s. pour plus d informations sur notre soci t , visitez nous en ligne l adresse job types full time, permanent schedule monday to friday education master s degree experience analytical function 8 years python 5 years machine learning 8 years","['data analytics', 'python', 'machine learning', 'physics', 'business insights', 'artificial', 'data science', 'computer science', 'analytics', 'artificial intelligence', 'mathematics', 'core', 'programming', 'machine', 'r']","['programming', 'python', 'business insights', 'r']","['data analytics', 'machine learning', 'applied', 'physics', 'artificial', 'data science', 'computer science', 'analytics', 'artificial intelligence', 'mathematics', 'core', 'machine']","['research projects', 'business value', 'education']"
5,7,Machine Learning Engineer / Data Scientist,"catchy intro honestly, we ve been brainstorming this catchy intro for about 20 minutes and everything that we throw at the wall is either too serious, or just downright lame, with no authenticity behind it. which is absolutely hilarious, considering everyday terrasense strives for authenticity. so that s it. that s what you get. our not so super catchy, not super lame, but not super corporate intro. authentic. hey, come work here and help us on this journey. why work with us our two main products target the utilities and defense sectors. besides understanding how to use machine learning to predict maintenance for transmission lines, or how to take the metadata from two sensors and fuse them together, we actually do appreciate the soft skills too. we strive to foster a culture of success, innovation, respect, and did we mention authenticity that s right, if you hate what the cto is saying, we fully expect you to step up and tell him he s wrong . the product manager does all the time and she still hasn t been fired. what you would be doing... ... on the development team for our mist product, working to create and deploy aerial surveillance with artificial intelligence. the product will utilize edge computing, computer vision and deep learning algorithms. okay so we hope that you got this far and are slightly intrigued by our culture and what you would be doing. here comes the hard part. this role requires you to be a canadian citizen or permanent resident having resided in canada for at least 10 years as well as a criminal record and credit check. you will be required to work locally with flexibility on work hours. these are hard requirements with no negotiation, so please do not apply to this particular role if you don t meet these requirements. we will have other roles that come up without such stringent requirements, but there is no wiggle room on this one. qualifications excellent knowledge of python 2 years of experience in building and shipping great software experience with deploying ml on the edge or in the cloud strong knowledge of ml frameworks knowledge of computer vision models, frameworks, and tools eligible for security clearance and to work in canada bonus experience with docker, video analytics, and or or gui development a plus bonus networking and cybersecurity experience compensation competitive salary and stock options based on experience, competency and length of service 5 weeks paid vacation training and professional development allowance, and extended medical and dental beer tuesdays at our neighbourhood microbrewery non compensation considerations accountability we truly do work hard, play hard and expect everyone to self manage...meaning we don t track hours. flexibility if your best time to work is from 10pm to 2am then we want to support that so we try to enable team communication by committing to m th 10am 2pm office hours. the rest is up to you. job type full time schedule 8 hour shift","['deep learning', 'computing', 'python', 'machine learning', 'cybersecurity', 'sensors', 'software', 'computer vision', 'security', 'networking', 'metadata', 'artificial intelligence', 'analytics', 'rest', 'algorithms']",['python'],"['deep learning', 'computing', 'machine learning', 'cybersecurity', 'sensors', 'software', 'computer vision', 'security', 'gui', 'networking', 'metadata', 'artificial intelligence', 'analytics', 'rest', 'algorithms']","['utilities', 'transmission', 'surveillance', 'negotiation', 'compensation']"
6,9,Sr. Data Engineer,"numerator is a data and tech company bringing speed and scale to market research. headquartered in chicago, il, numerator has more than 2,000 employees worldwide. the company blends proprietary data with advanced technology to create unique insights for the market research industry that has been slow to change. the majority of fortune 100 companies are numerator clients. job description numerator is looking for a sr. data engineer who is a big data enthusiast and has a passion for working with an interesting robust set of data. in this role, you will work in our platform to help ensure that our data quality is flawless. as a company, we have millions of new data points every day that come into our system. you will be working with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our customers, on time. you will be using the latest cloud data warehouse technologies to build robust and reliable data pipelines. a major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and delivering to production. you will have a broad impact and exposure across numerator as you help build out and expand our technology platforms across several software products. this is a fast paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production. what you get to do develop expertise in the different upstream data stores and systems across numerator design, develop and maintain data integration pipelines for numerators growing data sets and product offerings collaborate with product and engineering teams to take requirements from prototype to production build data validation testing frameworks to ensure high data quality and integrity write and maintain documentation on data pipelines and schemas skills requirements what we are looking for 5 years of experience in building a data warehouse and data pipelines knowledge of software engineering best practices across the development lifecycle, coding standards, code reviews, source management, build processes, testing, and operations expert in sql, including advanced analytical queries, window functions, ctes and query optimization advanced proficiency in python experience administering a cloud data warehouse experience with etl tooling and data processing, and knowing how to transform data to meet business goals experience with schema design and dimensional data modeling knowledge of and experience implementing data security and governance best practices curious and interested in learning about the latest in data warehouse technology and willingness to mentor junior team members bs in mathematics, statistics, computer science, engineering, economics, physics, or other behavioral and or or equivalent quantitative science. nice to have amazon web services experience terraform and or or ansible for infrastructure deployment airflow experience building and monitoring dags, developing custom operators and using script templating solutions experience supporting production systems and developing on call or incident management playbooks ability to work with team members located in multiple geographies and time zones. what we offer you more data than you could imagine to play with data that matters and that is shaping the impact of billion dollar brands. brillant, motivated and passionate colleagues with whom to spend your time. an inclusive and collaborative company culture we work in an open environment while working together to get things done, and adapt to the changing needs as they come. market competitive total compensation package. volunteer time off and charitable donation matching. regular hackathons to build your own projects and work with people across the entire company strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups. great benefits package including health or vision or dental, exceptional maternity leave coverage, unlimited pto, flexible schedule, 401k or rrsps matching and much more. if this sounds like something you would like to be part of, we d love for you to apply don t worry if you think that you don t meet all the qualifications here. the tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience. while this position can be remote, numerator is only able to hire in many, but not all, states and provinces. in certain cases, if you are not located in a specific area where numerator is able to hire, you may not be eligible for employment. we are an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.","['schemas', 'coding standards', 'numerator', 'documentation', 'big data', 'templating', 'terraform', 'sql', 'python', 'statistics', 'data processing', 'software', 'physics', 'data', 'integration', 'pipelines', 'amazon web services', 'data pipelines', 'testing', 'production systems', 'data quality', 'algorithms', 'ansible', 'airflow', 'economics', 'security', 'schema', 'computer science', 'mathematics', 'optimization', 'modeling', 'etl']","['terraform', 'sql', 'python', 'amazon web services', 'pipelines', 'data', 'documentation', 'big data', 'production systems', 'data quality', 'ansible', 'airflow']","['schemas', 'coding standards', 'and', 'templating', 'statistics', 'data processing', 'software', 'physics', 'quantitative science', 'data', 'integration', 'data pipelines', 'testing', 'algorithms', 'economics', 'security', 'schema', 'computer science', 'mathematics', 'optimization', 'modeling', 'script', 'etl']","['validation', 'incident management', 'environment', 'design', 'market research', 'employee resource groups', 'governance', 'compensation', 'law']"
7,10,Material Engineer/Scientist,"this is a unique opportunity to join the technical team of an early stage company to support the development of a novel implantable medical device and ensuring its readiness for early human use. the materials engineer or scientist will be responsible for conducting applied industrial research activities in accordance with an established quality management system. the materials engineer or scientist will provide subject matter expert input into device evaluations and pipeline projects that relate to metal and polymer material properties. the materials engineer or scientist will work in a fast paced and dynamic environment where taking initiative and collaborating cross functionally are critical for success. key responsibilities act as a key contact for material characterization, structure, properties, processing and performance perform and evaluate hands on processing of materials including heat treatment, solvent cleaning, and sterilization develop and validate test methods related to material properties collaborate with multiple parties to execute testing according to standardised testing methods for material evaluation compile, analyze and present technical data to provide objective traceable evidence of material properties for device design history file compilation completion of technical reports related to materials evaluation assist in the review of manufacturing processes for impact on material properties contribute to failure mode and effects analysis of device and accessories by evaluating applicable risk scenarios and degradation mechanisms with potential mitigation tasks assist with other product development documentation activities. education and experience requirements bs in materials engineering, biomaterials, materials science, or polymer science minimum of 2 years of materials science industrial experience hands on experience with material testing equipment such as tensile testing, hardness, corrosion, spectroscopy , thermal analysis , thermogravimetric analysis , microscopy , resorption or hydrolytic degradation, etc. experience with new product development preferred. additional skills working knowledge of iso 9001 and or or iso 13485 is preferred. excellent documentation, communication and interpersonal relationship skills. ability to adhere to quality management systems requirements. ability to manage competing priorities in a fast paced environment. experience with statistical analysis and related software appreciated. proven expertise in usage of ms office suite. candidates must reside in or relocate to calgary ab and be legally entitled to work full time in canada. job types full time, permanent salary 50,000.00 100,000.00 per year benefits on site parking paid time off schedule monday to friday covid 19 considerations fluid biotech inc. is following all applicable city, provincial and facility safety requirements. ability to commute or relocate calgary, ab education bachelor s degree work remotely no","['software', 'testing', 'compilation', 'documentation', 'thermal analysis', 'spectroscopy', 'statistical analysis', 'technical reports']",['documentation'],"['software', 'testing', 'management systems', 'technical', 'compilation', 'thermal analysis', 'spectroscopy', 'statistical analysis', 'technical reports']","['sterilization', 'environment', 'materials science', 'education', 'characterization', 'manufacturing processes', 'iso 9001', 'material', 'iso 13485', 'design', 'materials', 'materials engineering', 'evidence', 'product development', 'corrosion', 'biomaterials', 'industrial research']"
8,11,Business Intelligence Data Engineer,"about blackline blackline safety is a world leader in the development and manufacturing of wirelessly connected safety products. we offer the broadest and most complete portfolio available in the industry. our products are designed to save lives and we monitor personnel working alone in populated areas, complex indoor facilities, and the remote reaches of our planet. blackline s products are used to keep people safe in the event of falls, missed check ins, person downs, and exposure to explosive or toxic gas. our design, development, sales, marketing, support, and production are all performed in house at our headquarters in calgary, ab. blackline safety is a publicly traded company . blackline safety is looking for a data engineer to help build and drive our blackline analytics and blackline vision platform. we have a world class connected safety system and we are building a data analytics and data science platform to match it. who are you you believe big data helps businesses solve real world problems. you have an aptitude for engineering and manipulating various forms of data frameworks including but not limited to data warehousing, modeling, analytics, and integrations from various data sources. you are not bound to a single tool or platform and can solve problems in creative ways. you are proficient in different computing languages such as sql, python, dax and aspire to learn alternate ways of resolving issues. you trust in data driven problem solving and believe visualizing large datasets is a necessity to achieve that. you like to explore datasets to find insights that nobody else sees. you can communicate these ideas through visualizations. you are team oriented, self motivated, creative, and excited to find answers to questions that the answer might not be obvious without going through large amounts of data. what will you do you have an ability and desire to work in our collaborative environment open team room, pair programming and fluid interactions with all products and operations teams. you will be a part of a high performing team that is focused on building solutions utilizing various approaches including agile capable of digesting real time feedback and working smartly to advance blackline analytics and blackline vision platforms. you are self driven, need minimal supervision and are comfortable pushing your own projects and getting things done. you will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flows and collection for analytics and data science teams. the pipeline needs to be scalable, precise, repeatable, secure, and accurate. you will work with some of the largest and most varied data sets in the wireless industry. you will expand and develop the blackline analytics platform alongside other data analysts and data scientists to make data driven decisions, build innovative data products and roll out advanced analytics. your contribution will help us increase internal efficiencies and evolve our products and services by leveraging large and diverse datasets generated by customers from around the world. the data architecture and framework and the technologies include iot, ecs, fargate, rds mysql, redshift, spark, emr, kinesis , lambda, datalakes, deltalakes, event bus, datadog, cd or ci pipelines on codepipeline and codebuild, cloudformation, alp, python, java, and more. requirements 3 years of experience in a data engineer role, who has attained a graduate degree in computer science, statistics, informatics, information systems, or another quantitative field. experience working with apis, integrations into reporting documents, building api endpoints for real time reporting advanced working sql knowledge and experience working with relational databases, query authoring , postgres, json as well as working familiarity with a variety of databases. experience building and optimizing big data data pipelines, architectures, and data sets. experience with big data tools hadoop, spark, kafka, datadog, eventbus, aws cloud services ec2, emr, rds, redshift, api calls, api generation hands on experience with cloud data warehouse and big data technologies . build processes supporting data transformation, data structures, metadata, dependency, and workload management. a successful history of manipulating, processing, and extracting value from large, disconnected datasets using etl or elt, matillion, ssis, trefecta, etc and integrating data from silos to a master data source working knowledge of message queuing, stream processing, and highly scalable big data data stores optional knowledge of netsuite, other 3rd party software integrations knowledge of satori reporting or any other turnkey integrative reporting knowledge of power platform operations, query, flow and bi and integrations knowledge of master data management blackline safety offers an exciting high growth environment an experienced, dynamic, and motivated team supportive, challenging, and collaborative work competitive salary and vacation medical, dental, and drug benefits company stock purchase plan with matching contributions our clients depend on blackline safety to monitor the wellbeing of their employees at work you can help to make a difference. come work with blackline safety in an exciting, fast paced work environment. job types full time, permanent schedule monday to friday education bachelor s degree experience building api endpoints for real time reporting 3 years building and optimizing big data data pipelines 3 years big data tools 3 years data engineering 3 years advanced sql knowledge and relational database 3 years work remotely temporarily due to covid 19","['computing', 'databases', 'emr', 'ci', 'big data', 'modeling', 'alp', 'mysql', 'java', 'data analytics', 'sql', 'python', 'statistics', 'cd', 'software', 'reporting', 'json', 'data science', 'queuing', 'analytics', 'programming', 'data', 'aws', 'netsuite', 'pipelines', 'data engineering', 'data warehousing', 'data pipelines', 'relational databases', 'data transformation', 'data products', 'iot', 'stream processing', 'metadata', 'workload', 'master data management', 'master data', 'cloud services', 'data structures', 'bi', 'resolving issues', 'dax', 'datasets', 'information systems', 'api', 'hadoop', 'computer science', 'ecs', 'ssis', 'etl']","['databases', 'emr', 'big data', 'rds', 'emr bus', 'alp', 'java', 'mysql', 'datadog', 'sql', 'python', 'json', 'programming', 'aws', 'netsuite', 'pipelines', 'iot', 'master data', 'big data data', 'bi', 'hadoop', 'api', 'ecs', 'eventbus', 'ssis']","['computing', 'pair', 'ci', 'data analytics', 'statistics', 'cd', 'software', 'reporting', 'data science', 'queuing', 'analytics', 'data', 'data engineering', 'data warehousing', 'data pipelines', 'relational databases', 'data transformation', 'data products', 'stream processing', 'metadata', 'master data management', 'cloud services', 'data structures', 'resolving issues', 'dax', 'datasets', 'information systems', 'computer science', 'modeling', 'etl']","['gas', 'environment', 'education', 'marketing', 'design', 'sales', 'forms', 'getting things done', 'manufacturing', 'architecture']"
9,12,"Developer, Data Science","req id 295813 at bell, we do more than build world class networks, develop innovative services and create original multiplatform media content we advance how canadians connect with each other and the world. if you re ready to bring game changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the bell team. bell is making unmatched investments in our world leading broadband fibre and wireless networks because we know they re the backbone of the products and services our customers love. if you re excited about transforming the way people connect, our network team is the right place for you. artificial intelligence is among the fastest growing business and technology disciplines. specifically in telecom, there are great opportunities to utilize machine learning and advanced analytics solutions to evolve network planning and operations and prepare for the future network. bell s network big data ai team is focused on utilizing machine learning, big data and advanced analytics technologies to enable bell s future ai powered networks. this is a rare opportunity for a motivated data and analytics professional to join a fast growing team of machine learning experts to design, develop data solution to support the entire bell network community. key responsibilities lead a team of data scientists and ai or ml developers in the design, development and deployment of ai enabled solutions to address complex business problems work with network big data ai coe team members, network engineering, operations as well as other bell businesses to understand and analyze business needs review ai or ml solutions developed by team members to ensure they are efficient, scalable and resilient refine ci or cd processes related to ai or ml solutions explore new sources of information to uncover new business opportunities at all levels of the business exercise leading edge analytics skills to identify previously undetected patterns of behavior or correlations between related datasets work with and present to all management levels maintain and expand knowledge of data systems and current technology through training opportunities work in an agile environment and contribute to the improvement of our development processes required competencies a bachelors or master s degree in computer science, math, applied science or engineering, or equivalent minimum 2 years experience leading a devops team minimum 5 years experience with machine learning and artificial intelligence algorithms and approaches minimum 4 years experience designing, documenting and presenting communicating ml solutions to complex business problems excellent documentation and communication skills. must be able to clearly communicate with a wide range of roles from hands on developer to senior executive team ability to assist other ml developers with designing, developing and reviewing their solutions. familiarity working with nosql databases and unstructured or semi structured data experience working with ci or cd tools and approaches experience with kubernetes or other container orchestration systems experience with jupyter notebook, git, and other software management tools advanced skills with sql and database systems such as mysql, mariadb, oracle, sql server, teradata, hive, impala skills with multiple analytical tools such as microstrategy, r, python, scala, tableau highly analytical skills and ability to work with large and complex technical data sets ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations knowledge of, and preferably experience with, big data and or or software development, and or or developing visualization tools ability to work with a team towards common goals ability to quickly learn new programming languages and frameworks able to manage multiple projects and priorities self starter who is comfortable working with and presenting to all management levels preferred competencies statistics and math background experience in telecom or it is a strong asset li ms1 tech employeereferralprogram bilingualism is an asset adequate knowledge of french is required for positions in quebec. additional information position type management job status regular full time job location montreal canada ontario mississauga canada ontario ottawa canada ontario toronto canada quebec montreal canada quebec verdun application deadline 07 or 09 or 2021 please apply directly online to be considered for this role. applications through email will not be accepted. at bell, we don t just accept difference we celebrate it. we re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. we welcome and encourage applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process. for a confidential inquiry, simply email your recruiter directly or to make arrangements. if you have questions regarding accessible employment at bell please email our diversity inclusion team at created canada, qc, montreal bell, one of canada s top 100 employers.","['analytical skills', 'databases', 'visualization', 'tableau', 'ci', 'documentation', 'big data', 'hive', 'mysql', 'kubernetes', 'sql', 'agile environment', 'python', 'statistics', 'cd', 'scala', 'database systems', 'software development', 'analytics', 'data systems', 'r', 'nosql', 'jupyter', 'teradata', 'machine learning', 'analytical tools', 'artificial intelligence', 'algorithms', 'programming languages', 'network engineering', 'devops', 'datasets', 'git', 'computer science', 'mariadb', 'ai']","['fibre', 'kubernetes', 'jupyter', 'databases', 'sql', 'teradata', 'python', 'tableau', 'scala', 'programming languages', 'git', 'documentation', 'big data', 'mariadb', 'hive', 'mysql', 'nosql', 'r']","['analytical skills', 'visualization', 'ci', 'container orchestration', 'agile environment', 'software management', 'statistics', 'cd', 'database systems', 'software development', 'analytics', 'data systems', 'machine learning', 'analytical tools', 'artificial intelligence', 'algorithms', 'planning', 'network engineering', 'devops', 'datasets', 'computer science', 'ai']","['investments', 'microstrategy', 'design', 'metrics']"
10,13,"Advisor, Wireless Data Analytics & A.I.","req id 299656 at bell, we do more than build world class networks, develop innovative services and create original multiplatform media content we advance how canadians connect with each other and the world. if you re ready to bring game changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the bell team. bell is making unmatched investments in our world leading broadband fibre and wireless networks because we know they re the backbone of the products and services our customers love. if you re excited about transforming the way people connect, our network team is the right place for you. bell s wireless orchestration insights team is focused on utilizing big data, advanced analytics and machine learning technologies to enable bell s ai powered networks. this is a rare opportunity for seasoned data scientist to join our fast growing team of data engineers and scientists as we design and develop solutions to support the bell wireless community. job description as a member of the network big data team and reporting to the network big data manager for wireless, the advisor will play a leading role in the development of new intelligence insights on existing network and customer data. by working closely with our business partners you will establish detailed project deliverables and work with smes to profile data and integrate new data sets. your main goal will be to ensure data pipelines for analysis, intelligence, and reporting are delivered with the utmost quality and reliability. primary responsibilities lead a team of data engineers, data analysts, and data scientists, to deliver dashboards, reports, and advanced ai models that provide insights and support wireless engineering and operations domains help establish and maintain an operational support model for high availability production environments. provide technical guidance for off hour failures when required work directly with all stakeholders to prioritize projects and work with the development team to ensure reference architecture is respected at the tactical level work with subject matter experts to build project requirements documentation, and ensure that project scope is maintained and resources are used effectively oversee and participate in all aspects of big data solution delivery life cycle from analysis and data profiling to design, development, testing, delivery, and support work with analytics administrators and other teams to develop and follow standardized practices for delivering new products and capabilities using big data technologies and adapt as new tools and systems are developed create formal written deliverables and other documentation, and ensure designs, code, and documentation are aligned with enterprise direction, principles, and standards provide technical input to assist in the development of strategic business cases used at management and executive levels for big data evolution work on analytics projects as a developer when required basic qualifications bachelor in computer science, computer engineering, electrical engineering, management information systems, or computer information systems is required must be proficient in sql or hiveql and other query languages experience with microstrategy and other data visualization tools played a leading role in the delivery of multiple end to end projects using hadoop experience working with traditional etl tools data warehousing architectures knowledge of predictive analytics techniques detail oriented and able to manage a constantly changing environment. strong personal leadership and collaborative skills, combined with comprehensive, practical experience and knowledge in end to end delivery of big data solutions experience leading project teams or management experience strong communication, technology awareness, and capability to interact work with senior technology leaders is a must ability to clearly communicate complex technical ideas, regardless of the technical capacity of the audience strong inter personal and communication skills including written, verbal, and technology illustrations. good knowledge on agile methodology and the scrum process delivery of high quality work, on time and with little supervision critical thinking or analytic abilities preferred qualifications experience in wireless telecommunications systems and data those systems produce knowledge of nokia, ericsson, samsung, cisco, etc for ran and core operations coding applications using hadoop components hdfs, hive, impala, sqoop, flume, kafka, confluent kafka, streamsets, hbase, etc. designing and deploying solutions big data solutions in public cloud environments demonstrated capability with business development in big data infrastructure business preferred skills bilingual who has the capacity to adapt his communication to most of the situations and audience. proficient in planning his communications, facilitating a meeting or workshop able to proactively plan his or her work over multiple timeframes week months year and juggle multiple priorities and deliver as per commitments able to plan and execute complex tasks without supervision, identify potential roadblocks and mobilise resources to remove them and achieve goals able to identify and analyze complex problem, identify root cause, provide detailed description and plan, design and deliver workaround or solution capable to evaluate without supervision the effort time required to complete a deliverable and or or task thru collaboration, teamwork, honesty, commitment and respect comfortable interviewing non technical people to gather or discuss requirements wireless or telecom operations and engineering business knowledge including basic understanding of radio access, core network and value added services technologies and configurations. li ms1 tech indeed employeereferralprogram bilingualism is an asset adequate knowledge of french is required for positions in quebec. additional information position type management job status regular full time job location montreal canada ontario mississauga canada ontario toronto canada quebec montreal canada quebec verdun application deadline 07 or 09 or 2021 please apply directly online to be considered for this role. applications through email will not be accepted. at bell, we don t just accept difference we celebrate it. we re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. we welcome and encourage applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process. for a confidential inquiry, simply email your recruiter directly or to make arrangements. if you have questions regarding accessible employment at bell please email our diversity inclusion team at created canada, qc, montreal bell, one of canada s top 100 employers.","['high availability', 'big', 'data infrastructure', 'dashboards', 'data visualization', 'data profiling', 'root cause', 'documentation', 'big data', 'hive', 'sql', 'reporting', 'coding', 'analytics', 'customer data', 'data warehousing', 'electrical engineering', 'machine learning', 'big data solutions', 'data pipelines', 'testing', 'computer engineering', 'scrum', 'sqoop', 'hadoop', 'information systems', 'computer science', 'public cloud', 'operational support', 'telecommunications', 'etl', 'ai']","['fibre', 'sql', 'high availability', 'sqoop', 'hiveql', 'hadoop', 'hive', 'public cloud', 'documentation', 'big data', 'telecommunications']","['dashboards', 'data visualization', 'data profiling', 'root cause', 'reference', 'reporting', 'requirements', 'analytics', 'customer data', 'data warehousing', 'electrical engineering', 'machine learning', 'data pipelines', 'testing', 'computer engineering', 'scrum', 'planning', 'predict', 'information systems', 'computer science', 'query languages', 'solution', 'methodology', 'operational support', 'etl', 'ai']","['business development', 'subject matter experts', 'environment', 'business knowledge', 'design', 'microstrategy', 'investments', 'architecture']"
11,15,Data Engineer,"data engineer are you a go getter who has a passion in building next gen data solutions for business problems are you a big fan of simplification and automation one of our top clients, the largest e commerce investor is looking for a data engineer to join their smart team to build the data driven app for early stage founders. 100 remote opportunity job description what we look for 5 years of experience as a data engineer. able to architect and scale data integrations from third party api docs independently, extracting the right business value for the vision and roadmap. interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes. comfortable working in server and database environments that are changing constantly. comfortable in a fast pace, relational databases and schemas involving time series. skills and interest in python, sql, snowflake, kubernetes, and pipeline management or orchestration tools , expert in coding. great communication skills and fast paced learning comfort working in a high growth, constantly changing environment. heavy bias towards action. ability to solve problems end to end on your own. implement ideas and experiments on your own with minimal support. have a strong business sense, you can foresee potential issues and solve them quickly. responsibilities you will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development. collaborate with all functions, ranging from core engineering team to data science team to the marketing team. you be in constant communication with the team to understand what features of the platform need to be built out and solve bug fixes when necessary. you will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself. if you are interested in this opportunity, please apply for this position with your updated resume. tor123","['kubernetes', 'sql', 'python', 'schemas', 'relational databases', 'data products', 'data solutions', 'api', 'data science', 'snowflake', 'automation']","['kubernetes', 'sql', 'python', 'go getter', 'api', 'snowflake']","['schemas', 'relational databases', 'data products', 'data solutions', 'data science', 'automation']","['environment', 'e commerce', 'marketing', 'business value', 'design', 'architecture']"
12,16,Data Scientist & Analyst (PhD Required),"please apply via the company hr page https or or or careers.php data scientist we are a data driven company with a collegial atmosphere looking for team members who can do great work for application in the algorithmic trading industry. our ideal candidate is a recent or soon to be phd graduate with experience in an academic or post doc research workplace looking to apply their capabilities to the real world. our approach is to train successful candidates about our industry, markets and products, as such we are looking for people seeking their initial entry position in the financial markets. about you you are driven by intellectual challenges, curiosity, and solving problems. you continuously seek to understand new and better approaches to analyze and interpret dirty data to improve understanding and reporting of investment results. you love to see your work put into practice. for individuals currently living outside of vancouver, we offer relocation assistance. what you ll do initial significant project is enhancing the understanding and reporting of investments returns developing and bringing research projects to completion identifying timely and unique data sets, exploring underlying data drivers, and developing understanding, quantities and reporting for use in an existing trading system what you bring required ph.d. in mathematics, physics or related fields in quantitative disciplines with a masters in the hard sciences highly analytical, keen attention to detail innate curiosity and an exceptional critical thinker who is results oriented demonstrated expertise in statistics and mathematical modelling strong communications skills thrive in a performance based environment require excellence of yourself and in the work you produce nice to have experience participating in national or international math, physics or computer science competitions is strongly preferred strong experience with python, c , r and kdb and coding concepts legally entitled to work in canada please apply via the company hr page https or or or careers.php data scientist job type full time salary 100,000.00 110,000.00 per year additional pay bonus pay benefits casual dress dental care disability insurance discounted or free food extended health care flexible schedule life insurance paid time off rrsp match vision care schedule monday to friday education doctoral degree work remotely no","['https', 'python', 'statistics', 'physics', 'reporting', 'c', 'computer science', 'mathematics', 'kdb', 'php', 'r']","['https', 'python', 'c', 'php', 'r']","['statistics', 'physics', 'reporting', 'computer science', 'mathematics', 'algorithmic']","['research projects', 'environment', 'education', 'trading', 'financial markets', 'investments', 'hr', 'insurance']"
13,18,Junior Data Scientist,"reporting to the technical manager, digital products, the junior data scientist works as part of a team to analyze structured and unstructured data, model complex problems, and identify opportunities for process and product optimization by using statistical, algorithmic, mining, and visual techniques. this role assists in developing machine learning predictive and prescriptive analytics models through the innovative understanding and use of large data sets and the verification of effectiveness to improve clinical processes and patient outcomes. the junior data scientist supports providence health care strategic priorities by understanding the clinical, financial, and operational issues to be solved and working closely with stakeholders, clinical and technical experts, and functional teams to leverage knowledge, interpret outputs, deploy solutions, and provide actionable insights. the role also assists in developing a solid and sustainable machine learning foundation and competency for phc. skills knowledge of supervised machine learning, decision trees, and logistic regression. display comprehensive understanding of, and skills using, statistical and data mining techniques such as glm or regression, random forest, boosting, trees, text mining, network analysis, simulation, scenario analysis, and clustering analysis. demonstrated ability to perform analytical functions and transform database structures including creating datasets and writing computer code to execute complex queries using statistical computer languages such as python, r, and sql. demonstrated proficiency working with large volumes of data across multiple servers using distributed data or computing tools such as hadoop, spark, mysql, aws, etc. demonstrated proficiency working with both relational and non relational databases . demonstrated understanding of data privacy, security and related tools such as anonymization and encryption demonstrated ability to use web services such as redshift, s3, digitalocean, etc. demonstrated skills in using data visualization tools and to visually present complex data to stakeholders for consideration. demonstrated skills in knowledge synthesis and translation activities including working with and sorting and manipulating unstructured data from different platforms. excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non technical partners and to communicate to multiple audiences using data storytelling and through graphics. demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building. strong analytical, critical thinking, and evaluation skills to discern and help solve the important problems facing health care, to identify new ways to leverage our data, and to direct efforts in the right direction. education a masters degree in mathematics, statistics, computer science, engineering or other quantitative degree is required plus three years experience working with large datasets and machine learning models including experience using statistical and data mining techniques, and distributed data or computing tools writing computer code querying databases and using statistical computer languages, or an equivalent combination of education, training and experience. duties 1. assists in transforming data into critical information and knowledge by working as part of the digital products team and with clinical management and staff, project or program managers, and members of the health informatics team to develop and implement ml models. uses these advanced ml models to identify patterns, trends, and opportunities to assist in making predictions or reducing workload that will have a significant impact across various clinical domains within phc. 2. identifies, cleans, and integrates large sets of structured and unstructured datasets from disparate sources for use in ml models and products. enhances data collection procedures to include information that is relevant for building advanced ml models. provides input to applications, databases, and systems used to assess study data quality. 3. works as part of the digital products team to use advanced ml processes to convert data from non functional forms, such as scanned image text, to functional forms ready for use in further ml models. 4. assists in developing predictive and prescriptive analytic models in support of the organization s clinical and business initiatives and priorities by working as part of the digital products team to apply advanced statistical and computational methods and innovative use of data, collaborate with developers in the construction of analytic models, and maintain detailed project status plans to achieve ml development cycle timelines and avoid development delays. 5. reviews clinical data at aggregate levels on a regular basis using analytical reporting tools to support the identification of risks and data patterns or trends. creates analytical reports and presentations to facilitate review and adoption of data driven choices. collaborates with project or program teams to address data related questions and to recommend potential solutions. 6. works with other members of the digital products team to assist with recommendations to management regarding strategic actions to maintain the ml development pipeline, analytic architectures, and life cycle, to avoid potential negative consequences and system failures, and to increase the positive impacts of ml systems. 7. works closely with clinical and management teams across phc to strategize, develop, and implement artificial intelligence products that translate into improved quality of care, clinical outcomes, reduced costs, temporal efficiencies, and process improvements. 8. identifies, engages, and collaborates with specific stakeholders as required for the development of ai products designed around phc s strategic priorities and clinical or business problems. assesses and implements improvements to ai products as needed and creates anomaly detection systems to track performance and data accuracy. 9. assists the digital product team members to communicate analytic solutions to management and shares ai product status throughout the various stages of the product lifecycle. 10. works with other members of the digital products team to support management in the development of strategies for scaling successful projects across the organization based on feedback from clinical or business clients and end users by maintaining project and other documentation, reviewing findings, and presenting analysis and actionable insights for further discussion and decision. 11. assists data scientists in fostering and developing a solid and sustainable machine learning foundation and competency for phc. assists management with the dissemination of successes and failures in an effort to increase analytics literacy and adoption across phc. 12. keeps up to date with the latest technology trends and methods by staying abreast of state of the art literature in the fields of operations research, statistical modeling, statistical process control and mathematical optimization. 13. performs other related duties as required.","['unstructured data', 'computing', 'dissemination', 'databases', 'data visualization', 'encryption', 'documentation', 'clinical data', 'graphics', 'mysql', 'trees', 'python', 'sql', 'statistics', 'logistic regression', 'reporting', 'decision trees', 'analytics', 'anomaly detection', 'aws', 'text mining', 'scenario analysis', 'data mining', 'servers', 'machine learning', 'relational databases', 'ai', 'data collection', 'data privacy', 'web services', 'artificial intelligence', 'statistical', 'data quality', 'process control', 'translation', 'datasets', 'hadoop', 'security', 'support management', 'computer science', 'mathematics', 'optimization', 'modeling', 'analytical', 'r']","['sql', 'python', 'databases', 'hadoop', 'documentation', 'aws', 'data quality', 'mysql', 'r']","['unstructured data', 'computing', 'dissemination', 'network', 'data visualization', 'encryption', 'clinical data', 'graphics', 'trees', 'statistics', 'logistic regression', 'reporting', 'decision trees', 'analytics', 'anomaly detection', 'text mining', 'scenario analysis', 'unstructured', 'data mining', 'servers', 'machine learning', 'relational databases', 'data collection', 'data privacy', 'web services', 'artificial intelligence', 'statistical', 'random', 'process control', 'translation', 'datasets', 'security', 'support management', 'computer science', 'mathematics', 'optimization', 'data patterns', 'modeling', 'analytical', 'ai']","['quality of care', 'environment', 'education', 'business initiatives', 'forms', 'presentations', 'art', 'operations', 'construction', 'adoption']"
14,19,Scientifique de recherche en génie environnemental/Environmental Engineering Research Scientist,"english follows scientifique de recherche en g nie environnemental opportunit d voluer au sein d une organisation mondiale milieu de travail innovateur offrant de nombreux d fis professionnels environnement de d veloppement technologique et d innovation postes bas s au saguenay lac st jean propos du poste nous sommes la recherche d un scientifique de recherche en g nie environnemental qui participera au d veloppement technologique en environnement au sein du centre de recherche et d veloppement arvida de rio tinto division aluminium. ce poste constitue une excellente occasion de d velopper et de proposer des solutions technologiques am liorant les plans d affaire des diff rentes usines de rio tinto. vous travaillerez selon un horaire de 5 jours de travail, 2 jours de cong et rel verez du chef de programme environnement, vous aurez les t ches suivantes participer l innovation dans le domaine du d veloppement technologique en environnement dans le secteur de l aluminium d velopper un r seau de contacts et coordonner des travaux avec des partenaires internes et externes ex cuter des projets de recherche et d veloppement visant la r duction de l empreinte environnementale de l industrie de l aluminium ex cuter des analyses de donn es complexes en utilisant des outils modernes des sciences des donn es assurer le leadership technique de plusieurs projets et superviser du personnel technique uvrant en laboratoire d finir les protocoles exp rimentaux en utilisant les meilleures pratiques d am lioration des affaires, en int grant les besoins des clients et en assurant le respect des r gles de sant , s curit et environnement propos de vous pour que votre candidature soit prise en consid ration, les exigences sont les suivantes baccalaur at or maitrise en g nie de l environnement, ou discipline du g nie connexe avec volet environnemental cinq dix ans d exp rience en milieu industriel, minier ou firme de g nie conseil expertise en traitement des rejets industriels et miniers atmosph riques, incluant la gestion des gaz effet de serre bonne ma trise des outils des sciences des donn es avec volet environnemental excellentes aptitudes en relations interpersonnelles, travail d quipe, communication et leadership d influence. ma trise compl te du fran ais ma trise avanc e de l anglais atouts exp rience en efficacit nerg tique connaissance des langages de programmation en sciences des donn es connaissance des outils lean et six sigma connaissance de la gestion de projet agile connaissance des proc d s de production de produits d aluminium votre lieu de travail le titulaire du poste sera amen travailler dans la r gion du saguenay et pourrait devoir se d placer occasionnellement au canada et l ext rieur du pays nous avons toujours su que rio tinto offre un milieu de travail formidable, et c est maintenant officiel r cemment, nous avons t nomm s parmi les meilleurs employeurs au canada notamment gr ce nos possibilit s de d veloppement et notre norme mondiale en mati re de cong parental. nous voulons avant tout offrir un milieu de travail stimulant, o nos employ s innovent afin de trouver de meilleures fa ons de produire les mati res qui servent fa onner le monde moderne, des t l phones intelligents jusqu aux immeubles en passant par les avions et les voitures, et les appareils m dicaux lectroniques. meilleursemployeurs. ce que nous offrons obtenez la reconnaissance de vos contributions, de votre capacit de r flexion et de votre travail acharn , et la satisfaction de savoir que vous avez aid le monde progresser. environnement de travail au sein duquel la s curit est toujours la priorit absolue occasions de d veloppement de carri re et aide la formation pour r aliser vos aspirations sur le plan technique et du leadership salaire de base concurrentiel tabli en fonction de vos comp tences et de votre exp rience, et programme incitatif annuel acc s en tout temps des programmes de sant or m dicaux favorables la famille, et des r gimes de retraite et d pargne r gime d actionnariat int ressant cong s pour divers motifs rabais pour les employ s propos de rio tinto l origine de chaque id e, de chaque innovation, de chaque petite chose qu on appelle progr s , il y a une personne un explorateur, un inventeur, un entrepreneur. un pionnier. depuis pr s de 150 ans, rio tinto est une entreprise de pionniers des g n rations d employ s audacieux partout dans le monde qui ont en commun la vision de produire des mati res essentielles au progr s humain. notre minerai de fer fa onne la silhouette des villes, de shanghai sydney. notre aluminium premier m tal certifi responsable au monde all ge les avions et les voitures. notre cuivre aide les oliennes produire de l nergie. notre bore contribue nourrir le monde et permet d explorer l univers. nos diamants c l brent les plus beaux moments de la vie. chaque voix compte nous sommes d termin s cr er un milieu inclusif o les employ s se sentent l aise d tre eux m mes. nous souhaitons de plus que chacun ait l impression que sa voix compte, que toutes les cultures sont respect es et que les points de vue, aussi vari s soient ils, sont non seulement bienvenus, mais galement essentiels notre succ s. nous nous traitons mutuellement avec quit et dignit , sans gard la race, au genre, la nationalit , l origine ethnique, la religion, l ge, l orientation sexuelle ou tout autre aspect distinctif. chez rio tinto, nous accueillons favorablement et encourageons les candidatures d autochtones, de femmes, de membres de la communaut lgbtq2s , de travailleurs g s, de personnes handicap es et de repr sentants d origines diverses. veuillez noter que vous devez r pondre toutes les questions de pr s lection pour que votre candidature soit prise en compte. environmental engineering research scientist opportunity to work for a global organization innovative work environment that offers many professional challenges technological development and innovation environment positions based in saguenay lac st jean about the role we are looking for an environmental engineering research scientist who will participate in technological development at the arvida research and development centre of rio tinto aluminium division. this role is an excellent opportunity to develop and propose technological solutions improving the business plans of rio tinto s different plants. you will work on a 5 day work schedule with 2 days off, and will report to the environment program manager. you will have the following duties participating in innovation in the field of environmental technology development in the aluminium sector. developing a contact network and coordinating work with internal and external partners. conducting research and development projects aiming at reduction of the aluminium industry s environmental footprint. performing complex data analyses by using modern data science tools. providing technical leadership for several projects and supervising technical staff working in the laboratory. defining the experimental protocols by using business improvement best practices, integrating the clients needs and ensuring that health, safety and environment regulations are respected. about you for your candidacy to be considered, the requirements are as follows bachelor s or master s degree in environmental engineering, or a related engineering discipline with an environmental component five to ten years experience in an industrial or mining environment or an engineering firm. expertise in treatment of industrial and mining atmospheric releases, including management of greenhouse gases. good proficiency in data science tools with an environmental component. excellent interpersonal relations, teamwork and influential leadership skills. complete proficiency in french . advanced proficiency in english . assets experience in energy efficiency knowledge of programming languages in data sciences knowledge of lean and six sigma tools knowledge of agile project management knowledge of production processes for aluminium products where you will be working the incumbent will be asked to work in the saguenay region and might have to travel occasionally in canada and outside the country. we have always known that rio tinto offers a tremendous work environment, and it s now official recently, we were named one of canada s best employers, particularly due to our development potential and our global standard for parental leave. above all, we wish to offer a stimulating work environment, where our employees innovate to find better ways of producing materials that serve to shape the modern world, from smartphones to buildings, including aircraft, cars and electronic medical devices. meilleursemployeurs. what we offer be recognized for your contribution, your thinking, and your hard work, and go home knowing you ve helped the world progress. a work environment where safety is always the number one priority career development education assistance to further your technical or leadership ambitions a competitive base salary reflective of your skills and experience with annual incentive program ongoing access to family friendly health and medical programs, pension and savings plans attractive share ownership plan leave for all of life s reasons exclusive employee discounts about rio tinto every idea, every innovation, every little thing the world calls progress begins with a first step, and someone willing to take it explorers, inventors, entrepreneurs. pioneers. for nearly 150 years, rio tinto has been a company of pioneers generations of people spanning the globe, all with the grit and vision to produce materials essential to human progress. our iron ore has shaped skylines from shanghai to sydney. our aluminium the world s first to be certified responsible helps planes fly and makes cars lighter. our copper helps wind turbines power cities and our boron helps feed the world and explore the universe. our diamonds help us celebrate the best parts of life. every voice matters at rio tinto, we particularly welcome and encourage applications from indigenous peoples, women, the lgbtqia2 community, mature workers, people with disabilities and people from different cultural backgrounds. we are committed to an inclusive environment where people feel comfortable to be themselves. we want our people to feel that all voices are heard, all cultures respected and that a variety of perspectives are not only welcome they are essential to our success. we treat each other fairly and with dignity regardless of race, gender, nationality, ethnic origin, religion, age, sexual orientation, or anything else that makes us different. please note, in order to be successfully considered for this role you must complete all pre screening questions.","['go', 'programming languages', 'data science', 'six sigma', 'screening', 'technology development', 'agile project management', 'smartphones', 'technical leadership']","['programming languages', 'data sciences', 'go']","['six sigma', 'data science', 'screening', 'technology development', 'agile project management', 'smartphones', 'feed', 'technical leadership', 'six']","['production processes', 'environment', 'environmental engineering', 'electronic devices', 'education', 'business improvement', 'development projects', 'environment gases', 'engineering research', 'energy efficiency', 'materials', 'aircraft', 'wind', 'turbines', 'buildings', 'regulations', 'environmental']"
15,21,"Scientist, Chemical Sciences","paraza pharma, inc. is a fast growing pharmaceutical research company offering a dynamic and collaborative work environment where scientific excellence, innovation and creativity are at the forefront. here, diversity, new points of view and a creative spirit are valued and considered as real assets. we provide our employees with ongoing support, training and development opportunities to expand their horizons while contributing to our shared passion for drug discovery. the medicinal chemistry and chemical development groups at paraza are seeking energetic, results oriented individuals with proven track records of success to join our dynamic teams. the successful candidate is expected to have extensive experience in modern organic synthesis. in addition, we are looking for individuals with abilities to analyze complex data sets, demonstrate sound decision making and analytical skills and able to provide creative proposals and solutions to advance on going projects. the candidate will be expected to work independently within a team structure, design and execute synthetic routes and troubleshoot when needed. the key responsibilities of the successful candidates include the following design and synthesis of novel target molecules as part of a medicinal chemistry team collection, analysis and interpretation of data sets. proposal of follow up experiments based on data trends troubleshoot and optimize reaction sequences participation in multidisciplinary team meetings prepare summary documents and presentations to chemistry and project teams minimum qualifications phd in organic, bioorganic or medicinal chemistry, with 0 2 years of post doctoral experience preferred qualifications comprehensive and up to date knowledge of synthetic organic chemistry demonstrated laboratory proficiency experience with the operation of standard laboratory instrumentation , and data analysis able to work within a team structure and effectively communicate with colleagues at all levels proven research track record as evidenced by a strong publication and or or patent record entrepreneurial spirit, and constantly seeking creative solutions to challenging problems excellent oral and written communication skills job types full time, permanent benefits casual dress company pension dental care disability insurance employee assistance program extended health care life insurance on site parking rrsp match stock options vision care schedule day shift monday to friday work remotely no covid 19 precaution remote interview process personal protective equipment provided or required social distancing guidelines in place sanitizing, disinfecting, or cleaning procedures in place","['data analysis', 'forefront', 'analytical skills', 'chemistry']",['forefront'],"['data analysis', 'analytical skills', 'chemistry']","['environment', 'presentations', 'design', 'team', 'drug discovery', 'insurance']"
16,22,"Associate Scientist, Chemical Sciences","paraza pharma, inc. is a fast growing pharmaceutical research company offering a dynamic and collaborative work environment where scientific excellence, innovation and creativity are at the forefront. here, diversity, new points of view and a creative spirit are valued and considered as real assets. we provide our employees with ongoing support, training and development opportunities to expand their horizons while contributing to our shared passion for drug discovery. the medicinal chemistry and chemical development groups at paraza are seeking energetic, results oriented individuals with proven track records of success to join our dynamic teams. the successful candidate is expected to have experience in modern organic synthesis with good laboratory skills and high productivity. the candidate will be expected to work independently within a team structure, design and execute synthetic routes and troubleshoot when needed. the key responsibilities of the successful candidate include the following synthesis of target molecules as part of a medicinal chemistry team troubleshoot and optimize reaction sequences participation in medicinal chemistry team meetings presentation of results to chemistry and project teams minimum qualifications msc in organic, bioorganic or medicinal chemistry preferred qualifications comprehensive knowledge of modern synthetic organic chemistry demonstrated laboratory proficiency in depth knowledge and hands on experience with a range of standard laboratory instrumentation, purification techniques , and data analysis proven research track record as evidenced by a strong publication and or or patent record excellent oral and written communication skills job types full time, permanent benefits assurance dentaire assurance invalidit assurance maladie compl mentaire assurance vie assurance vision options d achats d actions programme d aide aux employ s reer collectif stationnement sur place schedule du lundi au vendredi quart de jour work remotely no covid 19 precaution remote interview process personal protective equipment provided or required social distancing guidelines in place sanitizing, disinfecting, or cleaning procedures in place","['data analysis', 'forefront', 'chemistry']",['forefront'],"['data analysis', 'chemistry']","['purification', 'environment', 'drug discovery', 'design']"
17,23,Data Scientist,"reporting to the technical manager, digital products, the data scientist analyzes structured and unstructured data, models complex problems, and identifies opportunities for process and product optimization by using statistical, algorithmic, mining, and visual techniques. this role develops machine learning predictive and prescriptive analytics models through the innovative understanding and use of large data sets and the verification of effectiveness to improve clinical processes and patient outcomes. the data scientist supports providence health care strategic priorities by understanding the clinical, financial, and operational issues to be solved and working closely with stakeholders, clinical and technical experts, and functional teams to leverage knowledge, interpret outputs, deploy solutions, and provide actionable insights. the role also serves a key role in developing a solid and sustainable machine learning foundation and competency for phc. skills thorough knowledge of the principles, processes, procedures, and methods involved in data mining, data analysis, statistical methods, and machine learning. demonstrated skills in ai product design and the analysis of quantitative data for the purpose of creating actionable insights and measureable impact on organizational outcomes. proven ability to plan, organize, and coordinate ai product activities. demonstrated proficiency using machine learning methods and techniques and machine learning software packages, and in manipulating large datasets. knowledge of supervised machine learning, decision trees, and logistic regression. display comprehensive understanding of, and skills using, statistical and data mining techniques such as glm or regression, random forest, boosting, trees, text mining, network analysis, simulation, scenario analysis, and clustering analysis. demonstrated ability to perform analytical functions and transform database structures including creating datasets and writing computer code to execute complex queries using statistical computer languages such as python, r, and sql. demonstrated proficiency working with large volumes of data across multiple servers using distributed data or computing tools such as hadoop, spark, mysql, aws, etc. demonstrated proficiency working with both relational and non relational databases . demonstrated understanding of data privacy, security and related tools such as anonymization and encryption demonstrated ability to use web services such as redshift, s3, digitalocean, etc. demonstrated skills in using data visualization tools and to visually present complex data to stakeholders for consideration. demonstrated skills in knowledge synthesis and translation activities including working with and sorting and manipulating unstructured data from different platforms. excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non technical partners and to communicate to multiple audiences using data storytelling and through graphics. demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building. strong analytical, critical thinking, and evaluation skills to discern and help solve the important problems facing health care, to identify new ways to leverage our data, and to direct efforts in the right direction. education a masters degree in mathematics, statistics, computer science, engineering or other quantitative degree is required plus five to seven years experience working with large datasets and machine learning models including experience using statistical and data mining techniques, and distributed data or computing tools writing computer code querying databases and using statistical computer languages. duties 1. transforms data into critical information and knowledge by working with clinical management and staff, project or program managers, and members of the health informatics team to develop and implement ml models. uses these advanced ml models to identify patterns, trends, and opportunities to make predictions or reduce workload that will have a significant impact across various clinical domains within phc. 2. identifies, cleans, and integrates large sets of structured and unstructured datasets from disparate sources for use in ml models and products. enhances data collection procedures to include information that is relevant for building advanced ml models. provides input to applications, databases, and systems used to assess study data quality. 3. uses advanced ml processes to convert data from non functional forms, such as scanned image text, to functional forms ready for use in further ml models. 4. develops predictive and prescriptive analytic models in support of the organization s clinical and business initiatives and priorities by applying advanced statistical and computational methods and innovative use of data, collaborating with and guiding developers in the construction of analytic models, and maintaining detailed project status plans to achieve ml development cycle timelines and avoid development delays. 5. reviews clinical data at aggregate levels on a regular basis using analytical reporting tools to support the identification of risks and data patterns or trends. creates analytical reports and presentations to facilitate review and adoption of data driven choices. collaborates with project or program teams to address data related questions and to recommend potential solutions. 6. makes recommendations to management regarding strategic actions to maintain the ml development pipeline, analytic architectures, and life cycle, to avoid potential negative consequences and system failures, and to increase the positive impacts of ml systems. 7. works closely with clinical and management teams across phc to strategize, develop, and implement artificial intelligence products that translate into improved quality of care, clinical outcomes, reduced costs, temporal efficiencies, and process improvements. 8. identifies, engages, and collaborates with specific stakeholders as required for the development of ai products designed around phc s strategic priorities and clinical or business problems. assesses and implements improvements to ai products as needed and creates anomaly detection systems to track performance and data accuracy. 9. communicates analytic solutions to management and shares ai product status throughout the various stages of the product lifecycle. 10. supports management in the development of strategies for scaling successful projects across the organization based on feedback from clinical or business clients and end users by maintaining project and other documentation, reviewing findings, and presenting analysis and actionable insights for further discussion and decision. 11. works to foster and develop a solid and sustainable machine learning foundation and competency for phc. assists management with the dissemination of successes and failures in an effort to increase analytics literacy and adoption across phc. 12. keeps up to date with the latest technology trends and methods by staying abreast of state of the art literature in the fields of operations research, statistical modeling, statistical process control and mathematical optimization. 13. performs other related duties as required.","['unstructured data', 'computing', 'dissemination', 'databases', 'quantitative data', 'network', 'data visualization', 'encryption', 'documentation', 'clinical data', 'graphics', 'mysql', 'trees', 'python', 'sql', 'statistics', 'software', 'logistic regression', 'reporting', 'decision trees', 'analytics', 'anomaly detection', 'aws', 'text mining', 'scenario analysis', 'data mining', 'servers', 'machine learning', 'ai', 'relational databases', 'data collection', 'data privacy', 'web services', 'artificial intelligence', 'statistical', 'data analysis', 'data quality', 'process control', 'translation', 'datasets', 'hadoop', 'security', 'computer science', 'mathematics', 'optimization', 'modeling', 'analytical', 'r']","['sql', 'python', 'databases', 'hadoop', 'documentation', 'aws', 'data quality', 'mysql', 'r']","['unstructured data', 'computing', 'dissemination', 'quantitative data', 'data visualization', 'encryption', 'clinical data', 'graphics', 'statistics', 'software', 'logistic regression', 'reporting', 'network analysis', 'decision trees', 'analytics', 'anomaly detection', 'reporting patterns', 'text mining', 'scenario analysis', 'unstructured', 'data mining', 'servers', 'machine learning', 'relational databases', 'operations research', 'data collection', 'data privacy', 'web services', 'artificial intelligence', 'statistical', 'data analysis', 'process control', 'translation', 'mathematical', 'datasets', 'security', 'computer science', 'mathematics', 'optimization', 'modeling', 'ai']","['quality of care', 'environment', 'education', 'product design', 'business initiatives', 'forms', 'presentations', 'art', 'construction', 'adoption']"
18,24,Data Scientist,"spare is looking for a data scientist to join the growing data science team if you love numbers, and you love making a change, this could well be the job for you. think of the data science team as a startup within a startup it questions assumptions, explores alternative solutions, and keeps spare on the cutting edge. you ll be working with a talented and motivated team that puts mobility data to good use, making a positive impact on lives across the globe. location this person can be based anywhere on the east side of canada what you ll do insightful analytics delve into spare s huge databases to improve our operations, and those of our customers. predictive modelling build and deploy cutting edge models to optimize customer experiences, boost revenue generation and inform strategic business decisions. product development work closely with product and engineering teams, such as the spare realize and spare analyze teams, to integrate data more effectively in their products, and to create a delightful user experience. professional services work closely with spare s growth team to deliver high quality consultancy style reports advising customers on how to design optimal transportation services. planning and simulations work closely with spare s partner success team to run transportation simulations using our in house transit planning tools. communication present your research and analysis internally and externally, to help your colleagues and customers to identify opportunities for growth or improvement. exploration research and discover new methods to acquire meaningful data, and new applications for existing data. innovation change the world of transportation, one day at a time you re right for this role because you... have proven experience in data science interpret that how you will have experience using different languages to manipulate large amounts of data and draw valuable insights. you can also identify what valuable means to different groups of people. have some technical expertise regarding data models and or or database design development. have a bachelor s degree where you used maths or statistics as a key part of your work. can compellingly visualize and communicate your insights to a variety of stakeholders, from colleagues to customers to ceos. have a solution seeking attitude, and a critical eye for detail. love learning, and helping others to learn too. thrive in a fast paced, highly collaborative work environment with a flat organizational structure. are interested in helping us create value for communities through our products, and want to make a global impact. what we re doing spare spare is a saas platform that enables anyone to launch a smart transportation service. our mission is to empower cities to transform how their communities move with accessible, sustainable transportation networks, starting with on demand transit we believe in creating a space for everyone to share their ideas, empowering creativity and continuous learning. we re still at the beginning of our story, and every team member has a key role in shaping the upcoming chapters and spare s direction. you will be able to influence your career progression and generate a lasting impact by making headway on the cause for shared mobility. not a mobility geek take a moment to think about why you chose to live where you do, how easy it is for you to move around, and what makes a city livable. mobility is paramount in every aspect of our lives, but not everyone has equal and easy access to public transit. let s change it together about our team we strive to build a diverse company full of inclusive, fun, hard working people who treat their colleagues exceptionally well. we look for the kind of people who are dedicated to going above and beyond and will build up the team as a whole by helping each team member achieve their own individual goals. spare is for the creative, the personal, the passionate, the uncompromising, and those who want to truly understand the impact transportation has on daily life. we re still at the beginning of our story, and every team member has a key role in where we are headed. what we offer a passionate, dedicated team, focused on innovation and building a world class platform. the opportunity to make an impact on communities around the world. add an aspect of social good into your day we offer competitive salaries, equity, and a comprehensive benefits package including health, dental, and paramedical coverage, as well as an employee and family assistance program to support the wellbeing of you and your family . health, wellness and education support through our 500 lifestyle spending policy. take a course or buy a kayak it s on us completely remote optional work environment and beautiful downtown vancouver office space if or when you prefer to be in the office. an inclusive environment, where we focus every day on our people and the people in communities around us. check out our hiring process blog post to learn about what to expect next spare labs is an equal opportunity employer. all applicants will be considered for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, or disability status. job type full time","['databases', 'statistics', 'user experience', 'data science', 'database design', 'simulations', 'analytics', 'saas', 'data models']","['databases', 'data models']","['database design development', 'statistics', 'user experience', 'data science', 'simulations', 'analytics', 'saas', 'planning']","['environment', 'education', 'professional services', 'design', 'product development', 'hiring']"
19,25,Research Scientist,"research scientist, health economics and outcomes research we are an independent consultancy in vancouver british columbia, specializing in epidemiology and health economics, with a particular focus on creating customized solutions to best meet our clients diverse needs. our team comprises epidemiologists, health economists, statisticians, and it specialists. our projects are led by senior team members with extensive experience across a wide range of heor studies. we have an extensive network of external academic and clinical experts who collaborate on studies that lie within their core areas of expertise. we are looking to hire an experienced research scientist to support a wide variety of health economic and epidemiologic research projects. the position is a full time six month contract with the potential for extension to a full time permanent position. responsibilities include leading design, protocol development, implementation and interpretation of retrospective observational studies and systematic reviews for prospective observational or chart review studies, coordinating, managing, and developing study protocols for patient data collection ethics application submissions data collection materials managing sites, and or or data collection activities with general public or patient study participants conducting statistical analyses managing large datasets mentoring junior team members scientific writing client communications education msc or phd in epidemiology, health economics, statistics, biostatistics, or public health, or equivalent experience experience 3 5 years of health research experience in a consultancy or academic work environment experience with at least one of observational studies, economic models, or systematic reviews managerial, leadership and project management skills excellent oral and written communication strong independent working skills organizational, multi tasking and problem solving skills, with the ability to work independently within a team environment as well as the ability to work under pressure to meet deadlines proficiency with microsoft outlook, excel, word, powerpoint is required familiarity with a statistical or data visualization package would be an advantage. contract length 6 months job types full time, contract benefits casual dress work from home schedule 8 hour shift work remotely temporarily due to covid 19","['biostatistics', 'statistics', 'datasets', 'data visualization', 'data collection', 'microsoft outlook', 'epidemiology']",['microsoft outlook'],"['biostatistics', 'statistics', 'protocol', 'datasets', 'data visualization', 'data collection', 'scientific', 'epidemiology']","['research projects', 'environment', 'outcomes research', 'education', 'public health', 'health economics', 'design', 'health research', 'materials', 'project management', 'mentoring']"
20,27,Data Scientist,"our research team s core mission is protecting microsoft 365 users across devices, identities, applications, and data via cross category, tightly integrated threat protection for sec ops and sec admins. if you believe that cyber attacks can happen without ever dropping an executable on disk and that a forward rule and a token can do more damage than powershell, this role may be for you protecting m365 users is a big challenge, but with the signals we have built today in microsoft defender for office 365 and microsoft cloud app security, we are the best equipped company in the world to realize this opportunity and fundamentally change the security world, both for our customers and for attackers. while each of the individual microsoft defender security products provide best in class protection across endpoints and cloud, combining all of these optics and protection capabilities brings the complete attacker behavior into focus like never before, allowing innovative new detection and response approaches across the entire attack graph and providing socs unparalleled scale, reduced time to investigate, and reduced time to remediate across their digital estate. to help design our single federated protection solution spanning all m365 cloud security products, we are seeking a senior data scientist with ai skills, security knowledge, and a growth mindset. we want your help innovating and designing our solution across microsoft 365 s security portfolio. responsibilities partner with geographically distributed product teams and security researchers to identify, understand, and address security challenges across devices, identities, applications, and data assets. formulate and build data processing pipelines to fuel data driven research and create new innovations across microsoft 365 s broad security signals. partner closely with fellow practitioners to iteratively refine systems as research evolves. deliver reusable components to research and product teams by communicating to a variety of stakeholders through documentation and presentation. facilitate tech transfer by partnering with product teams to deliver new product capabilities. contribute to active engagement with the security ecosystem through papers, presentations, blogs, and or or external collaborations. invest in your growth as a security practitioner by actively seeking new knowledge from the data, from your colleagues, and from external communities qualifications required qualifications 5 years of data engineering experience with a background in fueling rigorous data driven inference methods . 2 years of cyber security experience with a background in modern risk matrices and emerging enterprise threats . bs or equivalent experience in computer science, engineering, or information technology. excellent programming skills and proficient at working with and manipulating large data sets , using modern big data systems , and interfacing with scientific tools . excellent cross group and interpersonal skills, with the ability to articulate the business need for product improvements. preferred qualifications cyber security experience with a background in modern risk matrices and emerging enterprise threats industry recognized author of security research papers, blogs, presentations, or books. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['data processing', 'data systems', 'matrices', 'security', 'powershell', 'computer science', 'documentation', 'programming', 'legal requirements', 'information technology', 'pipelines', 'data engineering', 'cloud', 'ops', 'ai']","['big', 'powershell', 'programming', 'documentation', 'pipelines']","['data processing', 'data systems', 'cloud security', 'matrices', 'security', 'computer science', 'information technology', 'data engineering', 'ops', 'ai']","['office 365', 'presentations', 'design', 'microsoft 365', 'optics', 'legal', 'recruiting', 'regulations']"
21,29,Data & Applied Scientist,"are you an applied scientist interested in understanding what happens on the web and making it better join the content services team our projects range from website understanding to improving the shopping experience on the web. for example, a project called clarity harnesses the power of big data to enable millions of website creators and owners to see what their customers experience is like and give them powerful insight that show where, how and why to improve those experiences. we also work on making the web better for everyone with work like edge shopping that making buying things faster, easier and cheaper. at the foundation of work is data about the user experience we capture signals about each user s web experiences across many hundreds of thousands of sites and analyze billions of experiences each day. from that wealth of data, we unlock insights about experience challenges and opportunities our data is extremely rich, complex and big at a scale you will find in few other places. your work affects millions of users each day in microsoft products. our challenges span many areas in ai from behavioral classification, recommendation systems, to summarization. we use ideas from a wide range of areas . over the course of several months you might work on problem ranging from detecting automated user agents to figuring out which coupons will work best on a website. we are a diverse team of data scientists, designers and engineers who excel at their craft, are passionate about their work, and have fun while doing it. as strong believers in open source, we contribute back via projects like github.com or microsoft or clarity. want to use state of the art ideas on extremely rich large scale data want to work on a newly formed team that runs like a startup and is growing rapidly come join us responsibilities as an ml focused applied scientist you will own data science work from beginning to end from understanding business requirements, data discovery and extraction, to model development and evaluation. use state of the art approaches in ml and data science to large scale experience and behavior to deliver high impact product features. optimize your models for large scale production deployment with stringent performance requirements. be comfortable solving problems in domains where figuring out the right problems to solve is key to your success and impact. bring an open mind, a can do attribute, and collaborative mindset to each day at work. qualifications required bachelor s degree in a related field focusing on machine learning and ai. demonstrated ability to deliver ml or ai solutions in a product setting. preferred 3 years of relevant work experience masters or phd degree in a related field focusing on machine learning and applied ai. experience applying ml and ai techniques to large scale behavioral data. be a strong communicator able work with both internal and external stakeholders microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work. machinelearning contentservices webxt","['model', 'machine learning', 'ai', 'user experience', 'data science', 'big data', 'github']",['big data'],"['model', 'machine learning', 'ai', 'summarization', 'user experience', 'data science', 'github']","['regulations', 'art', 'legal', 'recruiting']"
22,30,Data Scientist,"at canada drives, we believe the experience of buying a vehicle should be easy and satisfying. since 2010, we have used technology to simplify the process of finding the right vehicle for any canadian of all financial circumstances. through our online application process today we connect nearly half a million canadians per year with dealerships across canada. for our next decade, we are excited to launch 100 online vehicle purchasing, with wide selection, great deals, and with speedy at home delivery. our vision is that buying and financing a vehicle will be fair, fast, simple and seamless. we are excited to be offering this role and we want you to join our expanding team what you ll be doing we have available positions for curious, motivated analytical experts to bring the power of data driven insights to the automotive retail and consumer finance customer experience. your work will impact potentially millions of canadians, helping match customers with the perfect vehicle, at the right price and with the best financing. as a data scientist, you will have the opportunity to apply a range of methods and tools from machine learning, statistics, data analysis, operations research and modern programming to a range of use cases across the automotive retail experience. you will be a trusted resource inside canada drives, providing insights, reports and sharing the data story. we are seeking someone who will thrive and be a champion of our culture of learning, entrepreneurship, and shared accountability. we have a unique opportunity to grow our data team from the ground up, taking advantage of an industry leading data access to transform the retail automotive experience for canadians. note this is a full time permanent position, eligible for remote or work from home position and is open to all applicants from across canada who are legally entitled to work in canada. preference will be for candidates with proximity to vancouver. what you should already have a bachelor s degree in a quantitative field, such as engineering, computer science, economics, mathematics or a similar technical discipline. 2 years experience in applying analytics, data engineering or data science proficiency in working with sql, python and or or r across large data sets proficiency in using modern data visualization tools, such as tableau, powerbi or similar confident communication skills and a willingness to seek our needs and find answers the ability think think critically about complex problems, challenge assumptions and implement creative solutions what would be nice to have a master s degree or higher, focused in data science, analytics or software engineering experience applying data science in the ecommerce, logistics, digital marketing or consumer finance domains familiarity with related disciplines such as project management, user experience design, software development and digital marketing experience in establishing data technology foundations for agile business intelligence, data lakes and data workbenches, and applied machine learning or ai experience with large scale data analysis technologies experience working with salesforce data models and with applications across the salesforce ecosystem specializations and applied experience in the following areas pricing analysis and appraisal customer segmentation and intent modeling marketing attribution and targeting logistics simulation and optimization recommendation engines funnel analysis and site flow optimization consumer credit and risk modeling","['tableau', 'user experience', 'data visualization', 'automotive', 'sql', 'python', 'attribution', 'statistics', 'software', 'data science', 'software development', 'analytics', 'programming', 'data models', 'data engineering', 'financing', 'machine learning', 'ai', 'operations research', 'agile', 'business intelligence', 'data analysis', 'pricing', 'economics', 'computer science', 'mathematics', 'optimization', 'site flow', 'modeling', 'risk', 'r']","['sql', 'python', 'tableau', 'data lakes', 'programming', 'business intelligence', 'data models', 'r']","['user experience', 'site', 'data visualization', 'automotive', 'attribution', 'statistics', 'software', 'data science', 'software development', 'analytics', 'data engineering', 'financing', 'machine learning', 'risk modeling', 'data analysis', 'use cases', 'economics', 'computer science', 'mathematics', 'optimization', 'modeling', 'ai']","['entrepreneurship', 'retail', 'purchasing', 'marketing', 'design', 'finance', 'customer experience', 'project management', 'operations', 'digital']"
23,31,Data Scientist,"about mobsquad we are a well funded, hyper growth, scale up looking for an experienced data scientist. if you ve ever dreamed of working with a top tier technology company scale up, on leading edge technologies, backed by the very best venture capitalists in the world, then this is your chance. some details about mobsquad mobsquad solves the significant and growing technology talent shortage faced by us based start ups and scale ups by enabling its clients to quickly have a turnkey virtual canadian subsidiary. mobsquad ensures technology professionals with us work visa challenges remain working with their current company, but nearshore from canada. this is accomplished via mobsquad s unique partnership with the canadian government, enabling work visas to be issued for technology professionals and their respective families within four to six weeks, and canadian permanent residency within six to eight months. additionally, mobsquad has unfettered access to top tier global technology talent which it relocates to canada and pairs with american as well as canadian clients on an exclusive, long term basis, helping firms not only retain their existing world class technology talent base, but grow it substantially. we re a certified b corporation, and have made numerous contributions to charitable organizations, as well as a financial commitment to the upside foundation. we believe we are playing a key role in enhancing canada s innovation economy, and have received financial support from the government of canada, province of alberta, province of nova scotia, and city of calgary, to support this ambition. for our workplace culture, we were recognized as the 3rd best place to work in canada in 2020, as well as recognized specifically for being one of the best workplaces nationally for inclusion mental wellness giving back youth and technology. we were also recognized as one of the best start ups to work for across canada. for our innovative business model, we have been featured in numerous media outlets including asian pacific post betakit bloomberg cbc global news gothamist international business times mit technology review nearshore americas nikkei asian review npr the economic times of india the financial times the globe and mail the information the new york times and the washington post. harvard business school published a case study on mobsquad last fall, and harvard business review featured us multiple times in an article that appeared on the cover of their november or december 2020 edition. you can learn more about us on our website. about the role as a data scientist, you will be part of a canada based team working remotely with a leading us scale up. your team will operate alongside many other talented developers and data scientists in canada, and you will be an integral part of the tech community that mobsquad has built. this role requires someone who has demonstrated an ability to bridge the gap between the theoretical and the practical. the ideal candidate has deployed or attempted to execute artificial intelligence theories from various machine learning models and algorithms. mobsquad is looking for proven researchers with a track record of publishing in impactful journals and conferences, or those with years of hands on industry experience. this role offers the opportunity to apply your knowledge of statistics and your analytical skills to mine data at scale and develop large scale ml models to reveal the value in data. you will support feature prototyping and utilize best practices to write production grade code. you will build data pipelines, implement ml based analytical algorithms, and work closely with the software development team to set up back end systems and interfaces that will deliver next generation analytics. about you you have an advanced degree in data science, computer science, engineering, or a comparable analytical field from an accredited institution you are expert in data mining, machine learning, deep learning, statistical modeling, and data visualization techniques using data oriented tools and languages such as python, r, and matlab you have over three years of experience or demonstrated fluency in relevant programming languages you have over three years of experience working with sql as well as nosql databases you have experience setting up and using large scale distributed data processing frameworks such as apache spark and hadoop mapreduce you have experience working with enterprise grade cloud computing platforms such as microsoft azure, amazon web services, or google cloud you have demonstrated ability to develop high quality code adhering to industry best practices you are familiar with designing experiments and collecting data for the purpose of deriving data analytics insights and solutions you have experiencing creating and deploying recommendation and or or predictive models you have work or project history reflective of a self motivated professional who excels when given open ended problems and broadly defined goals, having an innate desire to discover the patterns and relationships in data that can be leveraged to provide business value what you ll get mobsquad a full time position that offers competitive compensation a benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. we give you the ability to build your package of benefits covering health , wellness , and rrsp a downtown office location with first rate amenities, surrounded by great restaurants and easily accessible transit for international candidates, sponsorship for an immediate work permit, expedited permanent residency, and canadian citizenship within four years at mobsquad, we support and encourage building a work environment that is diverse, inclusive, and safe for all. we invite and welcome applicants of all backgrounds, regardless of race, religion, sexual orientation, gender identity, national origin, or disability.","['analytical skills', 'databases', 'data visualization', 'bespoke', 'microsoft azure', 'interfaces', 'python', 'sql', 'statistics', 'data processing', 'data analytics', 'data science', 'software development', 'analytics', 'technology', 'cloud computing', 'nosql', 'data mining', 'amazon web services', 'machine learning', 'data pipelines', 'apache spark', 'statistical', 'artificial intelligence', 'algorithms', 'matlab', 'deep learning', 'prototyping', 'programming languages', 'hadoop', 'computer science', 'modeling', 'r']","['sql', 'python', 'databases', 'amazon web services', 'programming languages', 'google cloud', 'apache spark', 'hadoop', 'microsoft azure', 'nosql', 'matlab', 'r']","['analytical skills', 'data visualization', 'bespoke', 'interfaces', 'data analytics', 'statistics', 'data processing', 'data science', 'software development', 'analytics', 'cloud computing', 'data mining', 'machine learning', 'data pipelines', 'statistical', 'artificial intelligence', 'algorithms', 'deep learning', 'prototyping', 'computer science', 'modeling']","['environment', 'business value', 'bloomberg', 'sponsorship', 'government', 'compensation', 'business']"
24,32,Data Scientist I,"td description tell us your story. don t go unnoticed. explain why you re a winning candidate. think td if you crave meaningful work and embrace change like we do. we are a trusted north american leader that cares about people and inspires them to grow and move forward. stay current and competitive. carve out a career for yourself. grow with us. department overview what does td stand for for starters, we believe in visionary leadership and insights. we believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data. as part of our data and analytics team, you ll be a fundamental part of crafting business processes enterprise wide by analyzing vast amounts of past and present data. td s vision for the future tailored, customized banking products, services and experiences for every single customer. if you ve been in business as long as we have, you know there s no such thing as one size fits all, and a diverse, inclusive data analytics team is a massive part of that future achievement. job description about this role you are eager to provide your burgeoning technical expertise as part of a team that takes on consistently complex projects across a wide range of business units. you are familiar with data functions including data modelling, visualization, data profiling, data origin and lineage, report design and more. you will employ these disciplines to help create data related solutions to drive business results. you thrive on positive feedback and use your specialized knowledge to implement feedback systems that evaluate your team s progress and create innovative new ways improve your overall performance. we are looking for someone to work as part of a trailblazing team of data scientists who create groundbreaking analytical solutions that improve our core work enterprise wide. as a data scientist i, these are the essential qualifications of this role guide on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the organization interpret the meaning of new strategic directions and set objectives and measurements implement monitoring and feedback systems to evaluate progress and identify ways of making continuous improvements capture and analyze information or data on current and future trends seek information on issues impacting the progress of organizational and process issues educate the organization on approaches, such as testing hypotheses and statistical validation of result help the organization understand the principles and the math behind the scientist process to drive organizational alignment translate up to date information into continuous improvement activities that enhance performance research organizational and professional trends, evaluate information sources, and collate and compare findings for bias, omission and accuracy, conduct objective analysis establish positive working relationships across multiple business and technology partners, program and project managers participate in knowledge transfer within the team and business units job requirements what can you bring to td tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes undergraduate degree or technical certificate five or more years of relevant experience inclusiveness at td, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. if you require an accommodation for the recruitment or interview process , please let us know and we will work with you to meet your needs. job family advanced analytics modelling job category primary enterprise data analytics job category enterprise data analytics hours 37.5 business line td wealth time type full time employment type regular country canada province or state ontario city toronto work location td centre south 79 wellington street west job expires 24 jun 2021","['go', 'data analytics', 'visualization', 'banking', 'testing', 'data science', 'project managers', 'data profiling', 'enterprise', 'analytics', 'statistical', 'measurements']",['go'],"['data analytics', 'visualization', 'banking', 'testing', 'data science', 'project managers', 'data profiling', 'enterprise', 'analytics', 'report', 'statistical', 'measurements']","['validation', 'environment', 'continuous improvement', 'design', 'adoption', 'business units']"
25,34,Data Scientist,"ridership is in flux. uncertainty about who s riding is at all time highs. transit agencies need real time insights to understand what s happening in their cities and so do the companies and academic partners that serve them. and then there s transit where are people booking trips where are folks headed what modes are they taking transit network planners would weep at having the data you ll have access to. you will be tasked with teasing meaning and insight out of all that data from o d matrices, to survey analysis to help our agency and operator partners deliver better service on the ground, while also protecting user privacy with swords and dragons. if your brain is wired for cities, if organizing data gives you a dopamine rush, and if improving one of the world s most highly used navigation apps would make you feel like a queen at the end of each day, this job is for you. you ll be trusted to reach elegant, simple conclusions from our big black box of user data, complemented by in app and in person research. responsibilities you ll draw insights from existing data sources, have input into the way we collect and structure our data, test all the hypotheses , create forecasts with that data, and talk data with our partners. you ll design our in app surveys and analyze the results. since we re not a giant company, you ll get to determine how we package the data that partners care about in a way that makes the most sense, and improves service. requirements you have a degree or hard won experience in a quantitative field stats, applied math, or econ convince us it s relevant. bonus points for an advanced degree, lots of experience, and or or special projects you are legally sworn from talking about. your portfolio of work shows you can make data sing in reality, not just in theory you re always asking questions, and able to find something interesting in any dataset. sql and nosql queries that befuddle other mortals are, to you, mere child s play. making sense of geospatial data is fun you. you have a facility for python, r, other languages used in analyzing data. you can calculate the required sample size for statistical significance for a survey and you can tell us why it s not actually significant since it s a convenience sample. you are an organized, analytical problem solver with strong written, oral and visual communication skills. would be nice if you have experience with data engineering, etl. you can talk smack about modern machine learning techniques. you have experience turning out production ready code. passion for urbanism you find cycling glamorous, you can navigate your city s public transit system without a map, and you believe free parking should only ever exist on a monopoly board. even better you ve worked at a transit agency or private mobility provider, or have a degree in transportation. don t feel like all the requirements apply to you but you still think you d be a great fit for transit don t hesitate to apply compensation and benefits competitive salary and stock options comprehensive medical and dental coverage 5 weeks vacation apple laptop and equipment 1,500 annual mobility allowance. stm bixi uber e bike scooter going car free is free at transit. a training and development budget generous maternal or paternal or parental leave policy. gotta fill out our tandem bicycles somehow flexible work hours spend your days surrounded by first rate teammates and the best view of montreal zoom backgrounds in the world a note on diversity public transit is used by overwhelmingly more women and people of colour than other modes of transportation. we try to make sure the diversity of our users is reflected in the team that serves them. because when we include people of all races, genders, sexual orientations, ages, and identities we end up building a better app for everyone who uses transit. we encourage candidates of all ages, genders, origins and orientations to apply. if you d like to specify which pronouns you d like to be referred to, feel free to include that in your application email. and if your lived experience has given you a unique perspective on all things transportation, mobility, accessibility, urbanism let us know, and we ll make sure your application gets the attention it merits. how to apply send your resume, a brief explanation of why you want to work for transit, a sample of an analysis you ve done , and any other information you find relevant to","['geospatial data', 'sql', 'navigation', 'python', 'machine learning', 'matrices', 'zoom', 'uncertainty', 'data engineering', 'map', 'solver', 'nosql', 'etl', 'r']","['sql', 'python', 'zoom', 'solver', 'nosql', 'map', 'r']","['geospatial data', 'navigation', 'machine learning', 'matrices', 'uncertainty', 'data engineering', 'etl']","['surveys', 'compensation', 'private', 'design']"
26,35,Data Scientist,"job description our precima team helps retailers turn shopper insights into strategic advantage. we leverage our deep expertise in data science and technology to mine shopper data, uncovering what drives consumer decision making. by using advanced modeling, artificial intelligence and cloud based saas solutions, we are able to put these insights at the fingertips of our clients. as a data scientist, you ll be part of a team of smart, highly skilled engineers and data scientists who are proud to partner with some of the world s leading retailers on challenging, cutting edge, data driven solutions all powered by our exceptional technology and people. our core technologies currently include java, angular, spring boot, apache nifi, mongo, postgres and snowflake, and we continue to adopt the best of breed in cloud native, low latency technologies. our team is co located and agile, with a central hub in toronto. what you ll do be responsible for analytics production support and deployment. this includes executing, developing, deploying and measuring nielsen precima s analytical products that are configured for clients. produce accurate statistical analysis and ensure high quality of the data analysis produced. implement, score, and maintain advanced statistical and mathematical models and customer segmentation. interpret, document and present analytical results to multiple business disciplines, providing conclusions and recommendations based off customer centric data. take analytical objectives and define data requirements. extract, clean, and transform customer and item level data for purposes of analysis, modeling or segmentation and reporting. participate in special projects and ad hoc as required we re looking for people who have bachelor or master degree in math or statistics, computer science, economics, industrial engineering. minimum of 1 2 years of directly related work in quantitative analysis with proven results in leveraging customer or transaction to address business objectives through a structured analysis leading to insights and recommendations. experience in retail and or or cpg is strongly preferred. strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis. high proficiency in sql and python or r or or similar statistical packages ability to translate business objectives into analytical plan or framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams and then to clients. ability to translate statistical and analytical results into clear written and verbal communication to internal or external stakeholders. excellent ability to be part of multiple projects or initiatives while simultaneously meeting deadlines in a diverse environment strong team player and ability to work in a collaborative environment additional information about nielseniq nielseniq is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. we provide consumer packaged goods manufacturers or fast moving consumer goods and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. our approach marries proprietary nielseniq data with other data sources to help clients around the world understand what s happening now, what s happening next, and how to best act on this knowledge. we like to be in the middle of the action. that s why you can find us at work in over 90 countries, covering more than 90 of the world s population. for more information, visit nielseniq is committed to hiring and retaining a diverse workforce. we are proud to be an equal opportunity or affirmative action employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.","['statistical analysis', 'java', 'sql', 'python', 'data analytics', 'statistics', 'reporting', 'data science', 'saas', 'analytics', 'spring boot', 'interpreting data', 'artificial intelligence', 'data analysis', 'customer analysis', 'economics', 'low latency', 'angular', 'computer science', 'modeling', 'snowflake', 'r']","['sql', 'python', 'snowflake', 'spring boot', 'angular', 'apache nifi', 'java', 'r']","['data analytics', 'statistics', 'cpg', 'quantitative analysis', 'customer analysis', 'reporting', 'economics', 'low latency', 'data science', 'interpreting data', 'data analysis', 'saas', 'artificial intelligence', 'analytics', 'computer science', 'modeling', 'statistical analysis']","['environment', 'industrial engineering', 'retail', 'genetics', 'production', 'hiring']"
27,37,Data Scientist,"our world relies on ai more and more each day. but what does it actually mean for ai to be reliable as you consider the question, are you finding that the rabbit hole grows deeper and deeper does it intrigue you as both a necessary and valuable question for people to answer if so, we d love to meet you. at datatron, we create technology to help the growing number of companies sprinting towards reliance on machine learning as part of their operations. our combination of model ops and governance products ensure machine learning artifacts created by our customers are easy for them to deploy, highly available, and continuously measured for target performance...regardless of how they were developed. we help them guard against bias and drift, safely manage the release of new versions, and alert them to potential issues as they arise. we take pride in the unique, agnostic platform we provide and believe we are contributing to the cause of ethical ai after all, can it fundamentally be ethical if you cannot rely on it as a data scientist on our team, you will be one of our primary subject matter experts and responsible for innovation in our products. you will be a leading voice in the field of ai governance, inventing cutting edge analysis techniques for assessing model performance, recommending the best means to evaluate the model across many domains and technologies to provide the widest support possible for our customer s data science teams. you will interact with fellow data scientists in different enterprises to understand what and how they deploy, how to effectively manage the necessary dependencies and support their operational realities, then collaborating with our product designers and engineers to create compelling new software features for our platform. we re looking for people who have at least 3 to 5 years of full time experience previously developing models for production use insight into how the operational realities of data science can be better managed and accelerated significant focus in the past on algorithm selection and identifying deployment considerations previous developed models requiring ensembling and sequential or multi stage inference validated multiple forms of structured and unstructured data against machine learning output visualized inference results for benchmarking, comparing iterations, and identifying anomalies experience with two or more popular machine learning frameworks and workbench products a willingness to adapt, are passionate about accelerating model lifecycles, and capable of working independently, putting in extra effort when necessary, as we are an early stage startup our benefits include medical or dental or vision coverage 401k lunch provided daily abundant snacks and drinks dedicated, heavily discounted parking and clipper direct gym reimbursement weekly happy hours and monthly company outings 10k referral bonuses, because after we hire you, we d love to hire some of your friends we are an equal opportunity employer and value diversity very highly at our company. for us, diversity is the true key to innovation and everyone in the datatron family is equally embraced for their unique perspective and experiences. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","['unstructured data', 'machine learning', 'software', 'data science', 'ops', 'ai']",[],"['unstructured data', 'machine learning', 'software', 'sprint', 'data science', 'and', 'ops', 'ai']","['subject matter experts', 'governance', 'forms', 'benchmarking']"
28,39,Data Scientist (Machine Learning),"events in recent years have made us all too familiar with the havoc that natural disasters can wreak, and the increasing frequency and intensity with which they are occurring. despite record levels of losses, conventional methods of risk modeling continue to paint at best an incomplete picture of these threats. zesty.ai uses novel data gathering and data science methods to produce higher quality information about the risks to property from catastrophes like floods and wildfires. while ai alone may not be able to thwart these disasters, it can help us become more prepared for them, and ultimately that will lead to better outcomes. as a data scientist , you are comfortable and excited to work closely with the engineering team to build the best ai tech possible. you will develop top tier models from unique and diverse data sources to provide strong insights and maximize the impact of our company efforts. you thrive in a collaborative, creative environment that moves fast and are comfortable setting in place structures and processes to help the company scale. the opportunity exploring data sets and developing new insuretech models with data science . develop computer vision algorithms that extract insights from aerial imagery and geospatial data research and model aspects of the built environment utilizing satellite imagery, lidar and other datasets help develop training and cross validation data sets for machine learning algorithms translate product management, engineering, and business constraints and queries into tractable data science questions iterate rapidly on everything all of the above happens in a fast paced business driven environment that you must be comfortable with what you bring to the zesty.ai lab team ba or bs degree in math, physics, computer science, and economics ms or ph.d. is certainly a bonus 1 2 years of experience working with computer vision and building and testing computer vision systems 2 3 years experience deploying machine learning models in production environments 2 3 years experience working with deep learning or neural network models ability to develop new models based on physics and ai sciences strong organizational and management skills with past experiences implementing best practices and processes experience working with large image datasets and related tools opencv, pillow, etc. proficient in sql experience working with cloud platforms must be legally eligible to work in canada why zesty.ai lab be part of a well funded growth stage start up market competitive comp and equity incentives to give you a stake in our future comprehensive health care plan flexible time off an upbeat and collaborative work culture company sponsored outings and offsites all your information will be kept confidential according to eeo guidelines.","['network', 'built environment', 'sql', 'geospatial data research', 'physics', 'computer vision', 'data science', 'product management', 'lidar', 'satellite imagery', 'machine learning', 'testing', 'algorithms', 'deep learning', 'economics', 'datasets', 'computer science', 'modeling', 'risk', 'ai']","['sql', 'opencv']","['network', 'built environment', 'geospatial data research', 'physics', 'computer vision', 'data science', 'product management', 'data gathering', 'satellite imagery', 'machine learning', 'testing', 'algorithms', 'deep learning', 'economics', 'datasets', 'lid', 'computer science', 'modeling', 'risk', 'ai']","['incentives', 'validation', 'environment', 'events']"
29,40,Data Scientist,"type full time primary location canada education bachelor s degree job description our client, an international investment bank, is looking for a data scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting edge data science tools and techniques. you will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine machine learning techniques with domain expertise across fixed income, equities, and credit. you will take point on running data science research projects and developing pocs along with building scalable, systematic solutions, and work to integrate these into the day to day lives of the users. job requirements required advanced degree in statistics, mathematics, information technology or a related field 5 years of hands on, technical experience with data science in a financial services setting demonstrated experience using a wide range of techniques and algorithms to deliver insights demonstrated experience in understanding business challenges and theoretical insights and translating them to working code multi asset class experience, including securitized products hands on experience with various machine learning tools, libraries, and development platforms, including jupyter. programming experience in python, sql, vba critical thinking and the ability to drive changes preferred exposure to automl platforms such as data robot or dataiku or h2o.ai. ability to compose dashboards in one or more of plotly dash, tableau, qlikview, d3.js prospect 33 is an equal employment opportunity or affirmative action employer. we are a diverse and inclusive company. great talent is always welcome at prospect 33 regardless of background, ethnicity, race, gender, sexual orientation, religious views, or even political views. job description our client, an international investment bank, is looking for a data scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting edge data science tools and techniques. you will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine machine learning techniques with domain expertise across fixed income, equities, and credit. you will take point on running data science research projects and developing pocs along with building scalable, systematic solutions, and work to integrate these into the day to day lives of the users. li nl1 education 3 job requirements required advanced degree in statistics, mathematics, information technology or a related field 5 years of hands on, technical experience with data science in a financial services setting demonstrated experience using a wide range of techniques and algorithms to deliver insights demonstrated experience in understanding business challenges and theoretical insights and translating them to working code multi asset class experience, including securitized products hands on experience with various machine learning tools, libraries, and development platforms, including jupyter. programming experience in python, sql, vba critical thinking and the ability to drive changes preferred exposure to automl platforms such as data robot or dataiku or h2o.ai. ability to compose dashboards in one or more of plotly dash, tableau, qlikview, d3.js prospect 33 is an equal opportunity employer. , title data scientist , employmenttype full time , https or or schema.org or , identifier propertyvalue , value 1805 , name prospect33 , hiringorganization sameas https or or prospect33.com , organization , name prospect33 , jobposting , dateposted 2021 05 03 13 46 07.840632 00 00","['https', 'jupyter', 'sql', 'python', 'machine learning', 'statistics', 'tableau', 'vba', 'dashboards', 'data science', 'analytics', 'mathematics', 'programming', 'information technology', 'algorithms', 'qlikview']","['https', 'jupyter', 'sql', 'python', 'auto', 'plotly', 'tableau', 'vba', 'programming', 'qlikview']","['machine learning', 'statistics', 'dashboards', 'data science', 'analytics', 'mathematics', 'information technology', 'algorithms', 'ai']","['research projects', 'education', 'trading', 'design', 'equities', 'portfolio managers', 'financial services']"
30,42,Data Scientist - Product Data Science,"company description twitter serves the public conversation by encouraging people all over the world to connect, learn, debate, and solve problems together. we believe conversation can change the world, and that s why tweeps come to work every day. job description you will work closely with our partners in product, engineering, design, and research to understand customer behavior, inform product decisions, and increase healthy participation on twitter. you will support the entire product development lifecycle from product ideation to opportunity sizing, from measurement design to experimentation, from causal analysis to post launch learning, and iteration into the next development cycle. you will analyze how changes to the platform affect customer behavior and business outcomes. you will also communicate findings to cross functional partners and use data to improve the team s strategy. qualifications you are a data scientist with a track record of delivering results. you find satisfaction in collaborating with partners and shipping changes that deliver measurable business impact. you apply machine learning and data science techniques when applicable, but are just as happy to implement a simple heuristic if it meets business needs. you are looking to join a strong, high performing team. you are great at collaborating with product managers, engineers, and designers to drive business impact through data science performing analyses on raw event data in modern data warehouse systems taking ambiguous business and technical problems to an appropriate solution defining metrics and using data to better understand customer needs qualifications advanced degree in a quantitative field expertise solving complex and highly impactful quantitative business problems with at least one scripting language and sql experience with one or more of the following in an applied setting developing statistical frameworks to understand customers and their behaviors, advanced statistical techniques for a or b testing, methods for experimental design, causal inference, or quasi experimental analysis bonus ability to create or improve reproducible analysis libraries bonus experience with pyspark or bigquery additional information we are committed to an inclusive and diverse twitter. twitter is an equal opportunity employer. we do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.","['sql', 'machine learning', 'experimental', 'pyspark', 'testing', 'scripting', 'data science', 'causal analysis', 'causal inference']","['pyspark', 'sql']","['machine learning', 'experimental', 'testing', 'scripting', 'data science', 'causal analysis', 'causal inference', 'experimental analysis']","['product development', 'design', 'metrics', 'product idea']"
31,44,Data Scientist,"at novisto, our vision is to be the world s leading software solution for integrated corporate sustainability management. our purpose is to advance a more inclusive and resilient society by enabling organizations to create value through sustainability. you will have the chance to work with incredibly talented and driven people within our engineering and business teams. while our employees are currently working remotely, we are taking thoughtful measures to ensure a smooth onboarding experience for any new employee joining our growing company. we are looking for an experienced data scientist to join us. you will be responsible for data discovery in vast amounts of data, applying data mining techniques, doing statistical analysis, and building high quality prediction systems. experience degree in computer science or relevant field 5 years with data related technologies 4 years with nlp techniques and algorithms 2 years with data mining, statistical analysis, prediction systems, visualisation tools experience with cloud services and infrastructure is a plus requirements excellent understanding of machine learning techniques and algorithms experience with data visualisation tools good applied statistics skills, such as distributions, statistical testing, regression good scripting and programming skills extended experience with nlp techniques such as text preprocessing, text representation, keyword extraction, text classification, topic modelling, semantic extraction techniques, sentiment analysis experience with pdf parsing text, tables and images experience with python and data science packages such as scikit learn, pandas, numpy, keras, tensorflow, pytorch experience with nlp packages such as gensim, nltk, spacy understanding of deep learning models for nlp such as bert, rnn, lstm personal skills excellent communication and teamwork skills an analytical mind, great attention to detail what we offer the opportunity to join an early stage, well financed company the chance to have an impact by creating a product that is bringing positive change around the world generous health benefits beautiful office, in the heart of old montreal","['prediction', 'parsing', 'pytorch', 'tensorflow', 'sustainability', 'statistical analysis', 'python', 'statistics', 'keras', 'nltk', 'software', 'scripting', 'data science', 'pandas', 'data', 'programming', 'sentiment analysis', 'data mining', 'machine learning', 'statistical testing', 'numpy', 'algorithms', 'cloud services', 'deep learning', 'nlp', 'gensim', 'computer science']","['python', 'keras', 'nltk', 'pytorch', 'sci', 'numpy', 'nlp', 'spacy', 'pandas', 'nlpsim', 'programming', 'bert']","['prediction', 'parsing', 'distributions', 'tensorflow', 'sustainability', 'statistical analysis', 'regression', 'statistics', 'semantic', 'software', 'scripting', 'data science', 'sentiment analysis', 'data mining', 'machine learning', 'testing', 'statistical', 'algorithms', 'cloud services', 'deep learning', 'computer science']",['onboarding']
32,45,Data Scientist,"bachelor s degree 3 years of experience with data scripting languages or statistical or mathematical software 2 years working as a data scientist experience in as many of the following areas measurement problems, causal inferencing, multi variate testing design, a or b testing design, descriptive analytics, and regression analysis. good understanding of supervised and unsupervised learning models amazon advertising is one of amazon s fastest growing and most profitable businesses. as a core product offering within our advertising portfolio, sponsored products helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through amazon. the sp team s primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. our products and solutions are strategically important to enable our retail and marketplace businesses to drive long term growth. we deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day as a data scientist on this team you will solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ml models by tailoring to business needs, and collaborating with scientists, engineers, bie s, and product managers. translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. in cases where questions cannot be answered with available data, work with engineers to produce the required data. deliver with independence on challenging large scale problems with ambiguity. manage and drive the technical and analytical aspects of advertiser segmentation continually advance approach and methods. retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance. analyze historical data to identify trends and support decision making. improve upon existing methodologies by developing new data sources, testing model enhancements, and fine tuning model parameters. provide requirements to develop analytic capabilities, platforms, and pipelines. apply statistical or machine learning knowledge to specific business problems and data. formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. work out why such examples are outliers and define if any actions needed. given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes. build decision making models and propose solution for the business problem you defined conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication. utilize code for data analyzing and modeling algorithms. why you love this opportunity amazon is investing heavily in building a world class advertising business. this team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. our solutions generate billions in revenue and drive long term growth for amazon s retail and marketplace businesses. we deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world class products. we are highly motivated, collaborative, and fun loving team with an entrepreneurial spirit with a broad mandate to experiment and innovate. impact and career growth you will invent new experiences and influence customer facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising this is your opportunity to work within the fastest growing businesses across all of amazon define a long term science vision for our advertising business, driven fundamentally from our customers needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. this role combines science leadership, organizational ability, technical strength, product focus, and business understanding. team video https or or youtu.be or zd 6lzw8rae phd in statistics, economics or related quantitate field. experience in measurement problems, causal inferencing, multi variate testing design, a or b testing design, manipulating data analyzing very large data sets, descriptive analytics, and regression analysis. excellent quantitative modeling, good knowledge of ml methods, statistical analysis, and problem solving skills. experience processing, filtering, and presenting large quantities of data. combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer s organization. demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences. ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations. demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. experience in advertising is a plus. amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. for individuals with disabilities who would like to request an accommodation, please visit https or or or en or disability or ontario","['https', 'statistical analysis', 'regression analysis', 'statistics', 'software', 'dynamics', 'analytics', 'data', 'pipelines', 'machine learning', 'quantitative', 'testing', 'algorithms', 'economics', 'business insights', 'simulations', 'modeling', 'script', 'system performance']","['https', 'pipelines', 'business insights', 'system performance']","['machine learning', 'regression analysis', 'statistics', 'software', 'quantitative', 'testing', 'scripting', 'economics', 'dynamics', 'simulations', 'data', 'variate', 'analytics', 'fine tuning', 'modeling', 'statistical analysis', 'algorithms']","['environment', 'investing', 'advertising', 'retail', 'business understanding', 'design', 'sales', 'inferencing']"
33,46,Data Scientist,"stradigi ai, a leading artificial intelligence solutions provider, is looking for a data scientist who will support our pre sales and marketing teams with insights gained from analyzing company data. the ideal candidate must have strong experience using a variety of data mining or data analysis methods using a variety of data tools, building, and implementing models, using or creating algorithms, and creating or running simulations. what you ll do participate and drive client workshops to capture business objectives and translate them into data requirements for ml purposes. work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. assess the effectiveness and accuracy of new data sources and data gathering techniques. develop custom data models and algorithms to apply to data sets. use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. coordinate with different functional teams to implement models and monitor outcomes. develop processes and tools to monitor and analyze model performance and data accuracy. required qualifications experience using statistical computer languages to manipulate data and draw insights from large data sets. experience working with and creating data architectures. financial knowledge or experience from capital markets is a definite asset. knowledge of a variety of machine learning techniques and their real world advantages or drawbacks. knowledge of advanced statistical techniques and concepts and experience with applications. excellent written and verbal communication skills for coordinating across teams. strong presentation skills for both internal stakeholders and client workshops. a drive to learn and master new technologies and techniques. we are looking for someone with 4 7 years of experience manipulating data sets and building statistical models, has a master s or phd in statistics, mathematics, computer science or another quantitative field, and is familiar with the following software or tools knowledge and experience in statistical and data mining techniques glm or regression, random forest, boosting, trees, text mining, social network analysis, etc. experience querying databases and using statistical computer languages r, python, slq, etc. experience using web services. experience creating and using advanced machine learning algorithms and statistics regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. experience analyzing data from 3rd party providers google analytics, facebook insights, etc. experience with distributed data or computing tools map or reduce, hadoop, hive, spark, mysql, etc. experience visualizing or presenting data for stakeholders using tableau, periscope, business objects. why consider stradigi ai we offer very attractive salaries. the opportunity to own shares in our company through our esop program. rrsp matching up to 3 a generous vacation program additional paid time off during the holidays health, dental and many additional wellness benefits flexible work arrangements, allowing you to work from home or the office","['computing', 'databases', 'tableau', 'hive', 'mysql', 'map', 'trees', 'python', 'statistics', 'software', 'decision trees', 'data models', 'text mining', 'scenario analysis', 'data mining', 'machine learning', 'ai', 'google analytics', 'web services', 'artificial intelligence', 'data analysis', 'algorithms', 'hadoop', 'neural networks', 'simulations', 'computer science', 'mathematics', 'optimization', 'modeling', 'r']","['python', 'databases', 'google analytics', 'hadoop', 'tableauigi', 'data models', 'hive', 'mysql', 'map', 'r']","['computing', 'trees', 'statistics', 'software', 'network analysis', 'decision trees', 'text mining', 'data gathering', 'scenario analysis', 'data mining', 'machine learning', 'web services', 'artificial intelligence', 'predictive', 'data analysis', 'random', 'computer', 'algorithms', 'neural networks', 'simulations', 'computer science', 'mathematics', 'optimization', 'modeling', 'ai']","['marketing', 'revenue generation', 'sales', 'capital markets', 'product development', 'workshops']"
34,47,Data Scientist,"analytics, toronto, ft your role explore customer data to uncover insights using data mining and analytic skills. training and tuning modern machine learning and ai algorithms to maximize performance and speed. building presentations to explain methodology, convey insights and share value based outcomes. work independently with tasks assigned. skills required bachelors degree in math, statistics, engineering or computer science fluency in python strong communication and problem solving skills. exposure to tableau an asset.","['data mining', 'python', 'machine learning', 'statistics', 'tableau', 'computer science', 'analytics', 'customer data', 'algorithms', 'ai']","['python', 'tableau']","['data mining', 'machine learning', 'statistics', 'computer science', 'analytics', 'methodology', 'customer data', 'algorithms', 'ai']",['presentations']
35,48,"Data Scientist, Growth & Retention","since being founded in 2011, prodigy education has grown from 3,000 local users to more than 100 million registered users worldwide. as one of the fastest growing edtech startups in north america, prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. anyone with an internet connection is welcome to create a free account for prodigy s popular math game for grades 1 to 8. prodigy education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. for more information visit our passion is our mission to help every student in the world love learning our data team is scaling rapidly as we continue to hit our product and growth milestones the work you do will aid the educational advancement of millions of students. you will have the chance to apply your analytics skills to not only help kids learn but also help our product and leadership teams to make better decisions. we are looking for a modelling and ml expert to join our growing team. you will have the chance to apply your data analysis, modelling, and coding skills to help our data, finance, and executive teams better understand our business and build the best possible company strategy. you will develop advanced models to analyze our paid memberships, and empower all teams with actionable insights on user conversion, churn, and engagement. your impact work with stakeholders, data scientists, and developers to create useful models to analyze our paid memberships. leverage data analytics and quantitative analysis to monitor the model s performance and identify new features to improve kpis. develop a deep understanding of our internal and external users to identify how our models can help solve their pain points. iterate upon successful mvps to ensure the user experience and code quality matches our internal standards. collaborate with key cross departmental stakeholders to maintain technical product roadmaps, prioritize requests, and ensure that business goals are being met. effectively scope projects so that they are lean, but also add enough value to validate your hypotheses and meet business needs. help our teams explore and understand our business and our users. design and develop a variety of metrics and models to inform the impact of company activities and lines of business. work on a variety of giant datasets, from their development and manipulation to visualizing them via polished dashboards. communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non technical backgrounds. who you are at least 3 years demonstrated experience with data science and modelling. specific experience delivering revenue related models which leverage analytics and machine learning good written and verbal communication skills with the ability to present a strong rationale for product decisions applied computational and mathematical model builder. expert skills and knowledge of sql and python programming languages. demonstrated application of model building and analytics to financially relevant problems. a team and customer centric mindset. passion for solving hard problems and building a great technical product, balancing speed and depth for greatest value. experience in business requirements analysis, design, implementation, and testing of solutions. ability to break down large projects into manageable tasks, and leverage agile methodologies such as scrum and kanban experience using analytics and user research to add significant value to a product expertise in working with bi platforms. ability to oversee and work simultaneously on different projects with a variety of timelines. willingness to learn and work in a hyper growth company love for our mission of helping kids everywhere enjoy learning. our core technologies sql python data related technologies such as data lakes and warehouses, spark, databricks, and similar cloud services bonus points for degree in engineering, computer science, stats, mathematics, or related disciplines. demonstrated ability to solve hard mathematical, algorithmic, and statistical problems. expertise in forecasting, time series analysis, user segmentation, financial modelling, and analyzing stripe or similar transaction data. experience working with cloud platforms like aws, gcp, databricks. experience working with a or b testing and experimentation, and applying statistical concepts. significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship. experience in the ed tech or saas industry previous experience scaling in a startup environment what we offer a culture of transparency, where team members are involved in important conversations full health benefits from day one for you and your family, fully covered we are a profitable company, with eligibility to participate in stock options for all full time permanent employees learning and development budget for all full time employees to use towards career growth and development opportunities we recognize 9 5 is not for everyone we offer flexible working hours that will allow you to schedule your work day with a bit more freedom while we operate 100 remotely for the time being, we understand the importance of togetherness. we offer frequent and fun team and company events, to stay connected and in the know. please note during the covid 19 pandemic, in order to keep all our candidates and team members safe, prodigy is operating, hiring and onboarding 100 remotely for the time being. come as you are. we believe the power of our collective potential will transform education. we are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. we welcome applications from people from all underrepresented groups, including people of any gender, age, or religion, members of the lgbtqia2 community, bipoc and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of prodigy education. if you feel like you don t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we d still love for you to apply we are an equal opportunity employer and are committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act, 2005 . prodigy education will provide accommodations to job applicants with disabilities throughout the recruitment process. if you require accommodation, please notify us and we will work with you to meet your needs.","['model building', 'requirements analysis', 'user experience', 'dashboards', 'data analytics', 'sql', 'python', 'kanban', 'gcp', 'time series analysis', 'software', 'data science', 'analytics', 'saas', 'aws', 'machine learning', 'testing', 'scrum', 'data analysis', 'rest', 'forecasting', 'edtech', 'cloud services', 'agile methodologies', 'programming languages', 'bi', 'datasets', 'computer science', 'mathematics']","['sql', 'python', 'gcp', 'programming languages', 'bi', 'data lakes', 'aws']","['model building', 'requirements analysis', 'user experience', 'dashboards', 'data analytics', 'kanban', 'time series analysis', 'software', 'data science', 'analytics', 'saas', 'hit', 'machine learning', 'quantitative analysis', 'testing', 'scrum', 'data analysis', 'rest', 'forecasting', 'edtech', 'cloud services', 'agile methodologies', 'datasets', 'computer science', 'mathematics']","['research projects', 'environment', 'large projects', 'events', 'education', 'metrics', 'entrepreneurship', 'onboarding', 'design', 'finance', 'user research', 'startups', 'hiring']"
36,49,Data Scientist,"trend micro, a global leader in cybersecurity, is passionate about making the world safe for exchanging digital information today and in the future. artfully applying our xgen security strategy, our innovative solutions for consumers, businesses, and governments deliver connected security for data centers, cloud workloads, networks, and endpoints. optimized for leading environments, including amazon web services, microsoft , and vmware , our layered solutions enable organizations to automate the protection of valuable information from today s threats. our connected threat defense enables seamless sharing of threat intelligence and provides centralized visibility and investigation to make organizations their most resilient. with over 6,500 employees in 50 countries and the world s most advanced global threat research and intelligence, trend micro enables organizations to secure their connected world. position summary as a part of our ottawa based advanced technology group at trend micro, you ll share in the proven success, innovation, and customer loyalty we ve had in the area of cloud and data center security. your role will be to design, implement, test, deploy and support high quality software for data center and cloud systems. this is a software development role requiring exceptional programming skills, proven software design abilities and a high degree of adaptability and creativity. if you love writing beautiful, efficient, and productive code and have a passion for seeing your code in production continuously then we want to talk to you. we re looking for someone who loves to work on a great cross functional team collaborating effectively with various groups to understand business objectives, customer needs and gaps, and deliver on the team objectives. will use their exceptional development skills to build innovative and sustainable solutions that solve our customer s problems. has current experience in modern programming languages and frameworks such as go, rust, typescript, microservice design. has a strong foundation in maths and applied experience in data science platforms and tools such as flink, matlab, scikit, numpy, scala. has experience in data visualization techniques and tools such as d3, seaborn. has experience in networking, network security and cloud platforms including aws, gcp. works fluently on a variety of platforms at varying heights in the software stack and is comfortable with low level and embedded domains as well as high level stacks. is a creative thinker that believes in end end thinking to solve current and future customer problems. has knowledge or experience developing secure code and or or working in the security domain. has a bachelor of computer science degree . trend micro welcomes and encourages applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process.","['go', 'cybersecurity', 'network', 'data visualization', 'vmware', 'gcp', 'software', 'scala', 'rust', 'data science', 'software development', 'data', 'programming', 'software design', 'aws', 'amazon web services', 'typescript', 'numpy', 'data centers', 'matlab', 'programming languages', 'security', 'networking', 'computer science', 'investigation']","['go', 'xgen', 'amazon web services', 'vmware', 'typescript', 'gcp', 'programming languages', 'scala', 'rust', 'sci', 'numpy', 'data centers', 'programming', 'aws', 'matlab']","['cybersecurity', 'software', 'network', 'security', 'data science', 'data visualization', 'software development', 'networking', 'software design', 'computer science', 'investigation']",['design']
37,50,Data Scientist 2,"the modern life and learning studio is looking for a strong data scientist to join our data science team to enable us to understand and drive data informed, high impact business decisions across our organization. in this role, you will be joining a team hungry to learn, leverage and value your expertise to grow the data science discipline into the rhythm of our bxt team structure. you will help shape and strengthen the business strategy for microsoft whiteboard and figure out the user needs and how to meet them on a visual expression canvas. you will have the opportunity to work closely with our product engineers, pms, designers, and user researchers. the successful candidate will have experience analyzing data from a wide range of datasets and across a breadth of technology platforms. they enjoy challenging projects, have strong analytical and presentation skills, technical aptitude, and a collaborative work style. we are looking for people who see challenges as opportunities, people who can look at complex problems and are able to provide actionable insights and informed decisions. responsibilities as a data scientist on the modern life and learning studio, you would be responsible for influence and empower the immediate stakeholder to make product improvements that yield business value by effectively making compelling cases through storytelling, visualizations, and other influencing tools. data preparation, statistics, and machine learning to investigate problems with the goal of supporting the questions required to support the greatest business needs. excellent creative thinking skills with emphasis on developing innovative solutions to solve complex problems that may not have one clear answer. manipulate and analyze complex, high volume, high dimensionality data from varying sources using a variety of tools and data analysis techniques. provide input to software engineering teams on new analytical capabilities needed. partner with researchers to help product teams better understand their users. help designers explore and understand scenarios in the product to address the unmet needs of the users. qualifications 3 years work experience as a data scientist. 2 years of experience with r or python and sql. 2 years of experience with one or more of the following technologies c, c , c , shell scripting, java, scope, hive, mapreduce, scala, spark, or pig. bachelor s degree is required, with preference given to a quantitative , or applied science discipline. ms, or dedicated data science training preferred. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['high dimensionality', 'sql', 'python', 'machine learning', 'statistics', 'data preparation', 'shell', 'software', 'scala', 'datasets', 'scripting', 'data science', 'c', 'data analysis', 'hive', 'java', 'mapreduce', 'r']","['sql', 'python', 'scala', 'shell script', 'c', 'hive', 'java', 'mapreduce', 'r']","['high dimensionality', 'machine learning', 'statistics', 'data preparation', 'software', 'datasets', 'data science', 'data analysis']","['business value', 'business strategy', 'legal', 'recruiting', 'regulations']"
38,51,Data Scientist,"this role will start off as work from home, gradually you will be required to work in our markham and toronto office. join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. the insurance industry is undergoing a transformation and you get to be in the driver s seat of this data driven, technology revolution. you will work on impactful projects that range from predicting customer life time values and optimizing customer journeys to incorporating novel data sources for building cutting edge pricing algorithms. you will leverage machine learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. this team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers. as a data scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. you will propose machine learning and statistical models for practical applications that impacts millions of customers. you will also mentor and guide your peers in novel approaches and provide peer review for their work. the team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. this is your chance to join the insuretech revolution the insurance industry has entered a period of unprecedented change, disruption and rapid technological development. aviva recognizes that in this rapidly changing environment building a distinctive capability in data science is critical demonstrating this commitment through the development of our data science practice. if you are passionate about data science and leveraging your analytical prowess to tackle business challenges, this role could be for you. we are embracing new technology and exploring new ways of working. with our constant advancement, you will be at the forefront of a fast evolving field. these exciting roles are at the heart of a high performing data science team that is transforming aviva in the digital age. here, we are creating a long lasting legacy and optimizing every customer s experience. what you need to succeed as a senior data scientist, you will need the following skills and experience to succeed in the role an educational background in computer science or engineering, math, statistics, physics or related field. a minimum of msc is required and phd preferred. 5 years of experience with model development and working with large datasets. this can include experience from any industry or academia . 5 programming experience in python or r with good grasp of software engineering standard methodologies such as code reusability, modularity, use of repos, etc. python or r or dataiku rest or xml or json or api ingestion spark or impala or hive expertise in machine learning theory and predictive modelling lifecycle api configuration conformance or alignment to it or enterprise architecture standards relevant experience in p c shiny app development geo analytics experience with specialization in weather environmental data ingestion what sets you apart a growth mindset with versatile skills and able to work through problems from first principles. a portfolio of projects that demonstrate your ability to draw inferences from data. this includes participation within the broader data science community including kaggle competitions or any personal projects with open data. a can do teammate who is willing to roll up the sleeves and do whatever is needed to move projects forward. that means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions. amazing people skills and able to translate and communicate complex algorithms to non technical individuals. someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners. the best problems in the industry are yet to be articulated. we need someone who is creative, self motivated and can lead projects independently. position objectives provide data support to claims business inclusive of data mining, automated reporting and modelling. transformation of complex data sets into meaningful conclusions recommendations develop innovative solutions for pattern recognition using machine learning and statistical approaches maintenance of expanding set of data mining tools, frameworks approaches communicate actionable recommendations based on insights or model results deliver proactive analysis on cat exposure, historical performance and decision making using weather and geo analytical approaches driving co ordination or delivery accountability of project and bau delivery based on timelines direction driving conformance or alignment to it or enterprise architecture standards additional information aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation.","['c', 'pattern recognition', 'hive', 'bau', 'forefront', 'python', 'statistics', 'software', 'physics', 'reporting', 'json', 'data science', 'enterprise', 'analytics', 'programming', 'data mining', 'machine learning', 'production systems', 'rest', 'algorithms', 'model', 'datasets', 'api', 'computer science', 'xml', 'r']","['python', 'forefront', 'json', 'api', 'model development', 'c', 'programming', 'xml', 'hive', 'r']","['data mining', 'machine learning', 'statistics', 'software', 'data ingestion', 'physics', 'datasets', 'reporting', 'pattern recognition', 'data science', 'enterprise', 'computer science', 'analytics', 'production systems', 'rest', 'algorithms', 'bau']","['actuaries', 'environment', 'insurance industry', 'customer journeys', 'architecture', 'environmental', 'hiring', 'insurance']"
39,52,Data Scientist,"do you want to work closely with the data and processes of a successful e commerce business were looking for an intermediate data scientist to come up with customized solutions based on state of the art machine learning and deep learning algorithms to help understand the patterns in the e commerce big data and extract meaningful conclusions and actionable results to help the business make progressive decisions. our analytics team prides itself on providing everyone at cymax with timely, accurate, and actionable information. our hardworking team makes this possible by collecting, analyzing, and reporting data to give insight into the big picture. whether through business intelligence, data science, or operations research, we use our expertise in big data to facilitate business decisions. what you ll do identify the data analytics problems that offer the most practical opportunities to the organization. study and understand the related datasets deeply and determine the most relevant datasets and kpis. collect large sets of structured and unstructured data from disparate sources. clean and validate the data to ensure accuracy, completeness, and uniformity. devise and apply models and algorithms to mine big data in collaboration with ai engineers. as a data scientist, you are expected to know the details of ml or dl algorithms, how to use or modify them, when to use them, and what algorithms are suitable for the specific problems that you are going to deal with. analyze the data to identify patterns and trends. interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method. building machine learning or deep learning scalable models for production. communicate findings and results to stakeholders effectively. experience with data visualization and storytelling. familiar with the application of cutting edge machine learning and deep learning algorithms in various topics from simple classification or regression to generative models. have a strong background in algorithm development and data driven problem solving methodologies using these algorithms. build machine learning models to answer business driving questions for areas like automated marketing and e commerce. have a deep understanding of very specific details of machine learning algorithms and be able to develop them from scratch or change their structure for a customized problem. you will be involved in a variety of tasks in the process of developing ai products data collection and synthesis, data analysis, algorithm design, and development. work with data analysts, ai engineers, and data engineers in the process of product development. use predictive modeling to increase and optimize customer experiences, revenue forecasting, pricing optimization, and other business outcomes. who you are 4 years relevant experience in advanced analytics, data science, machine learning, or artificial intelligence roles in the e commerce space. familiar with all steps of industry level machine learning methodologies. proficiency in various machine learning libraries such as tensorflow, keras, or pytorch. engineering experience using large data systems on sql, and good to have experience with spark. good to have experience with docker, and model deployment on k8s. expertise in framing a data driven solution for a business problem. why work here the cymax group of brands build tech that runs business. founded in 2004, our vision was simple design an exceptional ecommerce experience. that idea evolved into a platform that includes online marketplaces cymax business and homesquare freight club, a logistics solution and digital supply chain tech enabling manufacturers with multichannel control channel gate. so, why work with us for newbies to online selling, there is no better place to gain a comprehensive education on the end to end ecommerce experience. for the well seasoned ecomm aficionado, you ll be on the cutting edge of ecommerce technology and innovation. for everyone, there s room to grow, mentorship, and a data driven culture filled with diverse people who can t wait to meet you. so why wait take your tech career to the next level and apply now","['unstructured data', 'pytorch', 'tensorflow', 'data visualization', 'big data', 'algorithm design', 'data analytics', 'sql', 'keras', 'reporting', 'data science', 'analytics', 'data systems', 'machine learning', 'data collection', 'artificial intelligence', 'business intelligence', 'data analysis', 'algorithms', 'forecasting', 'deep learning', 'datasets', 'optimization', 'modeling', 'algorithm development', 'ai']","['sql', 'keras', 'pytorch', 'generative models', 'big data', 'business intelligence']","['unstructured data', 'tensorflow', 'data visualization', 'algorithm design', 'data analytics', 'reporting', 'data science', 'analytics', 'data systems', 'machine learning', 'data collection', 'artificial intelligence', 'predictive', 'data analysis', 'algorithms', 'forecasting', 'deep learning', 'datasets', 'optimization', 'modeling', 'algorithm development', 'ai']","['e', 'commerce', 'education', 'marketing', 'art', 'design', 'operations', 'product development']"
40,53,Specialist Data Science,"at cn, we work together to move our company and north america forward. be part of our information technology team, a critical piece of the engine that keeps us in motion. from enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value added tasks. you will be able to develop your skills and career in our close knit, safety focused culture working together as one team. the careers we offer are meaningful because the work we do matters. join us job summary you will be part of a team that spans across all business domains. you will provide advanced analytical insights using data analysis and machine learning techniques. you will collaborate with teams across the company, exploring various data sources to help identify new opportunities while driving the adoption of ai. as an expert data scientist, you will combine your knowledge of machine learning and software development skills to automate model development, training, and deployment. you will leverage your experience in building reusable algorithms, functions, and libraries to use in model development for predictive and prescriptive analytics. story telling is critical to the change management practice of putting the model into real live environment. success will be dependent on hypothesis generation, exploration of data, using ai to discover insights, to developing automation pipelines and visual analytics all being explained to our stakeholder s community. the data analytics team is helping cn to create a data driven culture where everyone can make better decisions, grounded in trusted data, and augmented by the power and scale of analytics. using advanced data platforms, and ai tooling, decisions can happen at just the right moment, impacting the environment, safety and operational excellence for our customers and team members, while always keeping an eye on the future, ready to explore... we are highly innovative, and passionate, we believe anything is possible, by embracing people culture, using the right technology, and having an agile mindset, we will drive the highest value to customers interested in working with a team of data innovators, and being part of a culture of transformation, creativity, and teamwork if so, we would love to connect with you main responsibilities work with structured and unstructured raw data to design and develop innovative predictive models, metrics, and dashboards to uncover actionable insights visualize and report data findings creatively in a variety of visual formats that provide insights to the organization influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset support and evolve the advanced analytics and data science roadmap by leveraging industry research, best practices, and emerging tools or technology collaborate on end to end automation efforts required to bring models to production build and maintain a strong engagement with key stakeholders to understand business needs and priorities requirements experience in the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques with hands on work experience 5 or more years of hands on work and practical business experience in machine learning and ai, including classification, clustering, time series analysis, nlp, demand forecasting and optimization excellent communication skills and capable of breaking down technical and complex concepts in a way that is understood by non technical audiences education or certification or designation masters or phd degree in a quantitative field such as math, statistics, computer science, economics, or data science technical skills or knowledge solid development experience with python and comfortable using various data science libraries such as scikit learn, pandas, numpy as well as frameworks like tensorflow, pytorch, keras and have applied these skills towards solving actual business matters comfortable working in and with a jupyter like environment and infrastructure, and familiar with github, data bricks have advanced knowledge in sql and apache spark expert level experience with at least one of the cloud computing platforms azure, aws, gcp familiar with tableau and or or power bi visual analytics purposes well versed in software and ai development lifecycles, including ml ops have agile experience and have a bias for action, removing blocks to get results fast assets experience with safe agile methodology and work in a fast paced environment having azure or other cloud certifications, for example azure data lake, data bricks about cn as a leading north american transportation and logistics company, cn is a true backbone of the economy. with a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. we transport us 200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000 mile network spanning canada and mid america. cn is the only canadian company listed in the transportation and transportation infrastructure sector of the dow jones sustainability world index . launched in 1999, the djsi world represents the gold standard for corporate sustainability. at cn, we work as one team, focused on safety, sustainability, and our customers, providing operational and supply chain excellence to deliver results. cn is an employment equity employer and we encourage all qualified candidates to apply. we thank all applicants for their interest, however, only candidates under consideration will be contacted. please monitor your email on a regular basis, as communication is primarily made through email.","['tableau', 'pytorch', 'tensorflow', 'dashboards', 'information technology', 'sustainability', 'github', 'data analytics', 'python', 'sql', 'statistics', 'keras', 'gcp', 'time series analysis', 'software', 'data science', 'enterprise', 'software development', 'analytics', 'pandas', 'aws', 'pipelines', 'cloud computing', 'ops', 'data mining', 'jupyter', 'analytical techniques', 'machine learning', 'apache spark', 'numpy', 'data analysis', 'algorithms', 'forecasting', 'automation', 'visual', 'model', 'bi', 'economics', 'nlp', 'computer science', 'optimization', 'modeling', 'ai']","['jupyter', 'sql', 'python', 'gcp', 'keras', 'tableau', 'bi', 'pytorch', 'apache spark', 'numpy', 'nlp', 'model development', 'azure data lake', 'pandas', 'aws', 'pipelines', 'visual']","['tensorflow', 'dashboards', 'information technology', 'modeling', 'sustainability', 'github', 'data analytics', 'statistics', 'time series analysis', 'software', 'data science', 'enterprise', 'software development', 'analytics', 'cloud computing', 'ops', 'data mining', 'analytical techniques', 'machine learning', 'predictive', 'data analysis', 'algorithms', 'forecasting', 'automation', 'visual', 'model', 'economics', 'computer science', 'optimization', 'methodology', 'ai']","['environment', 'change management', 'education', 'metrics', 'design', 'operational excellence', 'adoption', 'architecture']"
41,54,Data Scientist,"introduction have you heard about the ibm garage it s a cross functional team that delivers a unique client co creation experience to accelerate client transformation. we use enterprise design thinking, our industry leading ibm garage methodology and ibm s multidisciplinary experts in full speed from the start. we design, develop, test, and deliver solutions. startup speed. enterprise scale. we apply user centric approaches to ensure all features add value for the user and achieve desired client impact. your role and responsibilities as a data scientist working at the ibm garage, you will be the subject matter expert on data and ai statistical models and ibm s leading edge analytic solutions and how they apply to solve the client s business problems. as part of the ibm garage team, you will advise on and implement models in machine learning, optimization, neural networks, and artificial intelligence such as natural language, and other quantitative approaches using ibm data science capabilities utilizing open source. you will partner with clients to understand business problems and work side by side with clients and other garage consultants on proofs of concept and minimally viable solutions that demonstrate business value and technical solutions. projects with clients will typically be 2 to 6 weeks and you will work in squads with other data scientists, designers, data engineers, front end developers, architects and with clients. the clients garage experience results in them purchasing ibm solutions. you will deliver meaningful insights and predict emerging trends to inform business solutions that optimize client value. to be successful in this role you leverage data engineering techniques to gather, prepare, cleanse, and transform client data for analysis and ai automation, including automating data pipelines demonstrate strong business acumen and ability to understand business problems, formulate hypotheses and test conclusions to influence solution design leverage a variety of structured and unstructured data sources, analytics, ai tools, and programming languages to derive meaningful data insights possess relevant industry and or or business domain knowledge such as finance, telco, retail, consumer product and health care which you will apply to shape solutions work in an agile fashion, iterating on the design to react to client feedback and demonstrate rapid progress expand partnerships at all levels of the client organization to identify new opportunities for data science applications prove the value of ibm s data and ai solutions to clients those that are based in montreal need to be fluently bilingual ibmreferred northamerica required technical and professional expertise at least 1 4 years as a data scientist with a deep understanding of statistics and statistical practices, nlp or nlu, supervised and unsupervised learning and deep learning, at least 1 2 years of experience with identifying data sources, transforming data, etc. at least 1 to 2 years in a client facing role, including facilitating client discussions and problem framing experience with a data science programming language, such as python or r coupled with sql experience writing applications to visualize data using open source tools such as shiny preferred technical and professional expertise academic training in a quantitative discipline and or or a specialized degree in data science or analytics understanding of analytics life cycle and or or crisp dm method and practices experience with restful apis and clustered data processing demonstrable experience in private and public cloud experience in developing and delivering appropriate analytic and or or machine learning models to achieve business goals about business unitibm has a global presence, operating in more than 175 countries with a broad based geographic distribution of revenue. the company s global markets organization is a strategic sales business unit that manages ibm s global footprint, working closely with dedicated country based operating units to serve clients locally. these country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients growth and innovation. by complementing local expertise with global experience and digital capabilities, ibm builds deep and broad based client relationships. this local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. additionally, the global markets organization serves clients with expertise in their industry as well as through the products and services that ibm and partners supply. ibm is also expanding its reach to new and existing clients through digital marketplaces. your life ibmwhat matters to you when you re looking for your next career challenge maybe you want to get involved in work that really changes the world what about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion are you looking for a culture of openness, collaboration and trust where everyone has a voice what about all of these if so, then ibm could be your next career challenge. join us, not to do something better, but to attempt things you never thought possible. impact. inclusion. infinite experiences. do your best work ever. about ibmibm s greatest invention is the ibmer. we believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. ibmers believe that the application of intelligence, reason and science can improve business, society and the human condition. restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 ibmers serving clients in 170 countries. location statementfor additional information about location requirements, please discuss with the recruiter following submission of your application. being you ibmibm is committed to creating a diverse environment and is proud to be an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. ibm is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","['unstructured data', 'design thinking', 'sql', 'python', 'statistics', 'data processing', 'data science', 'enterprise', 'analytics', 'programming', 'data engineering', 'r', 'machine learning', 'data pipelines', 'ibm', 'artificial intelligence', 'dm', 'automation', 'deep learning', 'tel', 'programming languages', 'neural networks', 'nlp', 'public cloud', 'optimization', 'ai']","['sql', 'python', 'programming languages', 'ibm', 'nlp', 'public cloud', 'programming', 'r', 'nlu']","['unstructured data', 'telco', 'statistics', 'data processing', 'operating units', 'data science', 'analytics', 'data engineering', 'machine learning', 'data pipelines', 'artificial intelligence', 'dm', 'automation', 'deep learning', 'neural networks', 'natural language', 'optimization', 'methodology', 'ai']","['environment', 'private', 'client value', 'retail', 'purchasing', 'business value', 'fashion', 'design', 'finance', 'sales', 'business domain', 'new markets', 'genetics', 'consulting', 'immigration', 'investments', 'emerging trends']"
42,55,Data Scientist,"who we are lightspark is an innovative cleantech company, bringing innovative technology solutions to consumers, trade, utilities and government to help make a more sustainable future. we are building a dynamic enterprise software as a service platform and are looking for people with a passion, curiosity and purpose for using their skills and creativity to make the world a better place. who you are you have a passion for putting your analytical data skills towards solving complex problems with a focus on geo spatial techniques, working well with teams, and fighting hard to meet deadlines and build break out products. job description we are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. your primary focus will be in applying data mining techniques, doing statistical analysis, understanding gis and geo spatial mapping and building high quality prediction systems integrated with our products. specifically, you will automate our building energy scoring using machine learning techniques, build recommendation systems, and further develop our catalog of products for energy efficiency and renewables building improvements. responsibilities selecting features, building and optimizing classifiers using machine learning techniques data mining and statistical analysis using state of the art methods extending company s data with third party sources of information when needed enhancing data collection procedures to include information that is relevant for building analytic systems processing, cleansing, and verifying the integrity of data used for analysis doing ad hoc analysis and presenting results in a clear manner creating automated anomaly detection systems and constant tracking of its performance skills and qualifications excellent understanding of machine learning techniques and algorithms experience working with geospatial data interest in climate change, energy efficiency and desirable that you have experience in energy and building modelling experience with common data science toolkits, such as python, weka, numpy, matlab, r, etc. excellence in at least one of these is highly desirable great communication skills and ability to present information to management team in a way that explains concepts and thinking experience with saas software development experience with data visualisation tools, such as d3.js, ggplot, etc. proficiency in using query languages such as sql, hive, pig experience with postgressql, spatial objects and experience with redis, amazon web services is required good applied statistics skills, such as distributions, statistical testing, regression, etc. good scripting and programming skills a bonus, including node js, javascript, graphql, react, ruby on rails and php data oriented personality if you are interested, please forward your cover letter and resume to hello lightsparkinc.com about lightspark lightspark software inc is a purpose driven saas company who has a mission to build a sustainable future by accelerating the engagement and success of energy efficiency and renewable technologies. we do this by using big data, machine learning and advanced design thinking and user interfaces, to increase building owner conversions to deep energy retrofits and solve the friction points for multiple use cases, including utilities, cities, municipalities, trade and manufacturers.","['prediction', 'geospatial data', 'design thinking', 'gis', 'cleansing', 'big data', 'statistical analysis', 'hive', 'javascript', 'sql', 'python', 'interfaces', 'statistics', 'software a service', 'software', 'scripting', 'data science', 'redis', 'enterprise', 'software development', 'saas', 'anomaly detection', 'programming', 'graphql', 'php', 'data mining', 'amazon web services', 'machine learning', 'testing', 'numpy', 'data collection', 'ruby on rails', 'statistical', 'ggplot', 'algorithms', 'matlab', 'technology solutions', 'r']","['sql', 'postgressql', 'amazon web services', 'pythonka', 'numpy', 'redis', 'ruby on rails', 'technology solutions', 'ggplot', 'programming', 'big data', 'php', 'javascript', 'hive', 'matlab', 'r']","['prediction', 'geospatial data', 'design thinking', 'cleansing', 'statistical analysis', 'systems processing', 'interfaces', 'statistics', 'software', 'scripting', 'data science', 'enterprise', 'software development', 'saas', 'anomaly detection', 'graphql', 'data mining', 'gis mapping', 'machine learning', 'testing', 'data collection', 'statistical', 'algorithms', 'use cases', 'software as service']","['utilities', 'art', 'energy efficiency', 'climate change', 'government']"
43,56,Data Scientist,"job description status permanent full time location montr al griffintown at brainfinance, we pride ourselves in offering the highest possible quality of customer experience. we are looking for a person who thrives in a team environment, who is passionate, driven and who yearns to grow personally and professionally. this person will become part of a team that thrives on the new challenges presented by a fast paced and constantly evolving environment. the chosen candidate will possess a keen eye for detail and will come up with innovative ideas that will contribute to the success of both the company and the customer experience. as a data scientist, you will be working with teammates who are passionate, helpful, and strive to get the best out of big data . responsibilities participating in daily and bi weekly scrum activities . working with business analysts and business units to understand the business and requirements. working with devops engineers and software engineers to integrate big data science solutions. developing data analysis and science solutions with python. leveraging numpy, scipy, pandas, mllib, scikit learn, nltk, scrapy, and keras. utilizing apache spark, apache kafka, and apache cassandra to develop scalable real time and data driven applications advantages competitive salary. fun and relaxed work environment. full health benefits medical. free healthy snacks and refreshments. advancement opportunities. great office location. providing opportunities to attend trainings and conferences requirements a bachelor degree in software engineering or related fields . software engineers experienced with python programming language. 3 years of experience with python machine learning and optimization. 2 years of experience with apache cassandra. 2 years of experience with apache spark. familiarity with apache kafka and apache mesos. familiarity with deep learning libraries such as tensorflow or theano or cntk. experience with git and continuous integration. being open to learn and explore new technologies. experience working in an agile environment .","['tensorflow', 'big data', 'apache', 'python', 'agile environment', 'scipy', 'keras', 'nltk', 'software', 'pandas', 'data', 'programming', 'integration', 'machine learning', 'scrum', 'apache spark', 'numpy', 'data analysis', 'apache kafka', 'cassandra', 'deep learning', 'bi', 'devops', 'git', 'optimization']","['mllib', 'python', 'scipy', 'keras', 'nltk', 'apache me', 'bi', 'scikit', 'big', 'apache spark', 'numpy', 'git', 'pandas', 'programming', 'big data', 'apache', 'apache kafka', 'cassandra']","['deep learning', 'agile environment', 'machine learning', 'continuous', 'software', 'scrum', 'devops', 'tensorflow', 'data science', 'optimization', 'integration', 'data analysis']","['environment', 'business units', 'customer experience']"
44,57,"Manager, Data and Digital Platforms","position summary at samsung electronics canada, we take pride in the creativity and diversity of our talented people they are at the forefront of everything we do. their skillset and mindset drive our continued success. we want the best of the best at samsung to join our team, not just those who fit into our culture but those who will add to our culture and make samsung an even better place to work. did we catch your attention yet if you want to work for one of the most recognized brands in the world and one of the top 100 employers in canada...and have a ton of fun . then please keep reading our perks competitive salary and performance based incentive plan for all levels employer paid medical and dental coverage from day one group rrsp plan that helps you save for the future fantastic employee discount on all samsung products subsidized cafeteria including free starbucks coffee or latte machine access to samsung u for 24 or 7 online learning employee referral program we want great talent like you position summary the data and digital platforms manager will play an important role in championing data as a corporate asset and increasing data, marketing platform and digital marketing measurement literacy across the organization. you will also lead all related data and analytics platforms and services, together with partners and vendors. this role will require you to work cross functionally with marketing, business, ecommerce, it and samsung headquarters teams to understand and develop samsung s data capabilities and infrastructure and use this knowledge to appropriately implement and evolve customer segmentation and measurement strategies across digital marketing campaigns. you will work closely with samsung s digital, media and crm agencies of record to ensure all data and tag management requirements are adhered to. you will be required to present campaign and performance based reports and dashboards with a focus on providing insights to help optimize marketing activities. in addition, you will be required to contribute to the overall data management sophistication of the organization through best practices in data governance. role and responsibilities essential duties and responsibilities data platform management lead the evolution and management of seca s data capabilities and infrastructure, including its data lake responsible for the successful implementation of data lake projects that align with business and marketing use cases and strategies by prioritizing business requests, maintaining learning agenda, working with internal stakeholders to propose new use cases and coordinating tests or modeling activities liaison with business leads to understand business needs and translate them into technical requirements that can be used by business analysts and data scientists to successfully create models, tests and other analyses ensure the outputs from business analysts and data scientist are aligned with initial request and delivers business value work with solutions architects to develop, optimize and automate data processing tasks maintain overall marketing data governance and compliance best practices in line with global samsung policy and canadian privacy law lead the management of all advertising and digital analytics platforms maintain quality, consistency and standard of data across marketing properties collaborate with various internal and external agency stakeholders to build data structures harmonized across both online and offline channels build and maintain connections between all data driven marketing platforms work with data science and business analysts to implement data layer strategies that allow seca to do in depth campaign and audience reporting work with digital marketing, ecommerce and agency leads to ensure best practices are followed around tagging requirements partner with internal and external teams to perform data quality audits, qa tags and identify issues, including building improvement plans provide recommendations for improvement around platform configurations and tags work with developers to communicate what an implementation is designed to accomplish ensure the data collected and used follows key regulations including pipeda and gdpr activation analysis lead the audience segmentation strategy and execution and govern its use throughout digital marketing crm campaigns leveraging the appropriate modeling, planning and targeting tools dmp, facebook, google marketing platform lead the democratization of audience based insights across the organization to help inform business strategy through regular cadence of updates and support provide the agency and digital team with audience lists and push to the dmp and other media buying platforms to support campaign execution recommend support ingestion of new data as required work with the agency to create, maintain and activate traits and segments in the dmp as well as our media platforms to enable targeted media execution monitor segment sizes and match rates across platforms and build improvement plans as required clearly show how improving the data audience strategy has translated into greater roi across campaigns lead measurement and reporting for digital marketing team, including audience centric analysis, by building processes around campaign performance analysis, contributing to all phases of the campaign planning kpi development, targeting, campaign optimization and measuring and reporting work with internal and external partners to develop full funnel dashboards and standardized reports to provide ongoing insight and learnings develop presentations for daily, weekly, monthly and quarterly performance reviews with digital, marketing and business teams, as well as external agencies work in close collaboration with internal digital, brand and insights teams and external agencies to create key performance indicators across paid, owned and earned media channels and roi models for all campaigns partner with marketing team members to bring learnings and improvement plans forward to better inform future campaigns collaborate with nahq and hq counterparts to both share and adopt best practices around reporting and dashboarding initiatives maintain working knowledge of industry best practices and changes in analytics tools, platforms and 3rd party data sources to help better inform insights effectively communicate ongoing work and successes achieved requirements education bachelor s degree preferably in marketing, mathematics or economics with an exceptional understanding of data analytics knowledge well versed in technical aspects of mainstream media buying platforms, audience targeting capabilities, how related pixels and events work and key metrics for success strong analytical skills must have a demonstrated track record of excellence in analytics strong affinity for learning new tools and systems experience analyzing data from digital marketing channels such as email, paid search, display, and social strong quantitative skills, with an ability to analyze and interpret complex sets of data strong microsoft excel skills, including pivot tables and chart creation familiarity with microsoft powerpoint, and experience developing insightful presentations detail oriented, organized and able to work on multiple projects over the course of a day and accurately set expectations regarding timing and deliverables effective communicator via both written and spoken word proactive self starter who is able to work independently demonstrated ability to think outside the box and take initiative to solve problems as they arise ability to make sound decisions in a timely manner based on the appropriate balance of data, by asking the right questions, at the right time, to uncover findings and drive relevant action naturally curious with sharp critical thinking skills excellent project management skills, a sense of urgency, with the ability to multi task strong attention to detail experience 5 years experience managing media platforms implementing customer segmentation strategies with a solid understanding of digital marketing measurement principles, methodologies and best practices hands on experience building and implementing large scale data and or or martech projects including data centralization and integration projects hands on experience working with adobe audience manager and google marketing platform experience managing marketing and consumer data, related tools and platforms experience working collaboratively as part of a cross functional team experience working with marketing performance dashboards with tools such as powerbi, tableau, or google data studio experience designing, implementing, and analyzing multivariate tests with tools such as visual website optimizer, adobe target, or google optimize samsung is an equal employment opportunity employer. samsung has an accommodation process in place and provides accommodations for job applicants with disabilities as appropriate. assessment and selection materials and procedures can be made available in accessible formats and methods as appropriate. if you require a specific accommodation because of disability or medical need, please let us know when selected to take part in our recruitment process so that reasonable arrangements can be made for the appropriate accommodations to be in place as you move through our process. we thank you for your interest in working for samsung. only candidates selected for an interview will be contacted. li dj1 indhigh skills and qualifications","['analytical skills', 'tableau', 'dashboards', 'technical requirements', 'dmp', 'electronics', 'data analytics', 'forefront', 'data processing', 'reporting', 'data science', 'analytics', 'data', 'integration', 'crm', 'microsoft excel', 'pivot tables', 'performance analysis', 'google data studio', 'data quality', 'data structures', 'economics', 'mathematics', 'optimization', 'modeling', 'data management']","['forefront', 'tableau', 'google data studio', 'data quality', 'electronics', 'microsoft excel']","['analytical skills', 'dashboards', 'technical requirements', 'gdpr', 'data analytics', 'tests', 'data processing', 'reporting', 'data science', 'analytics', 'data', 'digital', 'integration', 'crm', 'data centralization', 'pivot tables', 'performance analysis', 'planning', 'use cases', 'data structures', 'economics', 'mathematics', 'optimization', 'modeling', 'data management']","['project management', 'law', 'and compliance', 'education', 'performance reviews', 'business value', 'materials', 'governance', 'digital', 'assessment', 'advertising', 'metrics', 'marketing', 'presentations', 'key performance indicators', 'key', 'events', 'affinity', 'business strategy', 'regulations', 'campaigns', 'agenda']"
45,58,Data Scientist,"our organization the alberta securities commission is the industry funded regulator responsible for administering the province s securities laws. it is entrusted with fostering a fair and efficient capital market in alberta and with protecting investors. as a member of the canadian securities administrators , the asc works to improve, coordinate and harmonize the regulation of canada s capital markets. the corporate finance division is responsible for reviewing the disclosure included in prospectuses and other offering documents reviewing continuous disclosure by issuers formulating recommendations for the development of rules, regulatory instruments, policies, and legislative amendments. the opportunity reporting to the manager, compliance, data risk, the data scientist will work with other members of the market intelligence team to provide analyses to the asc divisions. you will have the opportunity to work with regulatory datasets and develop analyses to help the asc better understand our capital markets support proactive compliance and inform policy development. analyses may require manipulating large or complex datasets and may require developing or enhancing existing databases. projects are likely to vary over time, which will give the successful candidate an opportunity to use a variety of methodologies. candidates should have an interest in learning about market developments and understanding the associated benefits and risks. key responsibilities include working with other team members to define the problem or question being answered, identify the data to be used, and decide on an appropriate methodology. working with a variety of staff throughout the asc. improving the usability of regulatory data sources. responding to ad hoc requests for data analysis, asc reports or publications. participating in analyses related to systemic and emerging risk for the csa systemic risk committee when required. the ideal candidate will possess a degree in finance, economics, mathematics or the physical sciences. graduate degree preferred. two five years work experience as a data scientist. experience cleaning, transforming and visualizing large data sets. experience with econometrics, statistical models, machine learning or predictive modeling. proficiency with python or r, sql, and tableau. a self motivated approach and enjoy finding solutions to problems. experience with kdb or q is an asset. experience in the financial industry is an asset. to apply click the apply for this job button to submit your resume, cover letter and salary expectations by july 9, 2021. you will be contacted if you are selected for an interview. more information about working at the asc including our comprehensive total rewards package can be found on our website at","['sql', 'python', 'databases', 'machine learning', 'securities', 'tableau', 'reporting', 'datasets', 'economics', 'data analysis', 'modeling', 'mathematics', 'usability', 'econometrics', 'r']","['sql', 'python', 'databases', 'tableau', 'r']","['market intelligence', 'securities', 'usability', 'reporting', 'datasets', 'economics', 'mathematicsizing', 'data analysis', 'modeling', 'methodology', 'machine learningive', 'econometrics']","['capital', 'finance', 'policy', 'capital markets', 'corporate', 'developments', 'disclosure']"
46,59,Data Scientist,"opentext the information company as the information company, our mission at opentext is to create software solutions and deliver services that redefine the future of digital. be part of a winning team that leads the way in enterprise information management. the opportunity the ai data scientist will focus on business analysis, data analysis, and model building in support of the delivery of ai and analytics to our opentext teams. this individual will be a professional that is self motivated and driven to accomplish company goals and who is comfortable multitasking in a fast paced, dynamic environment. you are great at working with business teams in all parts of the business to gather conceptual business needs, translate them into clear functional business requirements create process models, diagrams, charts, powerpoint presentations work with technical teams and or or study relational database tables to create technical data requirements from the business requirements build data models in python or r using a magellan notebook work with application support, product management, and engineering teams on quarterly upgrades and feature requests for magellan product suite self motivated and driven to accomplish company goals and who is comfortable multitasking in a fast paced, matrixed environment perform data preparation, linkage, and feature selection calculating model accuracy reporting and visualizing results or insights provide end user support and training as needed what it takes bachelor s degree in computer science, engineering, business or equivalent experience 5 years of proven abilities related to data analysis, reporting, analytics, and data modeling experience working with data in databases experience with sql, python, and r excellent listening, interpersonal, written, and oral communication skills experience with opentext magellan preferred experience working in a complex, matrix, fast paced environment attention to detail with emphasis on accuracy and quality ability to prioritize work to balance multiple projects and deadlines the ability to work independently, as part of a team, and cross functionally within the organization at opentext we understand and value diversity in our employees and are proud to be an equal opportunity employer. we hire the best talent regardless of race, creed, color, national origin, ancestry, disability, marital status, sex, age, veteran status or sexual orientation. if you require accommodation at any time during the recruitment process please email applicants have rights under federal employment laws including but not limited to family and medical leave act , equal employment opportunity and employee polygraph protection act","['model building', 'databases', 'business analysis', 'application support', 'software solutions', 'sql', 'python', 'diagrams', 'reporting', 'analytics', 'product management', 'data', 'data models', 'data preparation', 'ai', 'data analysis', 'information management', 'computer science', 'modeling', 'r']","['sql', 'python', 'databases', 'process', 'data models', 'r']","['model building', 'data preparation', 'business analysis', 'application support', 'diagrams', 'reporting', 'computer science', 'analytics', 'product management', 'data', 'user support', 'data analysis', 'modeling', 'software solutions', 'information management', 'ai']","['environment', 'presentations']"
47,62,Data Scientist,"data scientist description at stantec, we approach every water, power and industrial process project we undertake whether at the local, regional, or national level thoughtfully, and execute it with excellence across all project phases. we partner with our clients to design fit for purpose solutions that address their communities unique needs throughout the related infrastructure lifecycle. our experts lead their fields and guide our work with scientific rigor, an innovative spirit, and a vision for growth. we re a place where you can apply your passion and collaborate with top talent on work that s critical to our clients, our communities, and the industry at large. your opportunity stantec s water group has an opportunity for an experienced data scientist who has worked with operational technologies. stantec is in the early stages of developing a digital platform to leverage our world class water engineering a science subject matter expertise called stantec insight analytics . sia uniquely combines an analytics toolkit with stantec s subject matter expertise to enable transformational asset operation, management, and decision making in real time. the successful candidate will aid with technical strategy, data science and engineering, and development within an agile software development team. stantec s digital solutions team works closely with project managers and clients to develop solutions that enable our clients to have top tier information access and analytics. this journey includes identifying, defining, and developing those products. several product and service oriented solutions have been developed at version 1.0 and more are being defined. our goal is to transform the water industry with best in class digital solutions. these solutions cover the complete project and water lifecycle, from planning to operations, and watershed management to wastewater treatment. the digital solutions team is looking for an operational technology data scientist to complement the existing team in achieving our mission over the long term. the position will include performing both product and project consulting work. responsibilities will include helping build out current and future digital solutions by designing and implementing data analysis techniques. this role requires the implementation of best practices in data science to meet project objectives using a code based approach. specifics in this role include defining data requirements to support project objectives, determining quality of input data, quantifying uncertainty of results, and designing traditional and machine learning based approaches for analysis. we are specifically looking for candidates that have worked in industrial, automation, instrumentation, or similar operational technology fields working with control systems. candidates with experience with microsoft azure, streaming analytics, machine learning, and application development are preferred for this position. your key responsibilities support the stantec digital solutions team in developing top tier digital solutions. this requires some travel to attend meetings with clients work with remote teams for development and implementation as needed for a variety of digital solutions for analytical dashboards and interfaces. focus on implementing best practices and developing for reusability automating data collection and etl workflows data analytics to generate recommended actions ability to understand storyboards, wireframes, and simple prototypes and, how to develop them into real solutions ability to communicate and coordinate with other team members to complete project tasks to meet specific deadlines you will be receiving direction from digital solution leadership in various locations and technical support from remote locations candidates must be well organized, self motivated, and enjoy finding solutions to problems qualifications capabilities and credentials can work well in a team environment without direct supervision and ability to productively work from home possess a hard working and positive attitude ability to participate and collaborate in project team setting and to engage in creative and critical thought possesses excellent time management skills, thorough understanding of task assignment and schedule, budgeting and efficient use of time and available resources possess strong interpersonal and communication skills, both written and verbal, along with the ability to prioritize multiple tasks ability to design and implement reusable data analysis techniques based on requirements, specifications, or prototypes experience working with operational technologies in an industrial, automation, or water treatment context is a must. this includes working with data sets from industrial control systems such as scada, plcs, and dcs experience with at least one business intelligence platform such as microsoft power bi or tableau experience working with web based apis using json or xml objects experience with machine learning libraries such as tensorflow and resources such as azure machine learning experience with streaming data analytics experience with big data tools such as hadoop, spark, or databricks experience working with location data and maps is preferred experience with python, r, or scala is preferred experience using azure devops is preferred experience working in a consultant role is preferred education and experience computer science or engineering related bachelor s degree from an accredited institution. minimum of 8 years of experience. typical office environment working with computers and remaining sedentary for long periods of time. field work may include exposure to the elements including inclement weather. this description is not a comprehensive listing of activities, duties or responsibilities that may be required of the employee and other duties, responsibilities and activities may be assigned or may be changed at any time with or without notice. stantec is a place where the best and brightest come to build on each other s talents, do exciting work, and make an impact on the world around us. join us and redefine your personal best. primary location canada british columbia burnaby other locations canada alberta calgary, canada british columbia vancouver, canada alberta edmonton job applications development organization bc 1117 water ca british columbia employee status regular job level manager travel yes, 10 of the time schedule full time job posting jun 11, 2021, 9 55 03 am req id 210001h9 stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. we prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. eeo including disability or protected veterans","['tableau', 'tensorflow', 'dashboards', 'big data', 'microsoft azure', 'interfaces', 'data analytics', 'python', 'scala', 'json', 'data science', 'software development', 'analytics', 'application development', 'budgeting', 'machine learning', 'scada', 'data collection', 'specifications', 'agile', 'business intelligence', 'data analysis', 'toolkit', 'automation', 'microsoft power', 'bi', 'devops', 'hadoop', 'project managers', 'computer science', 'uncertainty', 'xml', 'etl', 'r']","['microsoft power', 'python', 'azure', 'tableau', 'scala', 'bi', 'hadoop', 'json', 'big data', 'business intelligence', 'microsoft azure', 'xml', 'control systems', 'r']","['tensorflow', 'dashboards', 'technical support', 'interfaces', 'data analytics', 'data science', 'software development', 'analytics', 'application development', 'budgeting', 'machine learning', 'scada', 'data collection', 'specifications', 'agile', 'data analysis', 'toolkit', 'automation', 'planning', 'dcs', 'devops', 'project managers', 'computer science', 'uncertainty', 'etl']","['project', 'environment', 'education', 'regulations', 'water industry', 'design', 'consulting', 'water engineering', 'compensation', 'hiring']"
48,63,Data Scientist,"are you looking for unlimited opportunities to develop and succeed with work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations. job description calling on a data scientist who can seamlessly combine tech know how with business acumen to go from a promising ml experiment to a shipped product, with real world impact. you will join the canadian advanced analytics team delivering decision support and insight to our insurance sales team. you will have dual reporting into advanced analytics and the sales organization to ensure that you are plugged into the data science community while staying close to our business needs. you will develop and implement analytics enabled solutions to improve business process, generate insights, support business goals, strategy development, and measure the impact of this work. you must have technical skills in both data and software development. there are 3 core skills we are looking for solid foundation in data science techniques and concepts in depth coding knowledge of in python and structured data able to communicate insights that the business can interpret and execute on and drive adoption. a true greenfield opportunity, you will join the team as we embark on cloud native architecture. key accountabilities build end to end machine learning solutions to solve complex customer problems working in collaboration with canadian insurance sales business to plan, scope, implement and sustain predictive analytics solutions focus on feature engineering, model training and model evaluation in addition to data munging or wrangling identify the right algorithms and statistical techniques for a specific project as well as the best features for a model. make business recommendations with effective presentations of findings at multiple levels of stakeholders including division heads. develop measurements and feedback systems mentor associates and peers on data science best practices key experiences 2 years working experience in developing and implementing data science techniques the last 2 years experience working with cloud native architecture using azure stack preferably and experience with azure ml will be an asset. experience with deep learning methodologies either in practice or in academia effective and concise oral and written storytelling and insights communication skills ability to work on multiple projects in parallel while managing constantly changing deadlines and priorities ability to document work and effectively prioritize documentation bsc or m.s. in a statistical, mathematical, or technical field or equivalent experience nice to have past experience in distributor based sales for life insurance or wealth management products, or other financial services industry if you are ready to unleash your potential, it s time to start your career with manulife or john hancock. about manulife manulife financial corporation is a leading international financial services group that helps people make their decisions easier and lives better. with our global headquarters in toronto, canada, we operate as manulife across our offices in canada, asia, and europe, and primarily as john hancock in the united states. we provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. at the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. as of december 31, 2020, we had 1.3 trillion in assets under management and administration, and in the previous 12 months we made 31.6 billion in payments to our customers. our principal operations are in asia, canada and the united states where we have served customers for more than 155years. we trade as mfc on the toronto, new york, and the philippine stock exchanges and under 945 in hong kong. manulife is an equal opportunity employer at manulife or john hancock , we embrace our diversity. we strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. we are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex , sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law. it is our priority to remove barriers to provide equal access to employment. a human resources representative will work with applicants who request a reasonable accommodation during the application process . all information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and manulife or john hancock policies . to request a reasonable accommodation in the application process, contact .","['go', 'deep learning', 'administration', 'python', 'machine learning', 'reporting', 'data science', 'software development', 'analytics', 'documentation', 'structured data', 'working experience', 'algorithms', 'measurements']","['go', 'python', 'documentation', 'predictive']","['deep learning', 'administration', 'machine learning', 'reporting', 'data science', 'measurements', 'software development', 'analytics', 'working experience', 'algorithms', 'feature engineering']","['environment', 'asset management', 'human resources', 'presentations', 'sales', 'architecture', 'financial services', 'adoption', 'business process', 'compensation', 'law', 'insurance']"
49,64,Data Scientist,"ready to create innovative solutions and best practices join our team have you ever dreamed about building an ai driven technologically advanced platform capable of helping millions of people and changing their lives for the best if so, your dream will come true with us telus is looking for a passionate and talented data scientist to join a highly skilled and dynamic advanced analytics team. in this role, you will be a key contributor to our next generation demand forecasting, and customer behavioral customer intents prediction models. you will create the most advanced machine learning solutions to enable various stakeholders to better anticipate telus customers needs and help them meet customers inquiries in advance. customer experience ai, data analytics spotlight our team works in a fun, innovative and challenging environment that directly influences the strategic direction and performance of the customer experience business our teams are responsible for the demand forecasting, customer intents and behavioral prediction, as well as performance analytics we work closely with our stakeholder teams to deliver on our strategic objectives our key stakeholders and partners include operations, marketing, finance, and technology transformation and more we provide opportunities for you to excel and show your stuff work on high value and high visibility projects we have flexible work styles with the ability to work in and out of the office you will work in a team that actively supports your personal development with progressive training and development tools. here s the impact you ll make and what we ll accomplish together as a data scientist, you re in great company, working alongside some of the brightest and creative data scientists, data engineers and data analysts. you will be part of the journey that brings us to a better understanding of our customers, in order to predict their needs and interaction behaviour. with your expert knowledge and experience in machine learning, you will contribute to the development of state of the art ml ai driven solutions such as demand forecasting, customer intents prediction and customer behaviour models. here s how lead the development and implementation of ml ai and big data solutions including predictive modelling, customer impact assessments, etc support and evolve the advanced analytics and data management roadmap by leveraging industry research, best practices and emerging tools or technology execute, oversee, and evolve models and algorithms selection to deliver solutions that are relevant and facilitate decision making build and maintain a strong engagement with key stakeholders to understand business needs and priorities identify opportunities for process or model optimization and refine to improve effectiveness or accuracy and enhance roi collaborate with data scientists and data engineers within telus as well as external data science communities qualifications you re the missing piece of the puzzle you are recognized for addressing business needs via your application of data mining and analysis, predictive modeling, statistics and other advanced analytical techniques you are sought out for your skills in machine learning , classification, clustering, segmentation, time series analysis, nlp, demand forecasting and optimization, with 5 or more years of practical business experience in the above areas you are capable of delivering technical and complex concepts in a way that is understood by non technical audiences you have solid development experience with python and you are comfortable using various data science libraries such as scikit learn, pandas, numpy as well as frameworks like tensorflow, pytorch, keras you are comfortable with jupyter environment and infrastructure, as well as know what github, spyder or pycharm are you possess advanced knowledge in sql you are familiar with at least one of the cloud computing platforms gcp, aws, azure you are well versed in software and ai development lifecycles you are a collaborative, creative, open minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ml driven models through an iterative approach great to haves masters or phd degree in a quantitative field such as math, statistics, computer science, economics, or data science data visualization experience data studio, tableau, powerbi, domo data environments experience ms sql, oracle g suite experience experience with agile methodology and team based software development workflows a bit about us our business is connecting canadians. our social impact is using our world leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. when you join our team, you re helping us make the future friendly. we re committed to diversity and equitable access to employment opportunities based on ability your unique contributions and talents will be valued and respected here. primary location ca ab calgary other locations ca ab edmonton schedule full time","['prediction', 'tableau', 'hypothesis', 'pytorch', 'tensorflow', 'data visualization', 'github', 'data analytics', 'python', 'sql', 'statistics', 'keras', 'gcp', 'time series analysis', 'software', 'data science', 'development tools', 'pandas', 'analytics', 'software development', 'aws', 'cloud computing', 'data mining', 'jupyter', 'analytical techniques', 'machine learning', 'testing', 'numpy', 'algorithms', 'forecasting', 'model', 'economics', 'data solutions', 'nlp', 'computer science', 'optimization', 'modeling', 'data management', 'ai']","['jupyter', 'sql', 'python', 'gcp', 'keras', 'tableau', 'pytorch', 'big', 'sci', 'numpy', 'nlp', 'pandas', 'aws', 'domo']","['prediction', 'hypothesis', 'tensorflow', 'data visualization', 'github', 'data analytics', 'statistics', 'time series analysis', 'software', 'data science', 'software development', 'analytics', 'cloud computing', 'data mining', 'analytical techniques', 'machine learning', 'testing', 'performance', 'predictive', 'algorithms', 'forecasting', 'model', 'methodology', 'economics', 'data solutions', 'computer science', 'optimization', 'modeling', 'data management', 'ai']","['validation', 'environment', 'marketing', 'art', 'finance', 'customer experience']"
50,66,Senior Clinical Scientist - Oncology - Home Based,"we believe that our people are the future of the industry. we provide a culture in which our employees can enjoy personal satisfaction, professional achievement and have the ability to strategically map out long term career plans. if you re ready to be a part of something inspiring join us and discover your pra. who are we we are pra. we are 20,000 employees strong, operating in more than 90 countries. we are committed to saving lives and we are constantly striving to be the best at what we do. our impact is real and we see it every single day. we are getting life saving drugs into the hands of those who need them most. who are you you are a leader that isn t afraid to delegate, but also isn t afraid to get your hands dirty. you look for new and innovative ways to problem solve. you are the ultimate planner and coordinator and are an excellent communicator. you have a serious passion for clinical development. you never settle for what is, but are always pushing clinical development forward to what it could be. you motivate others to do the same. most of all, you want to do it in a place where you re more than an employee number. a place you love working. still here good. because if this is you, we d really like to meet you. the sr clinical scientist will be accountable for the clinical or scientific execution of the clinical protocol. responsibilities what you will be doing may lead or support a study or studies, depending on size or complexity. if lead, accountable for the clinical or scientific execution of the protocol. as lead, will be responsible for the following clinical point of contact for scientific issues or questions for internal and external stakeholders responsible for trial design and endpoint development in collaboration with cd leads the medical monitoring team in performing mm activities, including development of the medical monitoring plan and review of sae reports sets up or supports sac, dmc, adjudication committees protocols or amendments collaborates with medical writer, participates in governance committee review authors protocol clarification letters contributor to study specific documents reviews or updates informed consent provides scientific input to sm for data management activities monitors data issues requiring clinical input monitors central lab reports and other external data for safety and critical values prepares scientific slides, attends and presents protocol information at investigator meeting scientific lead on clinical trial team reviews specs, initiates allocation request form and approval schedule in allocation schedule generation system coordinates planning of lab, bio specimens and imaging specifications co authors newsletters with sm participates in database lock activities collaboratively plans csrs, ctds or wmas with medical writing supports publications or presentations as needed reconciles and review all protocol deviation classifications in spectrum assesses and prepares protocol deviation list for csr collaborates with medical writing to develop trial results communication for investigators provides scientific assessment for operational reviews supports sm or mw activities as needed to achieve ctt deliverables. provides clinical specifications to sm to support interactions with external vendors may act as mentor to other css qualifications what you need to have educational requirements bs or ba in life sciences with 7 yrs clinical research experience ms or phd in life sciences with 5 years clinical research experience if no degree in life sciences, must have significant experience in clinical development minimum years of experience minimum 2 years pharmaceutical experience with demonstrated leadership responsibilities required. medical monitoring experience required oncology experience required excellent excel and pp skills required excellent written and oral communication skills ability to travel up to 15 to qualify, applicants must be legally authorized to work in the canada or us, and should not require, now or in the future, sponsorship for employment visa status position based remote in us or canada pra is an eeo or aa employer and is committed to providing opportunities to minorities, women, veterans and individuals with disabilities. options apply for this job onlineapply share sorry the share function is not working properly at this moment. please refresh the page and try again later. share on your newsfeed connect with us","['css', 'cd', 'clinical development', 'specifications', 'data management', 'specs', 'map']","['css', 'map']","['cd', 'clinical development', 'specifications', 'data management', 'specs', 'planning']","['presentations', 'design', 'life sciences', 'clinical research', 'governance', 'sponsorship', 'oncology', 'assessment', 'committees']"
51,67,Data Scientist,"the ctc personalization customer analytics team is the central hub for engaging consumers with exciting and inspirational loyalty and product offers through better use of customer data, driving incremental sales and profit. the promo analytics and operations team is accountable for creating a high performance, cross banner, silo free source of all customer data enabling quick and efficient customer insights, audience creation, customer journey analyses and advanced customer modelling. the data scientist role provides technical leadership in all facets of the project, from selecting key customer features and interactions to ensuring accurate data blending to deriving new customer attributes through descriptive and predictive analytics through a deep understanding of applying the data science lifecycle to customer modelling. the data scientist will be the subject matter expert in combining customer related data sources, collaborating with teams that produce customer insights, deploy unique personalized offers directly to customers and developing other customer data products. the dynamic environment requires individuals with a cross functional background, excellent organizational skills, experience working in an agile project environment, advanced analytical ability, strong communication skills to deal effectively with stakeholders and the ability to work effectively in a team as well as independently. the primary responsibilities of the data scientist include efficiently and accurately integrate customer data from a variety of organizational systems. derive customer attributes and intents through novel uses of the data at hand and models to describe and predict customer behaviour, as well as a deep understanding of customer behaviour. ensure generated insights meet standards of analytical and statistical rigour, highlighting gaps where necessary. provide mentorship to team members on data, code, and data science best practices. lead the creation of efficient, cost effective high availability pipelines. work with it teams to ensure that project needs are met in the next generation of ctc data platforms. provide ad hoc analytics and recommendations for action as needed. qualifications professional post secondary education at the master s level, with 2 5 years experience in a business environment. extensive knowledge of statistics, predictive analytics and data science techniques to improve customer understanding through creative problem solving and modelling. experience leading analytical projects with iterative improvement in a fast paced environment. ability to understand what data means about a customer. technical strong familiarity with statistical modeling tools and data science libraries. python sql are required. experience building dashboards and visualizations in enterprise grade bi tools. good working knowledge of relational and non relational databases in big data and or or cloud environments . intermediate knowledge of standard desktop tools such as excel and powerpoint interpersonal provides a positive influence and excels in a fast paced team environment with the ability to take on leadership responsibilities while embracing and driving innovative solutions that improve the performance of the team. advanced written and verbal communication skills. strong interpersonal skills with the ability to embrace and action constructive feedback positively. exceptional attention to detail. strong ability to work with complex and evolving systems and extensive and varied data. manage changing or conflicting priorities and make effective decisions quickly. adapt to rapid and continuous change to project requirements and priorities. canadian tire is an equal opportunity employer. we are committed to a diverse and inclusive workplace for all. we recognize that our future success depends on the perspectives and contributions of all our employees their diverse backgrounds, abilities and experiences make our business stronger. if you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. all accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. ctr marketing ontario toronto permanent full time job posting jun 21, 2021, 10 42 38 am","['personalization', 'high availability', 'dashboards', 'big data', 'technical leadership', 'ct', 'sql', 'python', 'statistics', 'data science', 'analytics', 'customer data', 'pipelines', 'customer', 'relational databases', 'data products', 'statistical', 'bi', 'modeling']","['sql', 'high availability', 'python', 'bi', 'big data', 'predictive', 'pipelines']","['personalization', 'ctc', 'statistics', 'relational databases', 'data products', 'dashboards', 'data science', 'analytics', 'statistical', 'modeling', 'customer data', 'analytical', 'technical leadership', 'customer']","['environment', 'education', 'marketing', 'sales', 'constructive feedback', 'candidate experience']"
52,69,"Data Scientist, Memberships Modelling","since being founded in 2011, prodigy education has grown from 3,000 local users to more than 100 million registered users worldwide. as one of the fastest growing edtech startups in north america, prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. anyone with an internet connection is welcome to create a free account for prodigy s popular math game for grades 1 to 8. prodigy education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. for more information visit our passion is our mission to help every student in the world love learning our data team is scaling rapidly as we continue to hit our product and growth milestones the work you do will aid the educational advancement of millions of students. you will have the chance to apply your analytics skills to not only help kids learn but also help our product and leadership teams to make better decisions. we are looking for a modelling and ml expert to join our growing team. you will have the chance to apply your data analysis, modelling, and coding skills to help our data, finance, and executive teams better understand our business and build the best possible company strategy. you will develop advanced models to analyze our paid memberships, and empower all teams with actionable insights on user conversion, churn, and engagement. your impact work with stakeholders, data scientists, and developers to create useful models to analyze our paid memberships. leverage data analytics and quantitative analysis to monitor the model s performance and identify new features to improve kpis. develop a deep understanding of our internal and external users to identify how our models can help solve their pain points. iterate upon successful mvps to ensure the user experience and code quality matches our internal standards. collaborate with key cross departmental stakeholders to maintain technical product roadmaps, prioritize requests, and ensure that business goals are being met. effectively scope projects so that they are lean, but also add enough value to validate your hypotheses and meet business needs. help our teams explore and understand our business and our users. design and develop a variety of metrics and models to inform the impact of company activities and lines of business. work on a variety of giant datasets, from their development and manipulation to visualizing them via polished dashboards. communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non technical backgrounds. who you are at least 3 years demonstrated experience with data science and modelling. specific experience delivering revenue related models which leverage analytics and machine learning good written and verbal communication skills with the ability to present a strong rationale for product decisions applied computational and mathematical model builder. expert skills and knowledge of sql and python programming languages. demonstrated application of model building and analytics to financially relevant problems. a team and customer centric mindset. passion for solving hard problems and building a great technical product, balancing speed and depth for greatest value. experience in business requirements analysis, design, implementation, and testing of solutions. ability to break down large projects into manageable tasks, and leverage agile methodologies such as scrum and kanban experience using analytics and user research to add significant value to a product expertise in working with bi platforms. ability to oversee and work simultaneously on different projects with a variety of timelines. willingness to learn and work in a hyper growth company love for our mission of helping kids everywhere enjoy learning. our core technologies sql python data related technologies such as data lakes and warehouses, spark, databricks, and similar cloud services bonus points for degree in engineering, computer science, stats, mathematics, or related disciplines. demonstrated ability to solve hard mathematical, algorithmic, and statistical problems. expertise in forecasting, time series analysis, user segmentation, financial modelling, and analyzing stripe or similar transaction data. experience working with cloud platforms like aws, gcp, databricks. experience working with a or b testing and experimentation, and applying statistical concepts. significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship. experience in the ed tech or saas industry previous experience scaling in a startup environment what we offer a culture of transparency, where team members are involved in important conversations full health benefits from day one for you and your family, fully covered we are a profitable company, with eligibility to participate in stock options for all full time permanent employees learning and development budget for all full time employees to use towards career growth and development opportunities we recognize 9 5 is not for everyone we offer flexible working hours that will allow you to schedule your work day with a bit more freedom while we operate 100 remotely for the time being, we understand the importance of togetherness. we offer frequent and fun team and company events, to stay connected and in the know. please note during the covid 19 pandemic, in order to keep all our candidates and team members safe, prodigy is operating, hiring and onboarding 100 remotely for the time being. come as you are. we believe the power of our collective potential will transform education. we are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. we welcome applications from people from all underrepresented groups, including people of any gender, age, or religion, members of the lgbtqia2 community, bipoc and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of prodigy education. if you feel like you don t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we d still love for you to apply we are an equal opportunity employer and are committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act, 2005 . prodigy education will provide accommodations to job applicants with disabilities throughout the recruitment process. if you require accommodation, please notify us and we will work with you to meet your needs.","['model building', 'requirements analysis', 'user experience', 'dashboards', 'data analytics', 'sql', 'python', 'kanban', 'gcp', 'time series analysis', 'software', 'data science', 'analytics', 'saas', 'aws', 'machine learning', 'testing', 'scrum', 'data analysis', 'rest', 'forecasting', 'edtech', 'cloud services', 'agile methodologies', 'programming languages', 'bi', 'datasets', 'computer science', 'mathematics']","['sql', 'python', 'gcp', 'programming languages', 'bi', 'data lakes', 'aws']","['model building', 'requirements analysis', 'user experience', 'dashboards', 'data analytics', 'kanban', 'time series analysis', 'software', 'data science', 'analytics', 'saas', 'hit', 'machine learning', 'quantitative analysis', 'testing', 'scrum', 'data analysis', 'rest', 'forecasting', 'edtech', 'cloud services', 'agile methodologies', 'datasets', 'computer science', 'mathematics']","['research projects', 'environment', 'large projects', 'events', 'education', 'metrics', 'entrepreneurship', 'onboarding', 'design', 'finance', 'user research', 'startups', 'hiring']"
53,71,Data Scientist / Machine Learning Expert,"this is an immediate vacancy. we are looking for team members who can join us immediately and work 35 hours a week. flexible schedule possible. all work is remote. we are looking for an enthusiastic and self motivated addition to our growing engineering team. the position offers a unique opportunity to be part of a small, fast growing, challenging environment, that takes on financial literacy and entrepreneurship education around the world. responsibilities you ll be working with frontend and backend engineers building company projects build end to end machine learning solutions to solve complex customer problems working closely with infrastructure architects to design scalable and cost effective solutions develop measurements and feedback systems requirements a degree in computer science, statistics, or related fields school transcript required strong math and statistics background high proficiency in python familiarity with django, algorithmic trading, or javascript mandated by the government to hire only canadian citizens or pr card holders under the age of 30. if you re passionate about data science, and are eager to learn and grow, please apply contract length 10 months part time hours 35 per week job types part time, contract salary 18.00 per hour benefits work from home schedule day shift education bachelor s degree experience data mining 1 year statistics 1 year machine learning 1 year language english licence or certification canadian citizenship or pr card and you are under 30 work remotely yes","['data mining', 'python', 'machine learning', 'statistics', 'financial literacy', 'data science', 'computer science', 'javascript', 'measurements', 'django']","['javascript', 'python', 'django']","['data mining', 'machine learning', 'statistics', 'data science', 'computer science', 'algorithmic', 'measurements']","['environment', 'education', 'entrepreneurship', 'trading', 'design', 'government']"
54,72,Data Scientist,"job summary define, develop and lead a data science program which identifies exploitation opportunities, and provides solutions and capabilities to address them. conduct research and recommend potential initiatives to analysts, and branch management and senior executive staff. autonomously find, enrich, transform, interpret, and exploit data to create intelligence products. act as a service representative on joint projects related to data science and participate in collaborative efforts where applicable. provide mentorship and guidance to fellow data scientists and data exploitation analysts, regarding intelligence analysis and associated activities pursued in response to the mandate. recommend new data exploitation projects in annual work plans by identifying analytical gaps and suitable solutions. regularly update knowledge of academic and industry data science practices and standards. effectively communicate and present findings to specialists, management and non technical audiences. clearly document methodologies employed in research and data exploitation solutions. education undergraduate degree in mathematics statistics computer science computer engineering field of study related to data analytics the educational program must be from an accredited learning institution recognized in canada. if you completed a program outside of canada you will be required to obtain proof of a canadian equivalency at your expense through a recognized credential assessment service. note any higher level of education could be recognized as experience. experience undergraduate degree and seven years of experience the candidate must possess seven years of experience in data science, data analytics or data mining. please note that out of the seven years of relevant experience required, at least four years must have been gained in data science specifically. the candidate must possess recent and significant experience in the following experience performing complex data exploitation on large volumes of data to provide tactical and strategic insights directly to analysts, business owners, and decision makers. experience gathering requirements and identifying opportunities to apply data science towards business objectives. experience prototyping and developing data exploitation capabilities using python, in a jupyter environment. experience visualizing analytics, writing reports, producing functional notebooks, and designing and delivering presentations. experience working with one or more of the following technologies tensorflow, pytorch, spark, scala. candidates must also possess recent and significant experience in at least two of the following experience with supervised and unsupervised machine learning. experience in the creation and implementation of algorithms and statistical techniques to resolve data science problems. experience with text analytics and natural language processing . experience in the design, creation, and implementation of graph analytics. experience with complex data processing for time series and patterns of life analyses. recent experience is defined as experience acquired within the last five years. significant experience is defined as the depth and breadth of experience that would normally be acquired by a person in a position where the performance of these duties constitutes his or her main functions over that period of time. competencies communication initiative innovation creativity ingenuity analytical skills coaching conditions of employment not applicable notes the majority of work in our organization must be done in the office and cannot be performed at home. a written exam will be administered. if successful, you will be invited to an interview. the exam will serve to evaluate your technical knowledge as it pertains to the position. reference links salary grade breakdown security requirements candidates must be eligible to receive an enhanced top secret security clearance. the process involves a security interview, a polygraph, and a background investigation that includes credit and financial verifications. the use of illegal drugs is a criminal offense. drug use is an important factor considered in your reliability and suitability assessment during the selection process. therefore it is important not to use any illegal drugs from the time you submit your application. others important applicants must clearly demonstrate in their application how they meet each education and experience criteria. failure to do so will result in the applicant being screened out of the career opportunity. csis is a separate employer and is not subject to the public service employment act . csis has its own classification, compensation system, and a different staffing regime. as such, we use a different staffing process and terminology. csis is committed to diversity and inclusion and the equitable participation of all canadians. should you require accommodation in relation to a disability, please tell us at the beginning of the selection process. this information will be kept confidential. the personal information provided in your application is protected under the privacy act and will be held in personal information bank sis or p pu 025. we thank all applicants for their interest in csis. however, only those who are selected for further consideration will be contacted.","['analytical skills', 'pytorch', 'tensorflow', 'data analytics', 'python', 'statistics', 'data processing', 'scala', 'data science', 'analytics', 'data mining', 'jupyter', 'machine learning', 'computer engineering', 'terminology', 'graph', 'algorithms', 'language processing', 'prototyping', 'security', 'computer science', 'mathematics', 'investigation']","['pytorch', 'jupyter', 'python', 'scala']","['analytical skills', 'strategic insights', 'tensorflow', 'natural', 'data analytics', 'statistics', 'data processing', 'data science', 'analytics', 'text', 'data mining', 'machine learning', 'computer engineering', 'terminology', 'graph', 'algorithms', 'language processing', 'prototyping', 'security', 'computer science', 'mathematics', 'investigation']","['environment', 'exploit', 'compensation', 'education', 'drug use', 'presentations', 'design', 'assessment']"
55,73,Data scientist,"overview as an engineering service provider, we serve clients who have specific needs in the areas of machine learning, data analysis and computer vision. as such, we are looking for a capable data scientist to join the inference team at kinsol research and offer his or her expertise in statistical modeling and machine learning. key responsibilities build statistical models and inference systems using multiple data sources create visualizations and documentation to explain complex concepts to software analysts and stakeholders provide expertise on quantitative modeling for the broader analytics group communicate results and findings derived from data throughout the organization in a clear, concise way collaborate with other areas of the company on long term projects learn, implement and share new methodologies and keep up to date with current trends in the area qualifications phd or msc degree in computer science, engineering, applied mathematics, physics or statistics 2 years of hands on experience with python practical experience in applying machine learning, especially developing models and inference systems experience in scaling up smaller projects and sharing work collaboratively across a wider team sufficient data warehouse and non relational data techniques knowledge to work effectively with engineering partners comfortable navigating new codebases in a unix environment additional assets exposure to amazon web services, ability to design decoupled, fault tolerant, highly scalable, highly available system architectures experience with agile development and collaborative software practices experience with docker containers and continuous integration practices contact information please send a resume and cover letter in a single pdf to with attn data scientist in the subject line.","['python', 'machine learning', 'statistics', 'amazon web services', 'software', 'quantitative', 'physics', 'computer vision', 'data analysis', 'statistical', 'documentation', 'analytics', 'computer science', 'modeling', 'unix', 'applied mathematics', 'integration']","['unix', 'python', 'documentation', 'amazon web services']","['machine learning', 'statistics', 'continuous', 'software', 'quantitative', 'physics', 'computer vision', 'relational data', 'data analysis', 'statistical', 'analytics', 'computer science', 'agile development', 'modeling', 'integration', 'applied mathematics']","['environment', 'design']"
56,74,in vitro DMPK Associate Scientist or Scientist,"paraza pharma inc. is an innovative company with an aim to significantly improve the efficiency of the drug discovery process from lead identification through lead optimization to development candidates. with an excellent team of highly creative drug discovery scientists trained in world reputed laboratories and deep experience in drug discovery and development from pharmaceutical companies such as merck, pfizer, wyeth, boehringer ingelheim, astrazeneca and schering plough, we offer collaborative opportunities to provide most efficient solutions. we are currently seeking for an in vitro dmpk associate scientist or scientist for a full time job position. job description as a member of the drug metabolism and pharmacokinetic group, the candidate will be in charge of performing standardized protocols, aiming at the screening and profiling of drug candidates on the basis of their in vitro adme properties. the candidate will also be involved in the validation and or or establishment of new in vitro assays. the work will mainly consist of classical bench work and cell culture and data analysis. the successful candidate possesses 3 to 5 years of experience in dmpk or in a related field with a good knowledge of the different biological mechanisms involved in the absorption, distribution, metabolism and excretion of novel chemical entity. experience in cell culture will be considered an asset. good communication skills and capacity to deliver results in a stringent schedule while maintaining excellent work quality is essential. major responsibilities culture and treatment of different cell lines. participate actively in compound screening campaigns by performing in vitro assessments involving biological matrices. data analysis and reporting. participate actively in the establishment or improvement of experimental methodologies. qualifications university degree in biochemistry, biology, pharmacology or related scientific field 3 to 5 years of experience in the industry demonstrated skills working with cells demonstrated team work spirit with capability to succeed in a fast paced environment, working on multiple projects with constantly changing priorities and deadlines. application deadline 2021 06 01 expected start date 2021 06 01 job types full time, permanent benefits assurance dentaire assurance invalidit assurance maladie compl mentaire assurance vie assurance vision cong s de vacances et compensatoires programme d aide aux employ s reer collectif r gime d achat d actions stationnement sur place schedule 8 heures du lundi au vendredi quart de jour work remotely no","['reporting', 'matrices', 'screening', 'optimization', 'data analysis']",[],"['reporting', 'matrices', 'screening', 'optimization', 'data analysis']","['pharmacology', 'validation', 'environment', 'biology', 'in vitro', 'biochemistry', 'drug discoveryck', 'campaigns', 'lead', 'cell culture', 'drug discovery', 'dmpk', 'dmp']"
57,75,"Data Scientist, Shopping","about pinterest millions of people across the world come to pinterest to find new ideas every day. it s where they get inspiration, dream about new possibilities and plan for what matters most. our mission is to help those people find their inspiration and create a life they love. in your role, you ll be challenged to take on work that upholds this mission and pushes pinterest forward. you ll grow as a person and leader in your field, all the while helping pinners make their lives better in the positive corner of the internet. we re looking for a data scientist to join the shopping team with the goal of building a successful shopping product at pinterest. you ll apply quantitative analysis, data mining and data visualization techniques to shape the strategy of the shopping experience at pinterest. what you ll do design advanced experiments for shopping product and shopping monetization perform deep dive analysis to understand and optimize the key levers of our shopping product team partner closely with eng team to improve shopping optimization and recommendation systems design core metrics that serve as the north stars for team efforts and model trade off decisions across product areas work with product managers and engineers to design data products, prove their value by running experiments and release into production what we re looking for ability to manipulate large data sets with high dimensionality and complexity fluency in sql and python or r 4 years experience doing quantitative analysis or statistical modeling strong experimentation expertise knowledgeable about best practices around data manipulation, building data pipelines, feature engineering and creating dashboards ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams to quickly turn insights into actions excellent communication skills and ability to explain learnings to both technical and non technical partners. experience in shopping or ecommerce products will be preferred li kp1 not specified 0","['data mining', 'sql', 'python', 'data pipelines', 'data products', 'data visualization', 'data manipulation', 'dashboards', 'statistical', 'optimization', 'modeling', 'r']","['sql', 'python', 'data manipulation', 'r']","['data mining', 'data pipelines', 'quantitative analysis', 'data visualization', 'dashboards', 'statistical', 'optimization', 'modeling', 'feature', 'data products dimensionality']","['design', 'metrics']"
58,76,Data Scientist,"data scientist sequence bio is a dedicated team of scientists, researchers, programmers, and business leaders driven to change the future of healthcare and accelerate the discovery of better, safer medicines and disease treatments. but, we need your help we are looking for individuals who are highly motivated, solutions focused, team oriented and passionate about adding value to a fast paced, growing company committed to benefiting the lives of individuals, families, and communities in newfoundland and labrador for generations to come. want to help make a bigger impact apply today overview of the role the data science and analytics team s work is focused on the analysis of data from whole genome genotyping, ngs whole genome sequencing, rnaseq and other omic s technologies that will be used to help identify the population structure of our cohort enabling sequence bio to search for novel drug targets to accelerate the development of better, safer medicines and disease treatments. this team is also responsible for developing tools and pipelines, implementing external, best practice, solutions into our discovery workflows and supporting all aspects of the analysis of sequence bio s research activities. reporting to the vice president, research, data science and analytics, the data scientist will be responsible for analyzing and structuring all aspects of the genomic and phenotypic data produced as part of our research objectives and play an integral role in supporting and working with the company s information technology, cohort operations and research teams to maintain a well founded, innovative and secure it infrastructure. they will also be responsible for the continued optimization of sequence bio s research and analysis platform, which will consist of a broad set of cutting edge tools and algorithms built to exploit big data architecture. the platform will use machine learning methodologies to conduct hypothesis and non hypothesis based pattern recognition to discover new biomarkers. ideal candidate bsc or msc in statistics, mathematics, computer science or another quantitative field. 1 3 years hands on data science and statistics experience. experience in the life sciences or health care industry is considered an asset. strong analytical and problem solving skills. excellent written and verbal communication skills for coordinating across teams. proven experience using statistical computer languages to manipulate data and draw insights from large data sets experience working with aws preferred. demonstrated experience working with and creating data architectures. a drive to learn and grow with a rapidly evolving early stage company. responsibilities reports to the vp, research, data science and analytics. provide input on bioinformatic tools, solutions and pipelines that sequence bio needs to develop or implement as part of sequence bio s research activities. implement and optimize algorithms for use by sequence bio and its wider community. work with scientists, bioinformaticians, statisticians, software engineers, systems analysts and clinical team members to develop, test and improve new genomic analysis techniques. organize, support, and collaborate across departments to meet project deliverables and timelines ensure team data analysis complies with company and international analysis and quality standards. other duties as required by your team lead or the executive team. willing to take initiative and create and take on new responsibilities as our company continues to grow. working at sequence bio at sequence bio, we do things a bit differently. and that makes sense, because when you re trying to transform drug discovery, you can t do the same old things again and again. the same goes for how we work. our culture is evolving and progressive, and the procedures, policies and processes we follow encourage success, foster creativity, and embrace innovation. an appreciation for the latest technology tools, and a commitment to flexible working hours during peak project deployment, is required. our commitment ethics, privacy and security excellence is rooted in everything we do at sequence bio. we promise to be transparent about our information policies and practices, and to return benefits to newfoundland and labrador. all employees must uphold the company s commitment in all they do. sequence bio is proud to be an equal opportunity employer. we recognize the importance and value of a diverse workforce and we are committed to creating an inclusive and respectful environment for all employees. if you require any accommodation to participate in the recruitment and selection process, please reach out to and we will work with you to meet your needs. apply before july 9th, 2021 5 00 pm newfoundland time.","['analyticsing', 'machine learning', 'statistics', 'software', 'reporting', 'security', 'data science', 'computer science', 'analytics', 'mathematics', 'optimization', 'big data', 'information technology', 'pattern recognition', 'pipelines', 'aws', 'algorithms', 'data analysis']","['pipelines', 'big data', 'aws']","['machine learning', 'statistics', 'software', 'reporting', 'security', 'data science', 'technology tools', 'computer science', 'analytics', 'genotyping', 'optimization', 'mathematics', 'information technology', 'pattern recognition', 'data analysis', 'algorithms']","['environment', 'sequencing', 'exploit', 'healthcare', 'life sciences', 'drug discovery', 'architecture']"
59,78,Data Scientist,"applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex, high volume data from a variety of sources. analyzes large quantities of data and presents insights and predictions to support management planning, execution and monitoring of business decisions. builds and maintains the production execution of data science into enterprise systems and architecture. key accountabilities include research, design and develop state of the art machine learning and forecasting solutions. lead the research, design, and construction of predictive models to enhance understanding of moneris core business and adjacent opportunities. work is conducted based on an understanding of specific business priorities and strategies. partner with data engineering and data analytics teams to inform the design of data infrastructure for data science build and perfect robust statistical techniques to achieve desired accuracy for existing projects and create solutions that help moneris exceed current performance levels participate in creating the structure for production data science workloads across the enterprise including leading on best practices, pipeline controls, and overall monitoring and management of model deployment. develop and roll out data science projects in production and lead the implementation of new tools and processes with business critical production accountability minimum position requirements degree in data science, statistics, mathematics, computer science, engineering, or other related fields. 3 years of experience in data science, statistical modeling, advanced analytics, or software development. you must be fluent in python and are able to design and develop sophisticated solutions with minimal supervision. strong proficiency with python and sql. experience with spark, databricks, and azure eco system is a big plus. strong proficiency with the git, vs code, jupyter suite, and data visualization tools and libraries such as tableau, powerbi, matplotlib, plotly, etc. this position requires advanced programming skills in python. at least 50 of the time will be spent on building new and improving existing solutions in python or spark.","['business analysis', 'tableau', 'data infrastructure', 'data visualization', 'data analytics', 'python', 'sql', 'statistics', 'matplotlib', 'data science', 'software development', 'analytics', 'programming', 'data engineering', 'jupyter', 'machine learning', 'enterprise systems', 'statistical', 'forecasting', 'git', 'computer science', 'mathematics', 'modeling']","['jupyter', 'sql', 'python', 'plotly', 'tableau', 'git', 'programming']","['business analysis', 'data infrastructure', 'data visualization', 'data analytics', 'statistics', 'support', 'matplotlib', 'data science', 'software development', 'analytics', 'data engineering', 'management', 'machine learning', 'enterprise systems', 'statistical', 'forecasting', 'planning', 'computer science', 'mathematics', 'modeling']","['art', 'design', 'construction', 'and', 'architecture']"
60,79,Data Scientist,"data scientist montreal, qc, canada req 1220 monday, june 21, 2021 edf renewables north america, a subsidiary of edf renewables, is a leading north american independent power producer boasting over 30 years of experience across a broad spectrum of services. our mission is to deliver renewable solutions to lead the transition to a sustainable energy future. scope of position the data scientist will lead and participate in the development, validation and delivery of algorithms, statistical models and reporting tools in the context of edfr s wind energy team. the employee will solve complex analytical problems and develop automated tools to streamline established wind assessment methodologies. this position will interact with internal customers and stakeholders to ensure project success while ensuring deadlines are met. the incumbent must be comfortable with project management as well as designing, creating, and deploying the data architecture to deliver solutions. ideal candidates will possess a combination of business knowledge, technical skills, and people skills to define and guide data strategy for the resource assessment team and maximize user adoption of any new tools or models put forth. working conditions approximately 95 of time is spent in the office environment, utilizing computers, servers, peripheral equipment, phones, and general office equipment. approximately 5 of the time is spent traveling outside of the office to other edf renewables locations or vendor locations located in the us, canada and mexico, for the purpose of project related work, and to attend conferences, trade shows, and professional development events. responsibilities 60 data science activities contribute to r d efforts in the energy assessment field using pre construction and operational data. collaborates with business partners to understand their problems and goals, develop predictive modeling, statistical analysis, data reports and performance metrics. use programming skills to explore, examine and interpret large volumes of data in various forms. develops and uses algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes. performs analyses of structured and unstructured data to solve multiple complex business problems utilizing advanced statistical techniques and mathematical analyses and broad knowledge of the organization and industry. interacts with internal and external peers and managers to exchange complex information related to areas of specialization. conducts data analysis and research, designs algorithm, recommends ongoing improvements to existing applications to help find new information for business decisions. 25 resource assessment efficiency, methodology, and research initiatives maintain ownership of edfr s automated wind resource assessment methodology code library collaborates with team members to ensure such a tool continually meets the group s needs optimize performance of tools where appropriate for efficiency gains and increased robustness. brings data science techniques and machine learning algorithms to bear in both pre construction development analyses and post construction operational analyses. integrates analysis tools to leverage existing databases and applications that store turbine data, met data, wind farm production data, and energy estimate results develops innovative and effective data driven algorithms and applications for energy assessment using advanced statistical and predictive modelling techniques. provides training or maintenance or bug fixes or updates for in house proprietary software packages and develops new modules to meet ongoing increasing needs from the energy assessment team. 10 resource assessment project work estimates energy production for wind projects under development designs turbine layouts to optimize energy production and minimize construction costs analyzes and solves resource assessment and development challenges analyzes data to identify and evaluate new sites for future projects communicates site characteristics, energy production potential, and risks to members of the senior management team and regional developers supports the key project development functions for all projects, including financial feasibility analysis, permitting, engineering, due diligence, project legal review, etc. 5 other duties as assigned qualifications bachelor s degree in mathematics, statistics, computer science, engineering, or related field required. master s degree or phd, a plus. strong interest in renewable energy and the environment minimum of 3 years experience providing advanced analytics within a business setting preferred. 1 year of data science implementation. able to facilitate discussions between small groups of technical leaders, recognize issues of conflict and inconsistency between data requirements, and pursue a resolution of these issues 2 or more years supporting progressively complex projects in predictive modeling, data analytics, machine learning, and big data technologies. minimum 2 years experience in sas or sql or other programming languages such as python, fortran or other mvc languages. ability to work with large data sets from multiple data sources. strong knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources. anticipates and prevents problems and roadblocks before they occur. demonstrates the ability to communicate technical ideas and results to non technical clients in written and verbal form. ability to work cooperatively as part of a team, as well as independently under own initiative effective communications skills that enable successful advocacy and alignment with a long term vision self starter, motivated, able to manage multiple priorities and tasks in a dynamic environment with a good understanding of software development standards and best practices. other details job function i03 pay type salary","['unstructured data', 'databases', 'big data', 'statistical analysis', 'data analytics', 'sql', 'python', 'statistics', 'software', 'reporting', 'data science', 'software development', 'data', 'programming', 'analytics', 'sas', 'servers', 'machine learning', 'mvc', 'project work', 'data analysis', 'algorithms', 'fortran', 'due diligence', 'programming languages', 'computer science', 'mathematics', 'modeling', 'r']","['sql', 'python', 'databases', 'programming languages', 'fortran', 'mvc', 'programming', 'big data', 'sas']","['unstructured data', 'project', 'modeling', 'statistical analysis', 'data analytics', 'statistics', 'software', 'reporting', 'data science', 'software development', 'data', 'analytics', 'servers', 'machine learning', 'predictive', 'data analysis', 'algorithms', 'due diligence', 'computer science', 'mathematics', 'methodology']","['internal customers', 'environment', 'trade shows', 'forms', 'project management', 'business knowledge', 'sustainable energy', 'research initiatives', 'legal', 'renewable energy', 'assessment', 'project development', 'validation', 'metrics', 'performance', 'construction', 'adoption', 'energy production', 'architecture', 'wind energy', 'events']"
61,80,Data Scientist,"who we are at criteo, our culture is as unique as it is diverse. with offices around the world, our incredible team of 2,600 criteos collaborates to create an open inclusive environment. we work together to achieve our goals, push boundaries, and be impactful. all of this supports us in our mission to power the world s marketers with trusted impactful advertising. we are looking for a highly motivated data scientist to contribute to the design and implementation of our commerce insights product, with a solid understanding of data science and machine learning algorithms. the commerce insights product has a wide range of data science challenges. the ideal candidate will have an extensive experience working with data, analyzing large data sets, with outstanding skills to identify and quantify opportunities for optimizations. you must thrive in a start up environment, be proactive, detail oriented and eager to learn and keep up with an evolving product landscape. you must have good judgement in identifying the right approach to a problem. how you ll make an impact you will contribute to the design and implementation of solutions to problems we encounter in building the commerce insights product. contribute to the development of a platform which collects and processes large amounts of data used in commerce insights product. gather and analyze data to extract valuable information relevant to prediction models. identify key prediction problems and propose innovating solutions. report, visualize and communicate results. contribute to the exploration and creation of new scientific understanding. work closely to satisfy stakeholders on other product as well as other r d teams to net our clients optimal performance results. what we re looking for bs or ms in data science, computer science, statistics, or a related field. 2 years of experience dealing with big datasets using tools that run on hadoop. 2 years of programming experience, in python or another language . experience developing and extending systems of moderate complexity a passion for shipping quality high performance code a strong sense of ownership and a dislike for passing the buck a problem solver, a fixer, and a creative technologist. we believe data analytics is a talent and a passion, not just a skill. be resourceful. a strong communicator and a team player who can work efficiently with others bonus skills practical experience writing map or reduce, spark or hive or presto or using a machine learning frameworks like tensorflow. familiarity with java, or scala experience working with product owners to understand and implement business requirements a demonstrated track record of taking initiative and acting as a leader experience working well in a very fast paced and continuously changing environment at criteo, we are committed to creating an environment where all criteos feel a sense of belonging. we nourish our diversity by listening to all cultures within criteo and there are many. we are proud to be a global team and conscious that it takes people with different perspectives, thoughts and cultures to succeed. criteo collects your personal data for the purposes of managing criteo s recruitment related activities. consequently, criteo may use your personal data in relation to the evaluation and selection of applicants. your information will be accessible to the different criteo entities across the world. by clicking the apply button you expressly give your consent.","['prediction', 'data analytics', 'python', 'machine learning', 'statistics', 'scala', 'datasets', 'hadoop', 'tensorflow', 'data science', 'hive', 'java', 'computer science', 'programming', 'algorithms', 'solver', 'map']","['python', 'scala', 'hadoop', 'big', 'java', 'programming', 'hive', 'solver', 'map', 'r']","['prediction', 'data analytics', 'machine learning', 'statistics', 'datasets', 'tensorflow', 'data science', 'computer science', 'personal data', 'algorithms']","['environment', 'commerce', 'advertising', 'design', 'acting']"
62,81,Data Scientist,"the company you ll join at carta we create owners and make private markets liquid. we live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment others live on the debt stack and may work their entire lives for a company and retire only with the cash they ve managed to save from their paychecks. our contribution to solving the wealth inequality problem is moving people from the debt stack to the equity stack. by making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners. at carta, we are helpful, transparent, fair, and kind. we are relentless executors, unconventional thinkers, and masters of our craft. to learn more, here is what one of our investors wrote about leading our series f. the team you ll work with our mission is to enable data driven decisions and products across carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. this is a foundational role in carta s fast growing data organization, working on one of the world s most valuable data sets at one of the fastest growing fintech companies of all time. the team consists of experts in product analytics, machine learning and data engineering. we partner with each other and cartan s across the company to solve impactful problems. our team strongly believes that being helpful accelerates results and we support one another to be successful at carta. the problems you ll solve as a data scientist, ml at carta, you ll partner with domain experts across the company to analyze and explore carta s proprietary data set. you will build statistical models that power new products and accelerate carta s business. examples of responsibilities will include perform exploratory analyses to understand the dynamics of private markets and ownership develop machine learning models to power new financial products and to extract trends from performance of existing products automate monitoring of data distributions to detect and flag anomalies partner with product managers, engineers, and business teams to incorporate data driven insights into decision making own, coordinate, and solve complex, cross functional problems that extend beyond the traditional boundaries of product, analytics, and data science the impact you ll have you will own significant projects directly aligning with carta s company wide initiatives of data products and data quality. your work will empower leaders across the company to make good product decisions and optimize operational efficiency. additionally, you will have the opportunity to set best practices for integrating our ml models into production helping carta s current and future data scientists. about you candidates must have a strong foundation in statistics, be proficient in sql and python, and have an analytical mindset. you have a strong bias towards simplicity, are excited by zero to one projects, and can efficiently communicate findings to leadership. example traits that we value 2 years of industry experience solving complex data problems with descriptive and predictive models proficiency with modern programming languages and datastores a deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance strong written and verbal communication skills, with a particular emphasis on data visualization a collaborative attitude and a helpful personality","['sql', 'python', 'machine learning', 'statistics', 'programming languages', 'data products', 'operational efficiency', 'data visualization', 'data science', 'dynamics', 'analytics', 'data quality', 'data engineering']","['programming languages', 'data quality', 'sql', 'python']","['machine learning', 'statistics', 'data products', 'operational efficiency', 'data visualization', 'data science', 'dynamics', 'analytics', 'data engineering']","['fintech', 'private', 'private markets']"
63,83,Senior Data Scientist (Machine Learning),"mastercard s cyber intelligence organization develops and delivers world class security products and services for customers across the globe. nudata security predicts fraudulent transactions by identifying good users from bad, based on their online behaviour. by analyzing over 38 billion behaviours annually, nudata harnesses the power of behavioural and biometric analysis to empower its clients to predict fraud and verify the user behind the device. this allows clients to predict fraud before a critical decision, reduce customer insult, and investigate bad actors efficiently. role we are looking for a senior data scientist with a minimum of 5 years of experience in a related field to join our team in the vancouver office. the position will be technical in nature where you will provide guidance on the various statistical methods and algorithms used in modeling work by our team, and provide mentorship to others in this area. this is a key role within the team responsible for developing models to support various nudata products, and you ll have exciting responsibilities, including analyzing complex, high volume data from varying sources and identifying key regularities, patterns and trends. prototyping and developing machine learning models in collaboration with an agile, high functioning team. spotting new opportunities in data collection, feature creation, feature selection, model tuning and evaluation practices, and taking those ideas from the first concepts to live product integrations. implementing effective monitoring and benchmarking for model performance comparison. leveraging new research in data modelling to identify opportunities, pioneering algorithms and systems that become key commercial products. maintaining model development pipelines, libraries and machine learning infrastructure. all about you ideally, you are statistically adept. you have studied in a quantitative field at a doctoral or master s level. you have the depth of knowledge required to identify appropriate techniques, follow and create formal proofs, define apt performance measures and adeptly explore or transform data. someone with a strong foundational knowledge of principles underlying common statistical learning techniques such as linear regression, support vector machine, tree based methods, bagging and boosting methods. a strong problem solver with critical thinking skills who can formulate a problem into solution. able to challenge assumptions and validate modeling solutions from a statistical inference perspective. capable of writing complex sql queries to process data. proficient with manipulating and analyzing data to gain meaningful insights using tools such as pandas for python. experienced in creating algorithms and applying machine learning models to solve real business problems. you have the vision to see what the next generation model looks like and can iterate over production models to generate a competitive edge in the market. a capable coder, able to write well abstracted, production quality code in python , r, java and or or c . you re experienced in using cloud services , and machine learning tools . experienced working with large data sets. you understand the benefits of batch processing and parallelization and know how to design a pipeline to scale out machine learning workflows. you have experience working with distributed data processing frameworks such as apache spark. an effective communicator in visual, verbal and spoken channels, able to identify a narrative in complex data and convey clear, actionable findings to different types of audiences. experienced in architecting end to end solutions for production deployment . it also helps if you are collaborative. we do our best work as a team, which means sharing, being open to giving and receiving support and constructive input. evidence based. we work to eliminate assumptions and test our hypotheses, and we value rigour. responsible. we offer the opportunity to drive major projects that protect consumers every day, internationally. we are looking for colleagues who care about that. motivated. we re a team of data scientists with personal and collaborative side projects, and we re looking for someone who shares our enthusiasm. innovative. data science is a continuously growing field. we like our team to keep pushing for new ideas and methods. we are looking for someone who is creative and not just always satisfied with the status quo. due to covid 19, most of our employees are working from home. we ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. we value the safety of each member of our community because we know we re all in this together. mastercard is an inclusive equal employment opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. if you require accommodations or assistance to complete the online application process, please contact and identify the type of accommodation or assistance you are requesting. do not include any medical or health information in this email. the reasonable accommodations team will respond to your email promptly.","['c', 'java', 'batch processing', 'sql', 'python', 'statistical inference', 'data processing', 'data science', 'pandas', 'pipelines', 'solver', 'machine learning', 'apache spark', 'data collection', 'statistical', 'algorithms', 'cloud services', 'model', 'prototyping', 'nudata', 'security', 'linear regression', 'modeling', 'r']","['sql', 'python', 'nu', 'apache spark', 'model development', 'java', 'pandas', 'c', 'pipelines', 'solver', 'r']","['batch processing', 'machine learning', 'prototyping', 'statistical inference', 'security analysis', 'data processing', 'security', 'data collection', 'model tuning', 'linear regression', 'parallelization', 'statistical learning', 'data science', 'modeling', 'algorithms', 'cloud services']","['law', 'onboarding', 'design', 'evidence', 'hiring', 'benchmarking']"
64,84,Staff AI Research Scientist - ATG,"company description servicenow is making the world of work, work better for people. our cloud based platform and solutions deliver digital workflows that create great experiences and unlock productivity for employees and the enterprise. we re growing fast, innovating faster, and making an impact on our customers and employees lives in significant and important ways. with over 6,900 customers, we serve approximately 80 of the fortune 500, and we re on the 2020 list of fortune world s most admired companies. we re looking for people who are ready to roll up their sleeves and help us build on our incredible momentum, our diverse, engaged workforce, and our purpose to make the world of work, work better. learn more on life at now blog and hear from our employees about their experiences working at servicenow. job description the advanced technology group at servicenow is a customer focused innovation group building intelligent software and smart user experiences using existing and emerging data and ai technologies to enable end to end, industry leading work experiences for customers. we are a group of researchers, applied scientists, engineers and product managers with a dual mission. we build and evolve the ai platform, and partner closely with business units to build products and end to end ai powered work experiences for customers. in equal measure, we lay the foundations, research, experiment and de risk ai technologies that unlock new work experiences in the future. team servicenow carries out fundamental research to push the limits of what ai can do for enterprises. you will be part of the element ai research group within the servicenow advanced technology group. role you will do fundamental research on low data machine learning with a focus on natural language processing and multimodal representations, within our low data learning research program. you will have a role of knowledge generation and transfer, as well of maintaining our scientific credibility within the academic community. what you get to do in this role research scientists have the responsibility to set up their own research agenda within the topics of the research team, supervise interns, collaborate with their colleagues and the global ai community. research scientists are also responsible to be on top of the latest trends and discoveries and of sharing their knowledge with their colleagues through internal communications and collaborative projects. research scientists are also responsible to act as scientific advisors for other teams in need for their expertise and contribute to the products of the company. qualifications in order to be successful in this role, we need someone who has a phd in machine learning, deep learning, computer science, artificial intelligence or a related field. a getting things done mindset with a desire to push the boundary of fundamental knowledge experience in natural language understanding and optionally on multimodal representation learning, reinforcement learning, graphs, time series, computer vision, etc. experience and mastery of scientific programming with python and numpy, and optionally also with java, javascript, or r. experience and mastery of deep learning programming in pytorch and optionally with tensorflow. experience contributing to research communities and or or efforts including publishing papers at top international conferences such as desire to work in a diversified team. when applying please provide cv cover letter research statement additional information servicenow is an equal employment opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. if you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at 1 501 8550, or email protected om for assistance. for positions requiring access to technical data subject to export control regulations, including export administration regulations , servicenow may have to obtain export licensing approval from the u.s. government for certain individuals. all employment is contingent upon servicenow obtaining any export license or other approval that may be required by the u.s. government.","['pytorch', 'tensorflow', 'servicenow', 'javascript', 'java', 'python', 'reinforcement', 'software', 'computer vision', 'programming', 'machine learning', 'ai', 'numpy', 'low', 'artificial intelligence', 'deep learning', 'administration', 'language processing', 'data learning', 'computer science', 'r']","['python', 'pytorch', 'numpy', 'programming', 'servicenow', 'javascript', 'java', 'r']","['deep learning', 'administration', 'machine learning', 'language processing', 'software', 'tensorflow', 'computer vision', 'low data', 'language understanding', 'computer science', 'natural', 'artificial intelligence', 'ai']","['licensing', 'getting things done', 'business units', 'government', 'regulations', 'law', 'agenda']"
65,85,Data Scientist,"responsibilities develop state of the art computer vision algorithms for object detection, classification, and face recognition. prototype hardware and software solutions for object detection, classification, and face recognition. develop and implement scalable and efficient modeling algorithms that can work with large scale data in production systems. collaborate with product management and engineering groups to develop new products and features. skills and qualifications phd or ms degree in computer science, electrical engineering, statistics, applied math, or other related fields. expertise in deep learning, deep neural networks, convolutional neural networks, artificial intelligence and or or related techniques. proficient in one or more programming languages such as python and java. familiarity with one or more neural network frameworks such as tensorflow, caffe or mxnet. strong analytical and quantitative problem solving ability. excellent communication, relationship skills and a strong team player. preferred qualifications experience with big data techniques . experience with relational and nosql databases. compensation tbd how to apply please send your resume to","['databases', 'tensorflow', 'big data', 'software solutions', 'java', 'python', 'object detection', 'statistics', 'computer vision', 'product management', 'nosql', 'electrical engineering', 'artificial intelligence', 'production systems', 'hardware', 'algorithms', 'deep learning', 'programming languages', 'neural networks', 'computer science', 'modeling']","['python', 'databases', 'production systems', 'programming languages', 'big data', 'hardware', 'java', 'nosql']","['deep learning', 'electrical engineering', 'deep', 'object detection', 'statistics', 'neural network', 'tensorflow', 'computer vision', 'neural networks', 'computer science', 'product management', 'artificial intelligence', 'modeling', 'software solutions', 'algorithms', 'neural networksvo']","['compensation', 'art']"
66,86,Research Programmer - Data Scientist,"canada s michael smith genome sciences centre today s research. tomorrow s medicine. the gsc is a department of the bc cancer research institute and a high throughput genome sequencing facility. we are leaders in genomics, proteomics and bioinformatics in pursuit of novel treatment strategies for cancers and other diseases. among the world s first genome centres to be established within a cancer clinic, for more than two decades our scientists and innovators have been designing and deploying cutting edge technologies to benefit health and advance clinical research. among the gsc s most significant accomplishments are the first publication to demonstrate the use of whole genome sequencing to inform cancer treatment planning, the first published sequence of the sars coronavirus genome and major contributions to the first physical map of the human genome as part of the human genome project. by joining the gsc you will become part of an exceptional and diverse team of scientists, clinicians, experts and professionals operating at the leading edge of clinical research. we look for people who share our core values science, timeliness, respect to join us on our mission to use genome science for the betterment of health and society. summary job reference no rp r00008 2021 05 19 dr. aly karsan and the karsan lab team at genome sciences centre are seeking a research programmer to join a marathon of hope cancer centre research project. the team will be working with other research programmers at the karsan lab for developing data analysis pipelines for various next generation sequencing data such as but not limited to scrna seq, targeted sequencing, atac seq, and bs seq, for the study of cancer evolution. we seek candidates with strong analytical and programming skills to research, develop, and improve our research pipelines. the role is ideally suited for detail oriented individuals with a strong interest in data analysis, research, and scientific programming within a high throughput academic setting. the karsan lab has a history of strong publications and can offer great experience in research with full access to the gsc s world class compute cluster. additionally, the karsan lab has a diverse computational biology core for knowledge sharing, collaboration, and support. duties or accountabilities design and implement bioinformatic data pipelines to meet objectives of the project work with other project team members to develop and test code, and implement analysis evaluate and incorporate third party software into pipelines produce thorough but concise written documentation of experiments, algorithms, validations, and other procedures as required. qualifications graduation from a recognized bachelor of science program in computer science or relevant program. a master s degree in a relevant field would be a strong asset. two years of recent related experience or an equivalent combination of education, training, and experience. core skills and abilities expertise with scientific programming and able to provide links to code samples via github familiarity with molecular and cellular biology excellent verbal and written communication skills demonstrated ability to interpret results comfortable working in a unix environment, including experience with shell scripting and common command line tools established ability to efficiently organize work assignments and establish priorities demonstrated interpersonal skills including the ability to work effectively with others in a team environment. additional assets familiarity in statistical analysis using modern computational tools familiarity in next generation sequencing datasets understanding of cancer biology functional knowledge of distributed version control systems, such as svn or git apply please submit a detailed cover letter and resume to using research programmer data scientist, karsan lab in the subject line of your email. this posting will remain online until filled. important we believe that diversity and inclusivity are essential for the advancement of human knowledge and science. we welcome all applicants and provide all employees with equal opportunity for advancement, regardless of race, colour, ancestry, place of origin, political belief, religion, marital status, family status, physical or mental disability, sex, sexual orientation, gender identity or expression, age, conviction of a criminal or summary conviction offence unrelated to their employment. all qualified candidates are encouraged to apply however, canadian citizens and permanent residents will be given priority. due to covid 19 restrictions, the position would require working remotely on a temporary basis. this will be re evaluated once plans to return to the office are made.","['documentation', 'statistical analysis', 'medicine', 'map', 'github', 'software', 'bioinformatics', 'unix', 'programming', 'pipelines', 'computational biology', 'data pipelines', 'project work', 'data analysis', 'algorithms', 'shell scripting', 'high throughput', 'datasets', 'git', 'computer science', 'version control', 'cluster']","['shell script', 'git', 'unix', 'programming', 'documentation', 'pipelines']","['statistical analysis', 'medicine', 'map', 'github', 'software', 'bioinformatics', 'computational biology', 'data pipelines', 'project work', 'data analysis', 'algorithms', 'planning', 'high throughput', 'datasets', 'bioinformatic', 'computer science', 'scientific', 'version control', 'cluster']","['environment', 'sequencing', 'education', 'genomicsomics', 'biology', 'design', 'molecular', 'clinical research']"
67,87,Data Scientist,"dawn infotek inc. is a professional it consulting team that partners with major financial institutions, investment firms and government sectors. we have been dedicated in delivering cutting edge consulting services and recruiting all levels of it positions for our clients. we are looking for a meticulous and enthusiastic data scientist to join our dynamic team to work at our bank client. type contract or permanent location toronto requirements must have excellent computing development skills, particularly statistical and database modeling tools well developed ability to adapt to various programming languages and environments. 1 year of hands on experience in quantitative analysis and machine learning exposure to quantitative analysis related to credit risk management and modeling is preferred. in depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte carlo simulation and bootstrapping techniques. well developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses. ability to efficiently manage multiple priorities to ensure timely delivery. attention to details, independence, and ability to effectively collaborate in teamwork. flexibility and creativity in problem solving. nice to have 1 years of experience in hands on quantitative or statistical analysis, preferably related to the non retail credit risk area in a major financial institution. candidates with this experience will take priority in the interview process. for immediate consideration, please apply as soon as possible to this posting by submitting your resume along with your availability date referrals are more than welcome we thank all applicants for your interest and referral. however, only qualified candidates selected for an interview will be contacted. must reside in toronto area. for further information on our company, please visit contract length 12 months job types full time, contract salary 50.00 60.00 per hour benefits work from home schedule monday to friday experience computing skills like sql, python, sas, r, access or vba, etc. 1 year quantitative analysis and machine learning 1 year regression modeling, monte carlo simulation 1 year quantitative or statistical analysis 1 year work remotely temporarily due to covid 19","['computing', 'sql', 'machine learning', 'regression', 'python', 'programming languages', 'bootstrapping', 'reporting', 'vba', 'it', 'database', 'monte carlo', 'modeling', 'statistical analysis', 'sas', 'r']","['sql', 'python', 'programming languages', 'vba', 'sas', 'r']","['computing', 'machine learning', 'regression', 'quantitative analysis', 'bootstrapping', 'reporting', 'database', 'monte carlo', 'modeling', 'statistical analysis']","['retail', 'risk management', 'referrals', 'consulting', 'recruiting', 'government', 'financial institutions']"
68,89,Data Scientist,"about praemo founded by industry experts and focused on the appropriate application of leading edge analytic technologies like ai within industrial operations, we believe there is a simpler, more cost, time and operationally effective way to harvest insights from the industrial and manufacturing data sets that already exist. praemo is an advanced data and analytics company that builds solutions utilized by a wide range of industrial operations. from discrete manufacturing to consumer packaged goods to mining and process plants, our technology, razortm fills a critical gap. utilizing an organization s operational and iot data as is, where is, and applying ai tools like ml , razortm transforms existing, under utilized data into context relevant insights. these insights alert industrial operators to any anomaly with the potential to harm performance in time to prevent it. responsibilities build machine learning based products or solutions, which provide descriptive, diagnostic, predictive, or prescriptive models based on data independently develop end to end applications develop and maintain performant and scalable applications work closely with and incorporate feedback from engineering teams maintain a customer centric point of view for applications requirements bs in computer science, systems engineering, computer engineering, or related fields 3 years of practical experience in machine learning is mandatory general knowledge of linux strong skills in python any experience with provisioning tools such as ansible or saltstack would also be helpful devops experience is a plus redis experience is a strong asset preferred qualifications phd or master s degree in a machine learning discipline experience with git or other version control software knowledge of agile development methodology background in user experience design experience leading engineering teams and projects experience utilizing gpu technology some mechanical and industrial process knowledge previous startup experience","['python', 'machine learning', 'linux', 'provisioning', 'systems engineering', 'software', 'iot', 'computer engineering', 'devops', 'user experience', 'git', 'redis', 'computer science', 'analytics', 'version control', 'ansible', 'saltstack', 'ai']","['python', 'linux', 'provisioning', 'iot', 'git', 'redis', 'ansible', 'saltstack']","['machine learning', 'systems engineering', 'software', 'devops', 'computer engineering', 'user experience', 'computer science', 'analytics', 'agile development', 'methodology', 'version control', 'ai']","['manufacturing', 'design', 'industrial operations']"
69,90,Junior Data Scientist/Analyst,"company description we are a global architecture, engineering, planning, and technology firm defining the cities of tomorrow. by connecting design and technology, we change how people experience their built environment. we work across disciplines to create the intelligent systems, sustainable buildings, and efficient infrastructure that shapes the way people live, move, learn, and heal. with over 3,000 employees and 60 offices around the world, we understand what it takes to work locally and scale globally. at ibi, we re defining the cities of tomorrow. job description the data scientist is responsible for modeling complex enterprise scenarios, discovering enterprise insights and identifying opportunities in the use of statistical, algorithmic, mining and visualization techniques. in addition to advanced analytic skills, this role is also proficient at integrating and preparing large, varied datasets, architecting specialized database and computing environments, and communicating results in a way that is customized to the target audience. this is an exciting role for someone seeking a challenging and dynamic role in enterprise analytics and an amazing opportunity to collaborate within ibi group globally towards connected and smarter environment and operations. working in close collaboration with buildings, land planning, infrastructure design and planning, transportation, and geomatics departments across ibi group, the data scientist demonstrates the capability to turn data into critical information and knowledge that can be used to make sound decisions. the successful candidate possesses a combination of keen business focused, advanced analytical, problem solving and programming capabilities to quickly develop and validate through models. most of the things you ll work on works in collaboration with all ibi group departments and external clients to discern and identify sources, develop data roadmap strategies and requirements, conduct analytical processes, and validates findings. understands the broader objectives, while leading the smaller initiatives to drive the work and outcomes. develops innovative and effective approaches to solve analytical problems and communicates results and methodologies. develops experimental design approaches and models to validate findings or test hypotheses. monitors and tracks performance decision systems and models . curates and establishes business objectives through technical writing and presentations with colleagues and external clients for the purposes of business development and strategic interests. supports team members in data analytics methodology and coding best practices. qualifications you ll need to have minimum bachelor s degree in mathematics, statistics, computer science, engineering, or related field master s degree preferred. completion of a data science or data analytics program in addition to the above bachelor s degree. minimum of 1 to 2 years of experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas. comfort manipulating and analyzing complex, high volume, high dimensionality data from varying sources is required. proficiency in statistical analysis, quantitative analytics, forecasting or predictive analytics, multivariate testing, and optimization algorithms and developing operational models. demonstrated ability in predictive analysis and deriving conclusions. demonstrated ability to propose solutions to business problems by leveraging pattern detection over potentially large datasets. experience with data visualization and business intelligence tools such as powerbi and tableau. strong analytical programming skills in python , data management . experience with any statistical modeling will be an asset. experience with mapping tools such as qgis and carto will be an asset. experience with ux or ui will be an asset. experience with web development will be an asset. a strong passion for empirical research and for answering hard questions with data is required. ability to communicate complex quantitative analysis in a clear, precise, and actionable manner through technical writing and presentations. additional information we are currently in a work from home model during covid 19, but when we do return to the office we re located at 55 st. clair ave west, this office is steps away from st. clair station and is easily accessible by bike, ttc and car. occupying 7 floors, with over 700 employees, it is the largest office at ibi group. the floors are open concept and represent our collaborative approach to projects. bi group provides a competitive benefit package and pays association dues and licensing fees. as an equal opportunity employer, we are proud to support the growth and equality of our people through initiatives like our mentorship program, global women s network, and diversity inclusion council. we welcome applications from all suitably qualified candidates regardless of age, race, disability, gender reassignment, marriage and civil partnership, pregnancy and maternity, religion or belief, sex and sexual orientation. we thank all applicants for their interest. however, only those selected for an interview will be contacted. as part of ibi group s selection process, candidates may be requested to consent to background checks relevant to the role under consideration for, prior to receiving a job offer. these could include work references, education and credential confirmation, employment verification, identity check, credit report, criminal offence and driver s license record. ibi we request applicants submit resume and portfolio highlighting relevant work experience. please limit pdf files to 10mb","['computing', 'visualization', 'tableau', 'data visualization', 'highity', 'qualitative research', 'built environment', 'empirical research', 'technical writing', 'statistical analysis', 'data analytics', 'python', 'statistics', 'data science', 'enterprise', 'analytics', 'programming', 'geomatics', 'quantitative', 'testing', 'statistical', 'business intelligence', 'algorithms', 'forecasting', 'ux', 'experimental', 'bi', 'datasets', 'web development', 'computer science', 'mathematics', 'optimization', 'modeling', 'data management', 'analytical', 'pattern detection']","['python', 'tableau', 'bi', 'qgis', 'programming', 'business intelligence']","['computing', 'multivariate', 'visualization', 'data visualization', 'qualitative research', 'built environment', 'predictive analysis', 'modeling', 'empirical research', 'technical writing', 'statistical analysis', 'data analytics', 'statistics', 'data science', 'enterprise', 'analytics', 'geomatics', 'quantitative analysis', 'quantitative', 'testing', 'statistical', 'predictive', 'algorithms', 'forecasting', 'planning', 'high dimensionality', 'ux', 'experimental', 'infrastructure design', 'datasets', 'web development', 'computer science', 'mathematics', 'optimization', 'methodology', 'data management', 'analytical', 'pattern detection']","['business development', 'environment', 'land', 'education', 'design', 'presentations', 'background checks', 'licensing', 'target audience', 'buildings', 'dues', 'external clients', 'architecture']"
70,92,Data Scientist,"position in data science using dynamic data driven modeling and ai or ml job description and responsibilities the selected candidate will be responsible for researching, designing, developing, and programming to implement algorithms for signal processing and time series data analysis using both deterministic and statistical methods data driven modeling to model the linear or nonlinear relationship between multivariate time series data that are often dynamically correlated feature extraction and clustering or classification of multivariate time series data. the successful candidate will work closely with a multi disciplinary team of engineers to apply the developed algorithms to solve practical problems in various sectors of industry, and assist them in validation and verification as well as technical documentation of the solution. desired education level and background ph.d. or master s degree preferably in electrical engineering, or otherwise, in computer science or applied mathematics with relevant experience and research interests required skills and qualifications a proven track record and solid expertise in the following fields system identification for data driven modeling of dynamic systems artificial intelligence and machine learning for modeling input or output relationship between time series data linear and nonlinear statistical regression modeling and analysis time and frequency domain signal processing and time series data analysis ai or ml for clustering and classification of time series data feature extraction and dimensionality reduction methods for time series data strong background in linear algebra working knowledge of optimization techniques and toolboxes is an asset technical documentation and presentation candidates must have proven experience of efficient, proficient computer programming and implementation of signal processing, time series analysis and data driven modeling methods in python. knowledge of matlab or simulink programming and toolboxes in the aforesaid domains is considered a valuable asset. experience in java and c is not required but considered beneficial. the selected candidate must be innovative and highly organized, and must have very good personal and interpersonal skills including problem solving, analytical thinking, learning, and team work and communication skills. professional proficiency in english language is essential. knowledge of french language is considered an asset. globvision, throughout its 24 years of existence, has repeatedly demonstrated commitment to diversity, equity, and inclusion as core and unwavering values of the company. they are not only central to the company s culture but considered as a mechanism by which we leave an endurable impact on our society. we strongly believe that the fusion of varied perspectives results in more innovative solutions to complex, challenging problems in our increasingly diverse and connected world. please note, this position is available for canadian residents only, and those selected for an interview will be contacted. job type full time benefits dental care disability insurance life insurance schedule monday to friday experience machine learning 1 year work remotely no","['c', 'dimensionality reduction', 'linear algebra', 'simulink', 'java', 'python', 'time', 'time series analysis', 'data science', 'programming', 'electrical engineering', 'machine learning', 'statistical', 'artificial intelligence', 'data analysis', 'algorithms', 'matlab', 'signal processing', 'computer science', 'technical documentation', 'optimization', 'modeling', 'applied mathematics', 'ai']","['python', 'c', 'programming', 'simulink', 'computer', 'java', 'matlab']","['dimensionality reduction', 'linear algebra', 'regression', 'data science', 'electrical engineering', 'machine learning', 'statistical', 'artificial intelligence', 'data analysis', 'algorithms', 'time series analysis driven', 'signal processing', 'dynamic', 'time series', 'computer science', 'technical documentation', 'optimization', 'modeling', 'applied mathematics', 'feature', 'ai']","['validation', 'insurance', 'education']"
71,93,Data Scientist,"we re transforming the cyber security industry about us f8th uses machine learning that can identify users and fraudsters in real time via 100s of patterns of how an individual uses their mouse, keyboard, touchscreen and other inputs. it continuously analyzes typing speed, movement speed, clicking speed, acceleration, and more, and then builds a behavioural profile. job description excellent sql skills, fluency in python, and experience with at least one statistical package deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance create and apply model and algorithm testing strategies to measure conduct multivariate testing and a or b testing to measure effectiveness of models and make ongoing changes collaborate and lead the teams in feature extraction, data representation, and automatic data pipeline and collection design, as well as data quality assurance monitoring functional, end to end, integration, regression, automated or manual testing requirements bachelor s or master s degree in data science, computer science, applied math, statistics or a related technical field. ms or phd degree in cs or related areas is preferred. 3 years experience in software development and machine learning hands on 3 years of experience on machine learning, text analysis, data mining, and nlp knowledge of scala, python, c , c , java or typescript with 2 3 years of experience experience with sql and nosql databases experience using pytorch popular nlp libraries such as fairseq, allennlp, huggingface or spacy experience with one or more back end programming languages such as c and python familiarity working with large data sets and big data platforms such as hadoop, pyspark, and kubernetes deep knowledge of advanced statistical techniques and concepts, machine learning techniques, and expertise in their applications excellent communications skills with the ability to share insights and expectations with clients, stakeholders and colleagues, both locally and remotely what we offer you start up lifestyle at a cyber security company experience working closely with the founders of the company note kindly mention the job title in the subject of your email expected start date 2021 07 01 job types full time, permanent benefits employee stock purchase plan schedule 8 hour shift monday to friday work remotely yes","['databases', 'pyspark', 'pytorch', 'c', 'big data', 'java', 'kubernetes', 'sql', 'python', 'statistics', 'scala', 'data science', 'software development', 'data', 'integration', 'nosql', 'data mining', 'typescript', 'machine learning', 'testing', 'text analysis', 'data representation', 'programming languages', 'manual', 'hadoop', 'security', 'nlp', 'data assurance', 'computer science']","['kubernetes', 'sql', 'python', 'typescript', 'databases', 'nlpcy', 'programming languages', 'scala', 'pyspark', 'pytorch', 'hadoop', 'nlp', 'c', 'data', 'big data', 'java', 'nosql']","['data mining', 'multivariate', 'machine learning', 'statistics', 'text analysis', 'algorithm testing', 'testing', 'manual', 'security', 'data science', 'software development', 'computer science', 'data', 'integration', 'feature', 'typing']",['design']
72,94,Senior Product Data Scientist,"this position is open to the us and canada. any applications outside of those locations will not be considered. coffee meets bagel coffee meets bagel s mission is to give everyone a chance at love. the app curates quality matches with fuller profiles that result in real conversations. globally, cmb has generated millions of real dates and thousands of lasting relationships. coffee meets bagel was named one of the top 10 dating apps by time magazine and the best dating app for women by refinery29. it has also been voted the 1 recommended dating app for singles looking for relationships. job description each day, our users visit our app with the hope of connecting with someone. these interactions generate millions of data points that can be used to help us better understand our customers experiences. we need you to ask and answer the questions that will transform this data into a better understanding of what our customers find delightful, and what they find painful, so that you can help drive changes that further our vision of helping singles form meaningful connections with other amazing singles the senior product data scientist will be responsible for partnering with our product and growth teams to provide the facts needed to make better decisions and to help push our products and services to better serve our customers. you will be responsible for building a strong understanding of our ecosystem, working with the product team to determine which projects are the most important, and being willing to use the right tool to find and explain relevant information and insight that will help the company operate better. responsibilities work cross functionally with product, design, finance, and engineering teams to provide data driven insights that will help define the product marketing roadmap and drive significant increase in core business kpis . create internal dashboards to monitor the health of the product and business kpis . deliver ad hoc analyses and reports to support business needs, investigate, triage and resolve metrics based issues without heavy guidance. assist in feature development from ideation to execution, including helping with user research, determining the best way to test new product features, and running deep analysis of feature performance post launch. create and share compelling presentations that motivates and inspires the team to build with conviction. when necessary, build models in r, python, or other systems that help us better measure and understand the results of experiments or user flows. qualifications bachelors in a quantitative field and 4 years post collegiate work experience as an analyst or data scientist or a masters or phd in a quantitative field with 2 years work experience as an analyst or data scientist. experience applying statistics to rigorously analyze data and derive insights to solve ambiguous problems. 1 years designing and evaluating experiments or quasi experiments high proficiency in sql business intelligence tools . basic proficiency in a scripting language like python, r, or julia capable of condensing data and telling a persuasive story to technical and non technical audiences. self starter who can thrive in a dynamic, fast paced environment, drive change through influence, and collaborate effectively with a variety of cross functional stakeholders. excited and hungry to try new tools and processes to achieve results. a serious passion for using data to build delightful products for our customers. competency with developer tools like git and bash is a plus please make sure to mark cmb as safe as our emails tend to go to spam.","['go', 'sql', 'python', 'bash', 'statistics', 'scripting', 'condensing', 'dashboards', 'git', 'business intelligence', 'r']","['go', 'sql', 'python', 'git', 'business intelligence', 'r']","['bash', 'statistics', 'conde', 'scripting', 'dashboards']","['environment', 'triage', 'metrics', 'marketing', 'design', 'finance', 'presentations', 'user research', 'product']"
73,95,Data Scientist,"data scientist location montreal, ottawa toronto we are the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are an expert at solving real world challenges with data, analytics, ai or ml and creativity. yes, creativity you know the theory and you have hands on expertise from studies, experience and or or self taught projects. and you re all about helping clients scale data into value. what you ll do provide hands on technical thought leadership, solve large complex business problems and drive actionable insights for clients prototype scale ai or ml solutions in production cloud environment to meet business needs stay abreast of ai or ml technologies, academic researches hands on techniques participate in development of innovative solutions for clients across functions industries what we re looking for at least 5 years embracing challenges with data science lifecycle in enterprise setting at least 3 years developing implementing ai or ml models, including professional experience with recommender engine, natural language processing, optimization operational research, computer vision and deep classical machine learning at least 3 years working with data science tools e.g. python, r, spark, sql, plotly, flask git at least 3 years designing operating tools services in cloud environments e.g. gcp, azure, aws databricks at least 2 years orchestrating and maintaining ai or ml models in a production environment using data ml ops tools e.g. docker, kubernetes, mlflow, jenkins circleci at least 5 years storytelling with data and communicating findings to a non technical audience bonus point if graduate degree in data science or related disciplines e.g. applied mathematics, statistics, computer science, economics, engineering and physics a blend of data science capability, consulting expertise and industry experience drive to learn and master new technologies and techniques","['jenkins', 'kubernetes', 'sql', 'python', 'gcp', 'statistics', 'physics', 'computer vision', 'data science', 'analytics', 'aws', 'ops', 'machine learning', 'ai', 'flask', 'automation', 'language processing', 'economics', 'git', 'computer science', 'optimization', 'applied mathematics', 'r']","['kubernetes', 'sql', 'python', 'plotly', 'gcp', 'jenkins', 'git', 'aws', 'mlflow', 'circleci', 'r']","['machine learning', 'language processing', 'statistics', 'economics', 'physics', 'computer vision', 'data science', 'computer science', 'analytics', 'natural', 'optimization', 'flask', 'applied mathematics', 'automation', 'ops', 'ai']","['environment', 'helping clients', 'consulting']"
74,96,Data and Applied Scientist,"empower microsoft customers to browse and communicate with confidence and trust and protect them from phishing and social engineering threats. that is what inspires us, drives our work, and pushes us to challenge the status quo every single day. we are anapplied research team bringingimpact driven research in thesecurity and compliance suite for o365 customers. we explore cutting edge techniques in diverse disciplines that protect our customers from social engineering attacks at scale, while advancing state of the art in the process. as a senior applied researcher your work will impact over half a billion microsoft customers. you will develop new capabilities that help the team to scale and work smarter. you will have the opportunity to analyze vast datasets and have a pulse on the latest research to positively influence our product roadmaps. you will be able to prototype and experiment in completely new areas. your research will delight customers and demonstrate microsoft s thought leadership in the security space. by working with teams across the broader group, you will need the right balance of passion, customer empathy, technical depth, and partnering skills. if you enjoy being on the cutting edge of applied research in security, come join us we re looking for someone passionate about leading and pushing forward cutting edge research for solving complex, highvolumeproblems related to social engineering. scmvan scmrjobs scmjobs responsibilities incollaborationwithadiverseteam,defineandexecute deep learning basedresearchtowards real world problems collaborate with some of the world s best researchers at microsoft research to drive fundamental research into real world security products impacting over half a billion people in over a hundred countries around the world. communicate internally and externally through academic and industry conferences, publications, open source releases and other mindshare venues such as blogs, media interviews, etc. explore bold research ideas, design and conduct scientific experiments, learn and iterate on further improvements of the research undertheumbrellaofresponsibleaiprinciples. qualifications required track record in research areas in deep learning, such as graph neural networks, knowledge graphs, nlp, computer vision, responsible ai as evidenced by at least 2 publications in academic conferences and or or open code contributions or 4 years of relevant industry experience realizing cutting edge research into product innovation. hands on experience with deep learning frameworks such as pytorch, tensorflow, etc. excellent written and verbal communication skills and the ability to simplify and explain complex ideas. excellentresearchskillswiththeabilitytobreaklong term research goals into achievable milestones. ability to clearly articulate the problems and explore related solutions. teamplayer,confidentandenthusiastic proven partner engagement and cross team collaboration skills preferred proven publication record in top tier venues. examples include but are not limited to icml, neurips, iclr, emnlp, acl, naacl, kdd, aaai, etc. experience with large scale data processing tools moderate software engineering skills for developing quick and accurate prototypes experience in safety and ethical aspects of ai. expert knowledge in security, reputation systems, anti fraud systems,phish detection technologies, and social engineering research microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['deep learning', 'data processing', 'software', 'pytorch', 'datasets', 'neural networks', 'security', 'nlp', 'computer vision', 'tensorflow', 'legal requirements', 'ai']","['pytorch', 'nlp']","['deep learning', 'data processing', 'software', 'datasets', 'neural networks', 'security', 'computer vision', 'tensorflow', 'legal requirements', 'ai']","['and compliance', 'applied', 'design', 'art', 'microsoft research', 'recruiting', 'regulations']"
75,97,Data Scientist,"job overview somadetect is a high growth technology startup in the dairy industry that is looking to expand its development team. we have a diverse team that strives to develop fiercely innovative solutions, with a focus on quality to create products that put farmers first. somadetect is now a fully remote company, with team clusters in buffalo, ny, and across canada . this is a remote position. we are looking for a data scientist that will join our existing team and participate in the development of predictive models that leverage massive amounts of image data. the data scientist will collaborate with a team of multidisciplinary engineers and researchers to tackle challenges related to the analysis or modeling of dairy data. this role will require someone that is well versed in the fundamentals of computer vision and machine learning. the ideal candidate will also have the experience and problem solving abilities necessary to extract insights and discover patterns within messy, real world data sets. this role focuses on work in real time with multiple sensor data, data acquisition, analysis, and modeling for building smart solutions for the dairy industry. this role utilizes deep learning on a fast gpu machine to facilitate the prediction and estimation operations. responsibilities and duties develop deep learning models for computer vision problems . responsible for enhancing the image data collection procedures collaboratively with our operational teams for building the relevant predictive models. responsible for processing, cleansing, and verifying the integrity of image data used for model development. responsible for developing processes and tools to monitor and analyze the data quality and model performance. evaluate new sensor models. build tools and framework for multiple cameras and sensor calibration. develop various computer vision algorithms that are efficient and robust. play an active role in end to end product development or deployment lifecycle. work collaboratively with other software developers and engineers to integrate algorithms into a complete product. test the ai products in the field and refine the products by learning and applying new algorithms. thoroughly test and objectively evaluate the scope of validity of any r d deliverables. qualifications requirements experience with opencv and deep learning frameworks tensorflow or pytorch or caffe experience with deep learning algorithms cnn, rnn, and lstm experience in computer vision algorithms and 2d sensor data proficient programming skills in python , r strong of computer vision fundamentals knowledge and experience in statistical and data mining techniques using time series datasets, bayesian probability, markov models . experience in using aws excellent oral and written communication works effectively in small teams ph.d. or master s degree in computer science, data science, bioinformatics, engineering, or equivalent experience 3 years of relevant experience in the computer vision and deep learning field experience in working in an agile environment, using project management and reporting tools we appreciate all expressed interest in this position however, only the candidates selected for an interview will be contacted.","['prediction', 'pytorch', 'tensorflow', 'cleansing', 'python', 'agile environment', 'data acquisition', 'software', 'bioinformatics', 'reporting', 'computer vision', 'data science', 'programming', 'aws', 'bayesian', 'data mining', 'machine learning', 'ai', 'calibration', 'data collection', 'probability', 'data quality', 'algorithms', 'model', 'deep learning', 'datasets', 'computer science', 'modeling', 'r']","['python', 'opencv', 'pytorch', 'model development', 'programming', 'aws', 'data quality', 'model performance', 'r']","['prediction', 'tensorflow', 'cleansing', 'markov', 'agile environment', 'data acquisition', 'software', 'bioinformatics', 'reporting', 'computer vision', 'data science', 'bayesian', 'data mining', 'machine learning', 'calibration', 'data collection', 'probability', 'algorithms', 'deep learning', 'time series', 'datasets', 'computer science', 'modeling', 'ai']","['product development', 'project management']"
76,99,Data Scientist,"what you ll do responsibilities in this role, you would report to the vp engineering. responsibilities will include conceiving and developing data driven solutions for clients creating and presenting results and findings to clients collaborating with developer resources to build data pipelines and operationalize solutions data cleaning reshaping what you ll need qualifications masters or ph.d in econometrics, financial economics, mathematics, statistics, physics, computer science, data science, engineering or equivalent experience 2 5 years of experience in a data science role experience in one or more programming languages experience with one or more data science frameworks strong understanding of data and business ability to work autonomously and in a team working in a fast paced environment ability to solve complex problems strong communication skills nice to haves past experience with one or more business intelligence or analytics platforms analytical experience related to the food and beverage industry past experience working with time series data we re looking for core skills jupyter forecasting python statistical modeling statistics interpreting data problem solving science","['jupyter', 'python', 'statistics', 'data pipelines', 'programming languages', 'economics', 'physics', 'data science', 'forecasting', 'interpreting data', 'computer science', 'analytics', 'mathematics', 'data cleaning', 'business intelligence', 'statistical', 'modeling', 'econometrics']","['programming languages', 'jupyter', 'python', 'business intelligence']","['statistics', 'data pipelines', 'financial', 'conceiving', 'economics', 'physics', 'data science', 'forecasting', 'computer science', 'analytics', 'data cleaning', 'mathematics', 'statistical', 'modeling', 'econometrics']",['environment']
77,100,Data Scientist,"maxa ai offers an ai powered saas solution for commercial performance that runs alongside a company s erp system. maxa deals with sme to x large enterprises in all industries, as well as affiliate partners. we are currently looking for a data scientist to join our montreal based team. about us we deliver business performance technology with python and sql. we move fast with infinite capacity our technology lives in the cloud. we eat business system data and time series for breakfast. we like math, science and engineering degrees. we love stories about failures even more. you have at least 5 years of experience as a data scientist. a few interesting stories about challenging real world datasets you ve tackled. used a combination of advanced statistics and machine learning to create and or validate predictive insights. a love for complex time series data. a passion for conversations about decision trees, regression and other types of ml algorithms applied to table data and time series","['sql', 'python', 'machine learning', 'statistics', 'datasets', 'decision trees', 'erp', 'saas', 'algorithms', 'ai']","['python', 'sql', 'erp']","['machine learning', 'statistics', 'datasets', 'algorithms data', 'decision trees', 'saas', 'ai']",['sme']
78,101,Data Scientist,"the data scientist will join the advanced analytics team focused on creating transformational analytics enabled capabilities across all of acosta s businesses. this can range from using statistical methods, data mining and machine learning techniques, or generating novel approaches uniquely suited the challenge. we value complementary and divergent experiences to bring many points of view on how to approach solve a problem. although our datasets range in size, you can expect to work with very large datasets regularly in this role. the incumbent in this position should exhibit the following acosta values people minded must show dignity and respect to all people integrity must exemplify the highest degree of ethical behavior results oriented must show passion, pride and commitment to succeed trust must be honest, sincere and confident teamwork must build trusting relationships innovation must progress through a combination of creativity, common sense and vision balance must maintain an optimistic attitude and keep perspective on what is important in life. essential functions development of analytical capabilities to serve diverse business use cases, in active collaboration with product management and technology counterparts. cross functional, internal and external consulting, including discovery or structuring of business problems, and exploratory analysis of candidate methods to identify promising approaches for development. creation and maintenance of solution documentation, including data transformation, models, and solution integration. ownership and lifecycle management for analytics capabilities working in a production environment, including computational performance, accuracy or validity, and extension to new uses. other duties as assigned qualifications job requirements graduate degree master s degree preferred 4 7 years of experience with programming languages like python , r or sas to write complex code and implement into a production environment. must be able to develop independently and guide others within the development team. practical experience with development, tuning, and maintaining machine learning capabilities at scale. experience generating linear and or or logistic regression models. must be able to generate complex analytic models on a large scale with no guidance. must be able to guide others in the same. experience with linear or integer programming and or or other optimization techniques. must be able to generate complex solvable optimization models on a large scale with no guidance. must be able to guide others in the same. experience with data science in microsoft azure or cloud environments using spark or alternative parallel computation capabilities highly desired. cpg, sales and or or retail experience highly desired knowledge, skills and abilities requirements an understanding of different data sources, their proper uses, and their limitations. must be able to identify data that is unclean and or or misapplied and must be able to recommend the proper methodology to fix any issues. excellent written and verbal communication skills that allows story telling. must be able to clearly speak english and must be able to communicate very technical procedures to a non technical audience. strong analytical and problem solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information residing in large datasets. ability to consult across various business functions to explain analytic functions and how they can be used to drive a business. intellectual curiosity is critical. acosta sales marketing is an equal opportunity employer by submitting your application you agree with and accept the acosta privacy statement and terms of conditions. us http or or acosta.jobs or privacy policy us or canada http or or acosta.jobs or privacy policy ca or acostaservices job information technology schedule full time job type standard shift day job job posting may 12, 2021, 4 29 43 pm","['documentation', 'information technology', 'microsoft azure', 'cp', 'python', 'logistic regression', 'data science', 'analytics', 'product management', 'integration', 'programming', 'sas', 'data mining', 'machine learning', 'data transformation', 'programming languages', 'datasets', 'optimization', 'r']","['python', 'programming languages', 'documentation', 'programming', 'sas', 'microsoft azure', 'r']","['computational performance', 'information technology', 'logistic regression', 'data science', 'analytics', 'product management', 'integration', 'exploratory analysis', 'data mining', 'machine learning', 'data transformation', 'optimizationvable', 'transformational', 'http', 'use cases', 'cpg', 'datasets', 'optimization', 'solution', 'methodology']","['environment', 'marketing', 'retail', 'sales', 'consulting']"
79,102,Data scientist,"summary ko os intelligence inc., established in 2017, is the realization of the vision of an experienced and multidisciplinary team coming from a wide range of scientific, academic and professional backgrounds. powered by machine learning, operations research and business analytics, ko os delivers personalized solutions that create a synergy around in house client systems. in this role, the candidate will work with a multidisciplinary team to design, develop create analytical solutions through applications of data mining, machine learning. the ideal candidate will help the team to develop ml applications and take advantage of emerging technologies around data science. the candidate will be expected to be hands on as well as guide and mentor new modellers in the team. responsibilities understand business needs and apply machine learning or big data technology to solve real world business problems ability to build and optimize deep architectures using machine learning techniques implement state of the art of natural language processing and be familiar with bert and transformers architectures data mining, working with structured and unstructured data manipulate high volume, high dimensionality data from varying sources to highlight patterns, anomalies, relationships, and trends present analysis and recommendations to the target audience minimum qualifications msc degree with 2 years of experience. moderate working knowledge of modelling or research or analytics or actuarial required. relevant statistical analysis work experience required. work experience knowledge relevant work experience in research and or or advanced analytic work in the insurance industry preferred. job specific, technical skills competencies computer proficiency ability to read or revise or review a statistical software program ability to create advanced programs from scratch. leading the business problem solving decision making. risk taking, innovation. results orientation. business perspective. seeks opportunities to learn. business acumen understanding and knowledge of key business knowledge areas . ability to leverage business knowledge to determine approaches to execution. critical thinking ability to take action in solving problems while exhibiting judgment and a realistic statistics understanding of advanced statistics underlying data models. ability to apply new statistical procedures to work. demonstrates strong ability and knowledge of database principles, data profiling, statistics and data modelling and can apply this knowledge in new or complex situations. preferred qualifications 2 years of experience in one or more of the following machine learning libraries, tensorflow, pytorch, cuda, cudnn, dlib, machine vision, and natural language processing 4 years of experience in programming with python, r, c or java 1 years of experience in handling data and working with database tools, e.g., sql, nosql, mongodb, hadoop or spark proven ability to work creatively and analytically in a problem solving environment excellent communication and interpersonal skills experience with contributing to open source project","['unstructured data', 'dlib', 'pytorch', 'tensorflow', 'c', 'data profiling', 'big data', 'mongodb', 'statistical analysis', 'business', 'java', 'machine vision', 'python', 'sql', 'statistics', 'software', 'data science', 'analytics', 'transformers', 'programming', 'data models', 'nosql', 'data mining', 'machine learning', 'statistical', 'cuda', 'high dimensionality', 'language processing', 'hadoop', 'r']","['sql', 'python', 'nosql', 'dlib', 'pytorch', 'hadoop', 'c', 'cuda', 'big data', 'programming', 'data models', 'java', 'bert', 'r']","['unstructured data', 'data mining', 'high dimensionality', 'machine vision', 'machine learning', 'language processing', 'statistics', 'software', 'tensorflow', 'data science', 'data profiling', 'analytics', 'natural', 'statistical', 'mongodb', 'statistical analysis', 'business']","['environment', 'insurance industry', 'business knowledge', 'design', 'art', 'target audience', 'operations', 'transformers']"
80,103,Data Scientist II,"bachelor s degree in any quantitative discipline such as statistics, mathematics, quantitative finance or operational research at least 5 years of experience working in analytics or data science or forecasting environment experience in working with databases and sql in a business environment demonstrated use of analytical packages and scripting languages such as r, python, sas and spss. prior experience in design and execution of science or analytical projects. worked extensively in large scale databases and data warehouse. amazon.com s customer trust and partner support mission is to make amazon the safest and most trusted place worldwide to transact online. amazon runs one of the most dynamic e commerce marketplaces in the world, with nearly 2 million sellers worldwide selling hundreds of millions of items in ten countries. ctps safeguards every financial transaction across all amazon sites. as such, ctps designs and builds the software systems, risk models and operational processes that minimize risk and maximize trust in amazon.com. ctps organization is looking for a data scientist for its forecasting and planning research team. the team is being grown to provide insights about its ctps planning and provide analytical solutions to help drive operational efficiencies, uncover the hidden risks and trends, reduce investigation errors and bad debt, improve customer experience and predict recommend the optimizations for future state of ctps operations. as a ds ii, you will be responsible for modeling complex problems, discovering insights and identifying opportunities through the use of statistical, machine learning, algorithmic, data mining and visualization techniques. you will collaborate effectively with internal stakeholders and cross functional teams to solve problems, create operational efficiencies, and deliver successfully against high organizational standards. the candidate should be able to apply a breadth of tools, data sources and analytical techniques to answer a wide range of high impact business questions and present the insights in concise and effective manner. additionally, you are an effective communicator capable of influencing and driving major decisions through data driven insights. this is a high impact role with goals that directly impacts the bottom line of the business. responsibilities use time series or ml forecasting techniques to forecast ctps investigations for improved long term and short term capacity planning. employ the appropriate algorithms to discover patterns of risks, abuse and help reduce bad debt design experiments, test hypotheses, and build actionable models to optimize ctps operations solve analytical problems, and effectively communicate methodologies and results build predict models to forecast risks for product launches and operations and help predict workflow and capacity requirements for ctps operations draw inferences and conclusions, and create dashboards and visualizations of processed data, identify trends, anomalies work closely with internal stakeholders such as business teams, engineering teams, and partner teams and align them with respect to your focus area experience in statistical techniques such as classification, clustering, regression, statistical inference, collaborative filtering, and natural language processing, experimental design, social networking analysis, feature engineering, etc. experience in creating forecasting using time series and causal models. experience or knowledge of advanced machine learning techniques such as gbm, random forest, etc. experience in e commerce or on line companies in fraud or risk control functions coding skills in one of the modern languages java, python, r experience with visualization technologies such as tableau compelling communication and influencing skills and participation in winning the support of management and influence the course of major strategic decisions","['databases', 'visualization', 'tableau', 'dashboards', 'java', 'sql', 'python', 'statistics', 'statistical inference', 'scripting', 'data science', 'risk models', 'analytics', 'sas', 'data mining', 'analytical techniques', 'machine learning', 'quantitative', 'algorithms', 'forecasting', 'language processing', 'experimental', 'software systems', 'mathematics', 'modeling', 'capacity planning', 'risk', 'investigation', 'r']","['sql', 'python', 'databases', 'tableau', 'sas', 'java', 'r']","['visualization', 'dashboards', 'networking analysis', 'natural', 'statistics', 'statistical inference', 'scripting', 'data science', 'risk models', 'analytics', 'data mining', 'analytical techniques', 'machine learning', 'quantitative', 'algorithms', 'forecasting', 'feature engineering', 'planning', 'language processing', 'experimental', 'operational research', 'software systems', 'mathematics', 'modeling', 'capacity planning', 'investigation']","['environment', 'design', 'finance', 'customer experience']"
81,104,"Data Scientist, Analytics & Insights","data scientist, analytics insights mississauga, on, canada virtual req 635 thursday, june 10, 2021 are you looking for more than a job at world vision canada we offer challenging careers that change the lives of children all over the world and it will change yours too. come and be part of a team of 400 canadians with a vision for the world life in all its fullness for every child. you will experience christian faith in action helping to make real and lasting change in the lives of the world s most vulnerable children. join the world vision canada team and be part of a powerful and effective force for good for children. for change. for life. position data scientist, analytics insights reports to manager, analytics insights position term full time permanent deadline until filled location remote within canada job purpose the data scientist, analytics insights is responsible for discovering insights and identifying opportunities to optimize experiences and help guide and inform key business decisions using statistical, algorithmic, mining and visualization techniques. in addition to advanced analytic skills, this role is also proficient at integrating and preparing large, varied data sets, architect of specialized database and computing environments, and communicating results. this role would act as a general consultant to the business on analytics initiatives, and designs and implements end to end solutions through the use of well established and leading edge techniques the data scientist will determine the appropriate solution to address the business problem at hand, extract and manipulate the data from various sources, execute and deploy the solution collaborating with other areas of the organization as needed, and communicate results back to the business in a clear and timely manner. this role supports the core mandate of the data science advanced analytics department, which is to create lasting customer focused analytics solutions covering all data domains , and enable insights led decision making across the organization. duties and responsibilities consults with business partners and identifies appropriate research approach or design to address the business problem at hand. provides in depth customer analysis and insight, helping to guide and inform decisions to optimize marketing initiatives, research customer personas, segments, and journeys, and highlighting trends as necessary. mines internal and external data to develop research results that emphasizes actionable recommendations and insights to support business decisions and marketing optimization. extracts and validates structured and unstructured data from various sources, proactively identifying new data sources to integrate into data analytics models. manipulates large data sets from multiple sources, performing big data analytics where possible to understand emerging trends, patterns, or insights through the use of statistical analysis. creates predictive models that inform key business decisions and executes models from design through to deployment, ensuring accuracy of data and that models are viable, repeatable, and scalable reports on model results once applied. educates the organization on advanced analytics approaches and techniques used, such as testing hypotheses and predictive modelling, helping the organization understand the principles and the underlying logic behind the process. leads model governance planning and execution process. takes initiative to find better methodologies and approaches to produce accurate, timely and actionable insights for wvc internal stakeholders and donor audiences. develops clear and comprehensive presentations of analytics results that emphasizes actionable recommendations and insights to support the development of new strategies and tactics. qualifications 3 to 5 years of relevant advanced analytics experience experience working in an agile environment an asset. bachelor s degree in mathematics, statistics or computer science or related field. master s degree preferred certification in machine learning and or or big data an asset. solid knowledge of statistical techniques with a focus on customer and digital data, and analytical modelling and other advanced analytics techniques . proficient in the use of statistical packages strong programming skills , and statistical modelling experience developing and using machine learning algorithms. demonstrates the following data scientist qualities clarity, accuracy, precision, relevance, depth, breadth, logic, significance, and fairness. proven ability to think strategically and to come up with solutions to loosely defined business problems. strong interpersonal skills a strong team player and collaborative with other departments curious mindset demonstrated analytical and communication skills, and commitment to life long, hands on learning. we bring life saving support in times of disaster. we help poor communities to take charge of their futures. we provide small loans and training that boost family livelihoods. we work with policy makers to change the way the world is run. our christian faith teaches us that every child, regardless of gender, faith or race, is a precious gift to the entire world and that their wellbeing concerns us all. we shall never rest while children suffer in situations that can be changed. canada s top 100 gta s top 10 our core values we are committed to the poor. we are christian. we are stewards. we value people. we are partners. we are responsive. qualified candidates must be able to demonstrate a commitment to the core values and mission of the world vision partnership. world vision canada takes our safeguarding responsibilities seriously and we provide an environment that is safe for our child and adult beneficiaries. we have strong recruitment procedures to make sure the safest and most suitable people work with the children in our programs. we provide our staff and volunteers with ongoing supervision, support and training in their work with child and adult beneficiaries. world vision canada welcomes and encourages applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process. thank you for your interest however only those applicants selected for an interview will be contacted. other details job family resource development fundraising job function individual contributor pay type salary telecommute 100","['unstructured data', 'computing', 'visualization', 'big data', 'statistical analysis', 'data analytics', 'agile environment', 'statistics', 'data science', 'analytics', 'programming', 'customer', 'machine learning', 'testing', 'rest', 'algorithms', 'model', 'computer science', 'mathematics', 'optimization']","['programming', 'big', 'big data']","['unstructured data', 'computing', 'visualization', 'statistical analysis', 'data analytics', 'agile environment', 'statistics', 'data science', 'analytics', 'machine learning', 'testing', 'rest', 'algorithms', 'planning', 'model', 'customer analysis', 'computer science', 'mathematics', 'optimization']","['resource development', 'world vision', 'environment', 'loans', 'fundraising', 'marketing', 'design', 'presentations', 'governance', 'safeguarding', 'world', 'emerging trends']"
82,105,Data Scientist,"about peritus.ai peritus is dedicated to building ai assistants to make tech workers more productive to achieve our vision of zero touch customer service. our patented cloud first knowledge engine uses advanced nlp and machine learning to enable continuous learning from content, discussions, case management, and agile development systems. we embrace a human in the loop philosophy to train data sets, refine recommendation quality, and learn from implicit user feedback. use cases the peritus knowledge engine is currently being deployed for the following use cases at large technology vendors customer self service ai assisted search and forum question answering automation to avoid new support cases. support automation assisted problem solving that accelerates resolution time and shifts left new knowledge to make the team smarter. services automation build and integrate custom solutions faster by automating code reuse and lower risk of daily ci or cd releases. the peritus technology platform starting with assisting tech users in quickly finding a needle in the haystack, vision extends to assist human reasoning for complex answers across dynamic sources of information. the company s technology platform ingests unstructured content, systems of record, and product telemetry at high volume velocity into an industry specific knowledge graph. we use reinforcement learning and a normalized ontology for people, products, and problems to assist human reasoning during problem solving and actively learn from implicit feedback. peritus has been granted two patents pertaining to reinforcement learning and using a knowledge graph applied to customer service. our team is proudly global with locations in the u.s , india , and canada. peritus venture investors include the hive, ideaspring, and benhamou global ventures. about the role as part of the canadian engineering team, execute the machine learning or artificial intelligence technology roadmap to solve the challenges of dealing with structured, semi structured and unstructured data in the context of a technology problem. responsibilities advance the machine learning capabilities of the product. analyze, select and implement machine learning or ai algorithms that improve the relevance of related incidents, accuracy of resolutions and routing of incidents. experiment with multiple algorithms simultaneously to identify the optimal algorithm. improve accuracy by incorporating implicit and explicit feedback from users. understand the data by interacting with the subject matter experts. about you you have a master s or phd in computer science, machine learning or equivalent field. your experience in building products from scratch using machine learning is a big plus. you have proven experience in developing algorithms using python and or or java, c or scala in one or more of the following fields machine learning, data analytics, information retrieval. you have experience applying statistics, probability, and machine learning to real business problems. you have experience in natural language processing such as topic extraction, building knowledge graph . you have experience with deep learning frameworks , applications, or services. you are smart, get things done, have great energy and thrive in a fast paced early stage startup environment. you have passion for creating customer value by applying cutting edge innovations in data science technology. please send your resume to","['unstructured data', 'ci', 'c', 'hive', 'java', 'routing', 'data analytics', 'python', 'statistics', 'reinforcement', 'cd', 'scala', 'data science', 'machine learning', 'telemetry', 'artificial intelligence', 'probability', 'algorithms', 'automation', 'deep learning', 'language processing', 'information retrieval', 'nlp', 'computer science', 'reinforcement learning', 'ai']","['python', 'scala', 'nlp', 'c', 'hive', 'java']","['unstructured data', 'ci', 'natural', 'routing', 'data analytics', 'statistics', 'reinforcement', 'cd', 'data science', 'machine learning', 'telemetry', 'artificial intelligence', 'agile development', 'probability', 'algorithms', 'automation', 'deep learning', 'use cases', 'language processing', 'information retrieval', 'computer science', 'ai']","['resolutions', 'subject matter experts', 'environment', 'customer value', 'customer service', 'ontology']"
83,106,Data Scientist,"about us backed by a 50 year legacy of engineering excellence, reliability and industry leading customer service, telesat has grown to be one of the largest and most successful global satellite operators. telesat works collaboratively with its customers to deliver critical connectivity solutions that tackle the world s most complex communications challenges, providing powerful advantages that improve their operations and drive growth. in addition to our state of the art global, geostationary satellite fleet, telesat lightspeed, our low earth orbit network scheduled to begin service in 2022, will revolutionize global broadband connectivity by delivering a combination of high capacity, security, resiliency and affordability with ultra low latency and fiber like speeds. telesat also provides industry leading technical consultation and support services to satellite operators, insurers and other industry stakeholders around the globe. privately held and headquartered in ottawa, canada, with offices and facilities around the world, telesat s principal shareholders are canada s public sector pension investment board and loral space communications inc. . for more information, visit purpose of job the senior data scientist will be responsible of studying real time and historical data residing in the data platforms to drive insights and b.i. by implementing ml or ai techniques. the candidate will be primarily focused on examining metadata for different use cases and assessing, developing and implementing ml or ai models using advanced statistical and modeling techniques. main responsibilities the role has 2 primary responsibilities data science research, develop, and implement machine learning algorithms and artificial intelligence into a variety of services and use cases. monitor the latest trends and techniques in machine learning and artificial intelligence to drive innovation. collaborate with other teams and share knowledge and ideas to drive optimal business decisions data visualization apply advanced and modern data visualization techniques to enable a digital experience create self serve dashboards to empower stakeholders and various business segments education experience required specialized knowledge, skills and abilities 5 years experience in data science with proven experience in ml and ai advanced understanding of machine learning, neural networks and deep learning expert in python proficiency in machine learning frameworks like scikit learn, tensorflow, pytorch, or keras general knowledge of data consumer hubs experience in studying complex data sets and strong knowledge in data visualization excellent communication and interpersonal skills ability to work under pressure and meet strict deadlines master s degree is an asset software engineering, computer science or mathematics with specialization in statistics, data analytics, or related discipline preferred. decision making supervision decision making in this role, the incumbent will unleash the power of machine learning and artificial intelligence to positively impact and recommend business decisions tied to lightspeed. supervision exercised there will be no supervision of other team members expected for this position. working conditions the successful candidate must be able to work in canada and obtain clearance under the canadian controlled goods program .","['support services', 'pytorch', 'tensorflow', 'data visualization', 'dashboards', 'data analytics', 'python', 'statistics', 'keras', 'software', 'data science', 'machine learning', 'metadata', 'artificial intelligence', 'algorithms', 'deep learning', 'neural networks', 'low latency', 'security', 'computer science', 'mathematics', 'modeling', 'ai']","['pytorch', 'python', 'keras']","['support services', 'tensorflow', 'sci', 'data visualization', 'dashboards', 'data analytics', 'statistics', 'software', 'data science', 'machine learning', 'metadata', 'artificial intelligence', 'algorithms', 'deep learning', 'use cases', 'neural networks', 'low latency', 'security', 'computer science', 'mathematics', 'modeling', 'ai']","['customer service', 'public sector', 'art', 'education']"
84,107,Associate Data Scientist,"pointclickcare is the leading north american cloud based healthcare software for the acute and long term and post acute care markets. for over 20 years, the company has held the same vision to help the world care for vulnerable populations. since its inception, pointclickcare has grown exponentially with over 1,700 employees today all working towards impacting the lives of millions. recognized by forbes as one of the top 100 private cloud companies and acknowledged by waterstone human capital as canada s most admired corporate culture, pointclickcare leads the way in creating cloud based software. with its recent acquisition of collective medical, pointclickcare solidifies its position as a high growth healthcare software provider, serving over 21,000 long term and post acute care providers and over 1,300 hospitals. their shared mission to support vulnerable populations is allowing pointclickcare and collective medical to connect disparate points of care at scale faster than anyone else in the market. for more information on pointclickcare, please connect with us on glassdoor and linkedin. position type co op student reporting to the vice president, data intelligence, the associate data scientist will be responsible for understanding, interpreting, manipulating, grouping and correlating our data with the goal of turning our vast amounts of meaningful insights for pointclickcare internally and for existing and new customer bases externally. key responsibilities analyzing and understanding pointclickcare s data thoroughly developing a full understanding of our customers challenges and need for data, in addition to our own internal needs translate business needs into requirements to build analytic plan for data models, approach and methodology perform data preparation activities necessary for feature engineering using machine learning, develop predictive models and visualization tools to deliver new insights and analytics products to our organization analyze and evaluate model for accuracy, algorithmic fairness and interpretability seek feedback on relative purpose, value and performance of completed analytics products experience required coursework or practical experience with data mining and building algorithms some experience in the evaluation of data or data sets work products involving data analysis and research proficient computer skills including use of microsoft office products or equivalent software and the ability to learn corporate software programs basic analytical, data mining, data modeling and data management skills, and ability to utilize data to drive strategic business directions practical ability to visualize data, communicates effectively about data, and utilizes data effectively strong problem solving and logical skills ability to think creatively and to work well both as part of a team and as an individual contributor. demonstrate ability to work with minimal direction, with the ability to coordinate complex activities. meticulous attention to detail excellent written and verbal communication skills and the ability to interact with a variety of customers and stakeholders. some exposure with a range of business intelligence and analysis tools sas, sql server reporting services, spss, r, microstrategy, or tableau is an asset statistical programming experience is an asset it is the policy of pointclickcare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic or civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. pointclickcare welcomes and encourages applications from people with disabilities. accommodations are available upon request for candidates taking part in all aspects of the selection process. please contact should you require any accommodations. when you apply for a position, your information is processed and stored with lever, in accordance with lever s privacy policy. we use this information to evaluate your candidacy for the posted position. we also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. when we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. if you have any questions about how pointclickcare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact pointclickcare s human resources team","['visualization', 'tableau', 'software', 'reporting', 'data', 'analytics', 'programming', 'data models', 'sas', 'data mining', 'data preparation', 'machine learning', 'sql server', 'statistical', 'business intelligence', 'data analysis', 'data intelligence', 'algorithms', 'modeling', 'data management', 'r']","['sql', 'tableau', 'data', 'programming', 'business intelligence', 'data models', 'sas', 'r']","['data mining', 'data preparation', 'machine learning', 'visualization', 'software', 'reporting', 'data analysis', 'analytics', 'data', 'modeling', 'statistical', 'methodology', 'data management', 'algorithms', 'feature engineering']","['human capital', 'private', 'healthcare', 'human resources', 'microsoft office', 'microstrategy', 'linkedin', 'law']"
85,108,Data Scientist,"company information name of hiring company nuvoola ai nuvoola ai is an artificial intelligence firm based in quebec, ontario, and new brunswick. we are market leader in artificial intelligence computer vision, implementing virtual guard solutions, with facial, license plate and character recognition, leveraging natural language interaction for various market and industries. we thrive at optimizing business processes and solving complex operational problems. we are a recognized and talented team partnering with the best in the industry and take serious proud of helping our customer reduce their operating cost, be more competitive while improving their overall efficiency. we offer a stimulating, high technology work environment and state of the art projects, coupled with professional development and continuing education with access to international conferences and sophisticated work equipment. nuvoola ai subscribes to the principle of equal access to employment and promotes the diversity of the workforce. please apply via https or or or company careers job title data scientist sector management finances and administration natural and applied science related fields health sales services supply chain, transportation, and related fields natural resources, agriculture public utilities fabrication services number of opening 1 designated work area montreal or chambly , ottawa , caraquet , remote job description are you passionate about creating sustainable solutions using ai and cloud technologies join the nuvoola ai team as a data scientist to solve interesting business challenges. we are looking for individuals that master a whole range of skills and talents going from being able to handle the raw data, analyzing that data with the help of statistical techniques, to sharing his or her insights with his peers in a compelling way. the candidate should be capable of figuring new ways of answering business needs where current bi formulas do not exist, should also be focused on predicting future results vs traditional bi views of current or past kpis. if you are looking for a team environment and a fun place to work, with emerging technologies and projects, nuvoola ai is the place for you. come and join us primary responsibilities works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business decisions. applies scripting and programming skills to assemble various types of source data into well prepared datasets with multiple levels of granularities . summarizes statistical findings and draws conclusions, presents actionable business recommendations. presents findings and recommendations in a simple, clear way to drive action. makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices. helps define the strategic direction that nuvoola ai should take with respect to ai. influences stakeholders on the best approaches to use for deep learning. identifies cloud infrastructure needs for deep learning. evaluates and makes recommendations for new tools, techniques, and technologies to develop and support evolving operational needs in the ai space. designs and develops custom data models and algorithms for the nuvoola ai product line. institutionalizes and develops the practice of data scientist within nuvoola ai. popularize complex solutions so that they are clear and understandable for non experts. promotes data science at nuvoola ai, its customers and to the external community. acts as a liaison between our university partners and nuvoola ai . works closely and supervises the future holders of a doctorate working on our innovating projects with such key partners. will physically work at those facilities when required. essential skills qualifications university degree in computer science, math, or related field or equivalent. masters or phd preferred. 5 years of work experience directly related to quantitative analysis with proven results. 3 years of work experience across a broad set of data science skills, including traditional statistical methods, machine learning and natural language processing. 3 years of experience with time series analysis, forecasting, and anomaly detection strong knowledge and hands on experience with r, python, sql and c. excellent oral and written communication skills excellent analytical, interpersonal and communication skills, including strong presentation skills. dynamic, positive attitude, practical, takes initiative to solve problems. excellent time management, organizational and collaborative skills. diplomas high school professional training bachelor s degree master phd required or privileged level in french bilingual fluent good average school level required or privileged level in english bilingual fluent good average school level required or privileged number of years of experience 3 to 5 years requited or privileged duration of contract fixed duration undetermined duration starting date april 2021 remuneration annual monthly weekly hourly amount from to the information on the salary is confidential public additional information why work at nuvoola ai stimulating work environment and state of the art projects, professional development and continuing education with access to international conferences, benefits after 3 months in position providing excellent coverage, open work environment and sophisticated work equipment. nuvoola subscribes to the principle of equal access to employment and promotes the diversity of the workforce.","['https', 'c', 'sql', 'python', 'time series analysis', 'scripting', 'computer vision', 'data science', 'programming', 'integration', 'anomaly detection', 'data models', 'r', 'machine learning', 'data collection', 'artificial intelligence', 'algorithms', 'forecasting', 'administration', 'deep learning', 'language processing', 'bi', 'datasets', 'computer science', 'cloud infrastructure', 'ai']","['https', 'sql', 'python', 'bi', 'c', 'programming', 'data models', 'r']","['natural', 'time series analysis', 'scripting', 'computer vision', 'data science', 'anomaly detection', 'integration', 'machine learning', 'quantitative analysis', 'data collection', 'artificial intelligence', 'algorithms', 'forecasting', 'administration', 'deep learning', 'language processing', 'datasets', 'computer science', 'cloud infrastructure', 'ai']","['utilities', 'environment', 'education', 'art', 'sales', 'agriculture', 'hiring', 'public']"
86,110,Data Scientist,"description we are looking for a data scientist who will work with a cross functional team of product, engineering, and customer success leaders to mine customer and end user data, build predictive models, develop data dashboards and visualizations, and conduct analytical studies in order to help improve our products and drive better outcomes for our customers. the ideal candidate should be passionate about behavioral data at scale, has a strong analytical and consultative mindset, a deep understanding of databases, visualization, and statistical and machine learning modeling techniques, and the ability to thrive in a dynamic, fast paced environment. this role will drive high impact to the company through engagement performance optimization, natural language processing, to persona analysis. company description viafoura partners with over 600 global media brands, helping them to engage, convert and monetize their digital audiences. with best in class engagement and content moderation solutions including real time conversations, live blogs, community chat, personalization tools, and ai powered moderation viafoura helps companies create active, civil, and loyal online communities reaching 500 million users every month, and generating massive scale real time data. advanced data analytics also offer customers access to unique and valuable insights into their audience s behaviors and preferences. as a result, the viafoura solution drives higher registrations and subscriptions as well as better targeted content and advertising. responsibilities formulate and lead guided, multifaceted analytic studies against large volumes of data interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific methods take ownership of end to end data analysis, reporting, and insights identify high potential but underexposed product and feature opportunities work with data partners to help develop integrated products works closely with engineering and product teams to develop a strategy for long term data products identify data gaps and present solutions through collaboration with engineering and product owners implement the strategies and set up a or b test experiments to support best practices qualifications master s or phd degree in an analytical field experience taking ownership of end to end analytical products 3 years of hands on experience in statistical modeling and analysis 3 years experience writing python and complex sql queries in a business environment 2 years of aws suite experience 1 years experience building machine learning models 1 years experience with quicksight or other visualization tools or open source libraries preferred qualifications analytical mindset and ability to see the big picture and influence others detail oriented and must have an aptitude for solving unstructured problems ability to work effectively in a multi task, high volume environment experience with commonly used dmps, cdps, and ad technology experience with natural language processing, sentiment analysis, semantic pattern detection, and machine learning ability to be adaptable and flexible in responding to deadlines and workflow fluctuations experience building natural language processing and or or recommendation systems in production a or b test experience job benefits competitive compensation comprehensive benefits professional development full remote work option","['personalization', 'visualization', 'databases', 'dashboards', 'data analytics', 'python', 'sql', 'reporting', 'aws', 'sentiment analysis', 'machine learning', 'data products', 'statistical', 'data analysis', 'language processing', 'optimization', 'modeling', 'pattern detection', 'ai']","['sql', 'python', 'databases', 'aws']","['personalization', 'data analytics', 'machine learning', 'visualization', 'language processing', 'data products', 'reporting', 'dashboards', 'data analysis', 'natural', 'statistical', 'optimization', 'modeling', 'sentiment analysis', 'pattern detection', 'ai']","['customer success', 'environment', 'advertising', 'subscriptions', 'compensation']"
87,111,Expert Data Science,"at cn, we work together to move our company and north america forward. be part of our information technology team, a critical piece of the engine that keeps us in motion. from enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value added tasks. you will be able to develop your skills and career in our close knit, safety focused culture working together as one team. the careers we offer are meaningful because the work we do matters. join us job summary you will be part of a team that spans across all business domains. you will provide advanced analytical insights using data analysis and machine learning techniques. you will collaborate with teams across the company, exploring various data sources to help identify new opportunities while driving the adoption of ai. as an expert data scientist, you will combine your knowledge of machine learning and software development skills to automate model development, training, and deployment. you will leverage your experience in building reusable algorithms, functions, and libraries to use in model development for predictive and prescriptive analytics. story telling is critical to the change management practice of putting the model into real live environment. success will be dependent on hypothesis generation, exploration of data, using ai to discover insights, to developing automation pipelines and visual analytics all being explained to our stakeholder s community. the data analytics team is helping cn to create a data driven culture where everyone can make better decisions, grounded in trusted data, and augmented by the power and scale of analytics. using advanced data platforms, and ai tooling, decisions can happen at just the right moment, impacting the environment, safety and operational excellence for our customers and team members, while always keeping an eye on the future, ready to explore... we are highly innovative, and passionate, we believe anything is possible, by embracing people culture, using the right technology, and having an agile mindset, we will drive the highest value to customers interested in working with a team of data innovators, and being part of a culture of transformation, creativity, and teamwork if so, we would love to connect with you main responsibilities work with structured and unstructured raw data to design and develop innovative predictive models, metrics, and dashboards to uncover actionable insights visualize and report data findings creatively in a variety of visual formats that provide insights to the organization influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset support and evolve the advanced analytics and data science roadmap by leveraging industry research, best practices, and emerging tools or technology collaborate on end to end automation efforts required to bring models to production build and maintain a strong engagement with key stakeholders to understand business needs and priorities requirements experience in the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques with hands on work experience 7 8 or more years of hands on work and practical business experience in machine learning and ai, including classification, clustering, time series analysis, nlp, demand forecasting and optimization excellent communication skills and capable of breaking down technical and complex concepts in a way that is understood by non technical audiences education or certification or designation masters or phd degree in a quantitative field such as math, statistics, computer science, economics, or data science technical skills or knowledge solid development experience with python and comfortable using various data science libraries such as scikit learn, pandas, numpy as well as frameworks like tensorflow, pytorch, keras and have applied these skills towards solving actual business matters comfortable working in and with a jupyter like environment and infrastructure, and familiar with github, data bricks have advanced knowledge in sql and apache spark expert level experience with at least one of the cloud computing platforms azure, aws, gcp familiar with tableau and or or power bi visual analytics purposes well versed in software and ai development lifecycles, including ml ops have agile experience and have a bias for action, removing blocks to get results fast assets experience with safe agile methodology and work in a fast paced environment having azure or other cloud certifications, for example azure data lake, data bricks about cn as a leading north american transportation and logistics company, cn is a true backbone of the economy. with a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. we transport us 200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000 mile network spanning canada and mid america. cn is the only canadian company listed in the transportation and transportation infrastructure sector of the dow jones sustainability world index . launched in 1999, the djsi world represents the gold standard for corporate sustainability. at cn, we work as one team, focused on safety, sustainability, and our customers, providing operational and supply chain excellence to deliver results. cn is an employment equity employer and we encourage all qualified candidates to apply. we thank all applicants for their interest, however, only candidates under consideration will be contacted. please monitor your email on a regular basis, as communication is primarily made through email.","['tableau', 'pytorch', 'tensorflow', 'dashboards', 'information technology', 'sustainability', 'github', 'data analytics', 'python', 'sql', 'statistics', 'keras', 'gcp', 'time series analysis', 'software', 'data science', 'enterprise', 'software development', 'analytics', 'pandas', 'aws', 'pipelines', 'cloud computing', 'ops', 'data mining', 'jupyter', 'analytical techniques', 'machine learning', 'apache spark', 'numpy', 'data analysis', 'algorithms', 'forecasting', 'automation', 'visual', 'model', 'bi', 'economics', 'nlp', 'computer science', 'optimization', 'modeling', 'ai']","['jupyter', 'sql', 'python', 'gcp', 'keras', 'tableau', 'bi', 'pytorch', 'apache spark', 'numpy', 'nlp', 'model development', 'azure data lake', 'pandas', 'aws', 'pipelines', 'visual']","['tensorflow', 'sci', 'dashboards', 'information technology', 'modeling', 'sustainability', 'github', 'data analytics', 'statistics', 'time series analysis', 'software', 'data science', 'enterprise', 'software development', 'analytics', 'cloud computing', 'ops', 'data mining', 'analytical techniques', 'machine learning', 'predictive', 'data analysis', 'algorithms', 'forecasting', 'automation', 'visual', 'model', 'economics', 'computer science', 'optimization', 'methodology', 'ai']","['environment', 'change management', 'education', 'metrics', 'design', 'operational excellence', 'adoption', 'architecture']"
88,112,Data Scientist,"you re more than just a statistician made to sound sexy. you re a happy, hands on, passionate analyst who can write code and knows math. reliance foundry co. ltd. is a surrey based, rapidly growing metal products company. with 95 years of experience in the cast metals industry, we now service our global customers by providing traditional site furnishing and castings in new and innovative ways. we are an agile small business with limitless growth plans that extend far beyond simple metal products. today, we are looking for enthusiastic, motivated and talented people to join our team. we are looking for a lead data scientist to develop comprehensive machine learning models for various smart city and related iot products. you will be in charge of managing and orchestrating large amounts of raw, real time data. we will rely on you to build exceptional data products to extract and deliver valuable business insights for our customers. in this role, you should be highly analytical with a knack for analysis, math, maybe some physics, and certainly statistics. critical thinking and problem solving skills are essential for interpreting data. we also want to see a passion for machine learning and research. your goal will be to help our customers analyze trends that matter to them and to empower their decision making process with actionable data. key responsibilities work within our digital products team to establish optimal data collection process and techniques. undertake preprocessing of structured and unstructured data. analyze large amounts of information to discover trends and patterns to deliver valuable insights. build predictive models and machine learning algorithms. present information using awesome data visualization techniques that cut through the noise. propose solutions and strategies to business challenges. collaborate with engineering and product development teams. required qualifications or preferences proven experience as a data scientist, preferably in a lead role. direct experience developing and training machine learning models. deep knowledge of sql and python familiarity with jupyter, javascript, c, c , or java is an asset. experience using business intelligence tools and data frameworks . analytical mind and business acumen. strong math skills . problem solving aptitude. excellent communication and presentation skills. you can summarize the complex into the simple. bsc or ba in computer science, engineering or relevant field graduate degree in data science or another quantitative field is preferred. attractive qualifications happy you were born with this special gene whereby your glass is always full. hustle factor you don t get discouraged by objections, and you get persistent when it comes to reaching your goals. passionate you re all about solving real problems, not just pitching. results driven you re able to think on your feet and love overcoming obstacles. adaptability you are open to feedback and coaching and ready to take your skills to the next level. organization you know how to allocate your time effectively. empathetic you re a good listener who knows how to get a real sense of customer s needs. customer focused you re always thinking about how to add value for the customer. ability to accomplish multiple tasks simultaneously with speed and accuracy. why should you apply full time position with a competitive benefits package, and salary structure. reliance foundry celebrates successes with fun company gatherings, luncheons, and other perks we believe in an environment that encourages a positivity while pursuing high standards. please submit resumes via email complete with personal cover letter and wage requirements to jazz gill, hr manager reliance foundry co. ltd. surrey, british columbia , canada e mail no telephone inquiries or agencies, please. applications will be assessed to determine a short list of candidates to be interviewed. we appreciate all interest, but only qualified candidates will receive responses.","['unstructured data', 'data visualization', 'c', 'javascript', 'java', 'sql', 'python', 'statistics', 'physics', 'data science', 'jupyter', 'machine learning', 'data products', 'iot', 'data collection', 'interpreting data', 'business intelligence', 'algorithms', 'business insights', 'computer science']","['jupyter', 'sql', 'python', 'iot', 'business insights', 'c', 'javascript', 'java']","['unstructured data', 'machine learning', 'statistics', 'data products', 'physics', 'data visualization', 'data collection', 'interpreting data', 'data science', 'computer science', 'business', 'algorithms']","['product development', 'environment', 'hr']"
89,113,DATA SCIENTIST,"who we are at leger, we know canadians. with over 30 years of experience, we are the most accurate market research firm in canada. joining our company means joining a team of 600 passionate people who are committed to their work. we are the largest canadian owned market research and analytics company, with 8 offices across canada and the united states. why you will love working with us we are the benchmark in our industry, and we offer important strategic advice to our clients. we distinguish ourselves through our company culture, our transparent management, our dynamic attitude and our flat company structure. our team is the basis of our success and as they say, birds of a feather flock together. if you want to join us and make a difference, our team is waiting for you your role as a data scientist provide effective, relevant and innovative insights to our clients through data modelling advise our internal external clients on the data and models to use to meet their business needs use your skills in big data mining and modelling i.e., machine learning algorithms, advanced statistical analyses, etc. share your knowledge and expertise with your coworkers joining our team as a data scientist means taking the values of quality, customer service, innovation, collaboration and commitment to heart. it means being passionate about data, various statistical analyses and storytelling. it also means sharing your knowledge, providing advice and contributing to the growth of the team. above all, it means growing and evolving in a stimulating and friendly environment. your responsibilities data mining and modelling from various sources perform advanced statistical analysis segmentation, maxdiff, conjoint analysis, factor analysis, turf, etc. and apply the various techniques to the market research industry develop predictive models, classification models, marketing attribution models, etc. process structured and unstructured data propose and develop effective business intelligence solutions aligned with client needs develop marketable tools such as simulators, dashboards and predictive models advise research teams on service proposals, deliverables, which models and analyses to use, which data to use, interpretation of results, etc. what you need to succeed requirements graduate degree in a quantitative field such as computer science, engineering, physics, statistics, applied mathematics or equivalent strong knowledge of programming languages with emphasis on machine learning and advanced analytics techniques practical experience in sql and database coding fluency in french and english is essential at least 2 years of experience in business intelligence and data modelling knowledge of statistical techniques and data mining skills practical experience with large databases collaborative spirit and ability to effectively communicate complex ideas to clients and coworkers excellent analytical and problem solving skills, with the capacity to identify the causes of problems and provide recommendations quicklyexperience in market research and marketing rigorous and accurate data processing with a keen eye for detail ability to work under tight deadlines and manage multiple projects benefits paid vacation group insurance employee recognition program leger university, training, mentorship, and continuing education employee assistance program profit sharing program pension plan flex program hybrid work model overall health allowance and more the perks of working with us at leger, our people are at the heart of our success. being part of our team means working in a friendly, respectful, and positive environment. happiness at work is one of our top priorities enjoying flexible benefits and other perks that foster a culture of well being. developing your skills and thriving professionally with our learning and mentorship opportunities. multiple opportunities for long term growth. more than one third of our permanent employees have been with leger for at least 10 years. making new friends and connections across canada and the united states. and much more if you want to be part of a great team and you think you are the motivated, talented and ambitious person we are looking for, submit your application we thank all applicants. however, only those selected for an interview will be contacted. leger is an equal opportunity employer. it prohibits discrimination based on age, colour, disability, national origin, race, religion, sex, sexual orientation, and any other legally protected class in accordance with applicable federal, provincial and local laws. leger is committed to creating and maintaining an inclusive and accessible workplace. if you are contacted for an interview and require accommodation during the interviewing process, please let us know.","['unstructured data', 'data mining', 'attribution', 'sql', 'machine learning', 'statistics', 'databases', 'data processing', 'programming languages', 'physics', 'dashboards', 'computer science', 'analytics', 'business intelligence', 'applied mathematics', 'statistical analysis', 'algorithms']","['sql', 'databases', 'programming languages', 'big', 'business intelligence']","['unstructured data', 'data mining', 'attribution', 'machine learning', 'statistics', 'data processing', 'physics', 'dashboards', 'computer science', 'analytics', 'applied mathematics', 'statistical analysis', 'algorithms']","['environment', 'education', 'marketing', 'market research', 'customer service', 'external clients', 'insurance']"
90,114,Data Scientist,"company description cardinal path, part of dentsu, is a leading digital analytics and digital marketing firm focused on delivering insight, understanding and outcomes that create competitive advantage for our clients. we engage at the strategic, business, and technical levels to generate tangible and quantifiable value for our partners. our clients include brands such as bridgestone, johnson and johnson, pfizer, asics and hundreds of others. cardinal path s mission is to know. to share. to be our partners competitive advantage. and our company culture reflects the importance of our people s expertise, wellness and happiness in everything we do. job description the data science consultant will have proven expertise in system architecture, database design, data integrations, and be an expert in sql and python. experience with delivering in big data platforms such as google bigquery, microsoft azure sql db or synapse, or amazon redshift is essential. expertise with traditional rdbms platforms such as sql server or oracle and nosql and hadoop environments would complement. data integration experience using etl platforms such as airflow, talend, alteryx, or fivetran is important. experience in the digital data and analytic ecosystem and intermediate knowledge in web analytic tools , and api expertise is a major plus act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts participate in product roadmap discussions and identifying key areas for improvement of products and services collect client project requirements, focusing on needs impacts and necessary technical outcomes create solution designs to solve for clients business and technical needs while keeping within budget produce documentation of data pipeline design and solution architecture for data warehousing and etl, following cardinal path s documentation standards create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security create ongoing standards and process for overall data architecture team, including developing governance, support and testing models perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. qualifications bachelor s degree in statistics, mathematics, business analytics or related field quantitative field, required with a minimum of 3 5 years experience with database development experience with cloud or big data technologies such as bigquery, azure sql db or synapse, amazon redshift is required experience with relational database systems including sql server, oracle, mysql, postgres advanced skills in data scripting and database development technologies deep knowledge of etl tools and how they can be applied to a big data environment familiarity with analyzing digital marketing, advertising and ecommerce data familiarity with web analytics tools such as adobe marketing cloud or google analytics experience with optimizing bi or visualization tools such as tableau, looker, domo or power bi experience with cloud platforms such as aws, azure, and google cloud familiar with nosql database technologies such as mongodb knowledge of technologies such as spark, hadoop, and airflow additional information we know through experience that different ideas, perspectives and backgrounds foster a stronger and more creative work environment that delivers better business results. we strive to create workplaces that reflect the clients we serve and where everyone feels empowered to bring their full, authentic selves to work. we are committed to working with our candidates from all ability levels throughout the recruitment process to ensure that they have what they need to be at their best. if you need accommodation during the application or interview process, please contact or to begin a conversation about your individual accessibility needs throughout the hiring process. li mz1","['visualization', 'business analysis', 'tableau', 'rdbms', 'big', 'alteryx', 'dashboards', 'data integrity', 'data standards', 'documentation', 'mongodb', 'business', 'mysql', 'microsoft azure', 'sql', 'python', 'looker', 'statistics', 'reporting', 'talend', 'database systems', 'database design', 'data science', 'data', 'analytics', 'integration', 'digital', 'aws', 'application development', 'data engineering', 'data warehousing', 'nosql', 'data mining', 'google analytics', 'testing', 'web', 'airflow', 'database development', 'bi', 'hadoop', 'datasets', 'security', 'api', 'system', 'mathematics', 'azure sql', 'data management', 'etl']","['tableau', 'rdbms', 'alteryx', 'big', 'data standards', 'documentation', 'big data', 'big data bigquery', 'domo', 'mysql', 'sql', 'python', 'looker', 'talend', 'data', 'aws', 'amazon redshift', 'nosql', 'google analytics', 'microsoft azure sql redshift', 'airflow', 'bi', 'hadoop', 'api', 'azure sql']","['visualization', 'business analysis', 'exploratory', 'data integrity', 'dashboards', 'mongodb', 'business', 'statistics', 'reporting', 'scripting', 'database systems', 'data science', 'database', 'analytics', 'data', 'integration', 'application development', 'data engineering', 'data warehousing', 'data mining', 'web analytics', 'testing', 'database development', 'datasets', 'security', 'system', 'mathematics', 'solution', 'data management', 'etl']","['validation', 'environment', 'advertising', 'marketing', 'design', 'sales', 'adobe', 'governance', 'digital', 'hiring', 'architecture']"
91,115,Data Scientist - NLP,"what is the opportunity as a data scientist in the nlp space you are part of a team responsible for developing rbc s nlp platform supporting a variety of projects. you will be part of the innovation and technology team at rbc, working on building technology components that rbc developers and businesses leverage to deliver business value. you will be working on projects using latest advancements in natural language processing to enable adoption and reuse across the enterprise. the position will involve research in a practical setting while building production systems and models. we want vocal futurists that can advocate their vision, who will be excited about creative problem solving as part of a cross functional team will obsess over writing smart, simple clean code will tirelessly strive to deliver the best solution supporting the user experience and will have the drive and desire to keep learning the latest. what will you do work with modern open source and vendor packages to support use cases in semantic understanding conversational ai. own the end to end cycle from understating the business problem, data discovery and extraction, model development and evaluation, to production deployment. stay up to date with latest research and apply it in practical settings to define strategy and deliver business value. perform code reviews and ensure a high level of code quality. provide technical mentorship within the organization to streamline adoption of nlp components. keep developer experience in mind when building tools and services for others to use. work in a cross functional, collaborative team aimed at delivering high value, high quality, and scalable nlp or ml solutions. what do you need to succeed must have master s or phd degree in mathematics, statistics or computer science with a focus on ai or ml areas 2 years of work experience in a data science and machine learning expert understanding of nlp tasks such as classification, ner, text generation, and topic modeling with practical experience using nlp libraries such as gensim, spacy hands on experience and expertise with different ai or ml frameworks such as keras, pytorch, tensorflow, sparkml, scikit learn solid experience in deploying production level ai models nice to have experience with deep neural networks architectures in particular transformer models familiar with container type environments docker, openshift 3 years of experience in advanced software engineering practices including agile techniques what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. we care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual. a comprehensive total rewards program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable leaders who support your development through coaching and managing opportunities work in a dynamic, collaborative, progressive, and high performing team flexible work or life balance options opportunities to take on progressively greater accountabilities opportunities to building close relationships with business partners learn more about rbc tech jobs join our talent community stay in the know about great career opportunities at rbc. sign up and get customized info on our latest jobs, career tips and recruitment events that matter to you. expand your limits and create a new future together at rbc. find out how we use our passion and drive to enhance the well being of our clients and communities at rbc.com or careers. job summary city toronto address 88 queens quay west work hours or week 37.5 work environment office employment type permanent career level experienced hire or professional pay type salary variable bonus required travel 0 exempt or non exempt n or a people manager no application deadline 06 or 25 or 2021 platform technology and operations req id 368717 ad code","['model', 'language processing', 'statistics', 'machine learning', 'keras', 'openshift', 'software', 'user experience', 'pytorch', 'tensorflow', 'neural networks', 'nlp', 'data science', 'computer science', 'mathematics', 'modeling', 'production systems', 'ai']","['openshift', 'keras', 'nlpcy', 'pytorch', 'nlp', 'rbc', 'rb']","['model', 'conversational', 'use cases', 'language processing', 'statistics', 'machine learning', 'text generation', 'software', 'user experience', 'tensorflow', 'neural networks', 'data science', 'computer science', 'natural', 'mathematics', 'modeling', 'production systems', 'ai']","['environment', 'events', 'business value', 'rbc', 'adoption', 'compensation']"
92,117,Data Science,"job category engineer job type full time job location canadausa location multiple locations description we are looking for data scientists who can develop best in class predictive models, machine learning models, and deep learning models and at the same time, they should be able to explain the decisions taken by the models automatically through plain simple english language. also, facilitate product solutions and enhance user experience with analytical insights and addressing the problem statements encountered by users responsibilities work with deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. experience using statistical computer languages r, python, slq, etc to manipulate data and draw insights from large data sets experience working with and creating data architectures knowledge of a variety of machine learning techniques clustering, decision tree learning, artificial neural networks, etc and their real world advantages or drawbacks knowledge of advanced statistical techniques and concepts regression demonstrate and document working prototype on test datasets and real world scenarios. innovate to come up with new solutions and improve existing solutions. be an enthusiastic and motivated member of the team. maintain knowledge of new technologies in the field of computer vision and machine learning. required skills python, linux os has hands on knowledge on setting up docker containerization and running application on ecs,eks very good exposure in setting up analytical tools such as rstudio, mlflow, databricks, jupyter etc. very good practical knowledge of using and implementing aws services ec2,s3,ecs,aws sagemaker. mathematical optimization, discrete event simulation, rules programming, and predictive analytics.","['deep learning', 'jupyter', 'python', 'machine learning', 'linux', 'user experience', 'datasets', 'neural networks', 'computer vision', 'analytics', 'programming', 'aws', 'optimization', 'ecs', 'containerization', 'r']","['jupyter', 'python', 'linux', 'rstudio', 'programming', 'mlflow', 'aws', 'ecs', 'containerization', 'predictive', 'r']","['deep learning', 'machine learning', 'mathematical', 'user experience', 'artificial', 'neural networks', 'datasets', 'computer vision', 'analytics', 'optimization', 'computer', 'rules']",['emerging trends']
93,118,Data Scientist,"transforming the future with the convergence of simulation and data data scientist do you like a challenge, are you a complex thinker who likes to solve problems if so, then you might be the new altairian we are searching for. at altair, your curiosity matters. we pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients success, as well as our own. job summary the goal of the data scientist is to provide impactful analytics for clients using available data. the data scientist works alongside project managers, etl professionals, relationship managers and sales managers to serve a diverse group of clients. the role is client facing and calls for a mixture of technical, business and people skills. data scientists apply data analysis and statistical techniques to various data sets to develop predictive models and apply other machine learning techniques. as a consultant, they are also critical in the phases prior to modelling defining the project, hands on data extraction, and data quality. after modelling, data science consultants are responsible for the presentation and deployment phases, and performing the tasks that lead to successful implementation of predictive analytics for our clients. location greater toronto area, ca what you will do requirements capture, data preparation and analysis, knowledge discovery, predictive analysis, business analysis and interpretation, reporting and scoring, roi analysis, strategic deployment of analytics, provide maximum business value to altair clients through analytics deployment, working in close collaboration with altair sales professionals and serving as knowledgeable trusted advisors to clients and industry partners, provide a spectrum of custom, rapidly deployable, solutions which include b2b and b2c data driven decision support capabilities conduct presentations to senior level clients when required what you will need basics strong quantitative background with msc or phd. 2 years working as a data scientist. deep knowledge understanding of data mining techniques . strong analytical and problem solving skills. good working knowledge of programming languages and platforms such as sas and or or sql , matlab, r or python. excellent written and oral communication skills. be able to work independently as well as in a team environment. how you will be successful envision the future communicate honestly and broadly seek technology and business firsts embrace diversity and take risks what we offer competitive salary comprehensive benefit package outstanding work or life balance flex time group rsp employee stock purchase program paid vacation paid holidays paid time off for community service collaborative environment charitable matching program why work with us altair is a global technology company that provides software and cloud solutions in the areas of product development, high performance computing and artificial intelligence . altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. with more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today s problems into tomorrow s opportunities. our vision is to transform customer decision making with data analytics, simulation, and high performance computing and artificial intelligence . for more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop ai, simulation and data driven digital twins to drive better decisions, and deliver advanced hpc and cloud solutions to support unlimited idea exploration. to learn more, please visit altair.com. ready to go onlyforward at our core we are explorers adventurers pioneers. we are the brains behind some of the world s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. we are the original trailblazers that make the impossible possible discovering new solutions to our customer s toughest challenges. altair is an equal opportunity employer. our backgrounds are diverse, and every member of our global team is critical to our success. altair s history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.","['go', 'computing', 'business analysis', 'electronics', 'sql', 'python', 'data analytics', 'software', 'reporting', 'data science', 'analytics', 'hpc', 'sas', 'data mining', 'machine learning', 'data preparation', 'ai', 'artificial intelligence', 'data analysis', 'data quality', 'matlab', 'programming languages', 'data extraction', 'project managers', 'etl', 'r']","['go', 'sql', 'python', 'programming languages', 'high performance', 'predictive', 'hpc', 'data quality', 'electronics', 'sas', 'matlab', 'r']","['data mining', 'computing', 'data analytics', 'machine learning', 'data preparation', 'business analysis', 'data extraction', 'software', 'reporting', 'data science', 'project managers', 'analytics', 'predictive analysis', 'artificial intelligence', 'data analysis', 'etl', 'ai']","['environment', 'b2c', 'business value', 'business culture', 'presentations', 'sales', 'design', 'product value', 'product development']"
94,119,Data Scientist,"core responsibilities 1. develops queries and performs extensive programming to access, transform, and prepare data for statistical modeling. 2. performs deep dive diagnostic, predictive, and prescriptive analytics to support data driven business decision making. 3. identifies and diagnoses data inconsistencies and errors, documents data assumptions, and forages to fill data gaps. 4. engages with internal stakeholders to understand and probe business processes in order to develop hypotheses. brings structure to requests and translates requirements into an analytic approach. 5. guides test design, research design, and model validation. provides statistical consultation services. serves as the analytics expert on cross functional teams for large strategic initiatives and contributes to the growth of the vanguard analytic community. 6. prepares and delivers insight presentations and action recommendations. communicates complex analytical findings and implications to business partners. 7. participates in special projects and performs other duties as assigned. qualifications minimum of three years related work experience in analytical roles. experience with data wrangling required programming skills to access, transform and prepare large scale data for statistical modeling. experience utilizing statistical and machine learning methods required. undergraduate degree in analytics, applied mathematics, economics, statistics or related analytical field of study or equivalent combination of training and experience. graduate degree preferred. about vanguard we are vanguard. together, we re changing the way the world invests. for us, investing doesn t just end in value. it starts with values. because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. we invest with purpose and that s how we ve become a global market leader. here, we grow by doing the right thing for the people we serve. and so can you. we want to make success accessible to everyone. this is our opportunity. let s make it count. inclusion statement vanguard s continued commitment to diversity and inclusion is firmly rooted in our culture. every decision we make to best serve our clients, crew , and communities is guided by one simple statement do the right thing. we believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. we empower our crew to contribute their distinct strengths to achieving vanguard s core purpose through our values. when all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on vanguard s core purpose. our core purpose to take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.","['model', 'machine learning', 'statistics', 'data wrangling', 'economics', 'analytics', 'statistical', 'programming', 'modeling', 'applied mathematics']",['programming'],"['model', 'machine learning', 'statistics', 'test', 'data wrangling', 'economics', 'analytics', 'statistical', 'modeling', 'applied mathematics']","['validation', 'investing', 'forages', 'consultation', 'design', 'presentations', 'strategic initiatives']"
95,121,Data Scientist,"patagona technologies is a software development company working with the canadian department of national defence on studying and combating online disinformation. we are looking for a data scientist to contribute to the development of various machine learning models on social media network data. you will work side by side with a computational social scientist to apply these models to various real world case studies to demonstrate and validate our systems. you will apply social network analysis approaches to various research contexts. responsibilities develop techniques to expand training datasets while limiting bias within those datasets. develop processes and tools to monitor and analyze model performance and data quality. gather and process data at scale, write scripts and queries, and work with apis. work with the team to provide research support using qualitative and quantitative methods. contribute to reports and studies for publication. qualifications experience using python to manipulate data and draw insights from large data sets. experience working with relational data using sql. experience visualizing and presenting data to stakeholders. experience working with cloud services for data processing and etl pipelines. excellent written and verbal communication skills for communicating with a team and writing for publication. knowledge and experience in statistical and data mining techniques for social network analyisis. knowledge of common machine learning techniques and their real world advantages or drawbacks. familiarity with data analytics and computational social science methods . strong problem solving skills and proactive in filling in own knowledge gaps through learning and asking questions. special consideration will be given to candidates with written language skills in french, russian and chinese. prior experience studying online disinformation or other social media analysis work. job type full time pay 75,000.00 83,000.00 per year","['data mining', 'case studies', 'python', 'machine learning', 'sql', 'data processing', 'pipelines', 'data analytics', 'datasets', 'software development', 'data quality', 'etl', 'cloud services']","['sql', 'python', 'pipelines', 'data quality', 'model performance']","['data mining', 'case studies', 'data analytics', 'machine learning', 'data processing', 'network analysis', 'datasets', 'relational data', 'software development', 'etl', 'cloud services']",[]
96,122,Machine Learning Engineer / Data Scientist,"catchy intro honestly, we ve been brainstorming this catchy intro for about 20 minutes and everything that we throw at the wall is either too serious, or just downright lame, with no authenticity behind it. which is absolutely hilarious, considering everyday terrasense strives for authenticity. so that s it. that s what you get. our not so super catchy, not super lame, but not super corporate intro. authentic. hey, come work here and help us on this journey. why work with us our two main products target the utilities and defense sectors. besides understanding how to use machine learning to predict maintenance for transmission lines, or how to take the metadata from two sensors and fuse them together, we actually do appreciate the soft skills too. we strive to foster a culture of success, innovation, respect, and did we mention authenticity that s right, if you hate what the cto is saying, we fully expect you to step up and tell him he s wrong . the product manager does all the time and she still hasn t been fired. what you would be doing... ... on the development team for our mist product, working to create and deploy aerial surveillance with artificial intelligence. the product will utilize edge computing, computer vision and deep learning algorithms. okay so we hope that you got this far and are slightly intrigued by our culture and what you would be doing. here comes the hard part. this role requires you to be a canadian citizen or permanent resident having resided in canada for at least 10 years as well as a criminal record and credit check. you will be required to work locally with flexibility on work hours. these are hard requirements with no negotiation, so please do not apply to this particular role if you don t meet these requirements. we will have other roles that come up without such stringent requirements, but there is no wiggle room on this one. qualifications excellent knowledge of python 2 years of experience in building and shipping great software experience with deploying ml on the edge or in the cloud strong knowledge of ml frameworks knowledge of computer vision models, frameworks, and tools eligible for security clearance and to work in canada bonus experience with docker, video analytics, and or or gui development a plus bonus networking and cybersecurity experience compensation competitive salary and stock options based on experience, competency and length of service 5 weeks paid vacation training and professional development allowance, and extended medical and dental beer tuesdays at our neighbourhood microbrewery non compensation considerations accountability we truly do work hard, play hard and expect everyone to self manage...meaning we don t track hours. flexibility if your best time to work is from 10pm to 2am then we want to support that so we try to enable team communication by committing to m th 10am 2pm office hours. the rest is up to you.","['deep learning', 'computing', 'python', 'machine learning', 'cybersecurity', 'sensors', 'software', 'computer vision', 'security', 'networking', 'metadata', 'artificial intelligence', 'analytics', 'rest', 'algorithms']",['python'],"['deep learning', 'computing', 'machine learning', 'cybersecurity', 'sensors', 'software', 'computer vision', 'security', 'gui', 'networking', 'metadata', 'artificial intelligence', 'analytics', 'rest', 'algorithms']","['utilities', 'transmission', 'surveillance', 'negotiation', 'compensation']"
97,123,Data Scientist,"we are looking for a great data scientist to join wysdom.ai a fast growing conversational ai company helping businesses offer their customers natural language ai solutions that deliver automated customer service and support over chat, through smart devices, search, or on the phone. wysdom offers a comprehensive conversational ai optimization suite helping businesses increase customer satisfaction, contain costs, and maximize revenue generation. we use a proprietary suite of analytics, optimization and testing tools, and offer services through a team of experienced conversational ai specialists who ensure clients maximize their conversational ai roi. brands around the world fully outsource their conversational ai needs to wysdom. we do all the work for enterprises as their business evolves, from set up to optimization. our customer s only job is to tell us what matters to their customers and what matters to them. we ll take it from there, while providing the ongoing insights on how wysdom is shaping the experience of the enterprise s customers. the wysdom platform is built on a state of the art nlp infrastructure, complemented with the tools, data and people to ensure successful operation of the suite of wysdom products. we are growing our team please join us as a data scientist based in our richmond hill headquarters. but what will i actually be doing the day to day will involve writing queries, building dashboards, and preparing analytical reports about product performance for our clients and the wysdom.ai team. you will work with sql, tableau, and python and ml frameworks or libraries to create stunning visuals showing how wysdom.ai is making their customers experience even better. there will also be opportunities to improve our ai processes and drive real change in our platform through developing tools and processes to streamline ai training and analytics. in this role, you will build and maintain efficient tableau dashboards and reports for a variety of wysdom customers maintain and help optimize tableau server instances for our clients conduct an ad hoc analysis as requested to dig into product performance assist in building out automated processes using python to enhance analytics at wysdom.ai continually improve our insights products through performance improvements, new metrics, and visualizations beyond theses day to day responsibilities, your sense of curiosity and analytical mindset, will challenge you to dig deeper into the ways in which we can continually improve our solution, our success rate, and the customer experience. about you degree in computer or data science, statistical analysis, math and engineering 2 3 years of experience with data visualization tools, specifically tableau and experience setting up and managing tableau server experience programming with python and with machine learning frameworks or libraries e.g. scikit learn, pandas, matplotlib, seaborn, tensor flow, or pytorch would be an asset experience with etl tools tableau etl, airflow advanced sql querying skills experience using excel or google sheets source control git strong problem solving, quantitative and analytical abilities knowledge of api s or web services integration about wysdom.ai wysdom.ai is a venture funded start up and is led by an experienced team of serial entrepreneurs with a history of building great teams and products. we offer a terrific work environment in all our offices, full company paid benefits from your first day, and a stock option program, to ensure you participate in the growth we see ahead. head here to read more about what it s like to work at wysdom. mzjvkjiuom","['tableau', 'pytorch', 'dashboards', 'data visualization', 'tensor flow', 'statistical analysis', 'sql', 'python', 'matplotlib', 'data science', 'pandas', 'analytics', 'programming', 'integration', 'google sheets', 'machine learning', 'testing', 'web services', 'airflow', 'nlp', 'git', 'api', 'optimization', 'etl', 'ai']","['sql', 'python', 'google sheets', 'tableau', 'pytorch', 'sci', 'nlp', 'git', 'api', 'pandas', 'programming', 'airflow']","['conversational', 'machine learning', 'matplotlib', 'testing', 'natural language', 'dashboards', 'data science', 'data visualization', 'analytics', 'web services', 'optimization', 'integration', 'tensor flow', 'statistical analysis', 'ad', 'etl', 'ai']","['environment', 'metrics', 'art', 'customer experience', 'customer service', 'customer satisfaction']"
98,125,Data Scientist,"about guestlogix we take the stress out of travelling for passengers. with our platform, airlines can deliver content that lets passengers tailor their trip uniquely for themselves. this includes items and services for travelers throughout their whole trip, like priority boarding or lounge access, a tour of the eiffel tower if you re in paris, or a personalized whiskey tour if you re in dublin. this approach to the travel experience transforms how airlines provide value to their passengers and drives ancillary revenue through every stage of the customer journey. the vision for our platform will deliver on this promise by leveraging ai to offer an extensive inventory of personalized, high demand and custom curated content including offers for pre, during and post travel through an intuitive, customer centric interface delivering benefits for passengers and airlines. and we need your help to make this vision a reality. who we are looking for guestlogix s vision for the future a personalized, ai driven travel platform for a seamless and stress free travel experience for every single traveler. you will be a massive part of that future achievement. our delivery team at guestlogix is looking to add a data scientist. you ll join a small, agile delivery team composed of product managers, designers, and developers all committed to delivering a great product collaboratively. what you will do here create cutting edge technology. you will bring your data skills and experience to bear on building a saas platform that makes passengers lives easier and stress free. you will produce scalable, well tested, and reusable enterprise grade code and models. solve problems. this is a role for someone who sees a problem and can identify the steps needed to resolve it and take action in a creative but stable way. collaborate. our small polyskilled teams work closely up and down our tech stack and across disciplines to build the best platform possible for our customers and passengers. what you will need to excel here a passion to create technology that will make the lives of passengers all over the world better. real world experience applying machine learning and nlp to solve problems for users. specific experience in using information extraction and knowledge graphs is a plus. experience writing code working in a variety of languages such as r, python, and sql. comfort and familiarity with agile and lean techniques and the desire to continuously improve how we deliver products. effective communication skills where you listen with the intent of truly understanding and are concise, articulate and candid when communicating both verbally and in writing. a drive for excellence and a passion for creating cool stuff, breaking down barriers and completely changing the game. join us on our journey to make air travel a great experience again. our crew enjoys a remote first way of working. you will have the flexibility and autonomy to innovate within small teams to build our first to market platform, using modern tools and methods. as if that is not enough, we provide you with a competitive salary and benefits, and provide you with the flexibility to manage work and life, along with virtually unlimited developmental opportunities to grow your skills and learn together on our journey. ljv17o1eg6","['sql', 'python', 'machine learning', 'information extraction', 'nlp', 'saas', 'r', 'ai']","['python', 'sql', 'r', 'nlp']","['saas', 'machine learning', 'information extraction', 'ai']",[]
99,127,Data Scientist,"this is an exciting opportunity to join our client s innovation and strategy team at the ground level you will be part of their innovation hub located in downtown toronto where your desire for impact will only be matched by your inate ability to collaborate with other like minded individuals to come up with creative solutions to retail data science problems. in this role, you ll have the chance to roll up your sleeves and apply data science methods and analytics to real world business situations. the data scientist will play a key role in enhancing advanced analytics and machine learning capabilities within the organization. you will be responsible for the building, training, scoring and monitoring of machine learning models. you will work closely with various stakeholders throughout our business to understand business needs and develop solutions through machine learning or other advanced analytics or predictive modeling techniques. job requirements ms or phd or equivalent in computer science, engineering, statistics, mathematics, or related technical field experience in developing machine learning algorithms, statistical and mathematical optimization models, and simulation and visualization tools strong understanding of regression modeling, time series analysis, cluster analysis, machine learning concepts such as supervised and unsupervised learning, classification, random forest, neural nets, etc. ability to identify predictive attributes of data sets and perform feature engineering to improve machine learning results experience with manipulating big data sets via sql able to process, filter and present large quantities of data experience in one or more programming languages experience with databricks, tableau and automl tools an asset","['sql', 'machine learning', 'statistics', 'visualization', 'regression', 'time series analysis', 'programming languages', 'tableau', 'data science', 'computer science', 'analytics', 'mathematics', 'optimization', 'big data', 'modeling', 'algorithms', 'cluster analysis']","['sql', 'tableau', 'programming languages', 'automl', 'big data']","['machine learning', 'statistics', 'visualization', 'regression', 'time series analysis', 'data science', 'computer science', 'analytics', 'mathematics', 'optimization', 'predictive', 'modeling', 'algorithms', 'feature engineering', 'cluster analysis']",['retail']
100,128,Sr Data Scientist,"position summary the successful candidate will assist in leveraging customer, digital and transportation datasets to create insights on pricing, marketing and customer travel behavior. the sr. data scientist will assist the director of data analytics and other key stakeholders to bring actionable data driven solutions to 407 etr. they will have the expertise and knowledge to mentor more junior members while also having the business acumen to understand how to frame a business problem and deliver insight that is actionable. this position is part of a highly collaborative and energetic team in a start up minded environment. position responsibility assemble and analyze data to understand customer behavior from existing 407 etr data, external data sources and emerging sources. building pricing models and optimization using python, gurobi or the like. undertake analysis of target customer groups for specific marketing and pricing programs and assess opportunities and strategies for marketing. ad hoc analysis and modeling of data. lead project based work with key business stakeholders. strong mentoring and leadership skills to support and coach junior members on statistical techniques and experimental design. strong experience building customer analytic models like price elasticity, attrition, lifetime value, churn and segmentation. ability to understand business stakeholder s issues and create valuable insight. raise awareness and action of data science within the company to help focus on fact based decisions. support the department along with the information technology management department in planning the structure and storage of new customer related data fields. represent the department in committees within the organization. qualifications a university degree in engineering, statistics, mathematics, or computer science. graduate degree in statistics or operations research preferred. minimum 10 years working experience with data science techniques clustering, regression models, classification, anomaly detection and other machine learning techniques. well developed business analysis, research and creative problem solving skills. organizational skills and time management skills planning and project management, and ability to meet multiple deadlines. strong communication skills and work ethic. highly collaborative team player with an entrepreneurial spirit. experience with python, tableau and aws cloud. note this job description is not intended to be all inclusive. employee may perform other related duties as negotiated to meet the ongoing needs of the organization. accommodations for disabilities or other grounds protected by human rights legislation are available upon request for candidates taking part in all aspects of the employment selection process.","['data analytics', 'python', 'machine learning', 'experimental', 'statistics', 'business analysis', 'tableau', 'datasets', 'information technology', 'data science', 'computer science', 'mathematics', 'optimization', 'anomaly detection', 'modeling', 'aws', 'working experience', 'etr']","['python', 'aws', 'tableau']","['data analytics', 'machine learning', 'experimental', 'statistics', 'business analysis', 'datasets', 'information technology management', 'data science', 'elasticity', 'computer science', 'mathematics', 'optimization', 'anomaly detection', 'modeling', 'working experience', 'ad hoc', 'planning']","['environment', 'human', 'marketing', 'design', 'lifetime value', 'project management', 'operations', 'customer travel', 'committees', 'project based', 'legislation', 'etr', 'mentoring']"
101,129,Data Scientist,"company description at thinking capital, we re changing the landscape of financial technology we are looking for a talented data scientist to join our incredible team. thinking capital belongs to the purpose financial family of businesses. thinking capital is a subsidiary of purpose financial, a diversified financial services platform focused on addressing historically underserved segments of the market. purpose is backed by omers, torquest partners and allianz. simply put, our mission is to empower canadian small businesses through innovative financial services. at the heart of our offering is our digital experience, which is powered by our proprietary software platform, our real time connections to a multitude of data sources and our advanced data science models. we are squarely in the corner of owners and entrepreneurs, providing for them, and at the right moment, the financial support they need to grow and thrive. job description you have spent countless hours over the years solving hard problems in mathematics, statistics and computer science. you thrive on extracting useful information from large messy data sets. you know that a data set that satisfies all the requirements of a specific statistical procedure is a rarity indeed and you know what to do about it. you have followed your passion for all things quantitative and are turning it into your profession. at thinkingcapital we encourage everyone to trust themselves, stop holding back and use your acquired knowledge to influence your future. everyone in the team is an integral contributor to our products, working with our customers to collaborate and design the best solutions. our open work culture provides the opportunity for you to contribute to all aspects of our business customer engagement, product ownership, software, qa, devops and 24 or 7 cloud service deployment. as a key member of our team your passion for data will help us design, develop and deploy our integrated cloud services that help small businesses succeed. what you ll do application of machine learning to an automated financial services platform design of sophisticated algorithms that work on large datasets in real time learn and adapt emerging machine learning methodologies to real problems identifying, assessing, and monitoring credit risk trends, communicating adherence to authorized risk tolerance parameters and support senior management decision making. diagnosing, documenting and reporting drivers of unexpected changes to portfolio or origination composition and credit performance. communicating your findings including future impacts to losses and proposed recommendations to senior management as required. qualifications you bring strong knowledge and real world experience machine learning and artificial intelligence statistical methodology python , r and sql algorithms, data structures, and computational mathematics experience with analytics for large messy data sets obtaining data from web sites via scraping, apis and third parties proficiency with linux command line working autonomously and being highly resourceful a masters degree in statistics or equivalent we value data scientists who can demonstrate personal or business projects that have solved real problems big or small with data sets that you have obtained. you found the right data, scraped it off a web site or used an api to get it. stored it, munged it, found all the anomalies and figured out what to do about them. you asked statistical questions of the data, found out that the data did not satisfy the requirements of the methodology you used, and figured out what to do about that. you derived useful information from the data and demonstrated value from the project. additional information why you should join us outstanding people surround yourself with a high performing, energetic and passionate group of people dedicated to the thinking capital mission. fintech revolution be part of a team that is revolutionizing the financial system and redefining how canadian small businesses access capital. fast paced environment take on complex projects in an innovative, start up like environment. amazing culture benefit from an amazing working environment offering you the flexibility to do your best work diversity of thought join a team that values diversity and collaboration.","['linux', 'computational mathematics', 'financial technology', 'sql', 'python', 'statistics', 'software', 'reporting', 'data science', 'analytics', 'machine learning', 'artificial intelligence', 'algorithms', 'cloud services', 'data structures', 'devops', 'datasets', 'api', 'computer science', 'mathematics', 'risk', 'r']","['sql', 'python', 'linux', 'api', 'r']","['machine learning', 'statistics', 'financial support', 'data structures', 'software', 'reporting', 'datasets', 'data science', 'devops service', 'computational mathematics', 'financial technology', 'computer science', 'mathematics', 'artificial intelligence', 'methodology', 'analytics sites', 'algorithms', 'cloud services']","['customer engagement', 'environment', 'fintech', 'capital', 'design', 'product', 'financial services']"
102,131,Data Scientist,"about the opportunity apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management assist us to drive innovation, enabling new underwriting paradigms, distribution models, and data management build and implement solutions that enable operational units, to improve quality and speed of core processes, in order to generate incremental revenue or reduce expenses proactively research new ways of modeling data to unlock actionable insights or improve processes effectively interpret modeling results, distill actionable insights and present them to partners collaborate across functions, and with clients to use analytics to influence business decisions work with existing data science groups and collaborate with internal partners, to leverage capabilities in big data technology about you undergraduate degree in computer science, engineering, statistics, or applied mathematics with 3 years experience or graduate degree in computer science, engineering, statistics, or applied mathematics, with 1 years experience insurance or financial services background would be an asset actuarial examinations or designation would be an asset expertise in advanced predictive analytic techniques strong experience with python or r working knowledge of sql experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining familiarity with cloud computing platforms familiarity with big data technologies , natural language processing, and deep learning frameworks would be assets excellent communication skills, ability to interpret modeling results, and convey them to partners fast learner with a drive to make a difference ability to thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines how to apply click the apply now button and follow the instructions to submit your resume. please note that we only accept documents in ms word or rich text formats. when referencing this job, quote 29411. you must currently reside within the greater toronto area and be permitted to work in canada to be considered for this opportunity. a recruiter will be in touch with you if your profile meets our client s requirements for this role.","['deep learning', 'sql', 'python', 'machine learning', 'statistics', 'language processing', 'testing', 'data science', 'computer science', 'analytics', 'big data', 'modeling', 'applied mathematics', 'data management', 'cloud computing', 'r']","['sql', 'python', 'big data', 'r']","['deep learning', 'machine learning', 'statistics', 'language processing', 'testing', 'data science', 'computer science', 'analytics', 'natural', 'modeling', 'applied mathematics', 'data management', 'cloud computing']","['underwriting', 'environment', 'design', 'expenses', 'claims', 'operational units', 'financial services', 'insurance']"
103,132,Research Data Scientist,"deepcell is an early stage stanford spin off company that has developed a platform capable of performing diagnostic and screening tests based on a simple blood draw. with the power of ai, microfluidics and genetics, we will change how prenatal screenings and liquid biopsies are done. deepcell technology has won multiple prestigious awards and is backed by top tier venture capitalists in silicon valley including andreessen horowitz and bow capital. responsibilities work with large, complex and ever growing data sets research and develop and advance the state of the art of techniques to solve machine learning problems at deepcell including supervised and unsupervised learning build and prototype analysis pipelines iteratively to provide insights at scale. develop comprehensive knowledge of deepcell s objectives and related functions, advocating for changes where needed for product development work in close collaboration with engineering, product, bio science and bioinformatics teams publish and patent minimum qualifications phd in computer science, related technical field or equivalent practical experience experience in computer vision, machine learning, algorithmic foundations of optimization, data mining, or machine intelligence programming experience in python and tensorflow contributions to research communities or efforts, including publishing papers in machine learning interest in solving impactful problems and applications to biotechnology effective communication with engineers and scientists from different disciplines preferred qualifications relevant work experience, including full time industry experience or as a researcher in a lab stellar publication record ability to design and execute on research agenda with the understanding and care to transfer to development and production","['data mining', 'python', 'machine learning', 'bioinformatics', 'tensorflow', 'computer vision', 'screening', 'computer science', 'programming', 'optimization', 'machine intelligence', 'pipelines', 'ai']","['pipelines', 'deepcell', 'python', 'programming']","['data mining', 'machine learning', 'tests', 'bioinformatics', 'tensorflow', 'computer vision', 'micro', 'screening', 'computer science', 'optimization', 'machine intelligence', 'ai']","['biotechnology', 'product development work', 'capital', 'genetics', 'art', 'design', 'agenda']"
104,133,Data Scientist 3,"zynga is a leading developer of the world s most popular social games that are played by people around the world every single day. to date, more than 1 billion people have played our games across web and mobile, including words with friends, farmville, zynga poker, merge dragons, empires puzzles, toon blast, and csr. zynga s programmatic ads platform team uses our outstanding and expansive data to acquire high value users for our gaming portfolio. we strive for a better understanding of our players which translates into challenges and features that delight them. here s where you would come in identify and formalize problems related to campaign and bidding optimization. design and develop systems and machine learning models to optimize campaigns at scale and low latency. be innovative, be creative, use every bit of that key commodity data. millions of people play zynga games every day, so our data is tremendously rich, and we have a lot of it this role will be responsible for communicating findings to your peers both technical and non technical. your solutions to difficult problems will need to be demonstrably impactful, visual, and maintainable. you will collaborate with engineering teams to build campaign bidders and optimizers. you will collaborate with user acquisition managers, product managers, and engineers to deliver business impact. responsibilities design and implement scalable systems and models to experiment with campaigns and creatives across channels and acquire users at scale work with large amounts of data to find and realize opportunities to acquire and re target users profitably delivering unambiguous business metric impact craft effective campaign strategies to acquire users across a multitude of user acquisition channels drive and empower user acquisition team to make quantitatively informed, evidence based decisions through custom visualizations, and etls to augment user data design, test, verify and implement machine learning models with zynga s games that impact millions of users. models may include but not limited to ltv modeling, campaign bid recommendations, budget allocation, clustering or segmentation, forecasting, fraud detection, and or or reinforcement learning build services and applications that improve effectiveness of campaigns, creatives, ad networks, and or or user segments. required skills and experience b.s. or b.a. in math, statistics, comp sci, engineering, or other quantitative field required masters, mba or phd preferred 3 5 years of relevant work experience in data science or analytics role in a machine learning team proficient in python or java or c or c or c or go demonstrated experience in deploying models or systems in high throughput or low latency environments strong experience in sql proven experience with some of the following machine learning, predictive modeling, deep learning experience in analyzing large datasets, preferably in a hadoop or spark environment, and deploying production ready systems at scale strong written and oral communication skills strong passion for gaming and performance marketing familiarity with openrtb, mobile programmatic ad tech, performance marketing, and or or user acquisition landscape is a big plus ability to build and maintain simple software services and systems at scale experience in deploying services in at least one cloud provider is a big plus what we offer you competitive salary, bonus plan, zynga rsu s , espp rrsp company match contribution extended health coverage, dental, disability, critical illness, eap, and life insurance virtual mental health and neurodiversity support programs goodlife fitness annual membership open vacation policy family planning support program generous paid maternity or parental leave subsidized back up child care zynga happy hours and frequent employee events casual dress every single day culture of diversity and inclusion including employee resource groups work with cool people and impact millions of daily players zynga is an equal opportunity employer. we are proud of our broad community we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. we welcome job seekers, players, employees, and partners from all backgrounds. join us we will consider all qualified job seekers with criminal histories in a manner consistent with applicable law. zynga is committed to providing reasonable accommodation to applicants with disabilities. if you need an accommodation during the interview process, please let us know li lm1","['go', 'c', 'java', 'poker', 'gaming', 'sql', 'python', 'statistics', 'reinforcement', 'software', 'data science', 'data', 'analytics', 'machine learning', 'fraud detection', 'forecasting', 'deep learning', 'high throughput', 'datasets', 'low latency', 'hadoop', 'optimization', 'modeling']","['go', 'sql', 'python', 'hadoop', 'c', 'java']","['deep learning', 'machine learning', 'statistics', 'high throughput', 'datasets', 'low latency', 'data science', 'data', 'fraud detection', 'optimization', 'analytics', 'modeling', 'predictive', 'forecasting', 'etls', 'software services', 'gaming']","['law', 'environment', 'events', 'marketing', 'eap', 'design', 'performance', 'employee resource groups', 'evidence', 'neurodiversity planning', 'mental health', 'campaigns', 'insurance', 'user acquisition']"
105,134,Data Scientist - JTM,"jumio transaction monitoring is disrupting a 7.5 billion compliance software market by offering an innovative platform and incorporating new data sources for our bank and fintech partners to monitor their transactions for suspicious behavior helping make the financial system safer while maximizing the value and utility of critical compliance resources. we are looking for a data scientist at jtm. in this role, you will get to work alongside various experts in customer success, product and engineering. you will analyze datasets to discover patterns, build and test models and implement them to improve our transactional monitoring system. responsibilities mine and analyse data from databases to create features, generate insights, drive optimization and improvement of product development. develop data models and algorithms to improve the current aml rule based system. develop processes and tools to monitor and analyse model performance and data accuracy in production. implement end to end machine learning solutions in a production environment keep pace with the state of the art technologies in machine learning experience and qualifications bachelor s degree in mathematics, statistics, computer science, engineering 3 years of industrial experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas or equivalent 2 years of industry experience with master s degree experience with data scripting languages hands on experience with machine learning frameworks such as scikit learn, tensorflow and pytorch knowledge of classical machine learning techniques knowledge of time series approaches a strong passion for empirical research and for answering hard questions with data is required. great to have experience and qualifications graduate degree in statistics, computer science, machine learning or related quantitate field. industrial experience in finance familiarity with saas development in cloud ecosystems like aws job type full time","['databases', 'machine learning', 'statistics', 'software', 'pytorch', 'datasets', 'scripting', 'tensorflow', 'qualitative research', 'computer science', 'analytics', 'mathematics', 'optimization', 'saas', 'data models', 'empirical research', 'aws', 'algorithms']","['databases', 'jtm', 'scikit', 'pytorch', 'aws', 'data models']","['machine learning', 'statistics', 'software', 'datasets', 'scripting', 'tensorflow', 'qualitative research', 'computer science', 'analytics', 'mathematics', 'optimization', 'data', 'saas', 'empirical research', 'algorithms']","['customer success', 'environment', 'art', 'finance', 'fintech compliance', 'product development']"
106,136,"Data Scientist, Machine Learning","the company you ll join at carta we create owners and make private markets liquid. we live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment others live on the debt stack and may work their entire lives for a company and retire only with the cash they ve managed to save from their paychecks. our contribution to solving the wealth inequality problem is moving people from the debt stack to the equity stack. by making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners. at carta, we are helpful, transparent, fair, and kind. we are relentless executors, unconventional thinkers, and masters of our craft. to learn more, here is what one of our investors wrote about leading our series f. the team you ll work with our mission is to enable data driven decisions and products across carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. this is a foundational role in carta s fast growing data organization, working on one of the world s most valuable data sets at one of the fastest growing fintech companies of all time. the team consists of experts in product analytics, machine learning and data engineering. we partner with each other and cartan s across the company to solve impactful problems. our team strongly believes that being helpful accelerates results and we support one another to be successful at carta. the problems you ll solve as a data scientist, ml at carta, you ll partner with domain experts across the company to analyze and explore carta s proprietary data set. you will build statistical models that power new products and accelerate carta s business. examples of responsibilities will include perform exploratory analyses to understand the dynamics of private markets and ownership develop machine learning models to power new financial products and to extract trends from performance of existing products automate monitoring of data distributions to detect and flag anomalies partner with product managers, engineers, and business teams to incorporate data driven insights into decision making own, coordinate, and solve complex, cross functional problems that extend beyond the traditional boundaries of product, analytics, and data science the impact you ll have you will own significant projects directly aligning with carta s company wide initiatives of data products and data quality. your work will empower leaders across the company to make good product decisions and optimize operational efficiency. additionally, you will have the opportunity to set best practices for integrating our ml models into production helping carta s current and future data scientists. about you candidates must have a strong foundation in statistics, be proficient in sql and python, and have an analytical mindset. you have a strong bias towards simplicity, are excited by zero to one projects, and can efficiently communicate findings to leadership. example traits that we value 2 years of industry experience solving complex data problems with descriptive and predictive models proficiency with modern programming languages and datastores a deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance strong written and verbal communication skills, with a particular emphasis on data visualization a collaborative attitude and a helpful personality","['sql', 'python', 'machine learning', 'statistics', 'programming languages', 'data products', 'operational efficiency', 'data visualization', 'data science', 'dynamics', 'analytics', 'data quality', 'data engineering']","['programming languages', 'data quality', 'sql', 'python']","['machine learning', 'statistics', 'data products', 'operational efficiency', 'data visualization', 'data science', 'dynamics', 'analytics', 'data engineering']","['fintech', 'private', 'private markets']"
107,137,Digital Data Scientist,"digital data scientist mon17852 description bombardier bombardier is a global leader, creating innovative and game changing planes. our products and services provide world class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. we are a global organization focused on working together with a team spirit. in your role, you will work on challenging and research based initiatives using advanced machine learning methods focusing on tangible outcomes nurture strong working networks with internal and external stakeholders to access large variety of data sources and enhance a.i. value creation prepare and integrate large and various types of data implement machine learning models, data mining methods, and statistical analysis leverage visualization tools or packages to create powerful representations of results produce data driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to stakeholders collaborate with the development team to deploy production scale solutions challenge status quo for data ecosystem and collaboratively innovate solutions to enable a.i. across teams quickly learn new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises articulate software and hardware requirements for a.i. solutions to non practitioners. qualifications as our ideal candidate, you have a masters in computer science, statistics, or data science relevant fields and an engineering background is desired you have strong data profiling, cleaning, mining and technical documentation skills you possess a minimum of 3 years of experience in developing machine learning models for real business problems you possess a minimum of 3 years of experience with nlp and text analytics methods and packages you have experience deploying a.i. solutions within business functions to improve business competitiveness. you have experience with mlops to build end to end pipeline and deploying models in production you possess experience with big data technologies, primarily in machine learning and statistics function above average expertise in one or more programming language java, c , ruby, python you have experience designing and implementing ai or data science algorithms or systems and managing the associated data by leveraging, connecting and operationalizing large scale enterprise data solutions and applications using best known data management and analytics platforms you have experience working in an agile development environment implementing ai or data science algorithms leveraging state of the art programming languages and libraries bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected characteristics to apply. whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone. join us at https or or bombardier.com or en or careers or career opportunities your ideas move people. job project or program management primary location ca qc montreal dorval organization aerospace schedule full time employee status regular job posting 21.05.2021, 5 29 38 pm unposting date ongoing","['https', 'visualization', 'c', 'data profiling', 'big data', 'statistical analysis', 'java', 'ruby', 'python', 'statistics', 'software', 'data science', 'enterprise', 'analytics', 'programming', 'data mining', 'machine learning', 'hardware', 'algorithms', 'programming languages', 'data solutions', 'nlp', 'computer science', 'technical documentation', 'data management', 'ai']","['https', 'ruby', 'python', 'programming languages', 'nlp', 'c', 'programming', 'big data', 'hardware', 'java']","['data mining', 'visualization', 'machine learning', 'statistics', 'software', 'data solutions', 'data science', 'data profiling', 'computer science', 'analytics', 'mlops', 'technical documentation', 'enterprise', 'data management', 'agile development', 'statistical analysis', 'algorithms', 'ai']","['and safety', 'environment', 'art', 'program management', 'aerospace', 'hiring']"
108,138,Data Scientist II,"td description tell us your story. don t go unnoticed. explain why you re a winning candidate. think td if you crave meaningful work and embrace change like we do. we are a trusted north american leader that cares about people and inspires them to grow and move forward. stay current and competitive. carve out a career for yourself. grow with us. department overview what does td stand for for starters, we believe in visionary leadership and insights. we believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data. as part of our data and analytics team, you ll be a fundamental part of crafting business processes enterprise wide by analyzing vast amounts of past and present data. td s vision for the future tailored, customized banking products, services and experiences for every single customer. if you ve been in business as long as we have, you know there s no such thing as one size fits all, and a diverse, inclusive data analytics team is a massive part of that future achievement. job description about this role while you are a natural leader, you don t mind getting your hands dirty. and in your role, you will simultaneously work to create data related solutions to drive business results, while working with senior leadership to communicate timelines and progress and identify business opportunities. you are not only a functional expert, you also possess broad managerial experience and specialized knowledge of regulatory and industry frameworks, using that knowledge to inform development cycles and develop industry leading analytic solutions. most of all, your work ethic and thought leadership inspires your team to innovate with purpose, execute with speed, collaborate to deliver world class data solutions and ultimately become leaders themselves. we are looking for someone to work as part of a trailblazing team of data scientists who create groundbreaking analytical solutions that improve our core work enterprise wide. as a data scientist ii, these are the essential qualifications of this role provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become core work you re doing work closely with business owners to find opportunities and serve as an ambassador for data science design and deliver enterprise analytic solutions for customers develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques build complex statistical models that learn from and scale to petabytes of data. analytical thought leadership and staying ahead of developments in data mining and the application of data science work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size generally accountable for a significant business management area that typically has enterprise wide impact or accountability enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels job requirements what can you bring to td tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes undergraduate degree or technical certificate seven or more years of relevant experience inclusiveness at td, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. if you require an accommodation for the recruitment or interview process , please let us know and we will work with you to meet your needs. job family advanced analytics modelling job category primary enterprise data analytics job category enterprise data analytics hours 37.5 business line td wealth time type full time employment type regular country canada province or state ontario city toronto work location td centre south 79 wellington street west job expires 24 jun 2021","['go', 'data mining', 'data analytics', 'machine learning', 'banking', 'business insights', 'technical', 'data solutions', 'data science', 'enterprise', 'analytics', 'data management']","['go', 'business insights']","['data mining', 'data analytics', 'machine learning', 'banking', 'technical', 'data solutions', 'data science', 'enterprise', 'analytics', 'data management']","['environment', 'marketing', 'business management', 'design', 'developments']"
109,139,Data Scientist,"there has never been a better time to join extreme, after three acquisitions extending our portfolio and go to market strategy, we have seen enormous opportunity and growth within the regions. aside from being a technology leader in the gartner magic quadrant, we also adamantly promote an internal culture that truly embraces diversity, inclusion and equality in the workplace. having diversity and inclusion as part of our core values and beliefs, we re proud to foster an environment where every extreme employee can thrive because of their differences, not despite them. responsibilities working under the guidance of the leader of the portfolio intelligence team, provide analytics and insight to the executive leadership team. collaborate with subject matter experts across the company to build impactful data analysis and visualization. using statistical modelling and ai techniques, provide leadership in business plan creation and forecasting. working with the product management organization, improve the business plan and financial modelling process. take a leadership role in the definition of customer success metrics in our cloud offerings. design and maintain data visualizations in tableau. required qualifications completed degree in a quantitative discipline master of business administration an asset. ml or ai competency an asset. advanced statistical methods and predictive modelling. excellent writing and communication skills. executive presentation skills. familiarity with data visualization software and techniques. experience with tableau an asset. required qualifications completed degree in a quantitative discipline master of business administration an asset. ml or ai competency an asset. advanced statistical methods and predictive modelling. excellent writing and communication skills. executive presentation skills. familiarity with data visualization software and techniques. experience with tableau an asset. ability to work with large datasets and provide concise analysis and insights capable of independent research and learning. location position is based in toronto, ontario area it is not budgeted for relocation. qualified local candidates are encouraged to apply. extreme networks, inc. creates effortless networking experiences that enable all of us to advance. we push the boundaries of technology leveraging the powers of machine learning, artificial intelligence, analytics, and automation. over 50,000 customers globally trust our end to end, cloud driven networking solutions and rely on our top rated services and support to accelerate their digital transformation efforts and deliver progress like never before. for more information, visit extreme s website or follow us on twitter, linkedin, and facebook. we encourage people from underrepresented groups to apply. come advance with us in keeping with our values, no employee or applicant will face discrimination or harassment based on race, color, ancestry, national origin, religion, age, gender, marital domestic partner status, sexual orientation, gender identity, disability status, or veteran status. above and beyond discrimination or harassment based on protected categories, extreme networks also strives to prevent other, subtler forms of inappropriate behavior from ever gaining a foothold in our organization. whether blatant or hidden, barriers to success have no place at extreme networks. li me1","['go', 'executive', 'visualization', 'machine learning', 'tableau', 'software', 'datasets', 'data visualization', 'digital transformation', 'networking', 'analytics', 'product management', 'artificial intelligence', 'data analysis', 'forecasting', 'automation', 'ai']","['go', 'tableau']","['visualization', 'machine learning', 'software', 'datasets', 'data visualization', 'digital transformation', 'networking', 'analytics', 'product management', 'artificial intelligence', 'data analysis', 'forecasting', 'automation', 'ai']","['environment', 'subject matter experts', 'customer success', 'metrics', 'design', 'forms', 'linkedin', 'acquisitions', 'business administration']"
110,140,Data Scientist,"design, develop, test, advocate, evangelize and build data driven products that help our customers improve business decisions. you will provide insight into analytic practices, design and lead iterative learning and development cycles. responsibilities understanding and worked with database systems. understanding and worked with machine learning algorithms. perform feature analysis. develop ontology for key market segments. develop outcome or event taxonomy for key business models. build utility code and handle miscellaneous support tasks. documenting software projects and maintaining project documentation. working in a team environment as well as working alone. qualifications experience with big data, artificial intelligence, natural language processing, machine learning and or or deep learning. python programming skills with two years or more of python experience. good verbal and written communication skills. knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. master s degree or six years related work experience delivering quality code on time. tools we use... confluence jira spark azure python keras bit bucket jupyter notebook scala postgres nice to haves... experience in some subset of the following java, r, python, sql, scala, spark. ph.d. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline. deep understanding of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques, supervised learning, recommendation and optimization algorithms.","['confluence', 'coding standards', 'big data', 'java', 'sql', 'python', 'statistics', 'keras', 'software', 'scala', 'physics', 'database systems', 'programming', 'jupyter', 'data mining', 'machine learning', 'software development life cycle', 'testing', 'artificial intelligence', 'algorithms', 'deep learning', 'project documentation', 'language processing', 'jira', 'feature analysis', 'optimization', 'modeling', 'software projects', 'r']","['jupyter', 'sql', 'python', 'keras', 'scala', 'confluence', 'jira spark', 'programming', 'big data', 'java', 'r']","['applied', 'coding standards', 'natural', 'modeling', 'statistics', 'software', 'physics', 'database systems', 'supervised learning', 'data mining', 'machine learning', 'software development life cycle', 'testing', 'artificial intelligence', 'predictive', 'algorithms', 'deep learning', 'project documentation', 'language processing', 'feature analysis', 'optimization', 'onto', 'software projects']","['environment', 'taxonomy', 'design', 'operations']"
111,141,Data Scientist,"duties or responsibilities identify valuable data sources and automate collection processes undertake preprocessing of structured and unstructured data analyze large amounts of information to discover trends and patterns build predictive models and machine learning algorithms combine models through ensemble modeling present information using data visualization techniques propose solutions and strategies to business challenges collaborate with engineering and product development teams requirements or qualifications proven experience as a data scientist or data analyst experience in data mining understanding of machine learning and operations research knowledge of r, sql and python familiarity with scala, java or c is an asset experience using business intelligence tools and data frameworks analytical mind and business acumen strong math skills problem solving aptitude excellent communication and presentation skills bsc or ba in computer science, engineering or relevant field graduate degree in data science or another quantitative field is preferred","['unstructured data', 'data mining', 'sql', 'python', 'machine learning', 'scala', 'data visualization', 'data science', 'c', 'computer science', 'business intelligence', 'modeling', 'algorithms', 'java', 'r']","['sql', 'python', 'scala', 'c', 'business intelligence', 'java', 'r']","['unstructured data', 'data mining', 'machine learning', 'data visualization', 'data science', 'computer science', 'modeling', 'algorithms']","['product development', 'operations']"
112,144,Data Scientist,"r le et responsabilit s extraire et analyser les donn es se trouvant dans les bases de donn es de l entreprise afin d optimiser et d am liorer le d veloppement des produits, les techniques de marketing et les strat gies commerciales. valuer l efficacit et l exactitude des nouvelles sources de donn es et techniques de collecte de donn es. laborer des algorithmes et des mod les de donn es personnalis es appliquer aux ensembles de donn es. utiliser une mod lisation pr dictive pour accro tre et optimiser l exp rience des clients, les revenus g n r s, le ciblage publicitaire et d autres r sultats op rationnels. laborer un cadre de tests a or b pour l entreprise et mettre l essai la qualit du mod le. coordonner diff rentes quipes fonctionnelles pour mettre en uvre des mod les et surveiller les r sultats. laborer des processus et des outils pour le contr le et l analyse du rendement des mod les et de l exactitude des donn es. exigences et requis titulaire d une ma trise ou d un doctorat en statistique, informatique, analyse des syst mes de gestion ou autre domaine connexe. au moins 6 ans d exp rience en science des donn es ou en statistiques appliqu es. solides aptitudes pour le d veloppement de produits et la r solution de probl mes. exp rience dans l utilisation de langages informatiques statistiques pour manipuler les donn es et extraire des renseignements de grands ensembles de donn es. exp rience dans la manipulation d ensembles de donn es et l laboration de mod les statistiques. exp rience avec diverses techniques d apprentissage automatique et de leurs avantages et inconv nients dans le monde r el. exp rience avec les techniques et concepts statistiques sophistiqu s . exp rience dans l utilisation et la cr ation d architectures de donn es. exp rience dans l utilisation de services web redshift, s3, azure, spark, digitalocean, etc. exp rience dans l analyse de donn es provenant de microsoft application insights, google analytics, site catalyst, coremetrics, adwords, crimson hexagon, facebook insights, etc. exp rience dans la visualisation et la pr sentation de donn es pour des intervenants, l aide de periscope, microsoft power bi, business objects, d3, ggplot, etc. exp rience de direction d initiatives ax es sur le service client. excellentes aptitudes pour la communication verbale et crite en vue de la coordination des quipes.","['microsoft power', 'google analytics', 'bi', 'ggplot', 'r']","['google analytics', 'microsoft power', 'bigp', 'r']",['tests'],['marketing']
113,145,"Data Scientist, Omnia AI","job type permanent primary location toronto, ontario, canada all available locations toronto ottawa vancouver learn from deep subject matter experts through mentoring and on the job coaching be encouraged to deepen your technical skills whatever those may be. be empowered to lead and have impact with clients, our communities and in the office. are you passionate about solving complex analytical problems, learning about the latest in cutting edge ai and continuing to develop your analytical and business development skills if you answered yes, then we have an opportunity waiting for you what will your typical day look like as a data scientist, you would take a hands on role in delivering advisory services to high growth organizations with a diverse team consisting of data scientists, data architects, software developers, information designers, and business or industry leaders. you will responsible for performing statistical modelling, computations, and data etl to deliver best of breed analytical solutions for clients business problems. you will work with large amounts of data on a granular level, from structured and unstructured data sources and participate in various structured and ad hoc analysis projects. you will also perform data analysis and communicate insights on client projects, and provide support in planning, data collection, and assist in pitches and proposal bids. about the team deloitte omnia, deloitte s artificial intelligence practice is comprised of specialized experts with hands on experience, and cutting edge information assets that facilitate successful artificial intelligence transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. enough about us, let s talk about you you are someone with data analysis experience using python, could ml , or similar tools 1 years or 3 years relevant work experience with applying analytics or working with data in any industry strong experience with statistical analytical techniques, data mining, and predictive models is required database and programming languages experience and data manipulation and integration skills using sql, oracle, hadoop, nosql databases, or similar tools is required experience with social media analytics and or or natural language processing and or or optimization is an asset knowledge using either aws, azure or gcp strong experience with machine learning project management experience is an asset ability to work with data with significant ambiguity, develop creative approaches to analytical problems, and interpret data and results from a business or industry perspective enthusiastic about solving complex problems with a variety of analytical tools professional services, consulting, or advisory experience is an asset strong oral and written communication skills interest in continuing to develop analytical and business development skills ba or bsc degree in computer science, applied mathematics, statistics, or related field is required. advanced degree is preferred. join deloitte and bring back that loving feeling, and love the company you keep. this position may require frequent travel to serve clients across north america. candidates must be able to enter the usa to work on client assignment. why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities deloitte encourages applications from all qualified candidates that represents the full diversity of communities across canada. this includes candidates from indigenous communities in support of living our values and our commitments to our reconciliation action plan . we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally. deloitte canada has 52 offices with representation across most of the country. we acknowledge our offices reside on traditional, treaty and unceded territories as part of turtle island and is still home to many first nations, m tis, and inuit peoples. we are all treaty people.","['unstructured data', 'databases', 'sql', 'python', 'gcp', 'statistics', 'software', 'analytics', 'integration', 'aws', 'nosql', 'data mining', 'analytical techniques', 'machine learning', 'data manipulation', 'data collection', 'artificial intelligence', 'data analysis', 'language processing', 'programming languages', 'hadoop', 'computer science', 'optimization', 'applied mathematics', 'etl', 'ai']","['sql', 'python', 'databases', 'gcp', 'programming languages', 'hadoop', 'data manipulation', 'aws', 'nosql']","['unstructured data', 'natural', 'statistics', 'software', 'analytics', 'integration', 'data mining', 'analytical techniques', 'machine learning', 'data collection', 'artificial intelligence', 'data analysis', 'planning', 'language processing', 'computer science', 'optimization', 'applied mathematics', 'etl', 'ai']","['business development', 'subject matter experts', 'professional services', 'project management', 'consulting', 'mentoring']"
114,146,Data Scientist / Engineer,"mobile data connectivity drives economic growth and brings vast social benefits to the world, but two thirds of the world s population is unable to access this valuable resource. our mission is to make affordable mobile communications available to every human on earth. we are founded by early product and growth team executives from facebook, and backed by world leading vcs including google ventures, social capital, sv angels, macquarie capital, and compound. we partner with some of the greatest institutions in the world including linkedin, supercell, twitter, microsoft, verizon wireless, singtel, and t mobile. summary as a data scientist or engineer at lotusflare, you will play a vital role in redefining connectivity on a global scale. you will work on products bringing connectivity to more than 10 million people across the globe. you will advocate data fueled products that help our customers to make data driven decisions. you will provide insight using leading analytics practice and ultimately produce new and creative analytic solutions that will become part of our core products including experimentation platform , analytics platform , and data platform. you are a strategic thinker who can form hypotheses, synthesize disparate information to validate those hypotheses, and provide actionable insights for the product team to scale user base. responsibilities participate in building models that will scale products with millions of users globally partner with cross functional teams including engineering, ux or ui, sales, marketing, and customer success to build growth strategies and manage complex, cross functional projects analyze diverse sources of data to devise actionable insights deep understanding of the b2c consumer markets and core metrics in the markets work with product managers to develop, execute, and test different growth experiments that have a significant impact on conversion across all funnels requirements undergraduate degree in quantitative fields including engineering, math, statistics from top tier institute or relevant field candidate must have the ability to independently build data pipelines, develop data models, and recommend growth strategies to product and executive teams 3 5 years of previous experience in building etls, analyzing consumer insights, creating metrics experience with sql and or or nosql database experience with data visualization, dashboards, and reports experience with scripting languages such as python candidate must be able to effectively synthesize disparate quantitative and qualitative data sets to make data driven decisions eager to learn new programming languages and tools when needed strong desire to work in a fast paced startup environment obsessive around moving critical business metrics and products strong communication skills, attention to detail, and ability to manage multiple projects and stakeholders great oral and written communication skills in english iyrrq3fnke","['ux', 'sql', 'python', 'statistics', 'data pipelines', 'programming languages', 'scripting', 'data visualization', 'dashboards', 'analytics', 'data models', 'qualitative data', 'nosql']","['sql', 'python', 'lotusfl', 'programming languages', 'data models', 'nosql']","['ux', 'statistics', 'data pipelines', 'scripting', 'data visualization', 'dashboards', 'analytics', 'qualitative data', 'etls']","['customer success', 'environment', 'metrics', 'marketing', 'capital', 'b2c', 'sales', 'linkedin', 'business', 'growth strategies']"
115,147,Data Scientist,"we are looking to hire a data scientist. missions tasks and responsibilities your day to day missions collect needs and specify the models to be implemented identify best practices to integrate ai in the firm s context create software solutions using ai technologies implement, test and deliver functionalities according to our standards deploy ai solutions to end users in this position, you will be guided by members of the amer bi center who will be committed to providing you with the tools and advice that you need to successfully reach your goals. you will be client facing, from collecting business requirements to identify and implement solutions bringing value and efficiency gains for the group. environment very vibrant position, many challenges for you to meet a team that fosters exchange and teamwork. projects on a human scale, sense of mutual support, high level of skills profile what if it was you you have completed a master s degree with a mathematics or compsci or engineering specialization and you are interested in machine learning. a first experience in data science using python is preferred. you are fluent in english and a working understanding of french. about you fast learner you are able to own over your work quickly team player you have a sense of responsibility proactive you feel comfortable taking initiatives flexible you enjoy working in a fast paced environment, with rapidly changing priorities result oriented and analytical you have a problem solving mindset technical skills required programming tools python, pandas, numpy, scikit learn, git, jupyter notebook databases postgresql, elasticsearch, oracle servers unix windows would be a plus knowledge of etl tools pentaho data integration, talend, informatica knowledge of bi tools power bi, tableau, grafana knowledge of devops tools docker, kubernetes, jenkins sharing a github or stackoverflow account data scientist missions t ches et responsabilit s vos missions au quotidien recueillir les besoins et pr ciser les mod les mettre en uvre identifier les meilleures pratiques pour int grer l ia cr er des solutions logicielles en utilisant les technologies d ia mettre en uvre, tester et fournir des fonctionnalit s conform ment nos normes d ployer des solutions d ia aupr s des utilisateurs finaux ce poste, vous serez guid par les membres du centre amer bi qui s engageront vous fournir les outils et les conseils dont vous avez besoin pour atteindre vos objectifs avec succ s. vous serez en contact avec les clients, de la collecte des besoins de l entreprise l identification et la mise en uvre de solutions apportant de la valeur et des gains d efficacit pour le groupe. environnement un poste tr s dynamique, de nombreux d fis relever une quipe qui favorise l change et le travail d quipe. projets taille humaine, sens de l entraide, haut niveau de comp tences profil et si c tait vous vous avez obtenu un master avec une sp cialisation en math matiques or compsci or ing nierie et vous tes int ress par l apprentissage automatique. une premi re exp rience en science des donn es en utilisant python est pr f rable. vous parlez couramment l anglais et avez une bonne compr hension du fran ais. propos de vous apprentissage rapide vous tes capable de ma triser rapidement votre travail joueur d quipe vous avez le sens des responsabilit s proactive vous vous sentez l aise pour prendre des initiatives souplesse vous aimez travailler dans un environnement en volution rapide, avec des priorit s qui changent rapidement orient vers les r sultats et analytique vous avez un esprit de r solution de probl mes les comp tences techniques obligatoire outils de programmation python, pandas, numpy, scikit learn, git, jupyter notebook bases de donn es postgresql, elasticsearch, oracle serveurs unix windows ce serait un plus connaissance des outils etl pentaho data integration, talend, informatica connaissance des outils de bi power bi, tableau, grafana connaissance des outils devops docker, kubernetes, jenkins partager un compte github ou stackoverflow","['databases', 'tableau', 'jenkins', 'software solutions', 'pentaho', 'github', 'kubernetes', 'python', 'postgresql', 'elasticsearch', 'talend', 'data science', 'windows', 'pandas', 'unix', 'programming', 'data', 'integration', 'r', 'jupyter', 'servers', 'machine learning', 'informatica', 'numpy', 'oracle', 'bi', 'devops', 'git', 'mathematics', 'etl', 'ai']","['databases', 'tableau', 'jenkins', 'sci', 'pentaho', 'kubernetes', 'python', 'postgresql', 'elasticsearch', 'talend', 'windows', 'pandas', 'unix', 'programming', 'grafana', 'jupyter', 'me', 'numpy', 'penho', 'oracle', 'bi', 'git', 'r']","['servers', 'machine learning', 'informatica', 'devops', 'data science', 'data', 'mathematics', 'integration', 'software solutions', 'github', 'etl', 'ai']",['environment']
116,148,Senior Big Data Developer,"req id 298498 at bell, we do more than build world class networks, develop innovative services and create original multiplatform media content we advance how canadians connect with each other and the world. if you re ready to bring game changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the bell team. bell s forward thinking customer operations team is creating the ultimate service experience for our residential, wireless and small business consumers. we lead strategic development and execution of day to day operations, develop tools and processes to drive service enhancements, manage customer loyalty and retention, and leverage big data and artificial intelligence to create intellectual property. we have been building our business intelligence team and have made tremendous strides in creating the best bi environment this industry has seen as a result, we ve been able to provide strategic guidance and intelligence that has contributed to bell s success. if you want to work with the latest greatest bi tools like, best in class teradata, sas and hadoop all within an agile methodology environment, then this may be the role for you our people are empowered to make big things happen and are supported by growth, training and personal development opportunities. about the role the big data developer will be a key member of the bell business intelligence big data team and work on the hadoop platform. the big data developer will work closely with hadoop administrators, data scientists, and business stakeholders. this position will be responsible for, but not limited to develop high performance data processing pipelines partner with business analysts and internal customers to improve our data coverage and analytic capabilities ability to take initiative to research, learn and recommend emerging technologies aim for defect free programming, create and maintain quality code, provide support during testing cycles and post production deployment, engage in peer code reviews. advanced and extensive knowledge of the business , technical environment, standards, processes, procedures, programming languages and operating systems. readiness and motivation to address and resolve highly complex and multifaceted development related issues, often independently. experience developing and using virtualization, container based and cloud platforms such as kubernetes, openshift, swarm, docker, etc. skills experience working with apache spark, kafka and other big data technologies experience in developing big data ingestion frameworks or experience in working with ingestion tools demonstrated analytical and problem solving skills, particularly those that apply to a big data environment. experience with data pipeline e.t.l. tools, such as talend 5 years or more experience with multiple mainstream programming languages such as python, java, c , c , go, etc. competencies strong communication skills self motivated willingness to learn excellent planning and organizational skills candidates will be required to complete a coding test as part of the interview process. li ad1 tech bigdata businessintelligence bilingualism is an asset adequate knowledge of french is required for positions in quebec. additional information position type management job status regular full time job location don mills canada ontario don mills canada quebec verdun application deadline 06 or 30 or 2021 please apply directly online to be considered for this role. applications through email will not be accepted. at bell, we don t just accept difference we celebrate it. we re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. we welcome and encourage applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process. for a confidential inquiry, simply email your recruiter directly or to make arrangements. if you have questions regarding accessible employment at bell please email our diversity inclusion team at created canada, on, don mills bell, one of canada s top 100 employers.","['go', 'openshift', 'c', 'operating systems', 'big data', 'java', 'kubernetes', 'python', 'data processing', 'talend', 'programming', 'pipelines', 'sas', 'teradata', 'testing', 'apache spark', 'data coverage', 'artificial intelligence', 'business intelligence', 'programming languages', 'bi', 'hadoop', 'virtualization']","['go', 'kubernetes', 'teradata', 'python', 'openshift', 'programming languages', 'bi', 'apache spark', 'hadoop', 'big', 'c', 'programming', 'big data', 'business intelligence', 'pipelines', 'sas', 'java']","['ingion', 'data processing', 'data ingestion', 'testing', 'data coverage', 'operating systems', 'artificial intelligence', 'virtualization', 'methodology', 'planning']","['internal customers', 'environment', 'talend', 'customer operations']"
117,149,Data Scientist - 05/12/21,"acerta s machine learning platforms leverage automotive assembly and vehicle data to detect the earliest indicators of future product failures. we help automakers optimize quality, safety, and reliability throughout the entire product life cycle, from the assembly line to the finish line. as an integral part of the data science team at acerta, you will productize, deploy, maintain, and monitor machine learning models running behind acerta s linepulse and autopulse products. our linepulse saas platform enables automakers to identify anomalies in production data for enhanced testing, accelerated root cause analysis, and improved manufacturing output. acerta s autopulse saas platform enables predictive maintenance of connected and autonomous vehicles based on production, maintenance, and on road data. requirements minimum of 3 5 years of data science experience using python strong ml and statistics background 2 years of software development experience experience with keras, tensorflow, and sklearn. experience with time series and operations data is an asset previous kaggle experience or similar is a plus ability to work in a fast paced agile environment experience using git in a team environment flexibility to adjust to changing priorities, requirements, and schedules familiarity with working on remote linux instances available in office full time responsibilities own significant product requirements and drive them from development to deployment tune and monitor machine learning models deployed for customers. research and apply state of the art in model interpretation and explainability package development in acerta s codebase we thank all applicants for their interest only those candidates selected for an interview will be contacted. acerta is committed to fostering a diverse and inclusive workplace. we strongly encourage applicants from all backgrounds and walks of life.","['automotive', 'python', 'machine learning', 'statistics', 'keras', 'agile environment', 'linux', 'testing', 'tensorflow', 'data science', 'git', 'software development', 'saas', 'root cause analysis']","['python', 'linux', 'keras', 'git']","['model', 'automotive', 'agile environment', 'machine learning', 'statistics', 'testing', 'tensorflow', 'data science', 'software development', 'saas', 'root cause analysis']","['manufacturing', 'environment', 'product', 'art']"
118,150,Data Scientist (Portfolio Modelling),"closing date 06 or 30 or 2021 worker type permanent language required english term duration data science and statistical modelling expertise needed use your extensive knowledge of risk management and finance in areas such as credit risk, allowance for credit losses, economic capital, and stress testing to support our portfolio management team. what you ll do unlock insights from complex and diverse groupings of internal and external data or developed models to tell a story use advanced analytics techniques to enable enlightened decision making choose appropriate ways to tell the story through words, visualization, and interpretation what we re looking for analytical thinker who can design and develop strategies that give users the information they need to make informed decisions creative thinker with research, analytical, and problem solving skills confident communicator who can translate knowledge for others relationship builder comfortable making recommendations for improvement what you ll need a bachelor s degree in agriculture, finance, business, economics, mathematics, statistics or computer science and at least four years of experience in depth understanding of statistics and mathematics combined with business domain knowledge highly proficient in visualization and analytics tools including but not limited to sas, ms power bi, aws environment and tools, r, python a passion for analysis, insights and storytelling if you are an fcc employee, use your workday portal to apply. if you are an fcc employee on leave, contact human resources for instructions on how to apply.","['python', 'visualization', 'statistics', 'bi', 'economics', 'testing', 'data science', 'computer science', 'analytics', 'mathematics', 'aws', 'sas', 'r']","['python', 'bi', 'aws', 'sas', 'r']","['visualization', 'statistics', 'stress', 'testing', 'economics', 'data science', 'computer science', 'analytics', 'mathematics']","['environment', 'capital', 'portfolio management', 'risk management', 'human resources', 'design', 'finance', 'business domain', 'agriculture']"
119,151,Data Scientist - Innovation & Attributes,"synopsis of the role as a data scientist, in this role, you will work closely with business stakeholders to understand their goals and determine how data can be used to achieve those goals. you will be tasked with designing data modeling processes, create algorithms and predictive models to extract the data the business needs, help analyze the data and share insights with peers. who is equifax at equifax, we believe knowledge drives progress. as a global data, analytics and technology company, we play an essential role in the global economy by helping employers, employees, financial institutions and government agencies make critical decisions with greater confidence. we work to help create seamless and positive experiences during life s pivotal moments applying for jobs or a mortgage, financing an education or buying a car. our impact is real and to accomplish our goals we focus on nurturing our people for career advancement and their learning and development, supporting our next generation of leaders, maintaining an inclusive and diverse work environment, and regularly engaging and recognizing our employees. regardless of location or role, the individual and collective work of our employees makes a difference and we are looking for talented team players to join us as we help people live their financial best. the perks of being an equifax employee we offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential. grow at your own pace through online courses at learning equifax. what you ll do as a data scientist at equifax, you will work directly with both internal stakeholders and external clients to deliver innovative decision science models attributes that leverage equifax s vast data assets. these include decision areas covering the credit lifecycle, geodemographic marketing attributes, ratings fraud models, as well as any new areas where data driven decision making can be informed by predictive modelling including advanced modeling techniques and machine learning when applicable. build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees and neural network develop new tools, advanced analytical techniques and products as part of the innovation team project management including defining business and technical requirements, resource planning and analytic solution design working alongside key clients as part of co innovation projects and effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the so what of the analysis creation of recommendations, market insights and dashboards following completed analysis and quality control of all analytical output qualifications bachelor s or advanced degree in a quantitative discipline such as engineering, economics, mathematics, statistics, or physics 3 years data science experience with expert knowledge of r, python, sas or sql in a large data environment 3 years experience creating and using advanced machine learning algorithms and statistics regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks proven hands on experience designing and building analytical solutions to solve real world problems, with limited direct supervision required creativity idea generation and the ability to extract business insights from analysis transform this into an easy to understand story extra points for any of the following master s level degree in a business related field or mba experience working in a cloud environment such as gcp an asset experience in working with credit data background in financial services, telecommunications or utilities favorable success attributes of an equifax employee does this describe you accountability curiosity collaboration think and act differently trust ownership decide execute ship we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. if this sounds like somewhere you want to work, don t delay, apply today we re looking for you primary location can toronto 5700 yonge function function data and analytics schedule full time","['dashboards', 'technical requirements', 'quality control', 'sql', 'python', 'gcp', 'statistics', 'physics', 'decision trees', 'data science', 'analytics', 'data', 'sas', 'scenario analysis', 'financing', 'machine learning', 'analytical techniques', 'algorithms', 'economics', 'business insights', 'neural networks', 'mathematics', 'modeling', 'telecommunications', 'r']","['sql', 'python', 'gcp', 'telecommunications', 'sas', 'r']","['dashboards', 'technical requirements', 'quality control', 'statistics', 'physics', 'decision trees', 'data science', 'analytics', 'data', 'scenario analysis', 'financing', 'machine learning', 'analytical techniques', 'algorithms', 'economics', 'neural networks', 'mathematics', 'solution', 'modeling']","['utilities', 'environment', 'resource planning', 'education', 'healthcare', 'marketing', 'design', 'project management', 'financial services', 'government', 'financial institutions', 'compensation', 'external clients']"
120,152,"Data Scientist, International Analytics","about the role the analytics team is looking for experienced data scientists to guide measurement, strategy, and tactical decision making as we expand our logistics platform into new countries. we are looking to hire in several countries across a variety of teams and levels to accelerate growth in our current international markets and lead the strategy and execution of new market launches data scientists at doordash work to uncover insights and turn them into relevant recommendations, driving decisions for the entire organization. analytics is integral to all operational areas at doordash. as a data scientist at doordash, you ll use your quantitative background to mentor other scientists and dive into large datasets to guide decision making. we tackle a multitude of exciting challenges including customer acquisition, balancing supply and demand, fraud and support, marketing, marketplace efficiency, and more. if you enjoy finding patterns amidst chaos, are excited to build a market from 0 to 1, and have experience using analytics to affect revenue, growth, operations or beyond, we re looking for someone like you you re excited about this opportunity because you will use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business build full cycle analytics experiments, reports, and dashboards using sql, r, python, or other scripting and statistical tools produce recommendations and use statistical techniques and hypothesis testing to validate your findings provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long term trends identify and measure levers to help move essential metrics and make recommendations work backwards from understanding and sizing problems to ideating solutions report against our goals by identifying essential metrics and building executive facing dashboards to track progress be excited to travel to meet with business partners and the team in each market we re excited about you because you have a degree in math, physics, statistics, economics, computer science, or similar domain 5 years of experience in data analytics, consulting, or related quantitative role experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc expertise of sql queries, etl, a or b testing, and statistical analysis with statistical packages, such as matlab, r, sas or python proficiency in one or more analytics visualization tools the insight to take ambiguous problems and solve them in a structured, hypothesis driven, data supported way the determination to initiate and lead projects to completion in a scrappy environment prior experience working abroad or in international expansion preferred but not required fluent english required, proficiency in additional languages a plus why you ll love working at doordash we are leaders leadership is not limited to our management team. it s something everyone at doordash embraces and embodies. we are doers we believe the only way to predict the future is to build it. creating solutions that will lead our company and our industry is what we do on every project, every day. we are learners everyone here is continually learning on the job, no matter if we ve been in a role for one year or one minute. we are customer obsessed our mission is to grow and empower local economies. we are committed to our customers, merchants, and dashers and believe in connecting people with possibility. we are all doordash the magic of doordash is our people, together making our inspiring goals attainable and driving us to greater heights. we offer great compensation packages and comprehensive health benefits. about doordash doordash is a technology company that connects customers with their favorite local and national businesses in all 50 us states, canada, and australia. founded in 2013, doordash empowers merchants to grow their businesses by offering on demand delivery, data driven insights, and better in store efficiency, providing delightful experiences from door to door. by building the last mile delivery infrastructure for local cities, doordash is bringing communities closer, one doorstep at a time. read more on the doordash engineering blog or at . our commitment to diversity and inclusion we re committed to growing and empowering a more inclusive community within our company, industry, and cities. that s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. we believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.","['visualization', 'hypothesis', 'dashboards', 'statistical analysis', 'sql', 'python', 'data analytics', 'statistics', 'physics', 'scripting', 'dynamics', 'analytics', 'sas', 'testing', 'matlab', 'economics', 'datasets', 'computer science', 'optimization', 'etl', 'r']","['sql', 'python', 'sas', 'matlab', 'r']","['data analytics', 'visualization', 'statistics', 'quantitative analysis', 'physics', 'scripting', 'datasets', 'dashboards', 'economics', 'testing', 'dynamics', 'computer science', 'analytics', 'hypothesis testing', 'optimization', 'statistical analysis', 'etl']","['environment', 'metrics', 'marketing', 'international markets', 'consulting', 'compensation', 'customer']"
121,153,Product Data Scientist,"the company you ll join at carta we create owners and make private markets liquid. we live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment others live on the debt stack and may work their entire lives for a company and retire only with the cash they ve managed to save from their paychecks. our contribution to solving the wealth inequality problem is moving people from the debt stack to the equity stack. by making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners. at carta, we are helpful, transparent, fair, and kind. we are relentless executors, unconventional thinkers, and masters of our craft. to learn more, here is what one of our investors wrote about leading our series f. the team you ll work with our mission is to enable data driven decisions and products across carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. we believe in building a strong data foundation to ensure data quality and to promote self service across the company. in addition, the data team works on developing proprietary data products using carta s rich and unique dataset. the team is split between data science or machine learning, data analytics, and data engineering. we like to partner with each other and with cartans across the company to get our work done. we constantly think about how we can improve and grow. the problems you ll solve as a member of this team, you will partner with business and product teams to use data to accelerate decision making. you will make sure our internal customers have access to consistent metrics and understand their definitions, partner with the rest of the data team to enable self service access to the data they need, and work on reporting and analysis to improve our products. examples of responsibilities include partner with business and product teams across the organization to understand business problems and help build data solutions work with data engineering team to build and implement data pipelines for new data sources build ml models and deeper analytics with data science team using sql and or or python to generate insights promote self service for business users and their data requests through looker or other methods structure and build etl infrastructure for new products and business lines the impact you ll have by partnering with teams within carta and providing data solutions, you will elevate our decision making and improve our products, operations and business direction. as you continue to build out our analytics toolkit, you will empower others in the organization to make data driven decisions. about you successful candidates in this role are excellent communicators who are always looking for opportunities to use data to make decisions. you have at least 5 years of analytics experience either in product analytics or data science. you are a self starter who can build relationships across the company, understand how to prioritize your work, is able to partner with members of your team, and understands when data can and should be used to improve carta. you have excellent attention to detail, are able to communicate with both business and technical team members and don t mind writing documentation. preferred tech stack sql python looker aws or sagemaker airflow dbt example of problems you will solve include working across multiple teams to standardize, document and generate core metrics for our business and our product re evaluate explores in looker to make sure they are easy to understand and use provide training sessions to teach members of other teams to use looker generate insights into how new features can impact a product release work with business partners and or or product managers to instrument new initiatives and come up with metrics to measure them collaborate with the rest of the data team to come up with new products based on data we are an equal opportunity employer and are committed to providing a positive interview experience for every candidate. if accommodations due to a disability or medical condition are needed, connect with us via email at as a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. check out our careers page to get to know us better as you think about your next step at carta.","['documentation', 'data analytics', 'sql', 'python', 'looker', 'reporting', 'data science', 'analytics', 'product', 'aws', 'data engineering', 'machine learning', 'data pipelines', 'data products', 'toolkit', 'rest', 'airflow', 'data solutions', 'etl']","['sql', 'python', 'looker', 'documentation', 'aws', 'airflow']","['data analytics', 'machine learning', 'data pipelines', 'data products', 'reporting', 'data solutions', 'data science', 'analytics', 'product', 'toolkit', 'data engineering', 'rest', 'etl']","['internal customers', 'metrics', 'private markets', 'dbt', 'business lines']"
122,154,Data Scientist,"at metricsflow, we work to shape the future of data attribution for a new kind of relationship between customers and companies. advocating for privacy first practices and a smarter, deeper, and non invasive customer learning, metricsflow innovates using machine learning and ai technology to equip businesses with the right tools. if you are passionate about the internet and how data is treated, you ve found the right place. metricsflow is seeking an exceptional individual to serve as a data scientist. the successful candidate will work closely with the product and engineering team to translate technological and customer requirements into valuable features that ensure a great user experience. responsibilities work with structured and unstructured raw data to design and develop innovative predictive models, metrics, reports, and dashboards to uncover actionable insights deliver results to drive the projects end to end, not limited to model training, but also including building data pipelines and integrating with engineering systems research industry best practices for features to be implemented in the metricsflow reporting application, with a focus on data science features including data preparation, machine learning, user identification implement scalable, efficient processes for large scale data analyses, model development and deployment. requirements 3 years in data scripting languages e.g python hands on experience in the application of predictive modeling, artificial neural networks, time series analysis, clustering and classification techniques, and other advanced analytical techniques experience using ci or cd tools good design and problem solving skills and an ability to innovate and solve challenging technical problems knowledge of the software development lifecycle and agile methodologies excellent organization and time management skills","['user experience', 'ci', 'dashboards', 'attribution', 'python', 'cd', 'time series analysis', 'reporting', 'data science', 'software development', 'data', 'analytical techniques', 'machine learning', 'data preparation', 'data pipelines', 'customer requirements', 'model development', 'agile methodologies', 'neural networks', 'modeling', 'script', 'ai']",['python'],"['user experience', 'artificial', 'ci', 'dashboards', 'attribution', 'cd', 'time series analysis', 'reporting', 'scripting', 'data science', 'software development', 'systems', 'data', 'analytical techniques', 'machine learning', 'data preparation', 'data pipelines', 'customer requirements', 'predictive', 'model', 'user', 'agile methodologies', 'neural networks', 'modeling', 'ai']","['design', 'metrics']"
123,155,"Operations Research Scientist/Data Scientist - Vancouver, Canada/Remote","operations research scientist or data scientist vancouver, canada or remote fit00030 description fujitsu has been consistently named as fortune world s most admired companies year after year, fujitsu is a leading multinational information and communication technology company at the forefront of driving enterprise scale digital transformation initiatives in organizations and communities around the world. offering a full range of technology products, solutions and services, fujitsu s commitment to r d continues to deliver cutting edge technologies, particularly in the fields of artificial intelligence, optimization, operations research, iot, blockchain, and supercomputing. combined with its core offerings in it infrastructure and cloud transformation, this has enabled fujitsu to develop vast international business operations employing over 130,000 people in 100 countries worldwide in all business sectors at the heart of the global economy. additionally, fujitsu s strong orientation towards the environment, sustainability, and social or societal impact has ensured it continues to be named to the dow jones sustainability world , the world s leading socially responsible investment index, year after year. fujitsu intelligence technology fujitsu intelligence technology limited is an emerging center of excellence and innovation hub within fujitsu s global operations for data science, artificial intelligence, optimization, quantum inspired computing, and digital transformation. located in vancouver, canada, and operating as a gateway to fujitsu s profound global engineering and innovation ecosystem, fitl is positioned as a digital transformation catalyst, working to grow fujitsu s ai and digital annealer business solutions both in north america and globally to support fujitsu s mission of making the world more sustainable through building trust in society with innovative solutions. fujitsu intelligence technology is comprised of a diverse team of data scientists, operations research scientists, software engineers along with a strong management support group committed to help businesses navigate and adapt to the digital world. we are committed to developing the talent of our resources through mentoring, collaboration, and education with internal or external stakeholders to shape them to become leaders in the digital transformation ecosystem. we value transparency and fairness in everything we do and look for people that are able to adapt quickly, stay ambitious, and be passionate about new technology. we are looking for an operations research scientist that would be working closely with the team in our vancouver, bc office. please note that remote work is an available option for this role. position summary we re looking for an experienced operations research scientist to join fujitsu s ai and optimization team to help solve real world challenges facing society and businesses across different industries, including manufacturing, healthcare, pharmaceutical, oil and gas, and financial services. as an operations research scientist, you are passionate about solving problems that make a difference to people, business, and society. you will play a crucial role in identifying and developing innovative advanced analytics solutions services to support business outcomes. in this position, you will be working in a fast paced, collaborative team environment to solve customer problems through data, using best of breed open source and proprietary ai and operations research technologies such as fujitsu s next generation quantum inspired digital annealer, a dedicated architecture for solving complex combinatorial optimization problems. responsibilities a successful candidate will perform the following collaborate with our clients and internal stakeholders to understand business processes, identify opportunities, and propose approaches to challenges in a consultative manner design, develop and lead the implementation of cloud or onpremises analytics solutions acquire, explore, analyze, visualize, cleanse, and transform large sets of data from various external or internal sources select and apply appropriate algorithms, methods, and tools create scalable data pipelines and machine learning systems clearly and objectively communicate progress, results and insights to clients investigate, define, select, and promote the use of processes, tools, frameworks, and best practices share ideas and expertise with colleagues in a collaborative team environment qualifications basic qualifications master s or phd degree in a quantitative field such as operations research, data science, computer science, quantitative finance, math, physics or a related engineering degree minimum seven years of experience in building models and developing algorithms for optimization, machine learning, statistics, mathematical programming, and simulation in industry and or or academia. minimum five years of work experience in managing and analyzing largescale structured and unstructured data using a data and analytics programming language, preferably python expert skills in operations research such as linear programming, metaheuristics, heuristics, quadratic programming experience with analytics, and optimization frameworks and packages such as numpy, scipy, pandas, gurobi, cplex, xpress, simulated annealing proven ability to communicate complex concepts and insights verbally and in writing to colleagues and clients with varying degrees of technical knowledge proven ability to efficiently work in a team excellent analytical and problemsolving skills excellent interpersonal skills ability to articulate complex technical concepts to nontechnical stakeholders ability to work effectively in highpressure situations ability to lead and deliver project against tight timelines organized, articulate, team player, open to collaborative workstyles and able to manage multiple deliverables for different projects at any given time familiarity and willingness to work in crosscultural and geo diverse teams preferred qualifications experience in designing and building production analytics solutions experience in data science using machine learning frameworks and packages such as scikitlearn, keras, pytorch, tensorflow consulting or experience in a clientfacing role experience with discrete event simulation experience with big data technologies such as hadoop and spark experience with visualization platforms such as tableau and powerbi experience with relational databases, sql and data modeling job type experienced job administration primary locationbc vancouver travel yes, 20 of the time","['unstructured data', 'computing', 'visualization', 'tableau', 'pytorch', 'tensorflow', 'big data', 'sustainability', 'sql', 'forefront', 'python', 'statistics', 'scipy', 'keras', 'software', 'physics', 'data science', 'pandas', 'analytics', 'programming', 'data', 'cloud', 'machine learning', 'data pipelines', 'relational databases', 'quantitative', 'iot', 'numpy', 'artificial intelligence', 'algorithms', 'blockchain', 'administration', 'linear', 'hadoop', 'computer science', 'optimization', 'modeling', 'digital transformation', 'ai']","['sql', 'python', 'forefront', 'scipy', 'keras', 'tableau', 'iot', 'pytorch', 'hadoop', 'numpy', 'pandas', 'programming', 'big data', 'cp']","['unstructured data', 'computing', 'visualization', 'tensorflow', 'sustainability', 'statistics', 'software', 'physics', 'data science', 'analytics', 'machine learning', 'data pipelines', 'relational databases', 'operations research', 'quantitative', 'artificial intelligence', 'algorithms', 'blockchain', 'administration', 'mathematical', 'linear', 'computer science', 'optimization', 'data modeling', 'cloud transformation', 'digital transformation', 'ai']","['gas', 'environment', 'education', 'healthcare', 'operations research', 'international', 'design', 'finance', 'business operations', 'operations', 'global operations', 'consulting', 'financial services', 'oil and', 'manufacturing', 'architecture', 'mentoring']"
124,156,"Data Scientist: Pricing, Fraud, Monetization","data scientist pricing, fraud, monetization london, on, canada req 43 thursday, january 28, 2021 about this position digital extremes is currently seeking a data scientist pricing, fraud, monetization to join our team. you will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. as a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data in a clear and compelling manner that inspires action. as an ideal candidate, you will also have experience with free to play games. responsibilities identify opportunities, advocate and direct changes to regional pricing, fraud prevention, vendors and customized offers ensuring positive player value and sentiment. collaborate with insight, marketing and development teams to improve the player purchasing experience working closely with the finance team ensuring proper management of vat, sales tax, financial tracking and chargebacks manage relationships and data pipeline with third party vendors use iterative experimental approaches, statistical methods and modelling to measure the effectiveness of changes extract and organize data into a reliable user friendly form and present it to the interested and affected parties on the team conduct ad hoc data analysis based on current team needs and management priorities requirements excellent organizational, communication and interpersonal skills bachelor s degree in a technical or quantitative discipline minimum 3 years of experience using data science techniques a passion for video games and understanding of gaming culture experience with regional pricing, custom offers and fraud of digital goods in depth knowledge of postgres sql, mongo db, python notebooks experience in the gaming industry, specifically free to play gaming is a plus strong quantitative analysis techniques and qualitative methods, as well as predictive modelling demonstrated success presenting complex research data in a clear and compelling manner that inspires action excellent organizational, communication and interpersonal skills self starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas about digital extremes founded in 1993 by james schmalz, digital extremes ranks as one of the world s top independent video game development studios. originating with the co creation of epic games multi million unit selling unreal franchise including unreal and unreal tournament, digital extremes went on to develop dark sector , bioshock for the playstation 3, the bioshock 2 multiplayer campaign, and the darkness ii. the studio has reached its greatest critical and commercial success with the free to play action game, warframe , boasting a global community of 50 million registered players on pc, ps4 , xbox one and nintendo switch . for more information about digital extremes, visit to sign up for warframe, visit why work at digital extremes our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. developing new and existing talent is our long term focus. we are honored that our work environment has been consistently recognized as one of canada s top 100 employers . we summon you to join our elite team the rewards of a career with digital extremes include competitive salary with bonus opportunities excellent benefits and paid time off matching rrsp plan employee assistance program professional development and career support fitness and parking or transit subsidies daily lunches prepared onsite by our in studio executive chef and professional kitchen staff all day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more join us digital extremes is an equal opportunity employer committed to diversity and inclusion. we welcome and encourage applications from people with disabilities. accommodations are available upon request for candidates taking part in all aspects of the recruitment process. we thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted. other details pay type salary","['sql', 'python', 'data science', 'game development', 'data analysis', 'gaming']","['playstation 3', 'sql', 'python', 'xbox one switch']","['quantitative analysis', 'data science', 'video', 'game development', 'data analysis', 'ad hoc', 'gaming']","['environment', 'sales tax', 'marketing', 'purchasing', 'finance', 'therapy', 'hiring']"
125,157,Data Analyst/Engineer,"telus is building the tv experience of the future if you want to be part of the most exciting journey, join our team we are going to reinvent how entertainment is brought to people, through technology, content and exciting user experience. we shall use the most modern and advanced technologies, creating small, independent and cohesive teams with diverse skills to reach a commonly agreed target rebuild entertainment responsibilities identify strategic data requirements for the enterprise. analyze structural requirements for new software and applications. migrate data from legacy systems to new solutions. determine how an enterprise s data will be stored and utilized. assess the enterprise s internal and external data and design blueprint to manage the available data. create an inventory of enterprise s data and store data in an easily accessible format. design and develop complex database management systems and separate public data from private ones. collaborate with enterprise s management needs to create data models in line with the organizations need. research to collate new data and update the company s database from time to time. requirements 7 years of proven work experience as data scientist, data analyst or similar role. in depth understanding of database structure principles. experience in independently managing complex projects. experience gathering and analyzing system requirements. knowledge of data mining and segmentation techniques. expertise in mysql, sql server, and oracle. familiarity with data visualization tools . excellent analytical, quantitative, and interpersonal skills, with impeccable attention to detail. ability to learn new technologies quickly. ability to work independently and with a cross functional geographically spread team. ability to interface with multiple cross functional teams and external partners. prior experience in tv architecture is a plus. job types full time, temporary salary 75.00 80.00 per hour application question how many years of experience do you have as a data scientist or data analyst how many years of experience with mysql, sql and oracle do you have work remotely yes covid 19 precaution remote interview process","['data mining', 'sql', 'software', 'legacy systems', 'user experience', 'system requirements', 'data visualization', 'database', 'data models', 'mysql', 'public']","['sql', 'public data', 'legacy systems', 'data models', 'mysql']","['data mining', 'software', 'user experience', 'management systems', 'system requirements', 'data visualization', 'database']","['architecture', 'blueprint', 'design', 'private']"
126,158,Senior Data Scientist - RACE21,"closing date june 30, 2021 reporting to the manager of data science, the senior data scientist at race21 brings deep understanding of big data and helps in building and enabling big data analytics solutions. they apply complex and most current modelling techniques to existing data sets in order to find optimization and or or improvement opportunities relevant to the context of the product being developed and business problem at hand. must have experience in the following domains operations research mixed integer programming linear programming constrained optimization responsibilities be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures designs, develops, and implements end to end cloud based machine learning production pipelines collects, parses, manages, analyzes and visualizes large sets of data using multiple platforms identifies opportunities across business operations to reduce cost, improve safety, sustainability, and efficiency extracts and visualizes insights from the available data sets and provides reports and guidelines for improving operations prepares documentations of the models, designs and techniques for data and product development teams translates complex functional and technical requirements into detailed architecture, design, and high performing software codes, tests, and documents new or modified data systems to create robust and scalable applications for data analytics ensures all automated processes preserve data by managing the alignment of data availability and integration processes works with fellow data scientists and engineers to ensure that all data solutions are consistent ability to architect highly scalable distributed systems using different tools develops standards and processes for integration projects and initiatives is prepared to communicate data science insights to internal clients and stakeholders qualifications computer science degree or equivalent education and experience master s or phd degree in information technology, computer science, or a related quantitative discipline a minimum of 3 years experience in data science proficient in python for data processing, statistical analysis, machine learning and visualization and skilled in writing sql queries experienced in applied data science within business operations and industry environments familiar with data modeling and different data structures and algorithms experienced as a data scientist within an agile team or other rapid development methods and environments excellent problem solving, critical thinking, and communication skills experience in developing presentations and communications to be shared with internal and external stakeholders brings a high energy and a passionate outlook to the role and can influence those around them in a collaborative and informative manner able to build a sense of trust and rapport that creates a comfortable effective workplace knowledge of simulation and optimization techniques is at teck, we value diversity. our teams work collaboratively and respect each person s unique perspective and contribution. qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically. we wish to thank all applicants for their interest and effort in applying for the position however, only candidates selected for interviews will be contacted. your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. teck respects the privacy of all applicants and the confidentiality of personal information. teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, and zinc, as well as investments in energy assets. headquartered in vancouver, canada, its shares are listed on the toronto stock exchange under the symbols teck.a and teck.b and the new york stock exchange under the symbol teck. the pursuit of sustainability guides teck s approach to business. teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. in 2019, teck was named to the dow jones sustainability world index for the tenth straight year, indicating that teck s sustainability practices rank in the top 10 per cent of the world s 2,500 largest public companies in the s p global broad market index.","['visualization', 'big', 'technical requirements', 'big data', 'information technology', 'sustainability', 'distributed systems', 'statistical analysis', 'data analytics', 'python', 'sql', 'data processing', 'reporting', 'data science', 'data', 'programming', 'integration', 'data systems', 'pipelines', 'machine learning', 'algorithms', 'data structures', 'linear', 'data solutions', 'computer science', 'optimization', 'modeling']","['sql', 'python', 'linear', 'big', 'programming', 'big data', 'pipelines']","['visualization', 'technical requirements', 'detailed', 'information technology', 'sustainability', 'distributed systems', 'statistical analysis', 'data analytics', 'tests', 'data processing', 'software', 'reporting', 'data science', 'data', 'integration', 'data systems', 'machine learning', 'algorithms', 'data structures', 'data solutions', 'computer science', 'optimization', 'modeling']","['disclosure', 'education', 'design', 'presentations', 'business operations', 'product development', 'investments', 'coal', 'environmental', 'business units', 'architecture']"
127,159,Data Scientist/Analytics Engineer,"what does your dream company look like if it s a fun, hyper growth startup where people look forward to coming to work monday mornings, keep reading... renorun we are market leaders, as the fastest growing materials supplier, delivering to canadian and us cities. to contractors, renovators and craftsmen, renorun is the single materials provider because they get quality materials, from anywhere, anytime, simply and reliably. we re truly disrupting the way construction professionals purchase and receive their materials. the proof is in the pudding we have recently closed one of canada s largest venture backed series a s for 2019 and are in search of amazing talent to help propel the company on to the next. so if you re looking for impact, look no further. come join renorun we are looking for a data scientist or analytics engineer to join our data team. you ll be an integral part of connecting the team to business and ensuring a win win for all your typical day includes building you will help build and maintain the data infrastructure at the heart of the company. partnering you will work closely with business stakeholders to understand their data needs and build out the required solutions. ownership from cleaning and transforming raw data into business logic to helping stakeholders build reports, you will have a hand in making sure the right data is getting to the right people at the right time. improvement you ll be constantly looking for ways to improve the modelling and data pipelines to reflect reality and increase efficiency. must haves 2 4 years experience working in analytics engineering, data science, or similar roles experience writing sql and python experience working with data visualization software experience in data modelling and working with data warehouses nice to haves bachelor s or equivalent in a relevant field experience working in a start up environment experience building or working with data pipelines and etl tools processes experience building or working with predictive models and machine learning algorithms perks competitive compensation packages including equity unlimited vacation comprehensive health, dental vision insurance incredible work environment and culture plenty of snacks dog friendly office why you should work with us we know building and renovation. we are industry leaders. we make puns. we have fun. we cut to the point because we value people s time. we are culture driven. we care a lot. and we say it. thank you for your interest in renorun for more information visit at renorun, we strive to build a workforce composed of individuals with diverse identities, backgrounds, abilities, and minds that will help us to grow, not only as a company, but also as individuals. renorun is an equal opportunity employer .","['sql', 'python', 'machine learning', 'data pipelines', 'software', 'data infrastructure', 'data visualization', 'data science', 'analytics', 'algorithms', 'etl']","['sql', 'python']","['machine learning', 'data pipelines', 'software', 'data infrastructure', 'data visualization', 'data science', 'analytics', 'algorithms', 'etl']","['environment', 'materials', 'construction', 'compensation', 'insurance']"
128,161,Data Scientist - Canada,"at shift technology, we re transforming insurance with ai. we help insurers fully automate more claims, deliver a great customer experience while protecting against risk and accurately identifying suspected fraud, making internal teams more effective and improving financial performance. since our launch in 2014 in paris, we ve raised over 320m with tier 1 investors, opened offices in boston, tokyo, singapore, london, madrid, mexico, hong kong, and sao paulo, and currently work with more than 80 of the world s leading insurers. if you are excited about joining a fast growing insurtech innovator with a passion for excellence and global culture, shift is the place for you. shift technology offers a unique opportunity to brilliant candidates to accelerate their careers in data science data scientists work on a broad range of subjects, acquiring a lot of technical and professional experience in data science, data engineering, coding, business understanding and client interactions skills invaluable in any career. our company is small enough that each person s achievements have an impact on overall performance, yet big enough to be a world leader in our domain. we are a fast growing company, the best contributors will grow to managerial or product tech lead positions much more rapidly than in bigger companies your role the data science team is in charge of technically delivering the shift products to clients, the key role in the success of our projects with clients. it is a hands on job, expect to be doing everything you can imagine from the technical side in an ai company implementation of the data engineering , usually from client extracts to the insertion of the data in our data stores developing, testing, tuning models and putting them in production for tasks such as fraud detection and automation detection in complex environments. automate key business tasks by implementing them in our production process framework in c conduct meetings with clients and interact with external stakeholders, whether it is direct user feedback, presenting business cases or defining the roadmap of evolutions for that client you will actively participate in the definition and development of our suite of products on fraud detection, anti money laundering and claim automation, working on various data types such as structured data, free text, documents and images. what we are looking for as a result of the range of the role, we are looking for people with diverse skills and proficiencies to help make our customers successful.we are open to people not having exactly all of the required skills, but in each one of those they must be willing to build expertise. as a result, we expect data scientists to be code savvy , either by having a degree in computer science and or or having developed some apps with actual users, or by willing to spend a lot of time practicing. writing scripts for models and notebooks is not enough at shift, we thrive on people who can write maintainable, production quality code that will run everyday without breaking. ai savvy , either by having a degree in machine learning and or or statistics or be looking to work on those subjects. having a clear understanding of statistics and machine learning problems, tasks and common resolutions is important to communicate internally and explain to the client how the product is working. client facing . you will need to be comfortable, clear and professional when talking to clients during meetings and by email. expect to talk with a client every other day and grow your communicational and presentational skills business smart . we don t expect candidates to know the insurance sector, but we want people who can learn and master the business aspects of our products english speakers . we are an international company with offices in many countries and 40 nationalities, the shift working language is english. eeo statement at shift we thrive to be a diverse and inclusive workforce. we hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non merit criteria. shift is proud to be an equal opportunity employer.","['structured data', 'machine learning', 'statistics', 'testing', 'data science', 'c', 'computer science', 'fraud detection', 'aiurt', 'data engineering', 'automation', 'ai']",['c'],"['insurtech', 'machine learning', 'statistics', 'testing', 'data science', 'computer science', 'fraud detection', 'structured data', 'data engineering', 'automation', 'ai']","['resolutions', 'financial performance', 'business understanding', 'customer experience', 'insurance']"
129,163,Senior Data Scientist,"les candidats r f r s ne doivent pas postuler directement pour ce poste. toutes les r f rences de candidats doivent d abord tre soumises dans workday par un coll gue de loblaw actuel. lieu 1 presidents choice circle, brampton, ontario, l6y 5s5 c est toute une d cision que de se joindre une entreprise. nous offrons des perspectives d emploi des personnes qui, comme vous, sont travaillantes, dynamiques et fiables. pourquoi ce role est il important the data, insights and analytics division at loblaw is looking for a data scientist to join our fast growing team. the team will look for your expertise in optimization in helping build production ready data science solutions. the ideal candidate must have expertise in the development of optimization algorithms, modern analytical programming and heuristics. the candidate would also thrive working in an agile development environment alongside talented data or software engineers and possess a flair for communicating optimization solutions, ideally with a retail pricing context. what you ll do act as one of the optimization subject manager experts within the data, insights analytics team, establishing and managing a priority work roadmap collaborate with the business to translate problem statements and then d esign and test analytical modules for modeling and optimization platforms be a strong individual contributor who can quickly extract data and hash out working prototypes leveraging cloud technology to solve business needs develop powerful business insights from data using a range of analytical techniques including, but not limited to building predictive models that learn from and scale to massive data sets and the production of interactive data visualizations support the organization in adapting optimization best practices and delivery methods partner with our data software engineering departments to build world class web based analytical solutions document and present methodology inside and outside the company strictly adhere to legal and compliance guidelines regarding access and exposure to sensitive and confidential information what you ll bring graduate degree in operations research, industrial engineering, applied mathematics, computer science or systems engineering with focus on optimization methods experience in retail and or or cpg pricing, promotions and assortment is a big plus excellent oral and written communication skills superb analytical and critical thinking capability to not only manipulate massive, complex datasets, but also to derive meaningful interpretations conclusions experience writing production grade code using scientific computing packages expertise in python or other modern programming languages expertise in using cplex, gurobi and or numerical algorithm groups solvers expertise in object oriented programming well organized and capable of handling multiple mission critical projects simultaneously while meeting deadlines a desire and ability to take initiative, multi task and work in a collaborative, fast paced environment capability to liaise with all levels across the enterprise on projects and ad hoc requests experience in short release lifecycle comment r ussir chez loblaw, nous recherchons toujours des personnes formidables pour continuellement renforcer notre culture. nous croyons que les gens formidables fa onnent nos valeurs, sont authentiques, b tissent la confiance et cr ent des liens. si cela vous ressemble et que vous tes ouvert d esprit, que vous avez une bonne attitude face aux changements et que vous aimez les d fis d un environnement de travail aux d tails dynamiques, postulez aujourd hui. en outre, nous croyons que la conformit aux lois consiste faire ce qu il faut. le respect de la loi fait partie de notre code de conduite il renforce ce que nos clients et nos parties prenantes attendent de nous. type d emploi temps plein role poste r gulier loblaw consid re que la diversit culturelle du canada est une source de fiert nationale et un symbole de force. nous nous sommes donn comme priorit de refl ter la diversit croissante du canada dans les produits que nous vendons, les gens que nous embauchons et notre culture d entreprise. des accommodements sont disponibles sur demande pour les postulants et coll gues atteints d un handicap. remarque si vous avez acc s libre service de l employ dans workday, veuillez postuler cet emploi en utilisant l application workday.","['computing', 'systems engineering', 'c', 'python', 'software', 'data science', 'analytics', 'programming', 'analytical techniques', 'algorithms', 'programming languages', 'business insights', 'datasets', 'computer science', 'optimization', 'modeling', 'applied mathematics', 'analytical', 'r']","['python', 'business insights', 'c', 'programming', 'programming languages oriented', 'r']","['algorithms', 'analytical techniques', 'methodology', 'computing', 'systems engineering', 'software', 'datasets', 'data science', 'computer science', 'analytics', 'optimization', 'agile development', 'modeling', 'software engineering', 'applied mathematics', 'analytical']","['environment', 'industrial engineering', 'and compliance', 'retail', 'operations']"
130,164,Data Scientist,"data scientist, 48hour discovery founded in 2017, 48hour discovery is a canadian biotechnology company with headquarters in edmonton, ab and satellite sites in san diego, california and seoul, south korea. the 48hd genetically encoded platform technology offers rapid discovery of pharmaceutical leads in the peptide or macrocycle therapeutic space to major pharmaceutical companies . we are currently seeking a creative and motivated data scientist to join our team. the ideal candidate will have strong prior knowledge of chemistry, biochemistry and experience with machine learning that involves chemical or molecular structures. this candidate will combine the knowledge of machine learning and chemical or molecular structures to develop automate, reusable models for predictive analytics in the peptide or macrocycle space. primary responsibilities this is a key position in developing the platform to discover future pharmaceutical leads while driving the adoption of ai. all applicants must be prepared to provide demonstrated experience in the following extensive knowledge in chemistry and or or biochemistry including chemical or molecular structures. work with structured and unstructured raw data to design and develop innovative predictive models using machine learning techniques. visualize and report data findings creatively in various visual formats that provide insights. additional consideration will be given to individuals with experience in the following work with next generation sequencing data. data collected from phage display experiments. bioinformatics background. qualifications msc or phd in computer science, machine learning, artificial intelligence, statistics, mathematics, engineering, computational biology, molecular biology, chemistry, biochemistry or a related discipline, with graduate level courses in machine learning, or equivalent practical experience. minimum 2 years in implementing machine learning software. extensive knowledge in chemistry and or or biochemistry. familiar with chemical or molecular structure. strong research experience in machine learning, preferably in deep neural network architectures. proficient in deep learning frameworks like pytorch and scientific computing packages. able to implement an algorithm as described in an academic paper using these frameworks in quality code. strong computer science background, with experience in object oriented programming, systems design, data structures and algorithms. proficient in python and or or r, with an interest in learning new languages. familiarity with source control and unix systems. efficient written and verbal communication skills with the ability to present to a wide range of audiences. this full time position has a term length of 18 month, with the possibility of extension, and offers a comprehensive benefits package. salary will be commensurate with experience and qualifications. job type full time salary from 70,000.00 per year benefits extended health care schedule monday to friday work remotely no","['computing', 'pytorch', 'python', 'statistics', 'software', 'bioinformatics', 'unix', 'analytics', 'programming', 'r', 'computational biology', 'machine learning', 'systems design', 'artificial intelligence', 'algorithms', 'deep learning', 'data structures', 'chemistry', 'computer science', 'mathematics', 'ai']","['python', 'pytorch', 'unix', 'programming', 'predictive', 'r']","['deep learning', 'computing', 'machine learning', 'statistics', 'data structures', 'computational biology', 'bioinformatics', 'software', 'systems design', 'chemistry', 'computer science', 'analytics', 'artificial intelligence', 'mathematics', 'neural network', 'algorithms', 'ai']","['sequencing', 'biotechnology', 'biology', 'biochemistry', 'design', 'molecular', 'adoption']"
131,165,Bilingual Data Science Associate,"company presentation world leader in gases, technologies and services for industry and health, air liquide is present in 80 countries with approximately 65,000 employees and serves more than 3 million customers and patients. oxygen, nitrogen and hydrogen have been at the core of the company s activities since its creation in 1902. air liquide s ambition is to be the leader in its industry, delivering long term performance and acting responsibly. entity and activity description founded in 1911, air liquide canada has over 2,200 employees and serves over 80,000 customers in canada s aeronautics, automobile, agri food, chemical, defense, electronics, energy, metallurgy, metal fabrication, mining and healthcare industries from our sites located in key industrial regions from coast to coast. missions and responsibilities the r d data science group at air liquide has an opening for a data scientist. the researcher will have the opportunity to work on challenging problems focusing on customers, patients and operations. the researcher will also interact with multi disciplinary teams composed of business, it and digital resources that define operating models, and build digital solutions. duties and responsibilities collaborate with the business to define needs and challenges, translate them into functional specifications, and develop solutions to address them. work with it and external organizations to obtain online or offline data. clean, and analyze the data. develop solutions relying on machine learning methods such as clustering, regression, classification, time series and deep learning. test and verify the performance of solutions with prototypes developed in r, python, or similar development environments. support the development of industrial tools and their deployment in the business units. train team members and the business, thus ensuring sustainability of the solutions for air liquide. publish research in internal reports, at conferences and peer reviewed journals competencies and profile master in computer science or related field 3 years of relevant experience is preferred a strong background and experience in statistics and machine learning strong programming skills in python or r ability to write production level, modular code demonstrates strong process and operational safety behavior at all times excellent communication and interpersonal skills ability to work in a multi disciplinary and international team preferred experience in aws, azure, and sql thank you for your interest. please note that only applicants selected for an interview will be contacted for more information on our company, visit us online at missions et responsabilit s vous aurez l opportunit de travailler sur des probl mes complexes centr s sur les clients, patients et les op rations. vous travaillerez au sein d une quipe multi disciplinaire compos e de profils d experts en science des donn es et de recherche op rationnelle. vous serez galement en interaction avec les quipes op rationnelles, des ti et du digital qui travaillent identifier des mod les op rationnels et construire des solutions digitales. d velopper des solutions bas es sur les approches d apprentissage automatique analyse par groupe , r gression, classification, s ries temporelles et apprentissage profond tester et v rifier la performance des solutions l aide de prototypes d velopp s en r, python ou des environnements de d veloppement similaires soutenir le d veloppement d outils industriels et leur d ploiement dans les unit s commerciales collaborer avec les op rations afin de d finir les besoins, les traduire en sp cifications fonctionnelles et d velopper des solutions pour y r pondre travailler en collaboration avec les ti et les organisations externes afin d obtenir des donn es en ligne or hors ligne. nettoyer et analyser les donn es. former les membres de l quipe et les op rations, afin d assurer la durabilit de ces solutions pour air liquide profil et comp tences ma trise en science des donn es 3 ann es d exp rience pertinente une exp rience en statistiques et d apprentissage automatique capacit produire du code modulaire et d ployable en production solides comp tences en python ou r fait preuve d un comportement ax s curit op rationnelle tout moment excellentes capacit s de communication et en relations interpersonnelles capacit travailler dans une quipe multi disciplinaire et internationale pr f r exp rience sur aws, azure et sql nous vous remercions de votre int r t pour air liquide. notez que seuls les candidats pr s lectionn s seront contact s. pour plus d informations sur notre entreprise, visitez nous en ligne job types full time, permanent schedule 8 hour shift monday to friday ability to commute or relocate montr al, qc education master s degree experience data science 4 years machine learning 3 years","['deep learning', 'sql', 'python', 'machine learning', 'statistics', 'data science', 'computer science', 'programming', 'aws', 'sustainability', 'functional specifications', 'electronics', 'r']","['sql', 'python', 'mes', 'programming', 'aws', 'electronics', 'operating models', 'r']","['deep learning', 'machine learning', 'statistics', 'functional', 'data science', 'computer science', 'specifications', 'sustainability']","['education', 'healthcare', 'hydrogen', 'acting', 'agri', 'metallurgy', 'business units']"
132,166,Data Scientist (Portfolio Modelling),"closing date 06 or 30 or 2021 worker type term language required english term duration 12 data science and statistical modelling expertise needed use your extensive knowledge of risk management and finance in areas such as credit risk, allowance for credit losses, economic capital, and stress testing to support our portfolio management team. what you ll do unlock insights from complex and diverse groupings of internal and external data or developed models to tell a story use advanced analytics techniques to enable enlightened decision making choose appropriate ways to tell the story through words, visualization, and interpretation what we re looking for analytical thinker who can design and develop strategies that give users the information they need to make informed decisions creative thinker with research, analytical, and problem solving skills confident communicator who can translate knowledge for others relationship builder comfortable making recommendations for improvement what you ll need a bachelor s degree in agriculture, finance, business, economics, mathematics, statistics or computer science and at least four years of experience in depth understanding of statistics and mathematics combined with business domain knowledge highly proficient in visualization and analytics tools including but not limited to sas, ms power bi, aws environment and tools, r, python a passion for analysis, insights and storytelling if you are an fcc employee, use your workday portal to apply. if you are an fcc employee on leave, contact human resources for instructions on how to apply.","['python', 'visualization', 'statistics', 'bi', 'economics', 'testing', 'data science', 'computer science', 'analytics', 'mathematics', 'aws', 'sas', 'r']","['python', 'bi', 'aws', 'sas', 'r']","['visualization', 'statistics', 'stress', 'testing', 'economics', 'data science', 'computer science', 'analytics', 'mathematics']","['environment', 'capital', 'portfolio management', 'risk management', 'human resources', 'design', 'finance', 'business domain', 'agriculture']"
133,167,"Scientist, Data","the data scientist will join the advanced analytics team focused on creating transformational analytics enabled capabilities across all of acosta s businesses. this can range from using statistical methods, data mining and machine learning techniques, or generating novel approaches uniquely suited the challenge. we value complementary and divergent experiences to bring many points of view on how to approach solve a problem. although our datasets range in size, you can expect to work with very large datasets regularly in this role. the incumbent in this position should exhibit the following acosta values people minded must show dignity and respect to all people integrity must exemplify the highest degree of ethical behavior results oriented must show passion, pride and commitment to succeed trust must be honest, sincere and confident teamwork must build trusting relationships innovation must progress through a combination of creativity, common sense and vision balance must maintain an optimistic attitude and keep perspective on what is important in life. essential functions development of analytical capabilities to serve diverse business use cases, in active collaboration with product management and technology counterparts. cross functional, internal and external consulting, including discovery or structuring of business problems, and exploratory analysis of candidate methods to identify promising approaches for development. creation and maintenance of solution documentation, including data transformation, models, and solution integration. ownership and lifecycle management for analytics capabilities working in a production environment, including computational performance, accuracy or validity, and extension to new uses. other duties as assigned qualifications job requirements graduate degree master s degree preferred 4 7 years of experience with programming languages like python , r or sas to write complex code and implement into a production environment. must be able to develop independently and guide others within the development team. practical experience with development, tuning, and maintaining machine learning capabilities at scale. experience generating linear and or or logistic regression models. must be able to generate complex analytic models on a large scale with no guidance. must be able to guide others in the same. experience with linear or integer programming and or or other optimization techniques. must be able to generate complex solvable optimization models on a large scale with no guidance. must be able to guide others in the same. experience with data science in microsoft azure or cloud environments using spark or alternative parallel computation capabilities highly desired. cpg, sales and or or retail experience highly desired knowledge, skills and abilities requirements an understanding of different data sources, their proper uses, and their limitations. must be able to identify data that is unclean and or or misapplied and must be able to recommend the proper methodology to fix any issues. excellent written and verbal communication skills that allows story telling. must be able to clearly speak english and must be able to communicate very technical procedures to a non technical audience. strong analytical and problem solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information residing in large datasets. ability to consult across various business functions to explain analytic functions and how they can be used to drive a business. intellectual curiosity is critical. acosta sales marketing is an equal opportunity employer by submitting your application you agree with and accept the acosta privacy statement and terms of conditions. us http or or acosta.jobs or privacy policy us or canada http or or acosta.jobs or privacy policy ca or job information technology schedule full time job type standard shift day job job posting may 12, 2021, 9 52 09 am","['documentation', 'information technology', 'microsoft azure', 'cp', 'python', 'logistic regression', 'data science', 'analytics', 'product management', 'integration', 'programming', 'sas', 'data mining', 'machine learning', 'data transformation', 'programming languages', 'datasets', 'optimization', 'r']","['python', 'programming languages', 'documentation', 'programming', 'sas', 'microsoft azure', 'r']","['computational performance', 'information technology', 'logistic regression', 'data science', 'analytics', 'product management', 'integration', 'exploratory analysis', 'data mining', 'machine learning', 'data transformation', 'optimizationvable', 'transformational', 'http', 'use cases', 'cpg', 'datasets', 'optimization', 'solution', 'methodology']","['environment', 'marketing', 'retail', 'sales', 'consulting']"
134,168,Data Scientist (Shopping Experience),"at loblaw digital, we know that our customers expect the best from us. whether that means building the best, most innovative online shopping experiences, or designing an app that will impact the lives of people across the country, we re up for the challenge. loblaw digital is the team responsible for building and operating the online businesses of canada s largest and most successful retailer. based in downtown toronto, we are an entrepreneurial, fast paced, and collaborative team working towards transforming the way canadians shop by creating leading ecommerce experiences in the online grocery shopping, beauty, pharmacy, loyalty, and apparel spaces, and we re only just getting started to achieve these goals, we are looking for talented and passionate individuals who want to collaborate and solve challenging problems and make significant and lasting impact on canadians. the impact you ll make as a data scientist on our team, you will build data science products that power a best in class personalized shopping experience, driven by an abundance of data from the loblaw enterprise. this work could be in the domains of product recommendations, personalized search, and personalized messaging, to name a few. you will work with stakeholders within loblaw digital to determine the best ways to surface these personalized experiences within customer shopping journeys, and leverage your collective domain expertise to design business logic guardrails around your model output. you will design experiments to measure the effectiveness of your product in driving customer engagement and value, through key business metrics such as clickthrough rate and attributed sales. what you ll do build robust, scalable, high performance ml solutions based on massive structured and unstructured datasets from various sources work with engineering and data platform teams to build and deploy your ml models into production work cross functionally with business teams product, trading, marketing, supply chain, web analytics etc. to source data, establish requirements, and define success does this sound like you ms or phd in a stem field especially computer science or equivalent work experience in a data scientist or closely related role a portfolio including work in the domain of data science and ml creative, resourceful, and productive problem solver able to work independently and collaboratively passion for building ml solutions to fluid, open ended problems experience in software development best practices comfortable with advanced sql querying proficient in python and familiar with a compiled language experience with big data tools, e.g. spark, beam, kafka. experience with dataviz tools such as tableau, looker, etc. how you ll succeed at loblaw digital, we seek great people to continually strengthen our culture. we believe great people model our values, are authentic, build trust and make connections. we re able to keep innovating because our colleagues are passionate about their work and excited about the future of ecommerce. you will get to work with some of the best digital minds and will have the support of world class technologies to craft products our customers will love loblaw digital recognizes canada s diversity as a source of national pride and strength. we have made it a priority to reflect our nation s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. accommodation is available upon request for applicants with disabilities in the recruitment and assessment process and when hired. in addition, we believe that compliance with laws is about doing the right thing. upholding the law is part of our code of conduct it reinforces what our customers and stakeholders expect of us.","['sql', 'python', 'looker', 'tableau', 'datasets', 'web', 'data science', 'software development', 'computer science', 'analytics', 'big data', 'solver']","['sql', 'python', 'looker', 'tableau', 'big data', 'solver']","['datasets', 'web', 'data science', 'software development', 'computer science', 'analytics', 'unstructured']","['customer engagement', 'metrics', 'marketing', 'apparel', 'design', 'sales', 'trading', 'assessment', 'business', 'law']"
135,169,Data Scientist - Telematics,"this role will start off as work from home, gradually you will be required to work in the montreal office location. join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive impactful decisions. the insurance industry has entered a period of unprecedented change, disruption and rapid technological development. aviva recognizes that in this rapidly changing environment building a distinctive capability in data science is critical demonstrating this commitment through the development of our data science practice. this team is exploring the frontiers of the insurance business such as how to harness the data from connected cars to deliver new types of products to customers. this exciting role is at the heart of a high performing data science team that is transforming aviva in the digital age. here, we are creating a long lasting legacy and optimizing every customer s experience. as a data scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. you will propose machine learning and statistical models for practical applications that impacts millions of customers. you will also mentor and guide your peers in novel approaches and provide peer review for their work. what you ll do transformation of very large and complex datasets into meaningful conclusions and recommendations build high performing machine learning and statistical models on very large datasets develop novel algorithms and innovative data driven solutions to solve business problems implement and help enhance existing ml pipeline, framework and modelling packages used by the team building and maintaining good quality code and help iteratively develop software to increase efficiencies show strong interest and understanding of the assigned business domain what you need to succeed as a data scientist, you will need the following skills and experience to succeed in the role university degree in computer science, math, statistics, physics, actuarial science or related field or equivalent. masters or phd strongly preferred 1 2 years of programming experience preferably in python with strong grasp of software engineering standard methodologies such as code reusability, modularity, use of repos, etc. 3 5 years of experience of building machine learning models for business applications advanced level understanding of machine learning fundamentals and model development principles 2 3 years experience with ml or ai technologies, such as scikit learn, keras. tensorflow, pytorch experience mining iot sensor data or telematics data will be considered an asset experience with big data technologies such as spark, databricks, scala will be considered an asset what sets you apart a growth mindset with versatile skills and able to work through problems from first principles. a portfolio of projects that demonstrate your ability to draw inferences from data. this includes participation within the broader data science community including kaggle competitions or any personal projects with open data. experience at all stages of data science problem definition, data acquisition wrangling, modelling, feature engineering and deployment. amazing people skills and able to translate and communicate complex algorithms to non technical individuals. someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners. experience working as part of an agile team the best problems in the industry are yet to be articulated. we need someone who is creative and self motivated additional information aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation. we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","['telematics', 'pytorch', 'tensorflow', 'big data', 'forefront', 'python', 'statistics', 'keras', 'data acquisition', 'software', 'scala', 'physics', 'data science', 'programming', 'machine learning', 'iot', 'algorithms', 'model', 'datasets', 'computer science', 'ai']","['python', 'forefront', 'keras', 'scala', 'pytorch', 'iot', 'sci', 'programming', 'big data']","['model', 'wrangling', 'machine learning', 'statistics', 'telematics', 'data acquisition', 'software', 'physics', 'datasets', 'tensorflow', 'data science', 'computer science', 'algorithms', 'feature engineering', 'ai']","['actuaries', 'environment', 'insurance industry', 'actuarial', 'team building', 'business applications', 'hiring', 'insurance']"
136,170,Process Data Scientist,"reference r2601779 position title process data scientist vaccines department data science, manufacturing technology location sanofi pasteur limited, toronto sanofi pasteur the world s leading vaccine company sanofi pasteur, the vaccines division of sanofi, is the largest company in the world devoted entirely to human vaccines. our driving goal is to protect people from infectious diseases by creating safe and effective vaccines. our company distributes more than 1 billion doses of vaccine each year, making it possible to vaccinate more than 500 million people across the globe. sanofi pasteur offers the broadest range of vaccines in the world, providing protection against 20 bacterial and viral diseases. sanofi is dedicated to supporting people through their health challenges. we are a global biopharmaceutical company focused on human health. we prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. we stand by the few who suffer from rare diseases and the millions with long term chronic conditions. with more than 100,000 people in 100 countries, sanofi is transforming scientific innovation into healthcare solutions around the globe. mission the data science team operates with a customer focused mindset to apply data analytics capabilities to deliver tangible benefits. the team actively works on improving data infrastructure and analytics capabilities to enable process monitoring, improve process understating and enhance decision making. process data scientistwill lead the way to support applied analytics and tech transfer activities for new vaccine manufacturing processes. this individual will play a key role during tech transfer operations to extract value out of analogous manufacturing processes by analyzing process data and working in partnership with subject matter experts to have a deep understanding of the production processes. the right candidate will identify and employ data engineering, data visualization and advanced analytics capabilities, including statistics and machine learning techniques to provide the right data science solutions to the business. key responsibilities take initiatives and drive for results with minimum supervision high level of maturity to work with different facets of the business including quality, manufacturing operations, automation, project management and supply chain. partner with stakeholders from multiple sites and departments to identify opportunities for applying machine learning and process modelling techniques to solve complex business challenges such as maximizing yield, write off avoidance, reducing process variability and predictable supply. extremely comfortable in storytelling in relation to data and processes, i.e., proven ability to explain manufacturing process through a data analytics mindset. exploit opportunities to leverage data from other manufacturing sites in the network to develop applied data analytics solutions such as real time process monitoring, data visualization and process modelling solutions. partner with data infrastructure team to apply re usable and efficient data engineering solutions when applying process analytics. promote a strong quality mindset with a focus on data integrity, validation and data governance. key requirements msc. or phd in process or industrial engineering with data science or process modelling background or a similar technical field. must have a minimum 3 years or 5 years of relevant process modelling or process diagnostics experience in manufacturing or industrial settings. strong experience in delivering insights through mathematical modelling and data visualization. proficient in using classification, clustering, dimensionality reduction, ensemble methods, neural networks and deep learning methods. experience using tools such as python, sql, r, knime, simca, jmp, r shiny and qliksense. experience with implementing etl processes for aggregating and contextualizing data. strong knowledge in working with data historian systems, including pi asset framework pi event frames infrastructure, manufacturing execution system and iot solutions. experience with developing business requirements, and ability to influence and communicate with a diverse group of stakeholders from multiple levels of management. ability to deliver projects with complex requirements and a strong customer focus. ability to succeed in a team oriented environment under very dynamic and fast paced working conditions. experience with big data ecosystem such as aws or microsoft azure is a plus. travel the candidate should be willing and able to travel to the usa as needed. applications received after the official close date will be reviewed on an individual basis. sanofi is an equal opportunity employer committed to diversity and inclusion. our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. we welcome and encourage applications from all qualified applicants. accommodations for persons with disabilities required during the recruitment process are available upon request. thank you in advance for your interest. only those candidates selected for interviews will be contacted. follow sanofi on twitter sanoficanada and on linkedin https or or or company or sanofi sanofi, empowering life gd sp li sp at sanofi diversity and inclusion is foundational to how we operate and embedded in our core values. we recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. we respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.","['https', 'data infrastructure', 'data visualization', 'data integrity', 'dimensionality reduction', 'big data', 'microsoft azure', 'data analytics', 'python', 'sql', 'statistics', 'simca', 'data science', 'analytics', 'data', 'aws', 'data engineering', 'jmp', 'machine learning', 'iot', 'process', 'knime', 'automation', 'deep learning', 'neural networks', 'etl', 'r']","['https', 'sql', 'python', 'simca', 'pasteur', 'iot', 'jmp', 'big data', 'aws', 'knime', 'microsoft azure', 'r']","['deep learning', 'data analytics', 'machine learning', 'statistics', 'data analytics monitoring', 'dimensionality', 'data infrastructure', 'data visualization', 'data science', 'process analytics', 'data integrity', 'analytics monitoring', 'analytics', 'data', 'neural networks', 'data engineering', 'automation', 'etl']","['production processes', 'subject matter experts', 'exploit', 'validation', 'industrial engineering', 'environment', 'manufacturing processes', 'healthcare', 'manufacturing operations', 'project management', 'governance', 'linkedin', 'manufacturing']"
137,171,Senior Data Scientist,"what is the opportunity as a senior data scientist, you will develop, design, and implement organization wide cutting edge aiops solutions at rbc technology infrastructure. leveraging leading edge technologies and various data sets, you will build machine learning based products to facilitate informed decision making and business process optimization in order to minimize outages and reduce downtime of rbc services which save considerable amount of costs and also improve user experience. what will you do work on challenging and research based initiatives using advanced machine learning methods focusing on tangible outcomes collaborate proactively with various business and operation units to identify business opportunities and designing innovative solutions to optimize processes and promote informed decision making prepare and integrate large and various types of data implement machine learning models, data mining methods, and statistical analysis leverage visualization tools or packages to create powerful representations of results produce data driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives collaborate with the development team to deploy production scale solutions quickly learn new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises what do you need to succeed must have phd. or masters in computer science, statistics, or relevant fields. expert in python programming to write production ready codes. strong data profiling, cleaning, mining and technical documentation skills 2 years of experience in developing machine learning models for real business problems 2 years of experience with nlp and text analytics methods and packages experience with big data technologies parallel processing techniques and apache spark, nosql or sql databases proficient in linux environment, shell scripting, and git nice to have strong knowledge and experience of different deep neural networks architectures and transfer learning experience with mlops to build end to end pipeline and deploying models in production familiar with container type environment docker, openshift experience in graph analytics and time series analysis what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. we care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual. a comprehensive total rewards program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable leaders who support your development through coaching and managing opportunities ability to make a difference and lasting impact work in a dynamic, collaborative, progressive, and high performing team a world class training program in financial services flexible work or life balance options opportunities to do challenging work opportunities to take on progressively greater accountabilities opportunities to building close relationships with clients access to a variety of job opportunities across business and geographies learn more about rbc tech jobs join our talent community stay in the know about great career opportunities at rbc. sign up and get customized info on our latest jobs, career tips and recruitment events that matter to you. expand your limits and create a new future together at rbc. find out how we use our passion and drive to enhance the well being of our clients and communities at rbc.com or careers. job summary city toronto address 330 front street w work hours or week 37.5 work environment office employment type permanent career level experienced hire or professional pay type salary variable bonus required travel 0 25 exempt or non exempt n or a people manager no application deadline 05 or 14 or 2021 platform technology and operations req id 349413 ad code","['visualization', 'databases', 'linux', 'openshift', 'user experience', 'parallel processing', 'data profiling', 'big data', 'statistical analysis', 'sql', 'python', 'shell', 'statistics', 'time series analysis', 'scripting', 'analytics', 'programming', 'nosql', 'data mining', 'machine learning', 'apache spark', 'graph', 'rb', 'neural networks', 'nlp', 'git', 'computer science', 'optimization', 'technical documentation']","['sql', 'python', 'databases', 'linux', 'openshift', 'apache spark', 'shell script', 'nlp', 'git', 'programming', 'big data', 'rb', 'nosql']","['data mining', 'machine learning', 'visualization', 'statistics', 'time series analysis', 'user experience', 'neural networks', 'parallel processing', 'data profiling', 'computer science', 'analytics', 'mlops', 'optimization', 'technical documentation', 'graph', 'statistical analysis', 'text']","['financial servicesc', 'environment', 'events', 'design', 'outages', 'business process', 'compensation']"
138,172,Data Scientist II,"about us the kraft heinz company is one of the largest food and beverage companies in the world, with eight 1 billion brands and global sales of approximately 25 billion. we re a globally trusted producer of high quality, great tasting, and nutritious foods for over 150 years. our brands are truly global, with products produced and marketed in over 40 countries. these beloved products include condiments and sauces, cheese and dairy, meals, meats, refreshment beverages, coffee, infant and nutrition products, and numerous other grocery products in a portfolio of more than 200 legacy and emerging brands. we spark joy around mealtime with our iconic brands, including heinz, kraft, bull s eye, hp, lea and perrins, quero, abc, master, banquete, plasmon, orlando, benedicta, honig, pudliszki, wattie s among others. no matter the brand, we re united under one vision to sustainably grow by delighting more consumers globally . bringing this vision to life is our team of 39,000 food lovers, creative thinkers, and high performers worldwide. together, we help provide meals to those in need through our global partnership with rise against hunger. we also stand committed to responsible, sustainable practices that extend to every facet of our business, our consumers, and our communities. every day, we re transforming the food industry with bold thinking and unprecedented results. if you share our passion and are ready to create the future, build a legacy, and lead as a global citizen there s only one thing to do join our table and let s make life delicious our culture of ownership, meritocracy collaboration we re not afraid to think differently. embrace new ideas. dream big. we empower our people at every level from entry level intern to senior leader to own their work. we share a responsibility to think like owners to be mindful of the collective and sustained success of kraft heinz which we apply to every situation, every day. as part of kraft heinz, you re supported to grow and achieve. you re expected to bring your authentic self to work every day, to lead with humility, and drive outstanding performance at every level and you ll be rewarded. you re given opportunities to leave a mark and build a legacy. but you won t do it alone. you re supported by passionate teammates along the way, and our collective, collaborative spirit fuels our incredible progress. job description the data scientist ii role is a key driver in developing and maintaining advanced analytics tools to help business make quicker and better decisions to maximize the business competitive advantage. this role will help maximize the roi on our large annual investments in data and technology by discovering hidden insights from data, developing models dashboards and improving faster decision making that will drive business results. we are looking for someone with a strong background in statistics or mathematics who can translate business problems to mathematical terms to drive business value. the data scientist is responsible for developing models, ensuring the models are up to date to meet changing business requirements and unlock new business opportunities. this role works closely with the principal data scientist to develop new and maintain existing analytics solutions. why should you join the team data science team is a new team and is instrumental in guiding advanced analytics journey at kraft heinz canada. the team works as a startup and as a part of this highly energetic team you will not only work on developing models but also get the unique opportunity to gain hands on experience to define data science framework at kraft heinz. overall, if you are passionate about data and would like to apply theoretical concepts to solve practical business problems, develop cutting edge algorithms and intelligent tools to show how data science can bring business value, all while working with a friendly team, this is going to be your dream team to enrich your data science career. the sky is not the limit in terms of enhancing your knowledge and working on a variety of projects with the data science team at kraft heinz canada responsibilities model and tool development develop, manage, maintain optimize machine learning models by working closely with data engineering, ml engineer and business stakeholders to deliver end to end solution. use of problem solving skills, advanced analytics methodologies to find hidden data insights to unlock new business opportunities assist data science team with development of complex tools, models or database builds as well as analytic requests visualization own data science visualization framework, tableau environment for assigned function adopt visualization best practices to develop dashboards team player leadership in the cross functional advanced analytics reporting and kpi development working with ml engineer to ensure integrity governance, rituals and routines of new data sources in snowflake database azure blob storage project management provide inputs or stories and assist in prioritization of data engineering sprints complete user acceptance testing on new releases qualifications must have master s degree in engineering, operations research, statistics, mathematics, or econometrics experience in programming languages sql, python or r fundamental knowledge on cloud computing technologies 3 5 years experience with development of large scale supervised, unsupervised ml models and forecasting models experience working with database systems and analytical tools, strong design sense for data visualization strong communication problem solving skills and a strong team player knowledge on version control system such as git knowledge on agile methodologies good to have knowledge on open source python visualization such as bokeh or streamlit etc. experience in working with azure ml and azure devops experience in dashboard development in tableau experience in development of heuristic models experience in working with agile teams and using tools such as jira kraft heinz is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. all qualified candidates will be considered for our opportunities, regardless of race, religion, faith, creed, age, ethnicity, marital status, gender identity, sexual orientation, or disability. job seekers with disabilities who require accommodation during the recruitment process or would like more details about accessibility should contact . ind123 li location toronto, on location don mills","['visualization', 'tableau', 'dashboards', 'data visualization', 'sql', 'python', 'statistics', 'reporting', 'database systems', 'data science', 'analytics', 'sprints', 'data engineering', 'cloud computing', 'econometrics', 'machine learning', 'acceptance testing', 'algorithms', 'forecasting', 'dashboard', 'agile methodologies', 'azure', 'jira', 'programming languages', 'devops', 'git', 'mathematics', 'version control', 'snowflake', 'r']","['dashboard', 'sql', 'python', 'azure', 'tableau', 'programming languages', 'jira', 'git', 'snowflake', 'r']","['visualization', 'tool development', 'dashboards', 'data visualization', 'design sense', 'statistics', 'reporting', 'database systems', 'data science', 'analytics', 'sprints', 'cloud computing', 'data engineering', 'econometrics', 'machine learning', 'acceptance testing', 'algorithms', 'forecasting', 'user', 'agile methodologies', 'devops', 'mathematics', 'version control']","['environment', 'business value', 'sales', 'project management', 'food industry', 'governance', 'operations', 'investments', 'new business opportunities']"
139,173,Senior Data Scientist,"hiring in the us and canada only at urbint, our mission is to make communities more resilient. we do this by pairing external data with artificial intelligence to identify areas of high risk and prevent catastrophic loss for utilities and infrastructure operators across the country. we are a team of close knit engineers, entrepreneurs, and data geeks who obsess over problem solving, new technologies, and making a positive impact in our communities. we encourage people from underrepresented groups to apply. job summary at urbint, the machine learning team does not work on making consumers spend more or on maximizing clicks. that is all fine we work on reducing carbon emissions, reducing infrastructure risk and avoiding fatalities. we find meaning and excitement solving these problems, and we hope you do, too. we are looking for a senior data scientist to join our high visibility, high impact machine learning team to help with this mission. the ml team collaborates with a diverse, broader mission team to deliver value for our customers. members of the machine learning team have the option to major or minor in areas from a large data science specialization spectrum technical product management, people management, data story telling, applied ml, ml research, automl and mlops . this is a great role for someone who enjoys variety and is also looking to expand their skill set in a structured fashion. what you ll do you will major in applied ml and minor in automl, focused on delivering value to customers. you will translate business problems into data science problems, and develop solution frameworks with focus on speed to value. you will own key portions of okrs that help maximize team productivity. you will have strong communication and organizational skills. you will convey complex ideas trade off decisions to business stakeholders. you will provide guidance to your team on task level prioritization and cross team coordination. you may support other teams during ideation with customers. overall, you will be responsible for delivering ml products that deliver measurable business value for customers. who you are 3 years of experience in data science or machine learning roles. experience solving concrete, real world machine learning problems. well versed in python or r . comfortable writing production ready code. demonstrated problem solving skills and experience maximizing team productivity. experience leveraging automl technologies. up to date with what s under the hood of some of the advanced ml tools available. nice to have experience with startup or agile environments. experience building automl tools. track record of creating excellent slack emojis and memes. benefits mission driven some companies use ai to serve better digital ads and trade stocks we seek to make our communities safer and more resilient 100 distributed work from anywhere distributed work monthly stipend competitive compensation package best in class medical coverage 100 benefits and premiums paid health perks wellness reimbursement educational allowance up to 1000 or yr weekly lunch stipend we re an equal opportunity employer. all applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","['emojis', 'python', 'machine learning', 'ai', 'data science', 'automl', 'agile environments', 'product management', 'artificial intelligence', 'r']","['emojis', 'python', 'auto', 'automl', 'r']","['machine learning', 'data science', 'mlops', 'product management', 'artificial intelligence', 'ai']","['utilities', 'carbon emissions', 'compensation', 'fashion', 'business value', 'people management', 'hiring']"
140,174,Scientifique de données / Data Scientist,"qui sommes nous buspatrouille est une entreprise sp cialis e dans la technologie de s curit . titre de principal fournisseur international de dispositifs visant faire respecter le bras d arr t des autobus scolaires, notre mission principale est d am liorer la vie des l ves o qu ils se trouvent. la technologie de buspatrouille a t d ploy e sur un plus grand nombre d autobus et a t utilis e pour d livrer un plus grand nombre de constats d infraction relatifs au bras d arr t des autobus scolaires que toute autre technologie des autres entreprises existantes l chelle mondiale. notre technologie exclusive transforme les autobus scolaires en autobus intelligents quip s de cam ras vid o, de gps, de t l m trie, de traitement de donn es et d archivage. de cette mani re, nous permettons aux comt s et aux districts scolaires d am liorer la s curit des enfants. buspatrouille est en pleine croissance. nous sommes donc la recherche d un ou d une scientifique de donn es pour int grer notre service de veille strat gique . si vous aimez travailler dans un environnement dynamique avec des coll gues talentueux, ce poste est pour vous. responsabilit s le poste de scientifique de donn es a une grande influence et n cessite de travailler en troite collaboration avec les clients ainsi qu avec les quipes des ventes et de l exploitation afin d aider prendre des d cisions fond es sur les donn es de mani re stimuler une croissance efficace de buspatrouille. si vous aimez la communication narrative et le fait d influencer les d cisions op rationnelles au moyen des chiffres, nous voulons faire votre connaissance il s agit d un poste de premier plan qui vous permettra d interagir r guli rement avec les chefs d entreprise, de d finir la feuille de route de l quipe et de recenser les besoins pour fournir des solutions innovantes. la personne id ale est autonome, tr s analytique, curieuse et a de la facilit plonger dans de grands ensembles de donn es afin d en tirer des enseignements. notre environnement volue rapidement et requiert une personne enthousiaste, flexible, soucieuse du d tail, analytique et l aise pour travailler avec plusieurs quipes et des priorit s concurrentes. mettre en pratique d excellentes comp tences en mati re d analyse et de r solution de probl mes pour prendre des d cisions d affaires dans un environnement dynamique afin de fournir des avantages aux clients et des analyses de performance. travailler de mani re ind pendante et en collaboration avec d autres scientifiques, des ing nieurs, des concepteurs, des d veloppeurs en veille strat gique et des gestionnaires de produits sur des projets complexes qui g n rent de la valeur pour buspatrouille. poss der d excellentes aptitudes la communication et tre capable de structurer un sc nario convaincant pour pr senter une narration l aide de donn es exploitables. tre capable de conceptualiser des probl matiques ou des occasions d affaires, de formuler des hypoth ses et des objectifs, de d finir des indicateurs cl s de performance et de faire des recommandations ad quates. construire des mod les prescriptifs et pr dictifs de calibre international pour r soudre des probl mes commerciaux dans un environnement qui volue rapidement. tirer parti des donn es internes et externes pour synth tiser des id es int ressantes qui expliquent les tendances sous jacentes de l cosyst me de l application automatis e des lois. rep rer les possibilit s d automatisation pour favoriser l volutivit et am liorer tant l efficacit que la productivit de l quipe largie. poss der de solides comp tences en communication crite et verbale, avec la capacit de synth tiser efficacement des id es pour les pr senter la haute direction ou des clients. en temps voulu, embaucher, former, encadrer et diriger une solide quipe d analyse de donn es pour buspatrouille. exigences un dipl me d tudes sup rieures en conomie, en finance, en statistique ou dans un autre domaine quantitatif. plus de trois ans d exp rience pertinente. une exp rience av r e de la manipulation d un large ventail de sources et de syst mes de donn es pour fournir des analyses et des visualisations qui ont des r percussions sur l activit . une solide compr hension th orique et une expertise concr te des bases de donn es, des structures de donn es, des m gadonn es, de l apprentissage automatique et des m thodes . une expertise dans les approches analytiques de pointe et les plateformes . une grande ma trise de sql, r ou python. des comp tences analytiques exceptionnelles et un sens aigu des affaires. d excellentes comp tences en communication, avec la capacit d influencer les d cideurs et d obtenir un consensus au sein des quipes. une curiosit intellectuelle, une grande autonomie et un esprit d quipe. r mun ration et avantages un salaire concurrentiel. des avantages sociaux complets, notamment une assurance soins m dicaux, soins dentaires et soins de la vue. un poste de direction au sein d une entreprise qui se d veloppe rapidement et qui est investie d une mission. l occasion de travailler avec une quipe tr s performante. l occasion de contribuer la cr ation d une entreprise vou e la s curit des enfants. nous sommes la recherche de membres essentiels de l quipe de buspatrouille qui nous aideront dans notre qu te pour accro tre la s curit des enfants. ce poste joue un r le important dans notre entreprise et constitue une formidable opportunit pour les personnes qui seront retenues. nous offrons un milieu de travail inclusif, diversifi , enthousiaste, int gre et profond ment engag . venez nous aider assurer la s curit des enfants. who we are at buspatrol, our mission is to create a culture of responsibility and awareness on the road. we are devoted to making the journey to and from school safer. we develop partnerships, deploy safety tech, and manage the entire program. we have equipped thousands of buses across north america with our innovative technology buspatrol america cares about student safety. we educate motorists every day by helping to enforce the law and work with school officials to improve safety. responsibilities the data scientist is a high impact role that will work closely with our customer, sales, and operations teams to help drive data driven decisions that accelerate buspatrol s efficient growth. if storytelling and impacting operational decisions through numbers is exciting to you, we want to hear from you this is a high visibility role that will drive predictive analytic insights and best practices as buspatrol expands its global footprint. the ideal candidate is a self starter, highly analytical, curious, and comfortable diving deep into large data sets to unearth insights. our environment is fast paced, and requires someone who is enthusiastic, flexible, detail oriented, analytical, and comfortable working with multiple teams and competing priorities. apply excellent analytical and problem solving skills to drive business decisions in a dynamic environment to deliver customer benefit and performance analytics work both independently and collaboratively with other scientists, engineers, designers, bi developers, and product managers on complex projects that deliver value to buspatrol excellent communication skills and ability to structure a compelling storyline to present a narrative using actionable data driven insights ability to conceptualize business issues or opportunities, formulate hypotheses and goals, define kpis and make appropriate recommendations build world class prescriptive and predictive models to solve business problems in a fast moving environment leverage internal and external data to synthesize nuggets of insights that explain underlying trends in the automated enforcement ecosystem identify and deliver automation opportunities to drive scalability, improve efficiency and productivity of the broader team strong written and verbal communication skills with ability to effectively synthesize insights to executives and or or customers knowledge and skill requirements strong theoretical understanding and applied expertise with databases, data structures, big data, machine learning, and methods expertise with industry leading analytics approaches and platforms expert proficiency in sql, r, and or or python exceptional analytical skills and strong business acumen outstanding communication skills with the ability to influence decision makers, build consensus with teams, and explain complex analytical concepts to people from other fields intellectually curious, self starter, team player education or experience s. in a quantitative field, such as economics, applied statistics, computer science, or mathematics 3 years experience applying data science methods to business problems in the commercial world compensation and benefits competitive salary comprehensive benefits including medical, dental and vision insurance an opportunity to work with a high performing team and travel an opportunity to help build a company dedicated to children s safety we re looking for a valued partner to add to our team. this is an important role for us, and a great opportunity for the right candidate. our environment is inclusive, diverse, ignited, built on integrity, and deeply committed. come and help us keep our children safe.","['sql', 'python', 'databases', 'machine learning', 'analytical skills', 'statistics', 'data structures', 'bi', 'economics', 'data science', 'scalability', 'computer science', 'analytics', 'mathematics', 'big data', 'automation', 'r']","['sql', 'python', 'databases', 'bi', 'big data', 'r']","['analytical skills', 'machine learning', 'statistics', 'data structures', 'economics', 'performance', 'data science', 'scalability', 'computer science', 'analytics', 'mathematics', 'automation']","['environment', 'education', 'sales', 'finance', 'compensation', 'law', 'insurance']"
141,175,Data Scientist/Engineer,"pitstop is looking for a data scientist or developer with exceptional ability to interpret and understand data and a passion for algorithms that provide impactful and reliable results. the data scientist or developer will develop, deploy and validate predictive algorithms which analyze a continuous stream of telematics data gathered by automotive sensor nets, as well as other related data. we seek creative candidates with a background in engineering, physics, mathematics and experience with contemporary machine learning techniques. the ideal candidate is someone who is focused on creating business value through good design and building the next generation of our predictive vehicle insights. he or she will have strong coding and software architecture skills and a self driven attitude to fail fast and succeed faster. responsibilities collaborate with cross functional teams to define, design, and ship new features in collaboration with others, design, build and validate predictive algorithms for vehicle prognostics perform exploratory analyses and develop procedures for feature extraction in preparation for algorithm analyses participate in software integration work to implement algorithms in production. work on bug fixing and improving architecture performance write documentation and present the results of work to others on the team requirements undergraduate or master s degree in engineering, physics, computer science or equivalent good knowledge of statistics, experimental design, and probability 3 years of experience in python, r or similar scripting language 1 years experience shipping high quality software to enterprise customers experience with sql understanding and experience with machine learning techniques such as regression, naive bayes, random forests, perceptrons, svm, deep learning devops experience nice to have s previous startup experience knowledge of automotive data, automotive physics or experience in the industry experience with version control systems knowledge of other programming languages including node js, c experience with big data frameworks such as spark, hadoop. pitstop is an equal opportunity employer we are actively seeking to create a diverse work environment because we believe differences make us stronger, and that our diversity is something to celebrate.","['telematics', 'c', 'documentation', 'big data', 'automotive', 'sql', 'python', 'statistics', 'software', 'physics', 'scripting', 'integration', 'software architecture', 'machine learning', 'probability', 'algorithms', 'deep learning', 'experimental', 'programming languages', 'devops', 'hadoop', 'computer science', 'mathematics', 'version control', 'r']","['sql', 'python', 'programming languages', 'hadoop', 'bayes', 'c', 'documentation', 'big data', 'r']","['automotive', 'software architecture', 'deep learning', 'telematics', 'machine learning', 'statistics', 'experimental', 'software', 'physics', 'scripting', 'devops', 'feature', 'version control', 'computer science', 'mathematics', 'integration', 'probability', 'algorithms']","['environment', 'business value', 'design', 'architecture']"
142,176,"Data Scientist, Fall 2021 Student Opportunities","we re now accepting applications for our 2nd round recruitment of data science roles. what is the opportunity who wouldn t want to be a part of a fantastic team of data scientists at rbc, our data science teams offer the opportunity to leverage rbc s data assets to develop innovative solutions in support of rbcs big data strategy. this position is an essential part to the bank as you develop next generation applications to meet our customers needs. by joining the rbc team as a data scientist, you will have the opportunity to analyze, design and implement data solutions to assist all business customers. what will you do utilize the latest technologies available, designing and building data solutions to meet business needs be an active contributor to not only your individual team, but to the rbc development community constantly seek out better ways to do things, new tools, new technologies, new processes work on transformational projects delivering new value work as part of an agile team responsible for end to end delivery of business needs deploy production scale solutions using the hadoop ecosystem, transforming statistical and machine learning models from single node architecture to parallel processing grid technology use business domain knowledge to independently lead the analytics process to identify valuable and innovative insights promote analytics across the enterprise to enable rbc to become a data driven organization what do you need to succeed must have programming skills in one or more of the following languages python or r experience utilizing sql scripts or querying proficient in building statistical and algorithmic models with complex and large datasets, including but not limited to supervised statistical learning, clustering, natural language processing, recommendation systems, times series analysis, experimental design , data visualization, deep learning ability to data extract, transform, and load processes with a variety of data types ability to perform complex data analysis on large volumes of data and present findings to stakeholders nice to have experience with big data technologies, primarily in machine learning and statistics function exposure to apache spark, hadoop and public cloud technologies, data serialization experience with big data processing tools like spark and hive, github functionality and workflow experience or exposure experience with messaging working on agile projects what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients succeed. we care about each other, reaching our potential, making a difference to our communities and achieving success that is mutual. visit people.rbc.com continued career advancement opportunities exposure to strong mentorship and leadership examples a world class training program in financial services opportunities to be a valuable member of a close knit, collaborative team that encourages networking a comprehensive total rewards program including bonuses and flexible benefits competitive compensation we encourage you to apply as soon as possible as we accept applications on a rolling basis, but please note that the formal application deadline is may 31, 2021. should you be selected to progress, someone from our team will reach out directly to provide instructions on next steps. otherwise, feel free to check for progress updates by logging in to your rbc profile. if the status has not changed, it denotes the fact that your application is still under review. while there is no one date when our employees will return, we can confirm that the majority of fall work integrated learning co op positions will start working remotely, however may transition to working at an rbc office as essential service restrictions are lifted. tad2021 learn more about rbc tech jobs","['data visualization', 'parallel processing', 'big data', 'hive', 'github', 'sql', 'python', 'statistics', 'data processing', 'data science', 'analytics', 'programming', 'logging', 'times analysis', 'machine learning', 'apache spark', 'statistical', 'data analysis', 'rbc', 'deep learning', 'language processing', 'experimental', 'hadoop', 'datasets', 'data solutions', 'public cloud', 'networking', 'r']","['sql', 'python', 'rb', 'rbcs', 'hadoop', 'apache spark', 'big', 'public cloud', 'programming', 'big data', 'logging', 'rbc', 'hive', 'r']","['deep learning', 'machine learning', 'language processing', 'experimental', 'statistics', 'data processing', 'datasets', 'data solutions', 'data science', 'parallel processing', 'data visualization', 'networking', 'analytics', 'statistical', 'natural', 'data analysis', 'github']","['design', 'business domain', 'financial services', 'functionality', 'rbc', 'compensation', 'architecture']"
143,177,Data & Applied Scientist 2,"are you passionate about building best image and video experience on the web and help billions of internet users find the most relevant and enjoyable image or video content on the web through recommendation and search do you want to work with a group of talented data and applied scientists and distributed system engineers to grow your experience or career in wide range of area including engineering skills, recommendation, computer vision, natural language processing, machine learning, deep learning, big data mining, and information retrieval etc our product depends on talents from diversified technical background. if so, this data scientist position on bing multimedia team may be a great fit for you bing multimedia team is looking for a talented machine learning scientist to help us build products and next generation of recommendation and ranking algorithms to make impact to power millions and millions of users. and it is a fun and fast paced team. responsibilities as data applied scientist, you will have wide range of responsibilities and opportunities to learn and make impact, which includes but not limited to analyze the problem through all data available to you including large scale crawled data and user engagement data etc. define problem and metrics to address various problems include relevance, authority, attractiveness, diversity, and freshness etc design and train ml system and model architecture collect data for training define ml engineer life cycle and drive project forwards through iterative release collaborate with other data applied scientist as well as distributed system engineer and program manager potentially mentor other engineers and proactively seeks mentorship from others qualifications required qualifications master or above degree in computer science, engineering, applied mathematics, or related fields 3 years recommendation, machine learning or computer vision or natural language processing experience and results in academy or industry. 3 years of experience with general purpose programming language good communication skills and ability to work in collaborative environment. good design and problem solving skills and an ability to innovate and solve challenging technical problems passion and self motivated embrace engineering excellence and delivering quality results at scale. preferred qualifications ph.d. in computer science, applied mathematics, related fields publications in major ml or ir or nlp or cv conferences. examples icml, nips, sigir, acl, emnlp, cvpr, kdd prior tech lead or dev lead microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['model', 'data mining', 'deep learning', 'machine learning', 'language processing', 'information retrieval', 'computer vision', 'nlp', 'computer science', 'programming', 'applied mathematics', 'algorithms']","['programming', 'big', 'nlp']","['model', 'deep learning', 'data mining', 'machine learning', 'language processing', 'information retrieval', 'computer vision', 'computer science', 'natural', 'applied mathematics', 'algorithms']","['user', 'environment', 'metrics', 'design', 'legal', 'recruiting', 'regulations', 'architecture']"
144,178,Data Scientist – Revenue management,"intelcom est un important fournisseur de plateforme de livraison au canada. pour soutenir sa transformation technologique et permettre la prise de d cision bas e sur les donn es, intelcom est actuellement la recherche d un expert en sciences des donn es gestion des revenus. dans le cadre de l implantation d une nouvelle plateforme de gestion des revenus, l expert en sciences des donn es est charg de construire des mod les de donn es, des simulations et de soutenir l utilisation de ceux ci par les utilisateurs. les r sultats obtenus serviront alimenter la strat gie de tarification et faire voluer l exp rience utilisateurs au fil du temps. vos responsabilit s analyser et visualiser les op rations commerciales et les donn es du march . comprendre le probl me de l entreprise, identifier les principaux d fis, formuler le probl me d apprentissage automatique et fournir des solutions. construire des mod les de donn es et des simulations et incorporer ces mod les dans la plateforme de gestion des revenus collaborer largement avec les parties prenantes, la direction du programme et les membres de l quipe de d veloppement de logiciels afin de s assurer que les solutions r pondent aux besoins de l entreprise. comp tences professionnelles trois ans d exp rience dans un poste similaire en gestion des revenus id alement dans le domaine de la logistique, du transport ou de la distribution deux ans ou plus d exp rience en tant qu analyste de donn es dans un contexte commercial ou scientifique dipl me en informatique, math matiques ou physique comp tences avanc es en programmation python conception orient e objet exp rience du travail avec de grands ensembles de donn es de mani re performante optimisation du code, op rations vectorielles, ex cution parall le. tests unitaires analyse de donn es l aide de pandas et numpy visualisation de donn es l aide de matplotlib et seaborn histogrammes, diagrammes de dispersion, cartes thermiques. analyse et visualisation de donn es de g olocalisation. bilinguisme situ griffintown , accessible par les transports en commun , notre culture encourage la cr ativit et l innovation, ainsi que le partage des connaissances et l entraide. vous rejoindrez le train au bon moment pour nos prochaines grandes tapes. votre travail aura un impact r el et significatif sur le succ s de l entreprise.","['python', 'numpy', 'pandas', 'simulations', 'r']","['pandas', 'python', 'nuy']","['simulations', 'tests']",[]
145,179,Data Scientist/Time Series,"reporting directly to the director of data science, this role is pivotal in implementing advanced time series solutions to deliver high quality results to clients. you will be interacting with multi function teams, including data integration, model development and other consulting functions to implement best practice and thought leadership. this role also works very closely with client project sponsors to ensure client satisfaction and business requirement fulfillment. duties and responsibilities implement currently available time series forecasting models develop customized forecasting algorithms required by specifications of each project prototype, simulate and benchmark accuracy of algorithms develops production ready codes in r works with main stakeholders including but not limited to account executives, management, project managers and consulting teams performs various other duties as delegated or assigned. required knowledge, skills, and experience the successful incumbent will have graduate degree in a statistics, math computer science or engineering program proficient in time series analysis and forecasting fundamental knowledge of supervised and unsupervised machine learning experience with data preprocessing, anomaly or outlier detection advanced programming skills in r language is mandatory knowledge of pharmaceutical industry is an asset capability to adapt in fast changing environment and eager to learn the ability to travel and work outside regular business hours as required proven, motivated self starter with the ability to lead by example and approach and solve business problems experience working in cross functional teams with the agility to learn new software applications and technologies demonstrated time management, problem solving and decision making competencies ability to work autonomously and in teams to effectively prioritize multiple projects and associated deliverables proven excellent communication, including presentation, hands on analytical with business savviness and customer relationship abilities proven ability to comprehend, analyze and research problems of a complex nature, make decisions and or or present recommendations preference for fast paced, rapid start up culture demonstrating the values of results, teamwork, energy, agility, respect, and can do environment","['model', 'machine learning', 'statistics', 'time series analysis', 'software', 'reporting', 'data science', 'project managers', 'computer science', 'data', 'specifications', 'integration', 'programming', 'algorithms', 'forecasting', 'r']","['programming', 'r']","['model', 'machine learning', 'statistics', 'time series analysis', 'software', 'reporting', 'data science', 'project managers', 'computer science', 'data', 'specifications', 'integration', 'algorithms', 'forecasting']","['environment', 'consulting']"
146,180,Senior Data Scientist,"funded by nec x s corporate accelerator program in silicon valley, we are spinning out an ecommerce insights start up in toronto. using award winning nec research technology in princeton, we are building our team in toronto to take our journey to the next level. we are looking for an experienced data science or ai researcher with a passion for text and aspect based opinion mining. you have several years of experience working with various aspects of text mining, data mining and opinion mining. you ll be joining as our data scientist and as such, you will be playing a key role in building our product and executing on our development roadmap. join us in changing the world of ecommerce and insights through ai. what s in it for you great work life balance join as an early team member, work directly with founders work on large scale data problems using ml or ai and text analysis what you ll work on the data scientist will work with a team of technologists to add features, improve performance, test and get the solution ready for a commercial launch. who you are m.s. or phd in computer science or related field. broad knowledge in machine learning and deep learning algorithms. hands on experience developing text analytics, sentiment analysis, opinion mining, nlp and aspect based opining mining. proficient in python. extensive experience using deep learning libraries such as pytorch and data analytics tools such as pandas and sql. detail oriented please include the square root of 225 on your application somewhere. requirements include excellent spoken and written english communication skills. experience with mining of reviews, especially in the ecommerce domain is a big asset. you have a passion for presenting data in creative and visual ways. the role use python and the vast array of ai or ml libraries to analyze data and build statistical models to solve specific business problems. improve upon existing methodologies by identifying new data sources, testing model enhancements, and fine tuning model parameters. experience leading large scale data projects and pushing production quality code, including deploying and assessing efficacy of a wide array of machine learning models in production environments. experienced in handling large data sets and databases using sql in a business environment. most importantly continually advance our technology in the areas of text analytics, sentiment analysis, opinion mining, nlp and aspect based opining mining. what we offer competitive compensation flexible working hours job type full time salary 118,809.00 144,170.00 per year schedule monday to friday experience nlp, sentiment text analytics 5 years python 5 years aspect based opinion mining 1 year machine learning 5 years work remotely yes","['databases', 'sentiment', 'pytorch', 'data analytics', 'python', 'sql', 'data science', 'pandas', 'analytics', 'sentiment analysis', 'text mining', 'data mining', 'machine learning', 'testing', 'algorithms', 'deep learning', 'nlp', 'computer science', 'ai']","['sql', 'python', 'databases', 'pytorch', 'nlp', 'pandas']","['data mining', 'deep learning', 'text analysis', 'machine learning', 'data analytics', 'testing', 'data science', 'computer science', 'analytics', 'fine tuning', 'sentiment analysis', 'text mining', 'algorithms', 'text', 'ai']","['environment', 'compensation']"
147,181,Machine Learning Engineer/Data Scientist,"about the role we are looking for a machine learning engineer who will be responsible for the development of algorithms that will be used as the basis for our mathematical models to automate trading platforms for sports betting markets. we are looking for a data scientist who will be responsible for developing unique approaches to complex modeling and inference problems which combines market and trading knowledge with math approach to recognize patterns and trends in betting markets. our ideal candidate should have degree or diploma in computer science or software engineering or statistics or equivalent 3 years of relevant experience with r or python 2 years of relevant experience as software developer, preferably using microsoft .net framework strong background in statistics experience with machine learning algorithms and probabilistic models experience using cloud computing platforms such as ec2 experience with modern r packages and technologies such as dplyr, tidyr, data.table, shinyr domain experience in on line gaming industry, financial markets or other 2 sided markets is a plus experience with stan, neural networks or deep learning on large problems, hadoop, mapreduce or high performance computing is a plus experience in sql and sql server is also a plus we offer an environment passionate about growth and learning competitive salary with bonus fitness subsidy program workplace that is conveniently located along the yonge or sheppard line what we are looking for this is a key role within the team and would suit someone who is passionate about working with data or data science. we are looking for someone with strong background in statistics, modelling and algorithms and who has the ability to convey complex information through data visualization. a thorough understanding and passion for sports and sports betting markets is ideal. experience with cloud computing as well as python is a plus. the above is intended to describe the general nature and level of work being performed. they are not intended to be an exhaustive list of all responsibilities, duties and skills required. crescendo technology thanks all candidates applying but only those selected for an interview will be contacted. selected candidates may be asked to complete an on line technical assessment. crescendo technology is an equal opportunity employer which values diversity in the workplace and we encourage candidates to apply directly and provide a copy of an updated resume. should you require an accommodation for the recruitment or interview process, please do not hesitate to reach out to us. to apply please send your resume with cover letter preferred to job features job category development","['computing', 'data visualization', 'gaming', 'sql', 'python', 'statistics', 'software', 'data science', 'cloud computing', 'cloud', 'machine learning', 'algorithms', 'deep learning', 'hadoop', 'neural networks', 'technical', 'computer science', 'modeling', 'r']","['sql', 'python', 'high', 'hadoop', 'r']","['deep learning', 'computing', 'machine learning', 'statistics', 'software', 'neural networks', 'performance', 'data science', 'data visualization', 'technical', 'computer science', 'modeling', 'cloud computing', 'algorithms', 'gaming']","['assessment', 'environment', 'trading', 'financial markets']"
148,182,Senior Data Engineer,"introduction have you heard about the ibm garage it s a cross functional team that delivers a unique client co creation experience to accelerate client transformation. we use enterprise design thinking, our industry leading ibm garage methodology and ibm s multidisciplinary experts in full speed from the start. we design, develop, test, and deliver solutions. startup speed. enterprise scale. we apply user centric approaches to ensure all features add value for the user and achieve desired client impact. your role and responsibilities we are looking for a big data engineer to join our entrepreneurial team as the subject matter expert on building big data solutions with great scalability. led by a solution architect, you will provide expertise and leadership to help design ibm data science and ai solutions that will help our clients drive technology benefits and business outcomes across industries. you will work with cutting edge technologies such as watson, as well as open source approaches with a passionate team of people who are driving the innovation and digital transformation to cross industry enterprise clients with the adoption of ibm data science and ai. an ideal candidate will also be familiar with design thinking, devops, big data engineering skills on architecture and solutions with best practices. key responsibilities work with stakeholders including the executive, product, data and design teams to assist with data related technical requirements and support their data infrastructure needs. provide the ability to work within agile development methodology and collaborate effectively with multi disciplinary teams build modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements. understand data architecture, build large scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow. have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms. working knowledge of message queuing, stream processing, and highly scalable big data data stores. have expertise in data persistence solutions, experience with the latest database technologies, and experience with building complex sql queries using various databases such as mongodb or db2 experience in software engineering with object oriented design, coding and testing patterns on large scale data infrastructures use devops best practices such as continuous integration, continuous delivery in the production implementation. ibmreferred northamerica required technical and professional expertise develop code using python, scala, r languages experience with relational sql and nosql databases, including postgres and cassandra. experience with data pipeline and workflow management tools 5 years design implementation experience with distributed applications 5 years of working experience in database architectures and data pipeline development demonstrated knowledge of software development tools and methodologies computer science with software engineering and math background desired demonstrated ability to adapt to new technologies and learn quickly preferred technical and professional expertise experience with big data tools hadoop, spark, kafka, etc. familiar with big data solutions with experience on hadoop based technologies such as mapreduce, hive mongodb or cassandra. 5 years design implementation experience with distributed applications 5 years of working experience in database architectures and data pipeline development experience with stream processing systems storm, spark streaming, etc. experience with object oriented or object function scripting languages python, java, c , scala, etc. knowledge of cloud technologies such as kubernetes, cloud foundry, paas, and iaas about business unit ibm has a global presence, operating in more than 175 countries with a broad based geographic distribution of revenue. the company s global markets organization is a strategic sales business unit that manages ibm s global footprint, working closely with dedicated country based operating units to serve clients locally. these country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients growth and innovation. by complementing local expertise with global experience and digital capabilities, ibm builds deep and broad based client relationships. this local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. additionally, the global markets organization serves clients with expertise in their industry as well as through the products and services that ibm and partners supply. ibm is also expanding its reach to new and existing clients through digital marketplaces. your life ibm what matters to you when you re looking for your next career challenge maybe you want to get involved in work that really changes the world what about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion are you looking for a culture of openness, collaboration and trust where everyone has a voice what about all of these if so, then ibm could be your next career challenge. join us, not to do something better, but to attempt things you never thought possible. impact. inclusion. infinite experiences. do your best work ever. about ibm ibm s greatest invention is the ibmer. we believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. ibmers believe that the application of intelligence, reason and science can improve business, society and the human condition. restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 ibmers serving clients in 170 countries. location statement for additional information about location requirements, please discuss with the recruiter following submission of your application. being you ibm ibm is committed to creating a diverse environment and is proud to be an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. ibm is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","['parsing', 'databases', 'design thinking', 'data flow', 'workflow management', 'big', 'data infrastructure', 'c', 'technical requirements', 'big data', 'mongodb', 'paas', 'working experience', 'hive', 'java', 'kubernetes', 'sql', 'python', 'data processing', 'software', 'scala', 'scripting', 'data science', 'queuing', 'enterprise', 'data', 'integration', 'data engineering', 'r', 'nosql', 'big data solutions', 'iaas', 'data transformation', 'continuous delivery', 'testing', 'ibm', 'stream processing', 'metadata', 'data quality', 'cassandra', 'data structures', 'devops', 'hadoop', 'data solutions', 'scalability', 'software development tools', 'computer science', 'digital transformation', 'ai']","['databases', 'big', 'c', 'big data', 'paas', 'hive', 'java', 'mapred', 'kubernetes', 'sql', 'python', 'scala', 'nosql', 'object function', 'iaas', 'ibm', 'data quality', 'cassandra', 'hadoop', 'r']","['parsing', 'design thinking', 'data flow', 'workflow management', 'data infrastructure', 'technical requirements', 'mongodb', 'working experience', 'distributed', 'data processing', 'software', 'scripting', 'operating units', 'data science', 'queuing', 'data', 'integration', 'data engineering', 'data transformation', 'continuous', 'continuous delivery', 'testing', 'design', 'stream processing', 'metadata', 'agile development', 'distributed applications', 'data structures', 'devops', 'data solutions', 'scalability', 'software development tools', 'computer science', 'methodology', 'digital transformation', 'ai']","['environment', 'genetics', 'new markets', 'sales', 'design', 'consulting', 'immigration', 'adoption', 'investments', 'architecture']"
149,183,DATA SCIENTIST,"the quantitative research team is looking for an entry or mid level data scientist in the field of time series analysis and pattern recognition to help with modelling work related to infrastructure optimization. you will be working with team of data scientists responsible for providing insights into client device management for cost savings and performance management. this is a fantastic opportunity to rapidly learn and advance in a growing company. requirements 2 years practical data science or engineering work experience out of school, in quantitative domains. strong quantitative background b.sc. or m.sc. preferred. familiarity with technical tools for analysis python, r, sql, spark. experience with software design concepts. previous software engineering background is a plus. ability to structure a project from idea to experimentation to prototype to implementation. what we expect enthusiastically tackling problems with a love for teaching and celebrating the successes of others. ability to synthesize information and consider problems from new perspectives. desire to share information with others and contribute to our top notch learning environment. self starter that is focused and driven with amazing follow through. driven to delivery quality solutions.","['sql', 'quantitative research', 'python', 'time series analysis', 'software', 'data science', 'software design', 'optimization', 'pattern recognition', 'performance management', 'r']","['sql', 'python', 'r']","['quantitative research', 'time series analysis', 'software', 'data science', 'software design', 'optimization', 'pattern recognition', 'performance management']","['environment', 'cost savings']"
150,184,Data Scientist,"about the role we are looking for a data scientist to join our team. in addition to collecting data and transforming data into usable format for models, the data scientist will be supporting back end infrastructure and deploying models and pipelines into production stacks. our ideal candidate should have expertise in r and other statistical programming languages experience in frequentist and bayesian statistical methods experience working with machine learning algorithms, probabilistic models, and or or other statistical modelling approaches experience with modern r packages such as dplyr, ggplot2, data.table, etc experience in front end r technologies for data products such as shinyr, flexdashboard ability to write complex sql queries working knowledge of software engineering fundamentals and workflows experience working with container orchestration platforms such as kubernetes or docker swarm cloud computing experience authority to legally work in canada we offer an environment passionate about growth and learning competitive salary with bonus fitness subsidy program free beverages in the office workplace that is conveniently located along the yonge or sheppard line what we are looking for this is a key role within the team and would suit someone who has a strong passion for working with data and data science. an individual with software engineering background is ideal. great communication and reporting skills required both orally and in written format. individual must have initiative to work independently and effectively with team members. interest in sports or betting markets a plus. the above is intended to describe the general nature and level of work being performed. they are not intended to be an exhaustive list of all responsibilities, duties and skills required. crescendo technology thanks all candidates applying but only those selected for interview will be contacted. selected candidates will be asked to complete an online technical assessment. crescendo technology is an equal opportunity employer which values diversity in the workplace and we encourage candidates to apply directly and provide updated resume. should you require accommodation for the recruitment or interview, please do not hesitate to reach out to us. reference id data scientist application deadline 2021 06 14 job types full time, permanent additional pay bonus pay benefits casual dress dental care disability insurance extended health care life insurance vision care wellness program schedule monday to friday covid 19 considerations due to current pandemic, wfh options are available. gloves, masks and hand sanitizers are made available at the office. experience r programming 3 years frequentist and or or bayesian statistical 2 years machine learning 2 years work remotely temporarily due to covid 19","['kubernetes', 'sql', 'machine learning', 'programming languages', 'software', 'data products', 'reporting', 'technical', 'data science', 'statistical', 'programming', 'bayesian', 'pipelines', 'cloud computing', 'algorithms', 'bayesian statistical', 'r']","['kubernetes', 'sql', 'programming languages', 'programming', 'pipelines', 'r']","['machine learning', 'software', 'data products', 'reporting', 'technical', 'data science', 'statistical', 'container orchestration', 'bayesian', 'cloud computing', 'algorithms']","['assessment', 'environment', 'insurance']"
151,185,AI Scientist,"paige is a software company helping pathologists and clinicians make faster, more informed diagnostic and treatment decisions by mining decades of data from the world s experts in cancer care. we are leading a digital transformation in pathology by leveraging advanced artificial intelligence technology to create value for the oncology clinical team. we are the first company to develop clinical grade ai tools for the pathologist, which resulted in our receiving fda breakthrough designation for our first product. paige has also received fda clearance for our digital viewer, fullfocus . we have also established multiple relationships with biopharma, laboratory, and equipment manufacturers that enables paige to develop an ecosystem ready to help patients receive better diagnoses and treatment. we re looking for ai scientists to join us. in this role you ll be part of a team of world leading experts in machine learning, computer vision and pathology. in this role you ll conduct publishable deep learning research using some of the largest digital pathology datasets in the world. you ll be working to save lives by improving the accuracy of cancer detection, classification, and treatment outcome. recent graduates and phd candidates who will defend soon are welcome to apply this position is fully remote for candidates based in canada. key responsibilities work with our ai scientists and engineers to develop and assess deep neural network models author top tier journal and conference papers on your research at paige attend conferences to present your work. requirements highly motivated phd degree in computer science or related field publication record in venues such as cvpr, iccv, neurips, tpami, iclr ijcv, miccai, etc. expertise in deep learning, especially for computer vision strong python coding skills computer vision expertise knowledge of deep learning toolboxes you are authorized to work in canada","['deep learning', 'python', 'machine learning', 'software', 'datasets', 'computer vision', 'computer science', 'artificial intelligence', 'digital transformation', 'ai']",['python'],"['deep learning', 'machine learning', 'software', 'datasets', 'computer vision', 'computer science', 'artificial intelligence', 'neural network', 'digital transformation', 'ai']","['oncology', 'fda', 'pathology', 'conference papers']"
152,186,Data Scientist,"minimum qualifications master s degree in mathematics, statistics, computer science or a related field, or equivalent experience preferred qualifications 3 years of experience working with large data sets 3 years of experience with statistical and data mining tools and methods 3 years of experience with statistical packages, such as r or sas 3 years of experience working with big data in a hadoop environment 3 years of experience with linear models and nonlinear modeling techniques 3 years of experience providing predictive and prescriptive analytics in a business setting 3 years of experience working with sql or other query languages ph.d. in mathematics, statistics, computer science or a related field required, or equivalent experience proficiency in the microsoft office suite knowledge of sql fluency in at least one scripting language knowledge of statistical methodologies for modeling and business analytics knowledge using analysis tools knowledge of data visualization tools job summary the data scientist is responsible for performing data mining, predictive modeling and forecasting to provide actionable insights and strategic direction for business leaders. the data scientist delves into the recesses of large data sets of structured, semistructured and unstructured data to discover hidden knowledge about our business and to develop methods to leverage that knowledge within our line of business. responsibilities develop predictive and prescriptive statistical or behavioral models from large sets of structured and unstructured data identify methods that allow continuous and automated statistical testing to enhance the predictability of deployed models communicate results to clients, team members and business leaders collect data for ad hoc and statistical analysis own the of deployment of applicable models for business projects communicate complex analyses, conclusions and solutions clearly to all audiences work with project managers to develop detailed project timelines disclaimer this is an outline of the primary responsibilities of this position. as with everything in life, things change. the tasks and responsibilities can be changed, added to, removed, amended, deleted and modified at any time by the leadership group. the company has policies to support applicants with disabilities, including, but not limited to, policies regarding the provision of accommodations that take into account an applicant s accessibility needs due to disability. for more information, please call us at 411 jobs or email us at","['unstructured data', 'data visualization', 'big data', 'statistical analysis', 'business', 'sql', 'linear models', 'statistics', 'scripting', 'analytics', 'sas', 'data mining', 'statistical testing', 'statistical', 'forecasting', 'hadoop', 'project managers', 'computer science', 'mathematics', 'modeling', 'nonlinear', 'r']","['sql', 'hadoop', 'big data', 'sas', 'r']","['unstructured data', 'data mining', 'linear models', 'statistics', 'statistical testing', 'scripting', 'data visualization', 'project managers', 'computer science', 'analytics', 'mathematics', 'query languages', 'business', 'modeling', 'predictive', 'statistical analysis', 'nonlinear', 'forecasting']","['environment', 'microsoft office']"
153,187,Senior Data Scientist,"wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. since 2006, we ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. every month 90 million people around the world spend over 23 billion minutes on wattpad to share and discover stories they can t find anywhere else. our brand banner includes wattpad, wattpad labs, wattpad studios, wattpad books and wattpad brand partnerships. we re proudly based in toronto, but our reach is global. come build the future of entertainment and storytelling, and write your next chapter with us wattpad is seeking a senior data scientist to join our storydna team. you will help guide and drive aspects of our technical strategy that use machine learning to model our story content and metadata. this senior role will be working across engineering, data and product leadership to help guide the evolution of the technical architecture, infrastructure and best practices used within our data organization. this role assumes a deep familiarity with both applied research and bringing models to production. the ideal candidate will have a deep interest in social mobile experiences, a passion for exploring innovative approaches to open ended problems, and developing solutions to both internal and user facing product centric problems. what you will be doing working cross functionally to identify problems and turn data into knowledge, which can be actioned into product features or business decisions designing experiments, inventing new algorithms, preparing datasets, and creating prototype implementations focusing on applications to various challenging business problems engaging with teams across the department to help evolve and guide their data science practices, technology strategy, architectures, and infrastructure working closely with product teams to understand their needs and intersecting business strategies to develop a cohesive data science roadmap creating strategies that improve our ability to run experiments as an organization presenting work within wattpad as well as in scientific and engineering communities collaborating and mentoring other data scientists, establishing best practices, and encouraging knowledge sharing between team members work with the team to break down large complex data science projects into manageable phases or deliverables building and delivering machine learning models into production what we re looking for quantitative background with a graduate degree in computer science, mathematics, statistics, or related field 5 years of experience in a quantitative role with knowledge of statistical machine learning, deep learning, and natural language computing experience in algorithm development, and adapting existing algorithms to novel applications comfort working with complex, high dimensional data ability to work within ambiguity and collaborate with the team to drive insights in a changing environment fluency with python, and familiarity with one or more deep learning software frameworks such as tensorflow,pytorch, or jax experience with large scale data processing tools development experience involving data pipelines, distributed systems, and performance analysis is a plus our ideal candidate is highly motivated, self driven, with a deep curiosity and passion for knowledge discovery what we offer competitive salary career development we believe in mentorship and supporting you to achieve your goals health benefits, fully covered on us rrsp contributions generous vacation and parental leave top up 200 or month transit and home office allowance, choice of hardware, flexible hours, hybrid office and remote work options corporate discount for gym membership for you and your family downtown halifax, ns location, with easy access to transit summer fridays with afternoons off and a whole lot more update wattpad is still actively hiring for this role we are a robust and growing business our search for new talent continues. due to the current state with covid 19, wattpad will conduct all interviews in a distributed manner using applicable third party software where needed and using visual interface tools such as google hangouts and zoom. our intention is to respect everybody s need for safety and adherence to social distancing. we also want to respect our team s personal needs and capacity for professional commitments during this time consequently our pace for the interviewing process might be impacted. about wattpad who are we entrepreneurs and do ers. our vision is to entertain and connect the world through stories, and our mission is to use the power of community and technology to unleash the full potential of stories to the world. what does that mean we are visionaries, community builders, passionate problem solvers, storytellers, coffee snobs , curious by nature, and culturally diverse. what are we obsessed with our users. solving complex problems and maximizing flow. learning constantly. building the next great storytelling product. finding the greatest stories ever told. dogs , coffee, and good snacks. how do we work autonomously, collaboratively, respectfully. balancing with work, family, and play...and all while having a great time. culture and diversity wattpad is an equal opportunity employer. we do not discriminate. period. wattpad welcomes and encourages applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process. we have taken a leadership position on creating a culture and an organization that truly values diversity. we are committed to fostering a global team that reflects the diversity of the wattpad community. at wattpad, we believe cultural fit doesn t mean culturally identical, and diversity of thought helps us to challenge one another to think big and think differently. we consider employment applicants without regard to age, race, colour, national origin, citizenship, religion, creed, sex, sexual orientation, veteran status, marital status, disability status or any other protected status. if you have any special needs or accessibility requirements, please let us know. we will do our utmost to accommodate, in accordance with applicable local legislation.","['computing', 'wattpad', 'pytorch', 'tensorflow', 'distributed systems', 'python', 'statistics', 'data processing', 'software', 'data science', 'language', 'machine learning', 'data pipelines', 'performance analysis', 'metadata', 'statistical', 'hardware', 'algorithms', 'deep learning', 'datasets', 'technical', 'zoom', 'computer science', 'mathematics', 'algorithm development']","['pytorch', 'python', 'zoom', 'hardware']","['tensorflow', 'natural', 'distributed systems', 'language computing', 'statistics', 'data processing', 'software', 'data science', 'machine learning', 'data pipelines', 'performance analysis', 'metadata', 'algorithms', 'deep learning', 'datasets', 'technical', 'computer science', 'mathematics', 'algorithm development']","['environment', 'legislation', 'hiring', 'architecture', 'mentoring']"
154,188,"Data Scientist, Supply Chain/Customer Profitability","1152275 who we are as the working and learning company, we at staples canada, are dynamic, inspiring partners to our customers and the communities in which we live. at staples, we inspire people to work smarter, learn more and grow every day. we look for people who are curious, approachable and passionate, and who enjoy finding solutions. if that s you, let s work, learn and grow together. we are building an inclusive and diverse team staples canada is creating an inclusive and diverse work environment. we welcome, value and thrive on perspectives and contributions from backgrounds that vary by race, gender, sexual orientation, gender identity or expression, lifestyle, age, educational background, national origin, religion or physical ability. if you have a disability or special need that requires accommodation, please let us know. some of what you will do as the data scientist, supply chain or customer profitability you will be responsible for applying advanced analytical methodology to drive business critical decisions at staples canada. you will perform statistical analysis, build models, and leverage machine learning to solve complex business problems. this role will implement and execute internal reporting focused on driving increased process efficiency and reducing cost in the customer s post purchase experience. you will work to optimize the balance between delivery cost and customer experience at staples canada. in this role, you will have the opportunity to help drive data technology decisions at one of canada s largest online retailers. specifically, you will build, validate, and maintain comprehensive data sets deploy machine learning models to dynamically accommodate for order costs and improve the post purchase customer experience solve complex supply chain and customer support challenges, and become the go to resource for all post purchase data at staples canada develop and implement feedback mechanisms for profitability models provide quantitative research and analysis to identify process improvement communicate business intelligence related to our fulfillment centers, transportation network, and customer service team develop dashboards and reporting in looker and distribute on a regular cadence some of what you need 4 6 years experience with big data technologies and machine learning post secondary education is required previous hands on ai or ml experience required understanding of server less computing concepts, ideally within google cloud platform expert working knowledge of sql, python, and or or node.js experience with data mining, cleansing, and etl familiarity with the segment customer data platform comfortable developing reporting in bi tools like looker or tableau curious approachable passionate problem solver some of what you will get associate discount health and dental benefits rrsp or dpsp performance bonuses learning development programs and more... additional information office environment option to work remotely travel required, 10 within canada and usa job ecommerce location ca on richmond hill schedule full time employment statement staples canada is an equal opportunity employer committed to diversity and inclusion and we encourage applications from all qualified candidates, including those with disabilities.","['go', 'computing', 'tableau', 'dashboards', 'cleansing', 'big data', 'less', 'statistical analysis', 'process efficiency', 'sql', 'quantitative research', 'looker', 'python', 'reporting', 'customer data', 'solver', 'data mining', 'machine learning', 'google cloud platform', 'business intelligence', 'bi', 'etl', 'ai']","['go', 'sql', 'looker', 'python', 'tableau', 'bi', 'google cloud platform', 'big data', 'business intelligence', 'less', 'solver']","['process efficiency', 'computing', 'quantitative research', 'machine learning', 'data mining', 'reporting', 'dashboards', 'cleansing', 'methodology', 'customer data', 'statistical analysis', 'etl', 'ai']","['environment', 'education', 'process improvement', 'customer experience', 'customer service', 'customer support']"
155,189,Ingénieur senior de données / Senior Data Engineer,"ing nieur senior de donn es vous avez envie de participer aux plus grands projets de transformation num rique avec des passionn s d innovation vous souhaitez participer la r alisation de grands changements d importance et des projets qui changent des vies avec lgs, les possibilit s sont infinies. nous sommes une entreprise locale, d envergure internationale, propuls e par la puissance du capital intellectuel d ibm. votre d veloppement professionnel et votre bien tre nous tiennent c ur et les possibilit s de carri re sont multiples. mentorat, formations illimit es et esprit qu quipe font partie de notre adn. travailler au sein d une entreprise qu b coise d envergure internationale procure de nombreux avantages horaire de travail flexible, environnement de travail de qualit , r mun ration comp titive, compte mieux tre, t l m decine, studio virtuel de cours en ligne et bien plus le centre d innovation client qu bec emploie un grand nombre de jeunes professionnels qui sont supervis s et encadr s par des employ s plus exp riment s dans un environnement favorable l apprentissage en continu, en plus d tre un lieu o la diversit et les talents de l international sont mis de l avant. le cic qu bec a des bureaux montr al, gatineau, rimouski et qu bec et fait partie du r seau mondial d ibm. vous tes int ress venez nous rencontrer, nous avons plusieurs emplois disponibles joignez notre quipe en tant que ing nieur senior de donn es ce que vous ferez capacit travailler directement avec le client afin de comprendre ses besoins et d y r pondre excellentes aptitudes en communication orale et crite participation des quipes travaillant dans un processus agile or scrum ou waterfall en s assurant que les histoires or t ches sont bien d finies et que toute l information et les outils garantissant le succ s sont la disposition collaboration avec le gestionnaire de projet et les intervenants du projet pour s assurer que nous respectons nos engagements capacit travailler de fa on autonome sur des t ches et fournir un travail de qualit sup rieure capacit travailler en quipe et faire preuve d ouverture aux commentaires et la r troaction capacit apprendre rapidement et s adapter un environnement dont le rythme est rapide traitement des donn es, conception et mod lisation des donn es et d ploiement du mod le dont vous aurez besoin 5 ann es d exp rience sur python 3 ann es d exp rience avec azure connaissance approfondie de sql, des pipelines de donn es big data , des architectures et des ensembles de donn es. exp rience profond avec de grands ensembles de donn es, des outils de gestion des pipelines de donn es et des flux de travail. exp rience de la construction de grands ensembles de donn es complexes et de m canismes de livraison pour soutenir l analyse avanc e et l analyse des insights. chez lgs, nous offrons des solutions d affaires, des services professionnels et des ressources valeur ajout e. notre expertise touche principalement l infonuagique, les services applicatifs, l analyse cognitive l intelligence artificielle et les services d appoint. ce qui nous distingue la force de notre capital intellectuel mondial et l affiliation de nos pratiques l expertise d ibm. notre adn est local, mais notre port e est internationale. senior data engineer do you want to be part of the biggest digital transformation projects with people who are passionate about innovation do you want to be a part of making big changes and working on projects that change lives with lgs, the possibilities are endless. we are a local company with a global reach, propelled by the power of ibm s intellectual capital. your professional development and well being are important to us and the career opportunities are endless. mentoring, unlimited training and team spirit are part of our dna. working for a quebec based international company offers many advantages flexible work hours, a quality work environment, competitive compensation, a wellness account, telemedicine, a virtual studio for online courses and much more client innovation center quebec is home to a large number of young professionals who are supervised and mentored by more experienced employees in a continuous learning environment, as well as being in place where diversity and international talent is at the forefront. cic qu bec offices are located in montreal, gatineau, rimouski and quebec city and is part of ibm s global network. join our team as a senior data engineer what you will do ability to work with the client directly to understand and meet their requirements excellent verbal and written communication abilities must effectively communicate with technical and non technical teams participate in teams working in an agile or scrum or waterfall process and ensure the stories or tasks are well defined and have all the information and tools to be successful work with the project manager and project stakeholders to ensure we meet our commitments ability to work independently on tasks and deliver with a high level of quality ability to work in teams and be open to comments and feedback ability to learn quickly and to adapt to a fast paced environment data processing, data design and modeling, deploying the model what you need to have 5 years python experience 3 years experience with azure deep knowledge of sql, big data data pipelines, architectures and data sets experience working with large data sets, data pipeline and workflow management tools experience building large, complex big data sets and delivery mechanisms to support advanced analytics and insights analysis cic ibmjobs type d emploi temps plein, permanent avantages assurance dentaire assurance maladie compl mentaire programmes de bien tre horaire du lundi au vendredi mesures covid 19 covid 19 update en raison de covid 19, nous avons mis en place des modalit s de travail alternatives pour assurer la s curit de tous nos employ s. comme le travail distance, la formation virtuelle, les entretiens vid o et l acc s aux webinaires.","['sql', 'python', 'forefront', 'data processing', 'data pipelines', 'workflow management', 'scrum', 'big', 'data', 'analytics', 'big data', 'modeling', 'pipelines', 'digital transformation']","['sql', 'python', 'forefront', 'big data', 'pipelines']","['data processing', 'data pipelines', 'workflow management', 'scrum', 'data', 'analytics', 'modeling', 'digital transformation']","['environment', 'compensation', 'capital', 'design', 'construction', 'intellectual', 'mentoring']"
156,190,"Data Scientist, Fraud Operations","dapper labs is at an inflection point in our journey and it might be the perfect time for you to join us. less than 6 months ago we launched nba top shot on the new flow blockchain and it is already on track to be the fastest growing marketplace in history. over 200 million in sales in the past 30 days and counting we need to scale our systems to handle the demand we re looking for engineering minded data scientists to build out our fraud operations team. you ll join a small team that s scaling rapidly and build sustainable foundations for the future. our data pipeline currently include segment and tableau. most of our backend systems are in go, frontends in react. we use vanilla postgres as well as kafka event driven architecture in nba top shot. we believe in an open digital future one where people own the assets they pay for and have full transparency into the software they re using. we believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they re helping create. crypto, or blockchain, is the technology that enables this future. blockchains are public computers that anyone can access, everyone can trust, and no one can block or take down. currencies and collectibles are only scratching the surface of what s possible. titles or years of experience don t matter to us impact, authenticity, and values alignment do. we are now a remote first team and open to hiring anywhere in the world. about the role work cross functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity create predictive models to understand user level fraud risk consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the dapper product team and our finance department bonus points if you have the following you have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made you are capable of applying your skills across a variety of use cases inflexible specialists need not apply you have a bachelor s degree in a highly quantitate field , and a master s degree preferred you have 5 years working experience in data science and or machine learning. strong knowledge of sql and python programming and graph databases you are naturally curious and passionate about fraud prevention if something seems off, you want to investigate what s going on and solve the true problem you are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions more about dapper labs dapper labs is the world s first blockchain entertainment company. we are the creators of industry leading experiences including cryptokitties and nba top shot, as well as dapper wallet, the simplest way to manage your assets and use the blockchain. we are also the original developers behind flow, a new decentralized blockchain designed from the ground up for scalability and ease of use. our mission at dapper labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. we have raised over 350m from leading vcs including fred wilson and chris dixon as well as venrock, samsung, google ventures, coatue, nba players, and global artists, among others. dapper labs partners include the nba and nbpa, the nfl pa, ubisoft, warner music, turner, dr. seuss, genies, and the ufc, as well as 100 others. visit our website to learn even more about dapper labs, including information about benefits and perks.","['go', 'sql', 'python', 'machine learning', 'databases', 'tableau', 'crypto', 'software', 'data science', 'scalability', 'vanilla', 'fraud detection', 'programming', 'less', 'working experience', 'blockchains', 'blockchain']","['go', 'sql', 'python', 'databases', 'tableau', 'crypto', 'vanilla', 'programming', 'less']","['machine learning', 'use cases', 'graph', 'software', 'data science', 'scalability', 'fraud detection', 'working experience', 'blockchains', 'blockchain']","['finance', 'sales', 'adoption', 'hiring', 'architecture']"
157,191,Data Scientist - Commercial Analytics,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or work in an office it s up to you. the role as a data scientist for the commercial analytics team, you will work with veeva engineers, consultants, and fellow data scientists to support analysis and analytical data deliverables. your role will be to generate and own the mathematical and behavioral models that will help drive the generation of impactful insights and suggestions for our clients. our ideal candidate is multi talented, with the capabilities to develop statistical, machine learning, and optimization models but they are also able to be client facing, to understand the business needs of our clients , and present complex statistical and machine learning models to the stakeholders. this is a great opportunity for someone who is excited about using their deep data science expertise to help shape the ml offerings of the veeva business. this role is based in the veeva toronto office 20 toronto st, toronto, on what you ll do develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner design, develop and assess highly innovative models for clustering, anomaly detection, and more build and run analysis of models and algorithms in order to assess performance and identify the best algorithms to present to customers ensure models and algorithms support our customers and help them drive towards more intelligent and effective engagement with their customers execute statistical and data mining techniques on large data sets to identify trends work closely with the data warehouse product team to ensure the architecture is effectively developed to support algorithms that are reproducible for many clients while being able to tailor said models for individual clients build models to help our business consulting and strategy teams work with customers on how to better understand healthcare behavior to improve patient outcomes provide subject matter expertise and advice on model design, data collection, and or or model evaluation to technical and non technical audiences contribute to developing and executing the team s research agenda, including writing white papers and presenting at conferences collaborate with data engineers to access data and explain data requirements collaborate with analytics consultants to communicate findings to senior leaders and business partners communicate analyses and results, along with implications, to technical and non technical audiences demonstrate impeccable ethics and judgment when dealing with confidential data share research insights both inside and outside the organization to become a thought leader in this space requirements ph.d. in economics, machine learning, applied statistics, applied mathematics, physics, engineering, computer science or other quantitative disciplines with at least 1 year of relevant industry experience, or an equivalent m.s. with 4 years of relevant demonstrable research experience advanced in depth specialization and experience in data analysis techniques such as classification, pattern recognition, clustering, feature analysis, nlp, fuzzy matching, sentiment analysis, a or b testing, active or adaptive learning proficient in r or python ability to manipulate large data sets and develop statistical models, and accurately determine cause and effect relationships excellent sql or spark skills intellectual curiosity, along with excellent problem solving and quantitative skills, including the ability to disaggregate issues, identify root causes, and recommend solutions, even in situations with non standard problems excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to other team members and clients must be comfortable with changing requirements and priorities must be results oriented and able to move forward without complete information and with minimal supervision nice to have experience with commercial aspects of the life sciences industry experience working with software as a service and or or enterprise products experience with aws hands on experience building models with deep learning frameworks veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['pattern recognition', 'sql', 'python', 'statistics', 'software', 'physics', 'data science', 'software as a service', 'analytics', 'anomaly detection', 'aws', 'sentiment analysis', 'data mining', 'machine learning', 'testing', 'data collection', 'data analysis', 'algorithms', 'model', 'deep learning', 'feature analysis', 'economics', 'nlp', 'computer science', 'optimization', 'applied mathematics', 'r']","['sql', 'python', 'san', 'nlp', 'aws', 'r']","['applied', 'pattern recognition', 'statistics', 'software', 'physics', 'data science', 'analytics', 'anomaly detection', 'sentiment analysis', 'data mining', 'machine learning', 'algorithms dimensionality', 'testing', 'data collection', 'data analysis', 'algorithms', 'model', 'deep learning', 'feature analysis', 'software as service', 'economics', 'computer science', 'mathematics', 'optimization']","['customer success', 'environment', 'healthcare', 'white papers', 'design', 'life sciences', 'agenda', 'consulting', 'regulations', 'business', 'architecture']"
158,192,"Research Associate / Scientist, Biology","fran ais plus bas research associate or scientist, biology nuchem sciences, a synthetic chemistry and biology contract research organization, is expanding and looking for candidates to fill positions as a research associate and scientist for its biology department. nuchem provides a variety of services to support biotech and pharmaceutical industries to identify and optimize pre clinical candidates in the area of small molecule drug discovery. visit at nuchem sciences, we are a dynamic team consisting of experienced scientists and fresh graduates where everyone contributes their ideas and talents towards a variety of diverse projects. we believe in a work environment that should be fun, safe, and productive with fully equipped, state of the art laboratories and flexible work hours. we are focused on attracting, retaining, developing, and advancing our people to their full potential by rewarding bold ways of thinking and integrating inclusive behaviors into every aspect of our work. responsibilities the successful candidate will be part of a growing in vitro biology team developing biochemical assays for target based screening and drug metabolism assays to support the drug discovery team. an extensive knowledge in assay development is required for this position. the main responsibilities are develop assays and cutting edge technologies for discovery against challenging targets establish new biochemical assays using a variety of readouts and technologies transfer assays to robotic systems when applicable and run screening assays develop in vitro assays that includes recombinant proteins as well as whole cells or cell lysates design, plan, and execute experiments, either independently or in collaboration with your teammates maintain excellent documentation and communicate clearly results to the team and client solve problems at a high level organize, support, and collaborate with other team members to meet project deliverables and timelines. requirements ms or phd in biology or biochemistry experience in enzymatic activity assays assay experience on different platforms including elisa and spectrophotometry would be a strong asset experience with automation and bioinformatics is an asset ability to multitask, prioritize and function in a fast paced, dynamic cro environment demonstrate experience in enzymology and or or cell biology and data analysis excellent written, organizational and documentation skills proactive with strong interpersonal skills able to thrive in a team based environment ability to communicate progress effectively with colleagues and managers impeccable attention to details applicants must be eligible to work in canada . compensation and benefits salary competitive and based on experience. additional pay annual bonus incentive plan. advantages full time permanent position health and dental care insurance plan short and long term disability insurance life insurance rrsp employer s matching program casual dress code flexible schedule on site free parking free lunch on fridays continuing education career development. schedule monday to friday apply today to work with state of the art research facility and become part of the nuchem sciences drug discovery team fran ais associ de recherche or scientifique, biologie nuchem sciences, une entreprise de recherche contractuelle en synth se organique et biologie, est en pleine expansion et recherche des candidats pour combler des postes d associ s de recherche et scientifiques en biologie. nuchem fournit une vari t de services pour aider les industries biotechnologiques et pharmaceutiques identifier et optimiser les candidats pr cliniques dans le domaine de la d couverte de m dicaments petites mol cules. visitez nous sommes une quipe dynamique compos e de scientifiques exp riment s et de jeunes dipl m s o chaque scientifique contribue activement par leurs id es et leurs talents divers projets de d couverte de m dicament. nous croyons un environnement de travail agr able, s curitaire et stimulant dans nos laboratoires la fine pointe de la technologie. nous nous effor ons d attirer, de fid liser, de d velopper et de faire progresser nos employ s leur plein potentiel en r compensant les fa ons de penser audacieuses et en int grant des comportements inclusifs dans chaque aspect de notre travail. responsabilit s le candidat retenu fera partie d une quipe de biologie in vitro en pleine croissance qui d veloppe des essais biochimiques pour le criblage bas pour des cibles l tude et des analyses de m tabolisme des m dicaments afin de soutenir l quipe de d couverte du m dicament. une connaissance approfondie du d veloppement d essais est requise pour ce poste. les principales responsabilit s sont d velopper des essais et des technologies de pointe pour l analyse de cibles comprenant un d fi accru tablir de nouveaux tests biologiques connus en utilisant une vari t de technologies et de mode d analyse transf rer les tests un syst me robotique, le cas ch ant et effectuer des analyses d activit maintenir une excellente documentation et communiquer clairement les r sultats l quipe et au client d velopper des tests in vitro qui incluent des prot ines recombinantes ainsi que des cellules enti res ou des lysats cellulaires. concevoir, planifier et ex cuter des exp riences, ind pendamment ou en collaboration avec vos co quipiers r soudre des probl mes de haut niveau organiser, soutenir et collaborer avec les autres membres de l quipe pour respecter les livrables et les ch anciers du projet. qualifications ms or phd en biologie or biochimie exp rience dans les tests d activit enzymatique exp rience de diff rentes plateformes incluant elisa et spectrophotom trie est un atout important exp rience avec l automatisation et la bio informatique est un atout capacit effectuer plusieurs t ches, prioriser et fonctionner dans un environnement orc dynamique exp rience en enzymologie et or ou en biologie cellulaire et en analyse de donn es excellentes comp tences r dactionnelles, organisationnelles et documentaire proactif avec de solides comp tences interpersonnelles capacit communiquer efficacement les progr s avec les coll gues et les gestionnaires souci du d tail impeccable les candidats doivent tre admissibles travailler au canada . r mun ration et avantages sociaux salaire comp titif et selon l exp rience. prime plan de boni annuel. avantages soins de sant et dentaire assurance invalidit assurance vie reer avec contribution jumel e de l employeur code vestimentaire d contract horaire flexible stationnement sur place gratuity d ner gratuity les vendredis formation continue d veloppement professionnel. horaire lundi au vendredi postulez d s aujourd hui pour travailler dans de nouveaux laboratoires de recherche et faites partie de l quipe de d couverte de m dicaments nuchem sciences job types full time, permanent schedule 8 hour shift work remotely no","['bioinformatics', 'chemistry', 'screening', 'documentation', 'data analysis', 'automation', 'r']","['documentation', 'r']","['robotic', 'tests', 'bioinformatics', 'chemistry', 'screening', 'data analysis', 'bas', 'automation']","['assay', 'environment', 'education', 'biology', 'vitro', 'in vitro', 'contract research', 'art', 'design', 'biochemistry', 'cro', 'compensation', 'drug discovery', 'insurance', 'in']"
159,193,Data Scientist / Scientifique des données,"statut poste permanent temps plein bureau vieux montr al, qc horaire de travail 35 heures semaine horaire flexible et t l travail r mun ration salaire comp titif dans l industrie et excellents avantages sociaux veuillez svp envoyer votre cv nous vous remercions de l int r t que vous portez aux occasions d emploi offertes par notre entreprise. seuls les candidats s lectionn s seront contact s. pour plus d informations sur nos services de recrutement, veuillez visiter notre site web avec plus de 30 ans d exp rience, notre client est la firme la plus pr cise au canada. joindre l entreprise, c est int grer une quipe de 600 personnes passionn es et investies dans leur travail. l quipe forme la plus grande firme de sondages, de recherche marketing et analytique propri t canadienne r partie dans 8 bureaux travers le canada et aux tats unis. au del d tre la r f rence dans l industrie et d offrir des conseils strat giques importants leurs clients, notre client se distingue par leurs culture d entreprise, leurs direction transparente, leurs dynamisme et leurs esprit porte ouverte. l quipe est la base de leurs succ s et comme on dit, qui se ressemble, s assemble. votre r le en tant que data scientist fournir des insights efficaces, pertinents et innovants aux clients gr ce la mod lisation des donn es conseiller les clients internes externes sur les donn es et mod les utiliser pour r pondre leurs besoins d affaires mettre contribution vos comp tences en exploitation et mod lisation de donn es de masse , i.e algorithmes de machine learning, analyses statistiques avanc es,.. partager vos connaissances et votre expertise aupr s de vos coll gues rejoindre l quipe en tant que data scientist c est avoir c ur les valeurs de qualit , de service client, d innovation, de collaboration et d engagement. c est tre passionn e par les donn es, les diff rentes analyses statistiques et le storytelling. c est vouloir partager ses connaissances, fournir des conseils et contribuer la croissance de l quipe. c est surtout vous panouir et voluer dans un environnement stimulant et convivial. responsabilit s exploitation et mod lisation des donn es diverses ex cuter des analyses statistiques avanc es segmentation, maxdiff, analyses conjointes, analyses factorielles, turf, etc. et appliquer les diff rentes techniques l industrie de la recherche marketing d velopper des mod les pr dictifs, de classification, d attribution marketing, traiter des donn es structur es et non structur es proposer et laborer des solutions en intelligence d affaires efficaces et align es sur les besoins des clients d velopper des outils commercialisables tels que des simulateurs, des tableaux de bord et des mod les pr dictifs conseiller les quipes de recherche sur les propositions de services, les produits livrables, les mod les et analyses potentielles utiliser, les donn es utiliser, l interpr tation des r sultats, etc. exigences aptitudes dipl me d tudes sup rieures dans un domaine quantitatif tel qu en sciences informatique, ing nierie, physique, statistiques, math matiques appliqu es ou l quivalent solides connaissances des langages de programmation avec emphase sur le machine learning et les techniques d analytique avanc e exp rience pratique en sql et codage de bases de donn es ma trise du fran ais et de l anglais, essentiel au moins 2 ans d exp rience dans le domaine de l intelligence d affaires et de la mod lisation des donn es connaissances des techniques statistiques et du data mining exp rience pratique avec des bases de donn es massives esprit de collaboration et capacit de communiquer efficacement des id es complexes aux clients ainsi qu ses coll gues excellentes capacit s en r solution de probl me, habilet s en analyse de probl me, en identification des causes et capacit s de fournir des recommandations rapidement exp rience en recherche marketing et en marketing grande rigueur, attention aux d tails et pr cision dans le traitement des donn es travailler avec des ch anciers serr s et gestion de projets multiples toujours pas convaincu notre client est plus qu une firme qui se diff rencie par son intelligence marketing c est aussi travailler dans une ambiance amicale, respectueuse et plaisante le bonheur au travail, une de leurs top priorit s des nouveaux projets longueur d ann e impossible de trouver le temps long cr er des liens d amiti serr s travers le canada et les tats unis profiter de plein d avantages vous allez voir on s occupe bien de vous et plus encore il faut bien vous garder des surprises nous vous remercions de l int r t que vous portez aux occasions d emploi offertes par notre entreprise. seuls les candidats s lectionn s seront contact s. pour plus d informations sur nos services de recrutement, veuillez visiter notre site web","['attribution', 'sql', 'data mining', 'machine learning', 'c', 'r']","['c', 'sql', 'r']","['data mining', 'machine learning', 'attri']",['marketing']
160,194,Senior Data Scientist,"who we are we care about the health, safety and wellness of the internet you have the chance to make a real difference in the ability for the diversity of humanity to engage each other in a more compelling, supportive, and optimistic way. we re looking for bold thinkers that look at the person to person interactions on the internet and know they have the empathy, insight and bias to action that will bring our vision of a better internet for the world to life. working with complex systems and deep learning data architectures, you will have the ability to define and drive cutting edge features and products that amplify positive interactions, while interfacing with a diverse set of customers and their end users. your work will celebrate what is good about the ease and ubiquity of internet socialization and community, while protecting participants in online communities from threats ranging from the relatively benign, to the most serious threats the internet exposes us to. and you ll do it across 100 billions of interactions a month on many of the most famous communities on earth. what we are looking for senior data scientists at two hat work cross functionally to develop creative solutions for customers using high quality data sets through intrinsic curiosity, goal oriented focus, and the ability to identify meaningful discoveries. they supervise interns, guide research activities, are key contributors to product development and product operations where machine learning is used to deliver amazing and beautiful products to our customers. they are responsible for collecting and analyzing the data used to train and test powerful machine learning models which scale to support over 100b human interactions every month. they also use that data to provide value to both customers and internal stakeholders. as our senior data scientist you supervise and support our team of research interns. develop tools, algorithms, machine learning models and automated systems that help identify high risk user generated content on social networks. work closely with our product and engineering team to turn models into products. perform data exploration, statistical analysis, and model the ways that social networks can use our tools. use insights to identify meaningful features and patterns. create prototypes and experiments to test the viability of insights and demonstrate results to the product team. partner with high profile clients to understand their data science needs present and visualize data to communicate findings to non data science team members and executive team who you are you believe in our mission and are passionate about amplifying joy and removing negativity from online communities. you have completed a phd or masters degree in computer science, statistics, or related field. you have 5 years of real world experience solving business problems with text, image or other media classification, using machine learning, data mining, and exploratory data analysis. experience should include working with related deep learning technologies working with cloud platforms experience with tableau is an asset experience with golang is an asset the details permanent position, 40 hours or week remote applicants are welcome two hat welcomes and encourages applications from people with disabilities. accommodations are available upon request for candidates taking part in all aspects of the selection process. join us we believe in an internet that is safe for everyone it is a vision that this team stands behind and strives to create every day. we believe that we are what we do. we are a growing startup with an evolving culture. our teams are ambitious, focused on quality, innovative, and deeply conscientious people. being part of this team means that you get to wake up everyday knowing that you are part of making the world a better, safer place for our children, families, and friends as an organization we are focused on delivering a beautiful, quality product to our customers companies that trust us to keep their communities connected and safe. are you optimistic, focused, collaborative, ambitious, and service driven but worried you don t have it all at two hat we know that not everyone gains experience following a traditional path. if you share our values and drive for growth, want to make a difference in the world, and meet most of the qualifications, we encourage you to apply. express your interest here and then follow us on facebook, twitter, and linkedin to learn more about how passionate we are about making the internet a better place.","['deep learning', 'data mining', 'machine learning', 'statistics', 'tableau', 'complex systems', 'data science', 'computer science', 'data analysis', 'statistical analysis', 'algorithms']",['tableau'],"['deep learning', 'data mining', 'machine learning', 'statistics', 'exploratory', 'complex systems', 'data science', 'computer science', 'data analysis', 'statistical analysis', 'algorithms']","['product development', 'product operations', 'linkedin']"
161,195,Senior Clinical Data Manager,"do you want to watch clinical development change, or do you want to be the one to shape it because we re hoping you re here for the latter. who are we we are pra. we are 20,000 employees strong, operating in more than 90 countries. we are committed to saving lives and we are constantly striving to be the best at what we do. our impact is real and we see it every single day. we help get life saving drugs into the hands of those who need them most. clinical data manager summary the cdm will perform scientific clinical data review in close collaboration with the study responsible physicians and study responsible scientists . responsibilities services rendered will adhere to applicable johnson johnson sops, wis, policies, local regulatory requirements, ich gcp, etc. provides scientific data review support for more than one low to moderate complexity trial or one high complexity trial. the data management expert who, within the therapeutic area, is performing scientific clinical data review in close collaboration with the study responsible physicians and study responsible scientists . tapping into technical and clinical expertise, closely collaborating with the srp, srs, data management functions and the rest of the study team members when implementing the data management related activities for protocols, with focus on more complex indication and therapy related elements of the study. reviews all necessary data flows, the data management plans and performs continuous data review activities on the studies in the assigned program. involved in study related activities from the protocol design stage onwards, providing input into the study specific and or or indication specific data collection tools. reviews scientific study data, manages cdm and srs or srp related queries in edc system and holds discussions with srs or srp. involvement in other review activities is possible. leads and or or attends meetings as appropriate. takes a leadership role with srp or srs and collaborates with the gdm to establish, align and confirm scientific clinical data review expectations for assigned trial. with the trial customer, cro and other functional partners in relation to cdm related activities reviews content and integration requirements for ecrf and other data collection tools establishes conventions and quality expectations for clinical data. set timelines and follow up regularly to ensure delivery of all clinical data managemen milestones creates the integrated review plan ensuring appropriate quality, scientific content, organization, clarity, accuracy, format, and consistency. reviews related clinical data management documents. ensures compliance with regulatory guidelines and documentation requirements. ensures real time inspection readiness of all assigned deliverables for the trial participate in regulatory agency inspection and j j internal audits as necessary. plans and tracks applicable cdm deliverables. ensures cdm deliverables are on time. takes a leadership role in collaborating with the srs or srp to ensure that dm and therapeutic area trial needs and deliverables are met. identifies and communicates lessons learned, best practices and frequently asked questions at the trial level. identifies and participates in process, system, and tool improvement initiatives within clinical data management. acts as backup for gdm, as appropriate . qualifications bs or ba degree or higher preferably in health sciences, or bs or ba degree or higher with professional clinical experience or exposure. data management experience preferably including clinical data review or significant experience with clinical data review. knowledge in medical terminology would be preferable collaboration with clinical teams. experience in clinical drug development within the pharmaceutical industry or related industry. college graduate data management experience or clinical data review. to qualify, applicants must be legally authorized to work in the united states, and should not require, now or in the future, sponsorship for employment visa status. pra is an eeo or aa employer and is committed to providing opportunities to minorities, women, veterans and individuals with disabilities. options apply for this job onlineapply share sorry the share function is not working properly at this moment. please refresh the page and try again later. share on your newsfeed connect with us","['gcp', 'clinical data review', 'clinical data management', 'data collection', 'clinical development', 'documentation', 'integration', 'clinical data', 'terminology', 'data management', 'rest', 'data review']","['gcp', 'documentation']","['clinical', 'clinical data review', 'clinical data management', 'data collection', 'clinical development', 'integration', 'clinical data', 'terminology', 'data management', 'rest', 'data review']","['ich', 'regulatory requirements', 'regulatory guidelines', 'inspection', 'design', 'inspections', 'sponsorship', 'cro', 'drug development', 'therapy', 'cdm', 'health sciences']"
162,196,"Data Scientist, R&D","individually we are people, but together we are aviva. individually these are just words, but together they are our values care, commitment, community, and confidence. this role will start off as work from home, gradually you will be required to work in the toronto or montreal office location. join an exciting team of actuaries, data scientists and engineers at the forefront of using data science and ai to drive impactful decisions. the insurance industry has entered a period of unprecedented change. the last few years has seen a huge increase in the number of connected consumer devices such as home assistants, smart home sensors and cars with self driving technology. aviva recognizes that data created by these devices allows new ways to understand clients deeply and offer them personalized digital services and experiences in real time. this exciting role is at the heart of a high performing data science team that is impacting all aspects of insurance, from distribution to underwriting and pricing to claims. as a data scientist r d, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products. you will work collaboratively with stakeholders to formulate problems and conduct research to propose viable solutions. you will leverage new data sources and experiment with new approaches providing enhancements through iterations. what you ll do influence the r d roadmap by identifying emerging business challenges and r d initiatives that have a high potential for applicability. push the boundaries on new methods and ways of addressing fundamental challenges in the area of ai or ml within the context of insurance industry assist in creating compelling prototypes by working closely with teams of actuaries, data scientists and engineers building end to end analytics solutions that drive impact. dive into huge, noisy, and complex real world data to discover insights and new predictive models for various business challenges. leverage the state of the art in the field, including sound publications in well known journals and conferences, and stay ahead of the curve on the newest ai methods. fast prototyping, feasibility studies, specification and implementation of data product components. what you ll bring as a data scientist, you will need the following skills and experience to succeed in the role university degree in computer science, math, statistics, physics, actuarial science or related field or equivalent. a ph.d. degree is strongly preferred. extensive r d experience in machine learning, statistics, and applying data science methods. proven research track record as scientific publication in well known machine learning journals and conferences will be considered an asset. advanced level understanding of machine learning fundamentals and model development principles. excellent presentation and communication skills, with a knack for articulating complex scientific and analytical concepts to people from various backgrounds. 3 5 years of programming experience preferably in python with strong grasp of software engineering standard methodologies such as code reusability, modularity, use of repos, etc. 3 5 years of experience of building machine learning models for business applications. 2 3 years experience with ml or ai technologies, such as scikit learn, keras, tensorflow, pytorch. experience mining iot sensor data will be considered an asset. experience with big data technologies such as spark, databricks, scala will be considered an asset. what sets you apart a growth mindset with versatile skills and able to work through problems from first principles. a portfolio of projects that demonstrate your ability to draw inferences from data. experience at all stages of data science problem definition, data acquisition wrangling, modelling, feature engineering and deployment. experience working as part of an agile team. the best problems in the industry are yet to be articulated. we need someone who is creative and self motivated. what you ll get competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities. exceptional career development opportunities. we ll support your professional development education. additional information aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation. we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","['pytorch', 'tensorflow', 'big data', 'forefront', 'python', 'statistics', 'keras', 'data acquisition', 'software', 'scala', 'physics', 'data science', 'analytics', 'programming', 'machine learning', 'ai', 'iot', 'digital services', 'model', 'prototyping', 'sensors', 'computer science', 'r']","['python', 'forefront', 'keras', 'scala', 'pytorch', 'iot', 'programming', 'big data', 'r']","['model', 'wrangling', 'machine learning', 'prototyping', 'statistics', 'data acquisition', 'sensors', 'software', 'physics', 'tensorflow', 'data science', 'computer science', 'analytics', 'digital services', 'feature engineering', 'ai']","['underwriting', 'actuaries', 'insurance industry', 'actuarial', 'education', 'art', 'feasibility studies', 'retirement', 'compensation', 'business applications', 'hiring', 'insurance']"
163,197,Data Scientist,"emplacement montr al qu bec de quoi s agit il il sera pratiquement impossible pour le cerveau humain de comprendre comment faire fonctionner et optimiser la prochaine g n ration de r seaux sans fil, c est dire le r seau 5g avec calcul en p riph rie distribu , qui entra nera une transformation conomique et sociale pour tous les aspects de la soci t . les technologies d apprentissage automatique et d autres technologies d intelligence artificielle seront essentielles si nous voulons saisir cette opportunit . nous sommes en train de mettre en place un acc l rateur d intelligence artificielle mondial au canada, aux tats unis, en su de et en inde, regroupant 300 experts charg s d acc l rer l ex cution de notre strat gie. ericsson est maintenant la recherche de scientifiques des donn es exp riment s pour largir consid rablement son quipe mondiale pour l acc l ration de l ia. avez vous une compr hension approfondie des technologies de ml et d ia dans ce r le, vous aurez besoin d avoir de solides comp tences en programmation et une bonne compr hension de la science des donn es et des outils d apprentissage automatique. vos connaissances et votre exp rience des m thodologies de la science des donn es seront mises profit pour r soudre des probl mes difficiles du monde r el au sein d une quipe tr s dynamique et internationale. vous travaillerez dans un environnement hautement collaboratif o vous communiquerez et planifierez les t ches et les id es. vous travaillerez sur des initiatives fort impact avec d autres ds en intelligence artificielle afin de stimuler la croissance et la rentabilit conomique d ericsson et de ses clients en d veloppant les offres actuelles d ericsson. vous contribuerez galement la cr ation de nouvelles offres dans les domaines des r seaux 4g et 5g pilot s par l intelligence artificielle, du nuage distribu , de l ido et d autres activit s mergentes. diriger l analyse fonctionnelle et technique au sein des entreprises ericsson et pour les clients strat giques afin de comprendre les besoins et les opportunit s des entreprises bas es sur les syst mes d information. permettre le d veloppement rapide et it ratif d une solution minimale viable valid e r pondant ces besoins. cela implique de travailler avec des p taoctets de r seaux 4g or 5g, des donn es iot et exog nes, et de proposer or s lectionner or tester des mod les pr dictifs, des moteurs de recommandation, des syst mes de d tection d anomalies, des mod les statistiques, des syst mes d apprentissage en profondeur, d apprentissage par renforcement et autres syst mes d apprentissage machine. mener des tudes et utiliser de mani re cr ative des sources de donn es nouvelles et or ou existantes. travailler avec les architectes de donn es pour exploiter les mod les de donn es existants et en cr er de nouveaux selon les besoins. collaborer avec les quipes de d veloppement de produits et les partenaires des entreprises ericsson pour industrialiser les mod les et solutions d apprentissage machine dans le cadre des offres ericsson, notamment en fournissant le code source, les flux de travail et les documents. travailler avec les nouvelles technologies et les promouvoir au sein des communaut s d entrevue de motivation d ericsson. contribuer au renforcement des comp tences en mati re d entrevues de motivation au sein des entreprises et des unit s de service la client le d ericsson. laborer de nouveaux concepts, m thodologies et techniques, et appliquer ou d velopper les concepts, m thodologies et techniques existants pour les projets interfonctionnels. pour r ussir, vous devez avoir une ma trise ou un doctorat en ing nierie lectrique, en informatique, en intelligence artificielle, en apprentissage machine, en physique ou dans un domaine connexe exp rience pratique plus de 2 ans d exp rience d apprentissage automatique dans le domaine de la science des donn es. une exp rience confirm e dans la r daction de logiciels de production une grande exp rience dans le d veloppement de mod les et la gestion du cycle de vie dans un ou plusieurs secteurs d activit or applications de solides comp tences en programmation dans divers langages et une ma trise de python ou c des comp tences confirm es en apprentissage automatique, par exemple en analyse discriminante par r gression lin aire or logistique, ensachage, for t al atoire, mod le bay sien, mvc, r seaux neuronaux, etc. de solides comp tences dans l utilisation des cadres d apprentissage automatique de pointe actuels tels que scikit learn, h2o, keras, tensorflow and spark, etc. la capacit confirm e mettre en uvre de nouveaux algorithmes et de nouvelles m thodologies issus d initiatives et de documents de recherche de premier plan sur les logiciels libres et portant sur leurs fonctionnalit s, leur volutivit et leur viabilit globale d industrialisation des connaissances en statistiques, telles que l analyse descriptive et l analyse supervis e et non supervis e vous pourriez galement avoir une certification im de mooc, un atout des applications et des connaissances sp cialis es en t l communications ou en ido, un atout la capacit travailler de mani re ind pendante avec beaucoup d nergie, d enthousiasme et de pers v rance une bonne aptitude communiquer en anglais crit et parl une capacit travailler dans un environnement de collaboration, notamment travailler avec des unit s commerciales complexes parties prenantes multiples, des clients mondiaux, des partenaires technologiques et d autres partenaires de l cosyst me dans une organisation matricielle mondiale multiculturelle, avec tact et pers v rance qu est ce que vous y gagnez chez ericsson, notre culture repose sur plus d un si cle de d cisions courageuses. chez nous, vous ne r vez plus de l avenir, vous le red finissez. vous ne d velopperez pas pour le statu quo, mais vous construirez ce qui le remplace. nous rejoindre est une fa on de faire voluer votre carri re dans la direction que vous souhaitez avec des centaines d opportunit s de carri re dans des lieux partout dans le monde, dans un endroit o la co cr ation et la collaboration sont ancr es dans les murs. vous vous retrouverez dans un environnement de communication o l empathie et l humanit servent de pierres angulaires pour notre fa on de travailler et o l quilibre travail vie personnelle est une priorit . bienvenue dans une entreprise inclusive et mondiale o votre possibilit d avoir un impact est infinie. que se passe t il une fois que vous avez pr sent votre candidature pour vous pr parer aux prochaines tapes, veuillez consulter ici https or or or en or careers or job opportunities or hiring process location montreal quebec our exciting opportunity it will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5g network with distributed edge compute, that will drive economic and social transformation for all aspects of society. machine learning and other artificial intelligence technologies will be vital for us to handle this opportunity. we are setting up a global ai accelerator in canada, the us, sweden and india, with 300 experts, to fast track our strategy execution. ericsson is now looking for experienced data scientists to significantly expand its global team for ai acceleration. do you have in depth understanding of ml and ai technologies in this role, you will need to have strong programming skills and strong understanding of data science and machine learning tools. you will use your knowledge and or or experience in data science methodologies apply them to solve challenging real world problems as part of a highly dynamic and global team. you will work in a highly collaborative environment where you communicate and plan tasks and ideas. you will be working on high impact initiatives with other ds in machine intelligence to drive growth and economic profitability for ericsson and its customers by accelerating current ericsson offerings. your contribution will also help to create new offerings in the areas of mi driven 4g and 5g network, distributed cloud, iot and other emerging businesses. conduct functional and technical analysis within ericsson organization and strategic customers to understand mi driven business needs and opportunities contribute to rapid and iterative development of validated minimum viable solution addressing these needs. this includes working with petabytes of 4g or 5g networks, iot and exogenous data, and proposing or selecting or testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learning and other machine learning systems conduct studies and find creative usage of new and or or existing data sources. work with data architects to leverage existing data models and build new ones, as needed. collaborate with product development teams and partners in ericsson businesses to industrialize machine learning models and solutions as part of ericsson offerings including providing source code, workflows and documents work with new technologies and champion them in mi communities within ericsson. assist mi competence build up in ericsson businesses and customer serving units help to develop new and apply or extend existing, concepts, methodologies, techniques for cross functional initiatives to be successful you have ms, or phd in electrical engineer, computer science, artificial intelligence, machine learning, physics, or related field applied experience 2 years of machine learning experience in data science. proven experience writing production grade software extensive experience in model development and life cycle management in one or more industry or application domain strong programming skills in various languages with proficiency in python and or or c proven skills in machine learning, e.g., linear or logistics regression discriminant analysis, bagging, random forest, bayesian model, svm, neural networks, etc. strong skills in the use of current state of the art machine learning frameworks such as scikit learn, h2o, keras, tensorflow and spark, etc. demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability strong knowledge in statistics, e.g., descriptive analysis and supervised and unsupervised analysis you may also have certifying mi moocs, a plus applications or domain knowledge in telecommunication and or or iot, a plus. ability to work independently with high energy, enthusiasm and persistence good communication skills in written and spoken english ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi culture, global matrix organization with sensitivity and persistence what s in it for you here at ericsson, our culture is built on over a century of courageous decisions. with us, you will no longer be dreaming of what the future holds you will be redefining it. you won t develop for the status quo but will build what replaces it. joining us is a way to move your career in any direction you want with hundreds of career opportunities in locations all over the world, in a place where co creation and collaboration are embedded into the walls. you will find yourself in a speak up environment where empathy and humanness serve as cornerstones for how we work, and where work life balance is a priority. welcome to an inclusive, global company where your opportunity to make an impact is endless. disclaimer the above statements are intended to describe the general nature and level of work being performed by employees in this position. they are not an exhaustive list of all responsibilities, duties and skills required for this position, and may be required to perform additional job tasks required by the manager. we provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity, gender expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or ericsson s code of business ethics. if you need assistance or to request an accommodation due to a disability, please contact ericsson at or 338 9966 for further assistance. primary country and city canada saint laurent mfield2 req id 543303","['https', 'tensorflow', 'c', '4gg', 'python', 'statistics', 'keras', 'technical analysis', 'software', 'physics', 'data science', 'programming', 'anomaly detection', 'data models', 'bayesian', 'r', 'machine learning', 'iot', 'testing', 'artificial intelligence', 'algorithms', 'model', 'deep learning', 'neural networks', 'scalability', 'computer science', 'reinforcement learning', 'ai']","['https', 'python', 'keras', '4g', '5g', 'iot', 'c', '4', 'programming', 'data models', 'r']","['tensorflow', 'sci', 'svm', 'machine intelligence', 'statistics', 'technical analysis', 'software', 'physics', 'data science', 'anomaly detection', 'bayesian', 'machine learning', 'testing', 'model development', 'artificial intelligence', 'algorithms', 'deep learning', 'neural networks', 'scalability', 'computer science', 'reinforcement learning', 'ai']","['law', 'environment', 'business ethics', 'art', 'electrical', 'business units', 'h', 'industrialization', 'product development', 'research papers', 'hiring']"
164,198,Senior Data Scientist,"job description our precima team helps retailers turn shopper insights into strategic advantage. we leverage our deep expertise in data science and technology to mine shopper data, uncovering what drives consumer decision making. by using advanced modeling, artificial intelligence and cloud based saas solutions, we are able to put these insights at the fingertips of our clients. as a data scientist, you will be responsible for developing and analyzing results and presenting insights and recommendations to our clients using ml or statistics methods. in this client facing role you will be responsible for generating and leveraging advanced analytics to deliver and build customer insights and customer centric strategies for our clients. this role is an integral part of the data science solution team. you bring relevant retail or cpg industry experience and expert capabilities in developing and interpreting segmentation, optimization and statistical modeling for both marketing and merchandising. what you ll do implement, score, and maintain advanced statistical and mathematical models and customer segmentations. produce accurate statistical analysis and ensure high quality of the data analysis produced interpret, document and present or communicate analytical results to multiple business disciplines, providing conclusions and recommendations based off customer centric data take analytical objectives and define data requirements. extract, clean, and transform customer and item level data for purposes of analysis, modeling or segmentation and reporting hands on data extraction and reporting off customer database we re looking for people who have master s degree math or statistics, computer science, economics, industrial engineering minimum of 2 years of directly related work or intern experience in quantitative analysis with proven results in leveraging customer or transaction to address business objectives through a structured analysis leading to insights and recommendations. highly proficient in sql and python experience in retail and or or cpg is strongly preferred. strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis ability to translate business objectives into analytical plan or framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams and then to clients. ability to translate statistical and analytical results into clear written and verbal communication to internal or external stakeholders excellent ability to be part of multiple projects or initiatives of varying size and complexity, while simultaneously meeting and exceeding deadlines in a diverse environment strong team player and ability to work in a collaborative environment strong interpersonal skills including written and oral communication additional information nielsen precima is a wholly owned business unit of nielsen. nielsen invented the very concept of market share. today, our data and insights continue to provide the essential foundation that make markets possible in the rapidly evolving world of commerce. modern consumers have access to more choices via more channels than ever before. li ak3 about nielseniq nielseniq is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. we provide consumer packaged goods manufacturers or fast moving consumer goods and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. our approach marries proprietary nielseniq data with other data sources to help clients around the world understand what s happening now, what s happening next, and how to best act on this knowledge. we like to be in the middle of the action. that s why you can find us at work in over 90 countries, covering more than 90 of the world s population. for more information, visit nielseniq is committed to hiring and retaining a diverse workforce. we are proud to be an equal opportunity or affirmative action employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.","['statistical analysis', 'sql', 'python', 'data analytics', 'statistics', 'reporting', 'data science', 'saas', 'analytics', 'market share', 'customer', 'interpreting data', 'statistical', 'artificial intelligence', 'data analysis', 'data extraction', 'economics', 'computer science', 'optimization', 'modeling']","['sql', 'python', 'market share']","['data analytics', 'statistics', 'cpg', 'quantitative analysis', 'customer analysis data', 'data extraction', 'reporting', 'economics', 'data science', 'data analysis', 'saas', 'artificial intelligence', 'analytics', 'optimization', 'modeling', 'statistical', 'computer science', 'statistical analysis']","['environment', 'industrial engineering', 'commerce', 'merchandising', 'marketing', 'retail', 'business disciplines', 'genetics', 'hiring']"
165,199,Data Scientist (AI/ML),"duration 6 months location can be remote we are seeking a data scientist with ai, ml experience. the data scientist will be responsible for partnering with key business stakeholders and leveraging client and industry data to develop predictive algorithms and models. the primary focus of the data scientist will be to identify trends in data to extract meaningful business insights and drive cross functional business solutions via statistical data analysis, and advanced analytics techniques in artificial intelligence and machine learning . the individual will also work closely with the product team and support the various stages of the analytics development lifecycle. roles and responsibilities using complex analysis techniques to uncover hidden insights in complex, multi variate data. turning questions that start with why into data driven answers. using data and trends to drive sophisticated forecasting, modeling and contact strategies. prepare and present insights directly with key stakeholders. writing and evaluating machine learning algorithms. leverage strong communication skills and business acumen to work closely with cross functional business owners to drive data and analytics technologies for business use. design, develop and implement predictive or analytical algorithms and statistical data modeling tools to derive insights for complex business operations and processes. be a subject matter expert in supervised and unsupervised ml algorithms and other applied ai techniques to derive meaningful and actionable insights from big data. implement scalable, efficient processes for large scale data analyses, model development and deployment. be responsible for effectively communicating insights, findings, test results, performance analysis to both functional teams, and the senior management along with recommendations for enhancements or improvements. continually drive to learn and master new technologies and techniques. constantly upskill and remain fully updated with the evolving data and analytics community. qualification and experience master s degree in computer science, it, or math . have a good understanding of data analysis, advanced analytics with exposure to ai or ml and technologies. experience with machine learning or artificial intelligence, and numerical programming frameworks . 5 years of experience in data science, data mining, analysis, and visualization with the ability to identify and present actionable insights from data to address business problems. demonstrated experience in using statistical and data manipulation languages . strong communication, presentation and documentation skills is also required. we thank you for visiting the job page. only candidates closely matching the requirement will be contacted for interview. wishing you all the best in your job search. email your resume to","['visualization', 'big', 'documentation', 'variate data', 'data science', 'analytics', 'multi', 'data', 'programming', 'data mining', 'machine learning', 'performance analysis', 'data manipulation', 'model development', 'statistical', 'artificial intelligence', 'data analysis', 'algorithms', 'forecasting', 'business insights', 'computer science', 'modeling', 'ai']","['business insights', 'model development', 'programming', 'big data', 'data manipulation languages', 'documentation']","['data mining', 'machine learning', 'visualization', 'performance analysis', 'forecasting', 'data science', 'modeling', 'analytics', 'statistical', 'artificial intelligence', 'data modeling', 'data analysis', 'computer science', 'algorithms', 'complex analysis variate', 'ai']","['design', 'business operations']"
166,200,Data Engineer/Scientist,"data engineer or scientist nugget.ai is recruiting and screening candidates on behalf of our partner teema. nugget.ai will be responsible for application and screening processes and if you re selected, teema will be responsible for the interview stages of the hiring process. teema s client is looking for an experienced data engineer or scientist who understands the data and aspires to learn and innovate. this role offers an opportunity to work with a twenty person product development team, managing your own team and collaborating with them, organizing the data and create models and algorithms based on the data along with interactions with clients and providing solutions to product development teams. qualifications master s degree on a relevant field hands on experience as a data scientist on a production environment experience with scala and machine learning good knowledge about java, python, r, jvm and hadoop strong ability to communicate on both business and technical subjects authorized to work in canada. core competencies action oriented maintains a sense of urgency to complete a task and seeks information rather than waiting for it. problem solving assesses situations quickly and provides effective and creative solutions for resolution. innovative contributes to the creation and promotion of an environment where creative thinking is embraced and encouraged. collaboration actively works with multiple individuals to complete a task or achieve a goal. data gathering resource planning ability to define problems, identify data sources, and develop a data collection plan. open minded willing to consider new ideas and or or new tools. resilience or resourceful possesses the capacity to recover quickly from difficulties. the company is a 10 year old vancouver based and for the foreseeable future, they are working 100 from home. you might need to visit the office a couple of days a week, so the candidate needs to reside in vancouver. if you re an exceptional data engineer or scientist, please apply today","['jvm', 'python', 'machine learning', 'scala', 'hadoop', 'data collection', 'screening', 'algorithms', 'java', 'r']","['jvm', 'python', 'scala', 'hadoop', 'java', 'r']","['machine learning', 'data gathering', 'resource planning', 'data collection', 'screening', 'algorithms', 'ai']","['product development', 'environment', 'hiring', 'recruiting']"
167,201,Data Scientist,"stradigi ai est un fournisseur sp cialis dans les plateformes d ia qui transforme la fa on dont les personnes et les entreprises interagissent avec l intelligence des donn es en vue de relever des d fis, d acc l rer la prise de d cision et de grandir avec l ia d s aujourd hui. joignez vous une entreprise d ia avant gardiste et innovante qui a c ur votre contribution, votre point de vue et votre bien tre. stradigi ai est la recherche d un scientifique des donn es qui soutiendra nos quipes avant vente et marketing avec des informations tir es de l analyse des donn es de l entreprise. le candidat id al doit avoir une solide exp rience de l utilisation d une vari t de m thodes d exploration de donn es or d analyse de donn es, de l utilisation d une vari t d outils de donn es, de la construction et de la mise en uvre de mod les, de l utilisation or de la cr ation d algorithmes et de la cr ation or ex cution de simulations. ils doivent avoir une capacit av r e g n rer des r sultats commerciaux gr ce leurs connaissances bas es sur les donn es. ils doivent tre l aise de travailler avec un large ventail de parties prenantes et d quipes fonctionnelles. le bon candidat aura la passion de d couvrir des solutions cach es dans de grands ensembles de donn es et de travailler en collaboration pour am liorer les r sultats commerciaux. faites partie d une entreprise d ia innovante et avant gardiste qui valorise vraiment ce que vous faites, ce que vous pensez et ce que vous ressentez. ce que vous ferez participez et dirigez des ateliers pour clients dans le but de capturer les objectifs commerciaux et les traduire en exigences de donn es des fins d apprentissage automatique. travailler avec les autres contributeurs de l organisation pour identifier les opportunit s de tirer parti des donn es de l entreprise pour d velopper des solutions commerciales. extraire et analyser les donn es des bases de donn es de l entreprise pour optimiser et am liorer le d veloppement de produits, les techniques de marketing et les strat gies commerciales. valuer l efficacit et l exactitude des nouvelles sources de donn es et des techniques de collecte de donn es. d veloppez des mod les de donn es et des algorithmes personnalis s appliquer aux ensembles de donn es. utilisez la mod lisation pr dictive pour augmenter et optimiser l exp rience client, la g n ration de revenus, le ciblage publicitaire et d autres r sultats commerciaux. coordonner avec diff rentes quipes fonctionnelles pour mettre en uvre des mod les et surveiller les r sultats. d velopper des processus et des outils pour surveiller et analyser les performances des mod les et l exactitude des donn es. profil recherch exp rience de l utilisation de langages informatiques statistiques pour manipuler des donn es et tirer des informations partir de grands ensembles de donn es. exp rience de travail et de cr ation d architectures de donn es. une connaissance financi re ou une exp rience des march s financiers est un atout certain. connaissance d une vari t de techniques d apprentissage automatique et de leurs avantages or inconv nients dans le monde r el. connaissance des techniques et concepts statistiques avanc s et exp rience des applications. excellentes comp tences en communication crite et verbale pour la coordination entre les quipes. comp tences solides en pr sentation pour les collaborations internes et les ateliers clients. une volont d apprendre et de ma triser les nouvelles technologies et techniques. nous recherchons une personne avec 4 7 ans d exp rience dans la manipulation d ensembles de donn es et la construction de mod les statistiques, titulaire d une ma trise ou d un doctorat en statistiques, math matiques, informatique ou dans un autre domaine quantitatif et familiaris e avec les logiciels or outils suivants connaissance et exp rience des techniques statistiques et d exploration de donn es glm or r gression, random forest, boosting, arbres, text mining, analyse de r seaux sociaux, etc. exp rience de l interrogation de bases de donn es et de l utilisation de langages informatiques statistiques r, python, sql, etc. exp rience de l utilisation des services web. exp rience de la cr ation et de l utilisation d algorithmes et de statistiques avanc s d apprentissage automatique r gression, simulation, analyse de sc nario, mod lisation, clustering, arbres de d cision, r seaux de neurones, etc. exp rience de l analyse de donn es de fournisseurs tiers google analytics, facebook insights, etc. exp rience avec les donn es or outils informatiques distribu s map or reduce, hadoop, hive, spark, mysql, etc. exp rience de visualisation or pr sentation de donn es pour les parties prenantes l aide de tableau, periscope, business objects. pourquoi consid rer stradigi ai nous offrons des salaires comp titifs, la possibilit de d tenir des actions dans l entreprise gr ce notre r gime d actionnariat des salari s, une contribution au reer allant jusqu 3 , un programme de vacances g n reux, des jours de cong pay s durant le temps des f tes, une assurance pour les soins m dicaux et les soins dentaires, des modalit s de travail flexibles, et bien plus nous soutenons galement un horaire de travail flexible qui permet de travailler autant la maison qu au bureau.","['sql', 'python', 'tableau', 'google analytics', 'hadoop', 'simulations', 'text mining', 'hive', 'mysql', 'map', 'r']","['sql', 'python', 'tableau', 'google analytics', 'hadoop', 'hive', 'mysql', 'map', 'r']","['random', 'simulations', 'text mining']","['interrogation', 'marketing', 'construction']"
168,202,Senior Data Scientist,"the modern life and learning studio is looking for a strong data scientist to join our data science team to enable us to understand and drive data informed, high impact business decisions across our organization. in this role, you will be joining a team hungry to learn, leverage and value your expertise to grow the data science discipline into the rhythm of our bxt team structure. you will help shape and strengthen the business strategy for microsoft education and how technology can be used effectively in the classroom. you will have the opportunity to work closely with our product engineers, program managers, designers, and user researchers to help shape our business strategies for many of our products. the successful candidate will have experience analyzing data from a wide range of datasets and across a breadth of technology platforms. they enjoy challenging projects, have strong analytical and presentation skills, technical aptitude and a collaborative work style. we are looking for people who see challenges as opportunities, people who can look at complex problems and are able to provide actionable insights and informed decisions. responsibilities as a data scientist in the modern life and learning studio, you would be responsible for influencing stakeholders to make product improvements that yield business value by effectively making compelling cases through storytelling, visualizations, and other influencing tools data preparation, statistics, and machine learning to investigate problems with the goal of supporting the questions required to support the greatest business needs. excellent creative thinking skills with emphasis on developing innovative solutions to solve complex problems that may not have one clear answer. manipulate and analyze complex, high volume, high dimensionality data from varying sources using a variety of tools and data analysis techniques. use and promote data exploration techniques to discover new or previously unasked questions. provide input to software engineering teams on new analytical capabilities needed. training and knowledge transfer to several software engineers and project managers across the team partner with researchers to help product teams better understand their users. help designers explore and understand scenarios in the product to address the unmet needs of the users. qualifications 5 years work experience as a data scientist experience with r or python and sql experience with one or more of the following technologies c, c , c , shell scripting, java, scope, hive, mapreduce, scala, spark, or pig bachelor s degree is required, with preference given to a quantitative , or applied science discipline. ms, or dedicated data science training preferred microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['c', 'hive', 'java', 'sql', 'python', 'statistics', 'software', 'scala', 'data science', 'machine learning', 'data preparation', 'data analysis', 'shell scripting', 'high dimensionality', 'datasets', 'project managers', 'legal requirements', 'mapreduce', 'r']","['mapred', 'sql', 'python', 'scala', 'c', 'hive', 'java', 'shell scripting', 'r']","['high dimensionality', 'machine learning', 'statistics', 'data preparation', 'software', 'datasets', 'data science', 'project managers', 'data analysis']","['education', 'business value', 'business strategy', 'legal', 'recruiting', 'regulations']"
169,203,"Data Scientist, Remote","introduction as a data scientist, you will be working closely with a fast paced software engineering team consisting of open minded and highly skilled individuals, that designs and continuously delivers a wide range of data analytics services for both clients and business partners. company infostrux is a select snowflake services partner building and operating reliable as code data cloud solutions for business intelligence, data analytics, and data product use cases. position overview interact with technical as well as purely business oriented clients analyze and document data science requirements, report progress and present results analyze data in any way needed, build statistical and machine learning models, help with ai projects work closely with data engineers on importing data from various data sources, data cleaning, integration, enhancement and validation suggest reusable patterns and process improvements to be implemented across the whole organization follow the trends and newest techniques and approaches in data science and bring them to practice where appropriate mentor other engineers qualifications passion for data excellent communication and technical writing skills experience with and deep understanding of different data science methodologies, approaches and processes 2 years of hands on data science experience hands on experience with aws, azure and or or gcp subject matter expertise in various business domains desired m.sc or ph.d. degree strong math or statistics or data mining or machine learning or ai background sql, nosql, spark or similar technologies python, r, javascript, kotlin or java, scala some software engineering experience","['data cleaning', 'technical writing', 'javascript', 'java', 'data analytics', 'sql', 'gcp', 'statistics', 'python', 'kotlin', 'software', 'scala', 'data science', 'integration', 'aws', 'nosql', 'data mining', 'machine learning', 'ai', 'business intelligence', 'snowflake', 'r']","['sql', 'python', 'gcp', 'kotlin', 'scala', 'java', 'aws', 'business intelligence', 'javascript', 'snowflake', 'nosql', 'r']","['data mining', 'data analytics', 'machine learning', 'use cases', 'statistics', 'software', 'data science', 'data cleaning', 'integration', 'technical writing', 'ai']",['validation']
170,204,"Data Scientist, Machine Learning Model Validation","td description tell us your story. don t go unnoticed. explain why you re a winning candidate. think td if you crave meaningful work and embrace change like we do. we are a trusted north american leader that cares about people and inspires them to grow and move forward. stay current and competitive. carve out a career for yourself. grow with us. department overview td model validation group is responsible for the independent validation and approval of analytical models used for risk, pricing, hedging, insurance, marketing and capital evaluation for portfolio of financial products. this also includes validation of decision making models. job description the position reports to senior manager, non retail model validation group within mv. detailed accountabilities include validate machine learning models and ai applications. develop or implement machine learning model validation methodologies and standards. ensure that the validation methodologies and standards are in line with industry best practice or address regulatory and audit requirements and or or findings in a timely manner. develop and apply a variety of statistical tests and modeling techniques to identify or recommend improvements to models and undertake related initiatives. ensure extensive testing of model sensitivity that help assessing model behavior and risk. implement and evaluate external models used for benchmarking internal model performance. participate in model selection and related due diligence activity. actively participate with business partners in internal data management to ensure data integrity and the completeness of data capture for model validation and development purpose. maintain full professional knowledge of techniques and developments in the field of machine learning and share knowledge with business partners and senior management. the position involves working effectively with different internal partners such as td wealth, td insurance, ed a, pbsa, layer6 and etc. job requirements strong quantitative skills with an advanced degree in one or more of the following areas computer science, mathematics, physics, statistics, machine learning, economics, finance, engineering, and or or actuarial science. up to 3 years experience of working in analytical environments. experience with and strong knowledge of machine learning theory and predictive algorithms bagging and gradient boosting methods, neural networks or deep learning, nlp, generalized additive models, graphical models, bayesian or probabilistic methods and etc. experience or knowledge of machine learning model interpretation or explanation, as well as bias or fairness assessment, tools and algorithms. experience with big data analytics tools and environments, such as, hadoop or hive, spark, and h2o. ability to research and implement machine learning algorithms from academic research papers is a plus. object oriented programming skills. proficient in one or more programming languages such as java, scala, python and or or r. knowledge of neural network tools such as tensorflow or keras, pytorch and or or mxnet. excellent verbal and written communication skills . quick learner who constantly works on improving their skills and expertise. good time management and multitasking skills with minimal supervision. inclusiveness at td, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. if you require an accommodation for the recruitment or interview process , please let us know and we will work with you to meet your needs. job family advanced analytics modelling job category primary enterprise data analytics job category enterprise data analytics hours 37.5 business line corporate time type full time employment type regular country canada province or state quebec city montreal work location 1350 rene levesque blvd corporate, td centre td tower 66 wellington street west provstate 2 ontario city 2 toronto job expires 13 jul 2021","['go', 'pytorch', 'tensorflow', 'data integrity', 'hive', 'java', 'data analytics', 'python', 'statistics', 'keras', 'scala', 'physics', 'enterprise', 'analytics', 'programming', 'bayesian', 'r', 'machine learning', 'testing', 'algorithms', 'model', 'deep learning', 'due diligence', 'programming languages', 'economics', 'hadoop', 'neural networks', 'nlp', 'computer science', 'mathematics', 'modeling', 'data management', 'ai']","['go', 'python', 'keras', 'programming languages', 'scala', 'pytorch', 'hadoop', 'big', 'nlp', 'programming', 'hive', 'java', 'r']","['tensorflow', 'data integrity', 'data analytics', 'statistics', 'tests', 'physics', 'enterprise', 'analytics', 'bayesian', 'machine learning', 'testing', 'algorithms', 'model', 'deep learning', 'due diligence', 'economics', 'neural networks', 'computer science', 'mathematics', 'modeling', 'data management', 'ai']","['validation', 'environment', 'benchmarking', 'marketing', 'capital', 'retail', 'finance', 'actuarial science', 'h', 'assessment', 'hedging', 'developments', 'insurance']"
171,205,"Data Scientist, R&D for Data Analytics Platform","transforming the future with the convergence of simulation and data data scientist, r d for data analytics platform do you like a challenge, are you a complex thinker who likes to solve problems if so, then you might be the new altairian we are searching for. at altair, your curiosity matters. we pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients success, as well as our own. job summary as a data scientist, you will be part of the product team, working in an r d capacity for development of features for the altair s data analytics platform. what you will do researching industry best practices for features to be implemented in the data analytics platform, with a focus on data science features including data preparation, machine learning, automl and explainable ai features ensuring that new features fit within the architecture of the data analytics platform developing python or r prototypes of the above data science features working closely with multiple developer teams to productize the python and r templates in the data analytics platform, ensuring incremental value delivered with each software version release what you will need basics advanced python, sql and r , including experience with data processing and ml pipelines excellent knowledge of the landscape of data analytics tools, including open source tools as well as enterprise platforms. experience working with big data 2 years experience building models that have achieved business value or reached production able to work in a fast paced environment can collaborate with others and build relationships with multiple teams, including developers, designers, subject matter experts and stakeholders empathy to translate end user needs into valuable features excellent communication skills able to communicate complex technical features to non technical teams and stakeholders. not afraid to ask for help when needed how you will be successful envision the future communicate honestly and broadly seek technology and business firsts embrace diversity and take risks what we offer competitive salary comprehensive benefit package outstanding work or life balance flex time paid holidays paid time off for community services collaborative environment why work with us altair is a global technology company that provides software and cloud solutions in the areas of product development, high performance computing and artificial intelligence . altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. with more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today s problems into tomorrow s opportunities. our vision is to transform customer decision making with data analytics, simulation, and high performance computing and artificial intelligence . for more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop ai, simulation and data driven digital twins to drive better decisions, and deliver advanced hpc and cloud solutions to support unlimited idea exploration. to learn more, please visit altair.com . ready to go onlyforward at our core we are explorers adventurers pioneers. we are the brains behind some of the world s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. we are the original trailblazers that make the impossible possible discovering new solutions to our customer s toughest challenges. altair is an equal opportunity employer. our backgrounds are diverse, and every member of our global team is critical to our success. altair s history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.","['go', 'data analytics', 'python', 'machine learning', 'data preparation', 'sql', 'ai', 'data processing', 'software', 'computing', 'data science', 'artificial intelligence', 'big data', 'hpc', 'pipelines', 'electronics', 'r']","['go', 'sql', 'python', 'big data', 'hpc', 'pipelines', 'electronics', 'r']","['data analytics performance', 'data analytics', 'computing', 'machine learning', 'data preparation', 'data processing', 'software', 'data science', 'artificial intelligence', 'ai']","['environment', 'subject matter experts', 'business value', 'business culture', 'design', 'templates', 'product value', 'product development', 'architecture']"
172,206,Data Scientist - Financial Crimes,"address 100 king street west job family group data analytics reporting applies knowledge of advanced analytic algorithms and technologies to deliver better predictions and or or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. applies strong communication and story telling skills to summarize statistical or algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business or groups. drives innovation through the development of data ai products that can be leveraged across the organization and establishes best practices in in alignment with data ai governance frameworks of bmo. acts as a trusted advisor to assigned business or group. influences and negotiates to achieve business objectives. recommends and implements solutions based on analysis of issues and implications for the business. assists in the development of strategic plans. identifies emerging issues and trends to inform decision making. understands and analyzes complex business problem, then formulates data driven hypotheses to drive business value. builds effective relationships with internal or external stakeholders and ensures alignment. supports data collection, integration, and retention requirements for data. develops experimental design approaches to validate findings or test hypotheses. defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets. diagnoses and resolves predictive or analytical model performance issues while monitoring system performance and implementation of efficiency improvements. applies innovative and best practices to advanced analytics services to ensure high quality standards. sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work. develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. provides advice and guidance to assigned business or group on implementation of analytical solutions. works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and or or decisions. works with various data owners to discover and select available data from internal sources and external vendors to fulfill analytical needs. applies scripting or programming skills to assemble various types of source data into well prepared datasets with multiple levels of granularities . develops agreed analytical solution by applying suitable statistical machine learning techniques to test, verify, refine hypotheses. summarizes statistical findings and draws conclusions, presents actionable business recommendations. presents findings recommendations in a simple, clear way to drive action. documents data flow, systems and processes in data collection to improve efficiency and apply use cases. performs experimental design approaches to validate finding or test hypotheses. uses the appropriate algorithms to discover patterns. builds effective relationships with internal or external stakeholders and ensures alignment. supports development of tools and delivers training for data analytics and ai. supports development and execution of strategic initiatives in collaboration with internal and external stakeholders. leads or participates in the design, implementation and management of core business or group processes. focus is primarily on business or group within bmo may have broader, enterprise wide focus. provides specialized consulting, analytical and technical support. exercises judgment to identify, diagnose, and solve problems within given rules. works independently and regularly handles non routine situations. broader work or accountabilities may be assigned as needed. qualifications typically between 5 7 years of relevant experience and post secondary degree in related field of study or an equivalent combination of education and experience. advanced degree in computer science, mathematics, physics, engineering, statistics, or other quantitative disciplines and or or equivalent experience experience with distributed computing language cloud technologies . experience with programming languages and machine learning or deep learning algorithms or packages . deep proficiency in statistical analysis, quantitative analytics, forecasting or predictive analytics, multivariate testing, and optimization algorithms. deep knowledge and technical proficiency gained through extensive education and business experience. verbal written communication skills in depth. collaboration team skills in depth. analytical and problem solving skills in depth. influence skills in depth. data driven decision making in depth. we re here to help at bmo we are driven by a shared purpose boldly grow the good in business and life. it calls on us to create lasting, positive change for our customers, our communities and our people. by working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world. as a member of the bmo team you are valued, respected and heard, and you have more ways to grow and make an impact. we strive to help you make an impact from day one for yourself and our customers. we ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. from in depth training and coaching, to manager support and network building opportunities, we ll help you gain valuable experience, and broaden your skillset. to find out more visit us at https or or jobs.bmo.com or ca or en . bmo is committed to an inclusive, equitable and accessible workplace. by learning from each other s differences, we gain strength through our people and our perspectives. accommodations are available on request for candidates taking part in all aspects of the selection process. to request accommodation, please contact your recruiter.","['https', 'computing', 'data flow', 'statistical analysis', 'data analytics', 'statistics', 'reporting', 'scripting', 'physics', 'data', 'analytics', 'integration', 'programming', 'machine learning', 'pattern detection', 'testing', 'quantitative', 'data collection', 'algorithms', 'forecasting', 'automation', 'deep learning', 'experimental', 'programming languages', 'technical proficiency', 'datasets', 'data solutions', 'computer science', 'mathematics', 'optimization', 'system performance', 'ai']","['https', 'programming languages', 'programming', 'predictive', 'model performance', 'system performance']","['computing', 'multivariate', 'data flow', 'technical support', 'statistical analysis', 'distributed', 'data analytics', 'statistics', 'reporting', 'scripting', 'physics', 'analytics', 'integration', 'machine learning', 'quantitative', 'testing', 'data collection', 'algorithms', 'forecasting', 'automation', 'deep learning', 'use cases', 'experimental', 'datasets', 'data solutions', 'computer science', 'mathematics', 'optimization', 'pattern detection', 'ai']","['education', 'business value', 'design', 'customer experience', 'business strategy', 'governance', 'consulting', 'strategic initiatives']"
173,207,Senior Data Scientist,"nucleo digital is searching for a senior data scientist help us design and build a modern tech stack for our client. we are looking for individuals who are passionate about the latest technologies and can lead the design and development of nimble and scalable applications. a successful candidate will bring deep analytical ability, software engineering expertise, and the ability to deliver results within a fast moving agile environment. requirements the following is a general description of the qualities that will make sure you are successful in this role. to be successful in this role you need to be comfortable with one or more dynamic programming languages, preferably java, c, r, python. strong experience with sql and nosql, particularly the platforms mongodb, elasticsearch, postgres, ms sql and db2. proficiency in mainstream machine learning or deep learning frameworks sklearn or tensorflow or keras or pytorch, etc. knowledge of classic and modern machine learning theories and algorithms especially using their output to create business enhancing knowledge graphs. experience in modular design for software development, such as creating and working with microservices experience with distributed systems such as spark and hadoop you articulate complex technical issues in plain language and always endeavour to improve and expand how you communicate. you thrive on rapid feedback and iterations to improve your practice. this team operates best with open collaborative communications channels. what is the job your role can be described as prime of the enterprise data team. to achieve this, you will collaborate with multiple teams and business departments. guide company projects to deliver and consume reliable, stable, and consistent dataset to the rest of the business. lead the design, development, and delivery of our end to end data and advanced analytics strategy to power our business platforms. day to day this role requires you to have significant skills and capabilities in delivering the following with speed, quality, and accuracy. design database structure or schema as well as etl processes to integrate data sources across the organization. curate and prepare data from multiple sources and apis in various forms for business consumption on regular basis. define data curation process automating the update and monitoring. build data solutions including search, machine learning models and knowledge graphs. participate in the building and maintenance of necessary microservices for the data solutions. coach and support data team members as well as develop and manage relationships with data vendors and partners. define data objects suitable for our enterprise requirements. diligently document your work and actions so they are repeatable actions. propose technical design and lead the implementation of data solutions. analyze existing database designs for performance or feature enhancement. what could your strong points be this role is an experienced one, with extensive experience in data wrangling, data science, and analysis. you are talented, measured by motivation, alignment of purpose, skills, depth of experience and learning agility. with this you bring to the team a sharpness, kindness, and open mindedness that is fuelled by both excellence and impact. a quick learning capability and are actively staying on top of the latest in the world of data science experience with the full data stack data analysis, data engineering, data science, and data infrastructure. effective communication able to build credibility and trust with the business. a hunger to make significant contribution to building and growing an impact driven ai and technology business over a period of several years. benefits what this full time position has to offer competitive salary or rate commensurate with experience supportive, challenging, and collaborative work environment","['pytorch', 'tensorflow', 'data infrastructure', 'technical design', 'c', 'mongodb', 'distributed systems', 'java', 'data curation', 'sql', 'agile environment', 'python', 'keras', 'software', 'elasticsearch', 'data science', 'software development', 'analytics', 'microservices', 'data engineering', 'nosql', 'machine learning', 'ai', 'data analysis', 'rest', 'algorithms', 'enterprise data', 'deep learning', 'programming languages', 'data wrangling', 'hadoop', 'data solutions', 'analytical', 'etl', 'r']","['sql', 'python', 'keras', 'programming languages', 'pytorch', 'hadoop', 'elasticsearch', 'c', 'java', 'nosql', 'r']","['tensorflow', 'data infrastructure', 'technical design', 'mongodb', 'distributed systems', 'data curation', 'agile environment', 'software', 'data science', 'software development', 'analytics', 'microservices', 'data engineering', 'machine learning', 'analytical ability', 'data analysis', 'rest', 'algorithms', 'enterprise data', 'deep learning', 'data wrangling', 'data solutions', 'etl', 'ai']","['forms', 'environment', 'design']"
174,208,"Data Scientist, Advertising Revenue Recommendations","bachelor s degree 3 years of experience with data scripting languages or statistical or mathematical software 2 years working as a data scientist experience in as many of the following areas causal inferencing, multi variate testing design, a or b testing design, descriptive analytics, and regression analysis. good understanding of supervised and unsupervised learning models. amazon advertising is one of amazon s fastest growing and most profitable businesses. as a core product offering within our advertising portfolio, sponsored products helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through amazon. the sp team s primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. our products and solutions are strategically important to enable our retail and marketplace businesses to drive long term growth. we deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day to be successful with amazon advertising, customers need to receive high quality recommendations that inform them of the right opportunities that help grow, defend and drive their business. to generate these high quality recommendations, we must discover differentiated insights that allow advertisers to understand the performance of their business over time, and performance and growth against their peers. this requires us to create models that predict successful outcomes for customers, create workflows for implementation, and measure the downstream impact of our recommendations. our science investment in this area helps advertising customers choose when to make changes to their advertising strategy, specifies the changes to make to drive their strategy, and predicts how their business will change as a result. job responsibilities contribute to customer facing products provide insights and metrics to track recommendation performance downstream impact. solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ml models by tailoring to business needs, and collaborating with scientists, engineers, bie s, and product managers. utilize code to analyze data and build statistical models to solve specific business problems. apply statistical or machine learning knowledge to specific business problems and data. build decision making models and propose solution for the business problem you defined translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. in cases where questions cannot be answered with available data, work with engineers to produce the required data. deliver with independence on challenging large scale problems with ambiguity. retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance. analyze historical data to identify trends and support decision making. improve upon existing methodologies by developing new data sources, testing model enhancements, and fine tuning model parameters. provide requirements to develop analytic capabilities, platforms, and pipelines. formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. work out why such examples are outliers and define if any actions needed. given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes. conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication. why you love this opportunity amazon is investing heavily in building a world class advertising business. this team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. our solutions generate billions in revenue and drive long term growth for amazon s retail and marketplace businesses. we deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world class products. we are highly motivated, collaborative, and fun loving team with an entrepreneurial spirit with a broad mandate to experiment and innovate. impact and career growth you will invent new experiences and influence customer facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising this is your opportunity to work within the fastest growing businesses across all of amazon define a long term science vision for our advertising business, driven fundamentally from our customers needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. this role combines science leadership, organizational ability, technical strength, product focus, and business understanding. team video https or or youtu.be or zd 6lzw8rae phd in statistics, economics or related quantitative field. experience in measurement problems, causal inferencing, multi variate testing design, a or b testing design, manipulating data analyzing very large data sets, descriptive analytics, and regression analysis. excellent quantitative modeling, good knowledge of ml methods, statistical analysis, and problem solving skills. experience processing, filtering, and presenting large quantities of data. experience using ml libraries, such as scikit learn, caret, mlr, mllib combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer s organization. demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences. ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations. demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment. experience in advertising is a plus. amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. for individuals with disabilities who would like to request an accommodation, please visit https or or or en or disability or us amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. for individuals with disabilities who would like to request an accommodation, please visit https or or or en or disability or ontario","['https', 'statistical analysis', 'regression analysis', 'statistics', 'software', 'dynamics', 'analytics', 'data', 'pipelines', 'machine learning', 'quantitative', 'testing', 'economics', 'business insights', 'quantitativeiate', 'simulations', 'modeling', 'script', 'system performance']","['https', 'pipelines', 'system performance', 'scikitr']","['mathematical', 'regression analysis', 'machine learning', 'statistics', 'software', 'quantitative', 'testing', 'scripting', 'economics', 'dynamics', 'simulations', 'data', 'variate', 'analytics', 'fine tuning', 'modeling', 'ml', 'statistical analysis']","['environment', 'investing', 'advertising', 'metrics', 'retail', 'business understanding', 'design', 'sales', 'inferencing', 'auction']"
175,211,"Data Scientist, Advanced Analytics, Global Risk Management - Toronto, ON","requisition id 106515 join a purpose driven winning team, committed to results, in an inclusive and high performing culture. the data scientist, advanced analytics will support business use cases delivery, in an agile rapid lab environment, aimed at accelerating benefits for customers and the bank, leveraging enterprise level data management tools and advanced analytics. she or he will work closely with peers across global risk teams, the business lines, it s and digital banking to expand the credit science practice and drive the grm analytics coe interaction model. the candidate will identify and prioritize opportunities to deliver innovative retail credit solutions leveraging risk reward predictions and strategy optimization frameworks. is this role right for you in this role you, will work in agile rapid lab environment to deploy new credit solutions in 90 day increments support forward thinking, high impact analytical use cases focused on supporting grm data, analytics and technology strategy and deliver actionable insights to capitalize on business opportunities collaborate with grm analytics coe key stakeholders and partners to define machine learning and artificial intelligence best practices for agile rapid labs support risk reward predictions delivery, strategy optimizations and machine learning playbooks to drive innovative credit solutions within risk appetite thresholds build 1 2 analytical playbooks across global retail and business banking footprint to support growth or de risking initiatives support research development work focused on the effective application of design thinking and scalable advanced techniques to drive ideation and innovation in analytics, machine learning and artificial intelligence support a high performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment communicating vison or values or business strategy and managing succession and development planning for the team support grm analytics coe with thought leadership and r d activities to influence grm stakeholders on trends regarding practical applications of machine learning and artificial intelligence to banking understand how the bank s risk appetite and risk culture should be considered in decision making do you have the skills that will enable you to succeed in this role we d love to work with you if you have post graduate degree in relevant stem discipline 1 3 years working experience in data science or machine learning or modeling, financial industry or fintech preferred ability to ingest and work with large volumes of structured and unstructured non traditional data working experience with big data tools such as sql, hive, spark working experience with open source programming languages such as python, pyspark, r, scala working experience with ml or ai techniques for strategy design knowledge of strategy optimization leveraging operations research principles would be an asset working experience with cloud computing platforms such as ms azure and google cloud working experience with devops principles and or or software engineering best practices would be an asset working knowledge of visualization tools such as tableau and power bi would be an asset strong collaboration skills with ability to translate technical knowledge into business value effective communication skills with ability to prepare project documentation and presentations what s in it for you the opportunity to join a forward thinking company surrounded by a collaborative team of innovative thinkers. a rewarding career path with diverse opportunities for professional development. internal development to support your growth and enhance your skills. a competitive compensation and benefits package. an organization committed to making a difference in our communities for you and our customers. we have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success this position is located downtown toronto location canada ontario toronto scotiabank is a leading bank in the americas. guided by our purpose for every future , we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['project', 'visualization', 'design thinking', 'tableau', 'pyspark', 'documentation', 'big data', 'working experience', 'hive', 'sql', 'python', 'scala', 'software', 'data science', 'analytics', 'cloud computing', 'r', 'machine learning', 'artificial intelligence', 'banking', 'programming languages', 'bi', 'devops', 'optimization', 'modeling', 'data management', 'ai']","['sql', 'python', 'tableau', 'programming languages', 'pyspark', 'scala', 'bi', 'grm', 'big data', 'hive', 'r']","['project documentation', 'use cases', 'machine learning', 'banking', 'design thinking', 'ai', 'software', 'visualization', 'devops', 'data science', 'analytics', 'artificial intelligence', 'optimization', 'modeling', 'working experience', 'data management', 'cloud computing', 'planning']","['environment', 'private', 'compensation', 'fintech', 'retail', 'gr', 'development work', 'research', 'grm', 'design', 'business value', 'business strategy', 'presentations', 'investment banking', 'capital markets', 'risk appetite', 'business']"
176,213,Senior Data Scientist,"for over forty years, vanguard has been on a mission to change the way the world invests. from our outstanding ownership structure to our low cost options, we are committed to our belief that nothing should stand in the way of investors meeting their goals. our center for analytics insights is dedicated to removing obstacles to these investors by using advanced analytics to solve our most difficult problems. do you want to lead and execute investigate diagnostic, predictive, and prescriptive analytics to support data driven business decision making you will be responsible to build alternative model approaches to assess sophisticated model design and advance future capabilities. mentors and develops junior data scientists and analysts. in this role you will leads the execution of large scale, more complex analytics projects. applies significant quality control and risk assessment of the model, methodologies, outputs, and processes for major data science projects. identifies and diagnoses data inconsistencies and errors, documents data assumptions, and forages to fill data gaps. engages with senior leadership to understand and probe business processes in order to develop hypotheses. brings structure to requests and translates requirements into an analytic approach. guides test design, research design, and model validation. provides statistical consultation services. serves as the analytics authority on cross functional teams for large critical initiatives and supplies to the growth of the vanguard analytic community. prepares and delivers insight presentations and action recommendations. communicates sophisticated analytical findings and implications to business leaders. reimagine the investment experience a world class client experience is something that can only be defined by our clients. leading the development and delivery of advanced, meaningful analytic products and services you will work to uncover difficulties and challenges a client may face and how they may differ across product lines. using analytical approaches such as predictive and prescriptive modeling your goal will be to bring tangible and significant business impact on vanguard s businesses and clients to drive overall efficiency. qualifications of the position minimum of eight years related work experience in analytical roles. experience with data wrangling required programming skills to access, transform and prepare large scale data for statistical modeling. experience utilizing statistical and machine learning methods required. undergraduate degree in analytics, applied mathematics, economics, statistics or related analytical field of study or equivalent combination of training and experience. graduate degree preferred. an ideal candidate will have graduate degree in a quantitative or analytical field such as data science, machine learning, mathematics, statistics, economics, computer science, engineering, operations research, physics, or other meaningful scientific field phd preferred. undergraduate degree in analytics, applied mathematics, economics, statistics or related analytical field of study or equivalent combination of training and experience. deep understanding and experience building models using deep learning, machine learning and optimization methods , tree based models, svm, random forests, gbm, time series analysis, linear or non linear or integer programming, etc. demonstrated experience in using the above methods to solve complex business problems thereby generating insights and providing best in class data driven solutions for customers. proven experience in managing and leading large complex projects, including formulating the business and analytical problem, extracting, cleansing, and manipulating large, and diverse data sets, building descriptive, predictive and prescriptive solutions and deploying these solutions in the cloud and or or on premise systems. proven experience in presenting analytical solutions, data relationships and results, and their business impacts to multiple business partners and, through outstanding data visualization and storytelling skills. strong proficiency in python, r, spark . about vanguard we are vanguard. together, we re changing the way the world invests. for us, investing doesn t just end in value. it starts with values. because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. we invest with purpose and that s how we ve become a global market leader. here, we grow by doing the right thing for the people we serve. and so can you. we want to make success accessible to everyone. this is our opportunity. let s make it count. inclusion statement vanguard s continued commitment to diversity and inclusion is firmly rooted in our culture. every decision we make to best serve our clients, crew , and communities is guided by one simple statement do the right thing. we believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. we empower our crew to contribute their distinct strengths to achieving vanguard s core purpose through our values. when all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on vanguard s core purpose. our core purpose to take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.","['data visualization', 'cleansing', 'quality control', 'python', 'statistics', 'time series analysis', 'physics', 'data science', 'analytics', 'programming', 'machine learning', 'statistical', 'risk assessment', 'model', 'deep learning', 'data wrangling', 'economics', 'computer science', 'mathematics', 'optimization', 'modeling', 'applied mathematics', 'r']","['python', 'programming', 'r']","['data visualization', 'cleansing', 'quality control', 'statistics', 'time series analysis', 'physics', 'data science', 'analytics', 'machine learning', 'test', 'statistical', 'risk assessment', 'model', 'deep learning', 'data wrangling', 'economics', 'computer science', 'mathematics', 'optimization', 'modeling', 'applied mathematics']","['validation', 'investing', 'consultation', 'presentations', 'design', 'operations', 'for', 'product lines']"
177,214,Senior Professional Environmental Scientist (Geoscience) and Business Lead,"senior professional environmental scientist and business lead duncan or abbotsford, b.c. madrone environmental services ltd. has immediate openings for a senior professional environmental scientist and business lead at our duncan or abbotsford offices. this is a full time position with comprehensive benefits. madrone is a well established environmental services company offering our employees a flexible work environment as well as exciting opportunities to advance within their professions. our interdisciplinary team of professionals include biologists, foresters, geoscientists, geomorphologists, hydrologists, agrologists and archaeologists. working together, we help our clients achieve best use of natural resources while meeting environmental protection goals. wage will be commensurate with experience. opportunity as a senior professional environmental scientist with madrone s geoscience practice, you will be the geoscience business lead and senior team member focused on the successful initiation to completion of projects, whose practice experience, organizational skills and leadership will play a pivotal role in our current breadth of geoscience practice. your role will be to provide technical expertise with the delivery of current projects, develop new business, and provide senior technical support and mentorship to staff. you will work with a team of professionals on a variety of initiatives to advance the efficiency of operations while providing mentorship for junior professionals and achieving business development goals for the geoscience business group. requirements master s degree in geology, earth sciences, or engineering, or equivalent, preferred professional geoscientist or professional engineer registration in good standing, or eligible for immediate registration in the province of british columbia minimum 15 years of consulting experience or equivalent, focused on geoscience related services including practice in land development, mining, forestry, and government ability to develop complex and long duration projects through effective client, landowner and regulator liaisons, and to develop detailed scopes of work to facilitate client goals and regulatory requirements project and team management experience is required, including effective management of schedules and budgets direct leadership experience in guiding intermediate and junior geoscience staff on project deliverables, and ability to supportively collaborate with a diversity of qps both of which are borne by excellent interpersonal communication and writing ability previous relevant client management and business development experience is preferred recent field experience within western canada and with applicable legislative frameworks strong organizational, time management, problem solving and analytical skills. general duties include adherence and promotion of all safety procedures data driven permitting and regulatory support services mentoring, developing and providing technical guidance to intermediate and junior staff develop and manage strong relationships with new and existing clients ensuring appropriate quality management on all team s projects participating in multi disciplinary project teams, guiding and coaching others contributing to the overall strategic development of the geoscience group, including growth, profitability and supporting the development of new processes, services, geographies and client sectors project management duties include cost tracking, invoicing, and working with deliverable deadlines leading specific tasks and objectives related to supervision or advisement of external 3rd party contractors. notice regarding covid 19 all interviews will be conducted virtually to maintain the safety of the applicants and interviewers. please send a cover and r sum attention to michelle lancaster, hr manager. we thank all applicants, however, only those shortlisted will be contacted. application deadline june 28, 2021 but may be extended until filled. visit our website at please visit our website to view all current job postings job types full time, permanent salary 38.00 51.00 per hour additional pay overtime pay benefits casual dress dental care employee assistance program extended health care flexible schedule life insurance on site parking paid time off vision care work from home schedule 8 hour shift day shift monday to friday overtime work remotely temporarily due to covid 19","['scopes', 'support services', 'analytical skills', 'r']","['c', 'r']","['technical support', 'scopes of', 'analytical skills']","['business development', 'environment', 'forestry', 'geology', 'regulatory requirements', 'job postings', 'project management', 'invoicing', 'hr', 'consulting', 'earth sciences', 'government', 'environmental', 'land development', 'insurance', 'mentoring']"
178,215,Pricing Data Scientist,"with thousands of beautiful spaces built for travel and living, sonder is transforming the future of hospitality. each sonder is purposefully selected, designed and maintained customized to reflect the vibe of its neighborhood. whether your stay is two days, two months or two years, in a studio or a six bedroom, sonder ensures a unique, yet consistent experience. and with 24 or 7 contactless service, professional cleanings that exceed cdc recommendations, and over 200 other quality standards, we re taking stay further for guests all around the world. sonder started in 2014, and now has thousands of spaces in cities across the globe. at sonder you will drive revenue growth by developing, deploying and testing optimal pricing algorithms and strategies across sonder s portfolio of units solve fundamental pricing strategy problems such as how do we develop a unique pricing strategy across our wide range of markets how do we identify and price optimally across different customer segments how do we optimally allocate inventory and build up bookings across channels how do we price and allocate inventory across different lengths of stay to maximize calendar utilization and contribution margin how do we test and measure the effectiveness of our pricing strategy define and implement a rigorous set of pricing metrics and experimentation methodologies partner with engineering, analytics and pricing ops team to implement and operationalize various pricing solutions partner with other functions such as sales, distribution and markets to define revenue strategy, targets and pricing guardrails what we look for bachelor degree in economics or econometrics, quantitative finance, computer science, math, engineering, or related quantitative field. experience working with product and engineering teams at high growth companies to solve problems, identify trends and opportunities, productionize recommendations prior experience in pricing optimization in a related industry is a big bonus 3 years experience in a data science role 3 years of experience with sql and python great communication skills being able to explain your work and the impact on the business to all types of business partners high energy self starter with a passion for data, attention to detail, and a positive attitude we also have great benefits to make your life easier so you can focus on what you re best at competitive salary generous stock option plan medical, dental and vision insurance unlimited vacation annual free credits and discounts to stay in sonders a company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work with colleagues we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status or other protected classes avec des milliers de beaux espaces construits pour le voyage et la vie, sonder transforme l avenir de l hospitalit . chaque sonder est s lectionn , con u et entretenu de mani re cibl e, et personnalis pour refl ter l ambiance de son quartier. que votre s jour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, sonder vous garantit une exp rience unique, mais coh rente. et gr ce un service sans contact 24 heures sur 24, 7 jours sur 7, des nettoyages professionnels qui d passent les recommandations de l aspc et plus de 200 autres normes de qualit , nous allons encore plus loin pour nos clients du monde entier. sonder a d but en 2014, et compte aujourd hui des milliers de chambres dans des villes du monde entier. sonder a d but il y a un peu plus de cinq ans et compte aujourd hui des milliers de places dans des villes du monde entier. l quipe de pricing data science est particuli rement bien plac e pour assurer le succ s et la rentabilit de sonder. l quipe cr e et met en uvre des strat gies de tarification bas es sur les donn es afin d optimiser les revenus et est responsable du d veloppement continu de nos mod les de pr vision. chez sonder, vous le ferez stimuler la croissance des revenus en d veloppant, en d ployant et en testant des algorithmes et des strat gies de tarification optimale dans l ensemble du portefeuille d unit s de sonder r soudre des probl mes fondamentaux de strat gie de tarification tels que comment laborer une strat gie de prix unique sur notre large ventail de march s comment identifier et fixer les prix de mani re optimale dans les diff rents segments de client le comment r partir les stocks de mani re optimale et constituer des r servations entre les diff rents canaux comment fixer le prix et r partir les stocks sur diff rentes dur es de s jour pour maximiser l utilisation du calendrier et la marge de contribution comment tester et mesurer l efficacit de notre strat gie de prix d finir et mettre en uvre un ensemble rigoureux de mesures de tarification et de m thodes d exp rimentation travailler en partenariat avec l quipe des op rations d ing nierie, d analyse et de tarification pour mettre en uvre et rendre op rationnelles diverses solutions de tarification tablir des partenariats avec d autres fonctions telles que les ventes, la distribution et les march s pour d finir la strat gie de revenus, les objectifs et les garde fous en mati re de prix ce que nous recherchons licence en conomie or conom trie, finance quantitative, informatique, math matiques, ing nierie ou domaine quantitatif connexe. exp rience de travail avec des quipes de produits et d ing nierie dans des entreprises forte croissance pour r soudre des probl mes, identifier des tendances et des opportunit s, produire des recommandations une exp rience pr alable dans l optimisation des prix dans un secteur connexe est un atout important 3 ans d exp rience dans un poste de data science 3 ans d exp rience avec sql et python grande capacit de communication tre capable d expliquer votre travail et l impact sur l entreprise tous les types de partenaires commerciaux une personne nergique, passionn e par les donn es, attentive aux d tails et ayant une attitude positive nous avons galement de grands avantages vous faciliter la vie pour que vous puissiez vous concentrer sur ce que vous faites le mieux un salaire comp titif un plan d options d achat d actions g n reux assurance m dicale, dentaire et visuelle vacances illimit es cr dits annuels gratuits et r ductions pour s journer sonders une entreprise qui a une grande vision, un environnement de travail dynamique et une quipe de coll gues intelligents, ambitieux et agr ables travailler nous sommes un employeur souscrivant au principe de l galit des chances et valorisons la diversit au sein de notre entreprise. nous ne faisons aucune discrimination fond e sur la race, la religion, la couleur, l origine nationale, le sexe, l orientation sexuelle, l ge, l tat civil, le statut d ancien combattant, le handicap ou d autres cat gories prot g es","['sql', 'python', 'quantitative', 'testing', 'economics', 'data science', 'computer science', 'analytics', 'optimization', 'algorithms', 'econometrics', 'ops', 'r']","['sql', 'python', 'r']","['quantitative', 'testing', 'economics', 'data science', 'computer science', 'analytics', 'optimization', 'pricing', 'algorithms', 'econometrics', 'ops']","['environment', 'metrics', 'bookings', 'finance', 'sales', 'hospitality', 'insurance']"
179,216,Data Scientist Engineer,"data scientist engineer 2100905 you can be part of an inclusive team of diverse talent and character. in this diversity lies our greatest strength. description at basf, we create chemistry through the power of connected minds. by balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. as the world s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation. we provide a challenging and rewarding work environment with a strong emphasis on process safety, as well as the safety of our employees and the communities we operate in and are always working to form the best team especially from within, through an emphasis on lifelong learning and development. and we are constantly striving to become an even better place to work. basf has been recognized as one of canadas best 100 employers in 2019. come join us on our journey to create solutions for a sustainable future data scientist engineer where the chemistry happens the data scientist will model complex business problems and provide insights through data analysis. in addition, the data scientist will be responsible for also evangelizing the capabilities of data science and basing decisions on data. the data scientist will be expected to participate in a community of practice to maximize the effectiveness of the insights team, through knowledge sharing and thoughtful curation of algorithms and methods. to identify opportunities for data driven insights, the data scientist, as an evangelist for marketing data science, will interact frequently with leaders and experts in various business organizations and become part of a global team. the data scientist will be responsible for coordinating and initiating their own activities as it relates to maximizing the value of insights delivered and derived from data. formula for success you will guiding business partners and non experts in the selection of valuable and feasible cases to create insights with statistics and machine learning. data selection and engineering model selection and optimization programming primarily in python model deployment in existing environments qualifications ingredients for success what we look for in you bachelor s degree in quantitative or computational science with a strong focus on marketing and statistics. 5 years experience in using statistic or modeling tools in non academic environment with a focus on business growth. certifications or publications relevant to data science, technical expertise, or marketing insights. demonstrated, hands on experience with r, python, or similar data science tools. significant experience with enterprise wide data initiatives and working with complex data and system infrastructures. experience in change management, scoping, requirements and solutions execution. experience in defining metrics and scorecards to demonstrate benefits of a successful data governance program. experience in handling exceptions and communication and partnering with cross functional teams. experience working in cloud first environments, particularly azure and aws. exposure to and experience with visualization tools . knowledge of it and business management information systems from a data perspective. strong communication skills demonstrated through work and education experiences understanding and prior experience with the agriculture industry a heavy plus. create your own chemistry what we offer you adding value to our customers begins with adding value to you. is the suite of benefits, perks, programs and unique opportunities we offer to support you the whole you in all stages of your life and career. with you create your own chemistry. the total rewards that you receive as a basf employee go way beyond a paycheck. from competitive health and insurance plans, to robust retirement benefits that include company matching contributions, to making sure you never stop learning, we believe investing in you is investing in our success. working for a large, global organization, you ll have a chance to grow professionally and personally, expand your network and build a rewarding and dynamic career. basf provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job primary location ca on mississauga function itse information technology services job type standard shift day job organization gda or bc rbps na canada mexico midwest 63009551","['go', 'python', 'machine learning', 'statistics', 'visualization', 'information technology', 'information systems', 'data science', 'chemistry', 'modeling', 'data', 'programming', 'optimization', 'aws', 'data analysis', 'algorithms', 'r']","['go', 'python', 'programming', 'aws', 'r']","['machine learning', 'statistics', 'visualization', 'information technology', 'information systems', 'data science', 'chemistry', 'modeling', 'data', 'optimization', 'data analysis', 'computational science', 'algorithms']","['environment', 'change management', 'investing', 'education', 'metrics', 'marketing', 'business management', 'retirement', 'governance', 'agriculture', 'environmental', 'insurance', 'business growth']"
180,217,Data Scientist - Molecular & Cell Engineering,"full timevancouver june 14, 2021 job id 21502 abcellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a highly motivated scientist with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our molecular cell engineering group. we focus on the discovery and development of therapeutic antibodies from natural immune repertoires, and believe that through teamwork, innovation, and mutual support, we can tackle the most challenging scientific problems. the successful candidate will interact with a multidisciplinary and dynamic team in a fast paced and focused environment. the candidate will be adept at multitasking, problem solving and critical thinking, and will demonstrate scientific rigour in their work. how you might spend your days using your understanding of molecular and cell biology to analyze and interpret large multifactorial data sets for the purpose of driving drug discovery, especially with regard to high throughput workflows and lead candidate selection facilitating effective communication between computational and experimental scientists, with an emphasis on bioinformatics and biology teams, in addition to other colleagues and partners organizing, supporting, and collaborating with team members to meet project deliverables and timelines building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high throughput experiments leading initiatives to standardize data output and data analysis training, mentoring, and supervising members of a dynamic team we d love to hear from you if you thrive in a collaborative environment you enjoy bringing out the best in your teammates you enjoy working in a fast paced work environment and coordinating with your team to juggle multiple competing priorities you take pride in being a self motivated person, fast learner, team player, and creative problem solver you are passionate about communicating complex data to interdisciplinary project teams required qualifications and experience phd or msc with work experience in a relevant field background in the life sciences molecular biology, cell biology, biochemistry, or biophysics preferred proficiency in python or r for analysis and data visualization demonstrated ability to create flexible data analysis pipelines intended for use by others experience working with and creating data architectures excellent skills in data visualization and presentation of key findings drive to learn and master new techniques excellent documentation and organizational skills impeccable attention to detail willingness to work flexible hours offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please submit your application through our website and refer to job id 21502 in your cover letter. only applicants selected for an interview will be contacted.","['python', 'machine learning', 'bioinformatics', 'high throughput', 'data visualization', 'documentation', 'data analysis', 'pipelines', 'solver', 'automation', 'r']","['python', 'documentation', 'pipelines', 'solver', 'r']","['machine learning', 'bioinformatics', 'high throughput', 'data visualization', 'micro', 'data analysis', 'automation']","['cell', 'environment', 'biology', 'antibodies', 'genomics', 'biophysics', 'biochemistry', 'life sciences', 'molecular', 'compensation', 'drug discovery', 'mentoring']"
181,219,Data Scientist – Antibody Assessment,"full timevancouver june 14, 2021 job id 21503 abcellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a highly motivated data scientist, with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our multidisciplinary team. our ideal candidate is a highly motivated and self directed scientist, a team player who thrives in a fast paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. this is an exciting opportunity to join one of canada s most innovative biotech companies and to contribute to our cutting edge research, driving the discovery of novel monoclonal antibodies for therapeutic use. how you might spend your days using your understanding of bioinformatics and biochemistry to analyze and interpret large multifactorial data sets for the purpose of driving drug discovery, especially with regard to lead candidate selection and predictive analysis organizing, supporting, and collaborating with team members to meet project deliverables and timelines building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high throughput analytical and biophysical experiments developing tools to collate, organize and process data inputs for our in house data visualization platform, celium. leading initiatives to standardize data output and data analysis for integration into laboratory information management systems or electronic notebook collaborating with other data scientists on projects, finding solutions, and sharing code we d love to hear from you if you thrive in a collaborative environment and enjoy bringing out the best in your teammates you enjoy working in a fast paced work environment and coordinating with your team to juggle multiple competing priorities you take pride in being a self motivated person, fast learner, team player, and creative problem solver you are passionate about analysis of complex data and communication to interdisciplinary project teams required qualifications and experience a graduate degree in bioinformatics, computational biology, immunology, immunogenetics, or a related field experience in the life sciences biochemistry, biophysics, cell biology, or molecular biology preferred proficiency in at least one common coding language python or r demonstrated ability to create flexible, reproducible data analysis pipelines intended for use by others experience working with and creating databases, data provenance, or data architectures excellent skills in data visualization and presentation of key findings drive to learn and master new techniques excellent documentation and organizational skills, with impeccable attention to detail a solid foundation in statistical analysis an understanding of basic machine learning would be desired offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please submit your application through our website and refer to job id 21503 in your cover letter. only applicants selected for an interview will be contacted.","['python', 'databases', 'machine learning', 'bioinformatics', 'high throughput', 'data visualization', 'data', 'documentation', 'integration', 'data analysis', 'information', 'pipelines', 'statistical analysis', 'r', 'solver', 'automation', 'computational biology']","['python', 'databases', 'documentation', 'pipelines', 'solver', 'r']","['machine learning', 'bioinformatics', 'computational', 'high throughput', 'management systems', 'data visualization', 'micro', 'integration', 'data analysis', 'information', 'statistical analysis', 'automation']","['cell', 'environment', 'therapeutic use', 'immunology', 'biology', 'antibodies', 'immune', 'immunogenetics', 'biophysics', 'biochemistry', 'genomics', 'life sciences', 'molecular', 'compensation', 'drug discovery']"
182,220,Data Architect,"job description we re a naan traditional company what is the recipe for a great career at fgf working at fgf brands, there is never a dull moment as a successful company that is continually growing there is always challenging yet rewarding work to be a part of. we have an entrepreneurial mindset which encourages all our team members to use their own creativity and out of the box thinking to come up with solutions and new ideas. let s be frank. fgf is not for everybody. our culture is unique. we dive headfirst into the unknown. if you re fun loving, talented and fearless, we re for you. what fgf offers disruptive and a naan traditional mindset an inclusive and dynamic culture accelerated career progression commitment to learning and development opportunity to be impactful competitive compensation data architect fgf brands is seeking an experienced data architect who will be responsible for the design and support of our data infrastructure and ecosystem. the position will be part of the business insight and analytics team. the ideal candidate will not only possess great communication skills but will also be very technical and hands on. additionally, the candidate requires deep it service management knowledge, coupled with broad technical knowledge, and the ability to design solutions by mapping business problems, providing end to end solutions combining process with technology. demonstrated ability to engage in discussions related to availability, agility, business value, security management, disaster recovery, and the value of process in an enterprise environment is required. the ideal candidate will be self motivated, a results driven technologist, who is passionate about building a highly scalable data infrastructure, keeping up with fgf brands rapid growth. key responsibilities defines data governance and standards to deliver a cohesive information architecture for fgf brands. define system level architecture and conduct dimension modeling data mart design. owns data solution design, methodology approach, and system architecture development. provide direction and insight on fgf data strategy, defining the target state architecture and roadmap. take active role in building, delivering and execution of target state architecture. actively work on migrating data from legacy systems to new solutions. design, document, construct and deploy database architectures and applications integrate technical functionality optimize and improve current database system performance by conducting tests, troubleshooting, and integrating new elements. break down complex projects and problems into actionable tasks that be delivered quickly and iteratively and provide value to the business stakeholders coordinate with data sciences department to identify future needs and requirements, supporting all translates user requirements and business use cases to conceptual, logical, and physical data models and workflow processes. translates a business glossary into logical and physical data models, and coach or supports data modelers, solution developers and data scientists in their development or testing or implementation effort. poc implementations and roadmap definition. work with a wide variety of data ranging between structured and un structured datasets own the kpis to measure the performance of the data ecosystem and provide visibility to senior leadership team provide operation support for information system. be a data advocate throughout the company qualifications 5 years of experience in enterprise environment working in data architecture or data warehouse, big data design and development. bs or ba or ms or ma in computer science or data science or related filed, or equivalent work experience highly preferred. data management association international certification as certified data management professional highly desired. expert level of experience working with sql server and relational databases and data modeling. strong programming skills and experience designing and building large scale data systems. sap bw and sap4hana exposure and knowledge is highly desirable. working experience with cloud based data warehouse technologies such as microsoft azure is highly desired. strong experience working in an agile development environment is highly desirable familiarity with data visualization tools knowledge of data mining and segmentation techniques proven analytical skills problem solving attitude devops knowledge fgf dna we are foodies and our passion is baked in... customer and product centricity you are always keeping our products front and center. flexibility, agility, adaptability you embrace speed, change and uncertainty. teamwork and collaboration you are a relationship builder. passion for excellence you look for innovative solutions and challenges the status quo. drives execution you are a risk taker or careers follow us on linkedin follow us on glassdoor follow us on instagram disclaimer the above describes the general responsibilities, required knowledge and skills. please keep in mind that other duties may be added, or this description may be amended at any time. genho ind1","['analytical skills', 'data infrastructure', 'data visualization', 'troubleshooting', 'working experience', 'microsoft azure', 'sql', 'security management', 'analytics', 'data', 'programming', 'data models', 'data systems', 'disaster recovery', 'data mining', 'relational databases', 'legacy systems', 'testing', 'information', 'user requirements', 'devops', 'datasets', 'system', 'computer science', 'uncertainty', 'it service management', 'modeling', 'data management', 'system performance']","['sql', 'legacy systems', 'programming', 'big data', 'data models', 'microsoft azure', 'system performance']","['analytical skills', 'data infrastructure', 'data visualization', 'troubleshooting', 'modeling', 'working experience', 'security management', 'tests', 'analytics', 'data', 'data systems', 'disaster recovery', 'data mining', 'relational databases', 'testing', 'agile development', 'data management', 'information', 'user requirements', 'use cases', 'devops', 'datasets', 'system', 'computer science', 'uncertainty', 'solution', 'methodology', 'it service management']","['environment', 'business value', 'design', 'sap', 'governance', 'functionality', 'linkedin', 'compensation', 'architecture']"
183,222,Senior Data Scientist,"about us propel is an innovative fintech company that provides services and unsecured financial products to consumers via a safe and secure online platform. propel was founded in 2011 in toronto to remove the complexity and bureaucracy that people often experience while trying to borrow money, and to provide an underserved population with unsecured credit in a respectful way and with extraordinary service. our goal is to provide our customers with a simple and convenient process our amazing team has experienced phenomenal growth and thrives on an entrepreneurial spirit, passion, and top tier talent. we believe in innovation and in measuring success through results and growing within talent and hard work never goes unnoticed, and we succeed together. about you you are a talented professional looking for a career, not a job. reporting to the chief risk officer, you will collaborate with business lines and other stakeholders and identify opportunities to drive business value. as a sr. data scientist you ll be working to uncover fraud and manage risk you picture yourself succeeding within a vibrant and entrepreneurial organization where your ideas will be heard, and where you will have an opportunity to showcase your talents and great skills. you are motivated by goals, a self starter, and a hardworking individual who likes to wear multiple hats. we are seeking a proven, driven team player who is looking to join a fast paced, high growth, energetic and forward thinking team. responsibilities ingest massive volumes of structured and unstructured format data, model, transform and store it in a variety of data stores. leverage distributed and open source computing tools for analysis, data mining and modeling. collaborate with data engineering and operational teams to deploy models and algorithms in production, across different channels and customer platforms. create and apply model and algorithm testing strategies to measure conduct multi variate testing and a or b testing to measure effectiveness of models and make ongoing changes. prepare detailed documentation to outline data sources, models and algorithms used and developed. present results to business line stakeholders and help implement real data driven changes. design and develop statistical models for usage in underwriting, existing customer management, marketing campaigns, and collection or recovery. assessing, cleaning, merging, and analyzing large datasets. design and develop business logic, pricing strategies, business forecasts, while optimizing profitability. utilize advanced statistical software to develop linear or non linear, parametric or non parametric, and classical or machine learning based predictive modeling or data mining analytic methodologies to minimize credit or fraud losses, maximize response and approval rates, and or or profitability of products. assist with the implementation of scorecards writing of clear and detailed model documentation. provide solutions and ideas to business partners to solve complex modeling and other analytic problems. requirements university degree in relevant stem disciplines . minimum m.s. or m.a. in a highly quantitative field . strong quantitative or statistical modeling capabilities, along with 2 3 years of experience in credit scoring and model development. 3 4 years of experience within the consumer lending environment preferred. production experience with experimental design, statistical analysis, machine learning and predictive modeling . programming skills in java, r or python. experience with common machine learning libraries in r, python, spark. experience with unix tools and shell scripting. solid sql skills for querying relational databases . we welcome and encourage applications from individuals from all groups, including aboriginal, women, visible minorities, and persons with disabilities, regardless of race, ethnicity, sexual orientation, creed, family status, national origin, age and gender. we thank all applications for showing an interest in this position. only those selected for an interview will be contacted. no agencies or phone calls. job types full time, permanent benefits casual dress dental care life insurance paid time off rrsp match schedule 8 hour shift education bachelor s degree experience consumer lending environment 3 years quantitative or statistical modeling capabilities 3 years work remotely temporarily due to covid 19","['computing', 'documentation', 'statistical analysis', 'java', 'sql', 'python', 'software', 'reporting', 'unix', 'programming', 'data engineering', 'data mining', 'machine learning', 'relational databases', 'testing', 'model development', 'variate', 'statistical', 'algorithms', 'shell scripting', 'model', 'experimental', 'datasets', 'algorithm', 'modeling', 'r']","['shell', 'python', 'sql', 'unix', 'programming', 'documentation', 'java', 'r']","['computing', 'algorithm testing', 'statistical analysis', 'software', 'reporting', 'scripting', 'data engineering', 'data mining', 'machine learning', 'relational databases', 'testing', 'model development', 'variate', 'statistical', 'predictive', 'algorithms', 'model', 'experimental', 'complex', 'datasets', 'modeling']","['underwriting', 'environment', 'education', 'fintech', 'customer management', 'business value', 'design', 'marketing campaigns', 'lending', 'business', 'insurance']"
184,223,Data Engineer,"about us ci global asset management is one of the country s largest investment fund companies. ci is known for its innovation and ability to adapt quickly to the changing needs of canadian investors. it provides employees with a fast paced and challenging work environment with opportunities for advancement. ci is part of ci financial, a diverse group of financial services firms. position data engineer location toronto status full time job overview we are currently seeking a data engineer to join our it client reporting data management team. the successful candidate will be responsible for optimizing our enterprise data pipeline to support delivery of enriched data for bi and advanced analytics consumption for portfolio managers. the successful candidate will become an integral part of our team by applying their proven data engineering ability to define and drive fit for purpose data pipeline solutions. what you will do design build large scale data pipelines and data infrastructure leveraging the wide range of data sources across the organization document assist development teams with best practice, data delivery solutions using enterprise data ingestion, etl and data management tools work closely with infrastructure teams to ensure an optimal data advanced analytics platform, for current and future state clean, prepare and optimize datasets, ensuring lineage and quality controls are applied throughout the data integration cycle support business intelligence analysts in modelling data for visualization and reporting stay current with advanced technologies, including ai or machine learning, data management, and cloud data storage techniques what you will bring experience 3 years of proven experience as a data engineer in a big data environment experience with integrating structured and unstructured data across various platforms and sources hands on experience with the aws suite of services supporting big data experience in the financial services specifically in portfolio management would be preferred experience in interacting with common portfolio management tools such as barra, factset, charles river and bloomberg would be preferred experience with master data management tools and processes would be an asset education or training bachelor s degree in computer science, engineering or a related field knowledge, skills, and abilities proficient in python, java, sql related languages proficient in sql database management systems knowledge of talend etl and related suite of tools an asset confident versatile it professional with the ability to communicate effectively across all levels of the business and it community working conditions routine office environment what you can expect from us our dedication to the employee experience at ci is aimed at supporting, empowering and inspiring our talented team through recognition compensation training development health well being communication feedback if you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking apply . only qualified candidates selected for an interview will be contacted. ci financial corp. and all of our affiliates are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. if you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at or call 416 364 1145 ext. 4747. if you are contacted by ci regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. we will work with all applicants to determine appropriate accommodation for individual accessibility needs. posting tags ind","['unstructured data', 'visualization', 'big', 'ci', 'data infrastructure', 'java', 'master', 'sql', 'python', 'reporting', 'talend', 'database', 'analytics', 'data', 'integration', 'aws', 'data engineering', 'machine learning', 'data pipelines', 'testing', 'business intelligence', 'enterprise data', 'bi', 'datasets', 'computer science', 'data management', 'etl', 'ai']","['sql', 'python', 'bi', 'big data', 'business intelligence', 'aws', 'java']","['unstructured data', 'visualization', 'ci', 'data infrastructure', 'reporting', 'management systems', 'database', 'enterprise', 'analytics', 'data', 'integration', 'data engineering', 'machine learning', 'data pipelines', 'data ingestion', 'testing', 'master data management', 'data storage', 'enterprise data', 'datasets', 'computer science', 'data management', 'etl', 'ai']","['environment', 'asset management', 'education', 'portfolio management', 'design', 'bloomberg', 'training', 'portfolio managers', 'financial services', 'compensation', 'tale']"
185,224,"Data Scientist, Fall 2021 Student Opportunities (8 Months Only)","what is the opportunity who wouldn t want to be a part of a fantastic team of data scientists at rbc, our data science teams offer the opportunity to leverage rbc s data assets to develop innovative solutions in support of rbcs big data strategy. this position is an essential part to the bank as you develop next generation applications to meet our customers needs. by joining the rbc team as a data scientist, you will have the opportunity to analyze, design and implement data solutions to assist all business customers. please only apply if you are available for 8 months. what will you do utilize the latest technologies available, designing and building data solutions to meet business needs be an active contributor to not only your individual team, but to the rbc development community constantly seek out better ways to do things, new tools, new technologies, new processes work on transformational projects delivering new value work as part of an agile team responsible for end to end delivery of business needs deploy production scale solutions using the hadoop ecosystem, transforming statistical and machine learning models from single node architecture to parallel processing grid technology use business domain knowledge to independently lead the analytics process to identify valuable and innovative insights promote analytics across the enterprise to enable rbc to become a data driven organization what do you need to succeed must have programming skills in one or more of the following languages python or r experience utilizing sql scripts or querying proficient in building statistical and algorithmic models with complex and large datasets, including but not limited to supervised statistical learning, clustering, natural language processing, recommendation systems, times series analysis, experimental design , data visualization, deep learning ability to data extract, transform, and load processes with a variety of data types ability to perform complex data analysis on large volumes of data and present findings to stakeholders nice to have experience with big data technologies, primarily in machine learning and statistics function exposure to apache spark, hadoop and public cloud technologies, data serialization experience with big data processing tools like spark and hive, github functionality and workflow experience or exposure experience with messaging working on agile projects what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients succeed. we care about each other, reaching our potential, making a difference to our communities and achieving success that is mutual. visit people.rbc.com continued career advancement opportunities exposure to strong mentorship and leadership examples a world class training program in financial services opportunities to be a valuable member of a close knit, collaborative team that encourages networking a comprehensive total rewards program including bonuses and flexible benefits competitive compensation we encourage you to apply as soon as possible as we accept applications on a rolling basis, but please note that the formal application deadline is june 27, 2021. should you be selected to progress, someone from our team will reach out directly to provide instructions on next steps. otherwise, feel free to check for progress updates by logging in to your rbc profile. if the status has not changed, it denotes the fact that your application is still under review. while there is no one date when our employees will return, we can confirm that the majority of fall work integrated learning co op positions will start working remotely, however may transition to working at an rbc office as essential service restrictions are lifted. tad2021 join our talent community stay in the know about great career opportunities at rbc. sign up and get customized info on our latest jobs, career tips and recruitment events that matter to you. expand your limits and create a new future together at rbc. find out how we use our passion and drive to enhance the well being of our clients and communities at rbc.com or careers. job summary city virtual address virtual work hours or week 37.5 work environment office employment type filter7 career level student job application deadline 06 or 27 or 2021 platform technology and operations req id 375217 ad code","['data visualization', 'parallel processing', 'big data', 'language processing analysis', 'hive', 'github', 'sql', 'python', 'statistics', 'data processing', 'data science', 'analytics', 'programming', 'logging', 'machine learning', 'apache spark', 'statistical', 'data analysis', 'rbc', 'deep learning', 'experimental', 'hadoop', 'datasets', 'data solutions', 'public cloud', 'networking', 'r']","['sql', 'python', 'rbcs', 'hadoop', 'apache spark', 'big', 'public cloud', 'programming', 'big data', 'logging', 'rbc', 'hive', 'r']","['deep learning', 'machine learning', 'language processing', 'experimental', 'statistics', 'data processing', 'datasets', 'data solutions', 'data science', 'parallel processing', 'data visualization', 'networking', 'analytics', 'statistical', 'natural', 'data analysis', 'github']","['environment', 'events', 'design', 'financial services', 'functionality', 'rbc', 'compensation', 'architecture']"
186,225,Major Projects Data Scientist,"major projects data scientist description your opportunity stantec is seeking a major projects data scientist to join our project risk review team. this position is based in vancouver, bc, canada. our project risk review team manages stantec s corporate risk review practice, using data driven insight to support major projects teams across all business lines through the pursuit and execution of stantec s largest and most complex engineering and architecture projects. this position reports directly to the cpo and offers exposure to the broader business with frequent interaction and mentorship from executive leadership throughout our global organization. this opportunity would appeal to individuals interested in gaining a unique professional development experience, applying advanced data science, visualization, and machine learning techniques on complex business and risk management problems. the ideal candidate would establish a one of a kind foundation and professional network to be at the forefront of business intelligence within the project management and engineering consulting industry. your key responsibilities develop and optimize machine learning and statistics models to support the project risk review practice, liaising with stantec s executive leadership and project teams across all business lines and regions to review, issue go conditions, track, and report on major projects worth over 15b in fees. lead the development of project and partner analytics, objective risk metrics, and machine learning tools to assess enterprise risk supporting executive leadership decision making with data driven insight. prepare and present quarterly risk management and major projects tracking reports identifying risk review trends and examining pursuit and project execution outcomes for executive leadership. lead the development and evolution of bi and collaboration tools supporting the project risk review processes to drive efficiency, improve data management practices, and streamline workflows utilized company wide. create a single source of truth by consolidating our various data models and queries create and enforce software engineering best practices to analytics code through version control, testing, and continuous integration. support ad hoc tasks and projects as required provide comprehensive analysis of current state of practice, identify best data sets, data science methodologies, algorithms, tools and infra needed to generate models to support the planned ml based investments qualifications your capabilities and credentials a strong understanding of addressing business needs through the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques you are a collaborative, creative, open minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ml driven models through an iterative approach a strong track record of performing data analysis and machine learning model development using python, r, and sql excellent interpersonal and communication skills ability to communicate complex results with confidence to technical and non technical audiences and stakeholders daily. must have experience with machine learning , classification, clustering, segmentation, time series analysis, nlp, demand forecasting and optimization must be an effective team player who has a demonstrated ability to work intuitively with minimal supervision, and possess qualities of professionalism, assertiveness, maturity and judgement. excellent attention to detail, time management and organization skills with a proven commitment to follow up and follow through ability to multi task, adapt and prioritize tasks to meet deadlines in a very dynamic environment the role requires the ability to handle interruptions and balance numerous and shifting priorities, and assist with multiple projects simultaneously ability to apply detailed solutions to big picture thinking knowledge of risk management frameworks and risk management concepts within a business, consulting or construction environment would be an asset. you are well versed in software and ai development lifecycles data visualization experience powerbi, r database experience ms sql, oracle development experience r, python education and experience completed, or in the process of completing, a bachelor s or master s degree in a field such as data science, computer science, mathematics, engineering, or statistics. 0 3 years of work experience knowledge of engineering and construction terms and contracting practices working conditions, special requirements typical office environment working with computers. sedentary no field work required. a combination of remote working and in office collaboration anticipated. stantec is a place where the best and brightest come to build on each other s talents, do exciting work, and make an impact on the world around us. join us and redefine your personal best. primary location canada british columbia vancouver job it generalist organization bc 1303 cpo canada employee status regular job level individual contributor travel no schedule full time job posting mar 8, 2021, 11 28 32 am req id 210000h9 stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. we prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. eeo including disability or protected veterans","['go', 'visualization', 'data visualization', 'risk', 'sql', 'forefront', 'python', 'statistics', 'time series analysis', 'software', 'data science', 'analytics', 'integration', 'data models', 'data mining', 'analytical techniques', 'machine learning', 'ai', 'testing', 'model development', 'business intelligence', 'data analysis', 'algorithms', 'forecasting', 'bi', 'nlp', 'computer science', 'hypothesis testing', 'mathematics', 'optimization', 'modeling', 'data management', 'version control', 'r']","['go', 'sql', 'forefront', 'python', 'bi', 'nlp', 'business intelligence', 'data models', 'r']","['visualization', 'data visualization', 'risk', 'statistics', 'time series analysis', 'software', 'data science', 'analytics', 'integration', 'data mining', 'analytical techniques', 'machine learning', 'continuous', 'testing', 'predictive', 'data analysis', 'algorithms', 'forecasting', 'model', 'computer science', 'hypothesis testing', 'mathematics', 'optimization', 'modeling', 'data management', 'version control', 'ai']","['validation', 'enterprise risk', 'environment', 'education', 'metrics', 'regulations', 'risk management', 'project management', 'project risk review', 'consulting', 'construction', 'investments', 'compensation', 'and', 'hiring', 'engineering', 'architecture']"
187,227,Senior Data Scientist,"we re transforming the grocery industry instacart is the north american leader in online grocery and one of the fastest growing companies in e commerce. since 2012, we ve been working towards creating a world where everyone has access to the food they love and more time to enjoy it together. groceries delivered to your door in as little as an hour. it seems simple, right well, it s more complex than that. from re routing deliveries during snowstorms, to connecting customers with coupons and deals for their favorite brands, to updating over half a billion grocery data lines every night...our efforts bring instacart closer to being the operating system for the grocery industry. solving these problems is what helps our customers get back time in their day, so they can do more of what they love. introducing our hybrid working model as the future of work evolves, so do we. we have a hybrid model where our roles are open to in office, flex, or remote work. learn more about our flexible approach to where we work. overview you will be joining a growing data science team and will tackle some of the most challenging and impactful problems that are transforming how people buy groceries every day. you will be embedded within our data driven product team as a trusted partner in uncovering barriers in the product s usability and utilize these insights to inform product improvements that drive angle changing growth. we re looking for a self driven, strategic thinker who can hit the ground running to ultimately influence decision making across the entire organization. about the job own analytical frameworks that guide the product roadmap design rigorous experiments and interpret results to draw detailed and actionable conclusions develop statistical models to extract trends, measure results, and predict future performance of our product build simulations to project impact of various product and policy interventions enable objective decision making across the company by democratizing data through dashboards and other analytical tools use expertise in causal inference, machine learning, complex systems modeling, behavioral decision theory etc. to shape the future of instacart present findings in a compelling way to influence instacart s leadership about you 5 years experience working in a quantitative role at a product company or a research organization ability to run rigorous experiments and come up with scientifically sound recommendations ability to write complex, efficient, and eloquent sql queries to extract data ability to write efficient and eloquent code in python or r a desire to build and improve consumer software products ability to translate business needs into analytical frameworks eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic environment, and a growth mindset needed to build a successful team and company li remote","['routing', 'data lines', 'sql', 'machine learning', 'python', 'software', 'complex systems', 'dashboards', 'data science', 'simulations', 'modeling', 'usability', 'causal inference', 'r']","['sql', 'python', 'r']","['routing', 'data lines', 'machine learning', 'software', 'complex systems', 'dashboards', 'data science', 'simulations', 'modeling', 'usability', 'causal inference', 'hit']","['e', 'environment', 'commerce', 'design', 'growing companies']"
188,228,Data Scientist - 312112,"data scientist on behalf of our client in the banking sector, procom is looking for a data scientist. data scientist job description the contractor is responsible for developing and implementing quantification methodologies for business banking credit risk parameters, which are key drivers to the risk rating system, internal processes and regulatory processes develop, implement and maintain risk quantification methodologies for non retail credit risk parameters such as pd, lgd and ugd perform research and analysis of applicable methodologies present and recommend appropriate alternatives implement estimation methodologies benchmark internal estimates with external models and or or data sources provide analysis and recommend actions as appropriate implement and maintain a rigorous framework of internal controls and comprehensive documentation for various applications and databases used in parameter estimation communicate results of analyses through documentation to internal or external audiences, and effectively manage the interface with relevant parties such as validation, audit, and regulators keep abreast with advances in credit risk analytics developments, products, and applications by vendors, consultants, regulatory agencies and competitors. recommend or develop enhancements appropriate for the bank data scientist mandatory skills excellent computing development skills, particularly statistical and database modeling tools well developed ability to adapt to various programming languages and environments 1 year of hands on experience in quantitative analysis and machine learning exposure to quantitative analysis related to credit risk management and modeling is preferred in depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte carlo simulation and bootstrapping techniques well developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses ability to efficiently manage multiple priorities to ensure timely delivery attention to details, independence, and ability to effectively collaborate in teamwork flexibility and creativity in problem solving a graduate degree in statistics, computer science or comparable quantitative discipline that includes rigorous exposure to statistical knowledge and techniques data scientist nice to have skills 1 years of experience in hands on quantitative or statistical analysis, preferably related to the non retail credit risk area in a major financial institution data scientist assignment start date asap 12 months to start data scientist assignment location toronto, on work remotely","['computing', 'databases', 'documentation', 'statistical analysis', 'regression', 'statistics', 'reporting', 'database', 'analytics', 'monte carlo', 'machine learning', 'bootstrapping', 'quantitative', 'quantification', 'parameter', 'banking', 'programming languages', 'computer science', 'modeling', 'risk']","['programming languages', 'databases', 'documentation']","['computing', 'machine learning', 'regression', 'banking', 'quantitative analysis', 'bootstrapping', 'statistics', 'reporting', 'database', 'computer science', 'analytics', 'quantification', 'monte carlo', 'statistical analysis', 'modeling', 'risk']","['validation', 'retail', 'risk management', 'developments']"
189,229,"Senior Data Scientist, NLP Natural Language Processing","introduction as a data scientist at ibm, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. work with best in class open source and visual tools, along with the most flexible and scalable deployment options. whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live. your role and responsibilities ibm watson health is looking for talented individuals destined to usher in the next era of healthcare. we live in a moment of remarkable change and opportunity. the convergence of data and technology is transforming healthcare and life sciences organizations today. new opportunities are being created that never existed before to meet the demands of this transformation. the rapid development team is a group of scientists and cognitive software developers within ibm watson health imaging. in collaboration with cross functional watson health teams, ibm research and external partners, the team develops cognitive solutions that combine imaging and clinical data to enhance clinical decision making. the team is responsible for developing and validating robust and scalable cognitive services and applications, including validation and evaluation of technologies being transferred from research and other collaborators. the team follows agile and devops methodologies to enable rapid iteration and responsiveness. we are looking for self motivated and driven candidates that are passionate about working on cutting edge technologies and that thrive in a highly collaborative environment. job responsibilities design and development of robust algorithms and techniques using text analytics, natural language processing and machine learning rapid development and validation of cognitive solutions by using and or or enhancing existing methodologies, frameworks and architecture development of criteria for testing algorithm and system s cognitive performance objectively from end user and market perspective. conduct performance evaluation and testing of algorithms and systems on test and real clinical data work with clinical collaboration and joint development partners to develop cognitive solutions support collection and annotation of data for algorithm development and evaluation integration of cognitive systems and components in watson health architecture, including watson health cloud planning, processing and performing all jobs in an efficient manner with minimum supervision conduct product development in compliance with watson health s methodology, practices and quality management system. required technical and professional expertise 3 5 years experience with solving real world problems using data analytics, natural language processing , and machine learning strong experience in machine learning, including deep learning and statistical models strong programming skills and experience with software systems architecture, web services, web applications, and current software development tools, technologies and frameworks strong publication record in peer reviewed conferences and journals demonstrated communication and cross functional collaboration skills fluent in english, spoken and written preferred technical and professional expertise strong knowledge of clinical information analytics domain, having applied nlp and machine learning techniques on unstructured data in emrs interest or experience with healthcare information protocols and common interoperability standards, such as ihe, hl7, dicom, xds and ihe, and healthcare systems such as pacs, emr, ehr, his and ris phd in text processing or nlp applied to medical reports must have the ability to work in canada without sponsorship. about business unitibm s cloud and cognitive software business is committed to bringing the power of ibm s cloud and watson or ai technologies to life for our clients and ecosystem partners around the world. ibm provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments with complete software solutions for business and it operations, development, data science, security, and management. our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their it estate, and automate operations with management visibility. with ibm, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners. your life ibmwhat matters to you when you re looking for your next career challenge maybe you want to get involved in work that really changes the world what about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion are you looking for a culture of openness, collaboration and trust where everyone has a voice what about all of these if so, then ibm could be your next career challenge. join us, not to do something better, but to attempt things you never thought possible. impact. inclusion. infinite experiences. do your best work ever. about ibmibm s greatest invention is the ibmer. we believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. ibmers believe that the application of intelligence, reason and science can improve business, society and the human condition. restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 ibmers serving clients in 170 countries. location statementthis role will involve working with technology that is covered by export regulations sanctions. if you are a foreign national from any of the following us sanctioned countries on a work permit, you are not eligible for employment in this position. being you ibmibm is committed to creating a diverse environment and is proud to be an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. ibm is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","['unstructured data', 'clinical data', 'em', 'software solutions', 'data analytics', 'software', 'data science', 'analytics', 'programming', 'integration', 'cloud', 'machine learning', 'testing', 'web services', 'information', 'web applications', 'algorithms', 'deep learning', 'language processing', 'devops', 'security', 'nlp', 'software systems', 'software development tools', 'emrs', 'it operations', 'algorithm development', 'ai']","['em', 'pacs', 'programming', 'nlp']","['unstructured data', 'clinical datation', 'natural', 'information analytics', 'clinical data', 'software solutions', 'data analytics', 'software', 'data science', 'analytics', 'integration', 'machine learning', 'testing', 'web services', 'web applications', 'algorithms', 'planning', 'text processing', 'deep learning', 'language processing', 'devops', 'security', 'software systems', 'software development tools', 'methodology', 'it operations', 'algorithm development', 'ai']","['validation', 'environment', 'healthcare', 'genetics', 'business value', 'design', 'life sciences', 'sponsorship', 'governance', 'consulting', 'immigration', 'product development', 'regulations', 'architecture', 'ehr']"
190,230,Senior Data Scientist,"miovision s mission is to provide the foundation for tomorrow s smart cities by transforming the way traffic networks are managed today. backed by the world s most advanced traffic ai, miovision s innovations in traffic signal planning and operations have made it possible for cities to improve the transportation experience for drivers, cyclists and pedestrians since 2005. with offices in kitchener, canada and cologne, germany, miovision serves over 17,000 municipalities worldwide. for more information, visit position summary miovision is looking for a senior data scientist who is passionate about using data to improve transportation networks all over the world. we have collected a variety of datasets from transportation networks globally, spanning multiple years. we are looking for a data scientist to live in the data determining the right questions to ask of the data, and to communicate the resulting insights. we want you to apply a variety of techniques, such as data analysis, statistical modelling and machine learning, to help our customers solve real world traffic problems. you will collaborate with data scientists, software developers, traffic engineers and computer vision specialists to develop data driven, customer facing solutions for a web based analytics platform. key accountabilities this role s main responsibility is to generate and own insights from these data. other accountabilities are to prepare, manipulate and analyze data from real world intersections build and own customer facing models around real time, 24 or 7 traffic data identify new sources of traffic data to combine with existing data sets research and implement new tools and techniques to solve novel problems drive improvements to data quality and completeness across the company frequently communicate insights and analyses with relevant departments master miovision s data stores and determine best practices for analyzing them understanding of current data collection techniques and biases or gaps skills or qualifications 5 years experience with data analysis, statistical analysis, predictive modeling, machine learning, or deep learning proficiency in one or more data related programming languages python and sql are preferred experience with data visualization tools experience with developing, validating and deploying models deployed in a production environment is an asset propensity to dive into new datasets, identify patterns or issues, and drive insights a desire to ask and answer questions using data eagerness to share new results across multiple disciplines perks and benefits note the majority of miovision employees are continuing to work from home due to covid 19 public health regulations. when it is safe to do so, we plan on a cautious reopening of our canadian office but will continue to offer flexible onsite and remote work options. our benefits are designed to reflect this and include comprehensive health benefits starting on day one rrsp matching plan mio days we extend all three day weekends to four days and provide a holiday shutdown in december virtual healthcare service providing employees and their families access to healthcare providers 24 or 7 internet subsidy and a remote work allowance enhanced paternity and maternity leaves unlimited vacation policy virtual fitness classes we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. please indicate if you require accommodation on your application, and our team will work with you to meet your accessibility needs. 8qrzxaavqv","['deep learning', 'sql', 'python', 'machine learning', 'programming languages', 'software', 'datasets', 'computer vision', 'data visualization', 'data collection', 'modeling', 'analytics', 'data analysis', 'data quality', 'statistical analysis', 'ai']","['programming languages', 'data quality', 'sql', 'python']","['deep learning', 'machine learning', 'ai', 'software', 'datasets', 'computer vision', 'data visualization', 'data collection', 'modeling', 'analytics', 'predictive', 'data analysis', 'statistical analysis', 'planning']","['regulations', 'public health', 'environment', 'healthcare']"
191,231,Senior Data Scientist / Scientifique des données senior,"the opportunity unity monetization team builds advertising, in game purchase promotion, and technologies used in hundreds of thousands of apps. our monetization platform processes tbs of data and delivers relevant content to hundreds of millions of users every day. unity is investing heavily in deep learning. in montreal, we develop groundbreaking machine learning centric products that provide millions of predictions each and every second to optimize the efficiency and profitability of user acquisition advertising campaigns. we are looking now for a senior data scientist to join our growing team you will have a huge impact on scoping out, contributing, and delivering on new monetization initiatives. unity s vast game monetization ecosystem provides you unique chances to create real world impact. what you ll be doing improve and develop deep learning models to revolutionize user acquisition advertisement for mobile gaming drive unity s user acquisition product in close collaboration with other data scientists, product managers, and engineers initiate and define new business opportunities and products based on data insights convey ideas, guide execution, and mentor junior team members what we re looking for strong background in deep learning, from concepts to implementation production experience of machine learning systems at scale proven focus on delivering business value good coding skills and engineering practices, familiar with agile software process and data driven development work with the tech stack of python or bigquery or spark or tensorflow or kubeflow or airflow you might also have experience in mobile advertisement and gaming background in business analytics or software engineering experience in container technologies life at unity unity is the world s leading platform for creating and operating real time 3d content. creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use unity to make their imaginations come to life. unity s platform provides a comprehensive set of software solutions to create, run and monetize interactive, real time 2d and 3d content for mobile phones, tablets, pcs, consoles, and augmented and virtual reality devices. the company s 1,400 person research and development team keeps unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. apps developed by unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. for more information, please visit . unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. if there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know. headhunters and recruitment agencies may not submit resumes or cvs through this website or directly to managers. unity does not accept unsolicited headhunter and agency resumes. unity will not pay fees to any third party agency or company that does not have a signed agreement with unity. l opportunit l quipe monetization de unity cr e des publicit s et des promotions pour les achats int gr s au jeu, ainsi que des technologies utilis es dans des centaines de milliers d applications. notre plateforme de mon tisation traite au quotidien plusieurs t raoctets de donn es, pour fournir un contenu pertinent des centaines de millions d utilisateurs. unity investit massivement dans l apprentissage profond. l quipe de montr al d veloppe des produits r volutionnaires centr s sur l apprentissage machine qui fournissent des millions de pr visions chaque seconde, afin d optimiser l efficacit et la rentabilit des campagnes publicitaires d acquisition d utilisateurs. nous sommes d sormais la recherche d une ou d un scientifique des donn es s nior qui rejoindra une quipe en pleine expansion vous contribuerez grandement l laboration, la mise en uvre et la r alisation de nouveaux projets de mon tisation. l cosyst me de mon tisation des jeux de unity est immense et vous offre des possibilit s uniques de produire un impact r el. ce que vous allez faire d velopper et am liorer des mod les d apprentissage profond destin s r volutionner la publicit li e l acquisition d utilisateurs pour les jeux sur mobile diriger les projets d acquisition d utilisateurs de unity en troite collaboration avec les scientifiques des donn es, les chefs de produits et les d veloppeurs issus d autres quipes lancer et d finir de nouvelles possibilit s commerciales et de nouveaux produits sur la base des donn es recueillies communiquer les id es des uns et des autres, guider l ex cution des projets et encadrer les quipiers moins exp riment s ce que nous recherchons une exp rience importante en mati re d apprentissage profond, depuis la conception jusqu la mise en uvre exp rience de la production de syst mes d apprentissage machine grande chelle priorit confirm e la production de valeur commerciale bonnes comp tences dans les domaines du codage et des meilleures pratiques d ing nierie, connaissance des processus logiciels agiles et du d veloppement pilot par les donn es travailler avec la pile technologique python or bigquery or spark or tensorflow or kubeflow or airflow vous avez peut tre galement exp rience dans la publicit et les jeux sur mobile exp rience en mati re d analyse commerciale ou logicielle exp rience en mati re de technologies de conteneurs la vie chez unity unity est la plateforme la plus utilis e au monde pour la cr ation et l ex cution interactive de contenu 3d en temps r el . des cr ateurs, notamment des d veloppeurs de jeux vid o, des artistes, architectes, concepteurs automobiles et cin astes, utilisent unity pour donner vie ce qu ils ont imagin . la plateforme de unity offre un ensemble complet de solutions logicielles pour cr er, ex cuter et mon tiser du contenu interactif 2d et 3d en temps r el pour les t l phones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de r alit augment e et de r alit virtuelle. notre quipe de plus de 1400 personnes assign es la recherche et au d veloppement fait en sorte que unity soit l avant garde du d veloppement et assure un soutien optimal pour les plus r centes technologies et plateformes. les applications d velopp es par les cr ateurs au sein de unity ont t t l charg es plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d appareils uniques. pour en savoir davantage, visitez le site . unity est un employeur ax sur l galit qui s engage cr er un environnement inclusif, innovateur et ce avec les meilleurs talents. nous offrons des opportunit s d emploi qui ne tiennent pas compte de l ge, de l ethnicit , de la religion, des limitations fonctionnelles, du sexe, de l identit sexuelle ou d un tout autre statut prot g conform ment la loi. s il y a des pre paratifs que nous pouvons faire pour vous aider a avoir une expe rience d entrevue confortable et positive, n h sitez pas nous en faire part. les chasseurs de t te et les agences de recrutement ne peuvent pas soumettre un r sum or cv directement sur notre site web ou un de nos gestionnaires. nous n acceptons pas d tre spontan ment sollicit s par un chasseur de t te et ou une agence une entente devra tre sign entre les deux partis. li dd1 sen","['virtual reality', 'tensorflow', 'software solutions', 'business', 'gaming', 'automotive', 'python', 'forefront', 'software', 'kuflow', 'data development', 'analytics', 'machine learning', 'unity', 'agile', 'airflow', 'deep learning', 'tablets', 'r']","['python', 'forefront', 'virtual reality', 'unity', 'kubeflow', 'r', 'airflow']","['gaming', 'deep learning', 'automotive', 'machine learning', 'tablets', 'software', 'tensorflow', 'analytics', 'agile', 'software solutions', 'software driven']","['user', 'environment', 'investing', 'law', 'advertising', 'business value', 'campaigns', 'new business opportunities']"
192,232,Senior Data Scientist,"status remote work from any canadian location. work location may be re evaluated based on pandemic status. this is a temporary full time role, covering a 14 to 16 month leave. we re looking for a senior data engineer to support data science initiatives for top tier ecommerce clients such as costco, sam s club, staples and fedex. as a senior member of the data team, you will have significant responsibility and influence in shaping its future direction. this role is inherently cross functional, and the ideal candidate will work across disciplines. you are able to iterate quickly on all stages of data pipeline and you will develop large scale data pipelines and analytical solutions using big data technologies. the successful candidate has strong communication and engineering skills. you will need to have a passion for quality and an ability to understand sophisticated systems. responsibilities design, model and develop data sets to support reporting analytics and exploratory analysis. research and employ cutting edge techniques to build and design the data infrastructure for distributed processing, aggregation, and collection of streamed real time data. architect and build data delivery solutions in a microservice environment. contribute to technical design and ongoing development of our custom etl solutions and analytics platforms, and help improve of design and delivery standards. focus on automation and optimization for all areas of dw or etl maintenance and deployment. work with big data developers to build scalable and supportable infrastructure. employ a variety of languages and tools to marry systems together. assess and recommend the implementation available and latest big data technologies. recommend ways to improve data reliability, efficiency and quality. responsible for developing the data architecture components that scales for the ever evolving data needs of the entire company. solve big data warehousing problems on a massive scale and apply cloud based services to solve challenging problems around big data processing, data warehouse design, and enabling self service. collaborate effectively with other members of the team and broader services group, including but not limited to product team, data science team, development teams and release and operations teams requirements min bachelor of computer science ideally masters in data 7 years of data engineering or similar experience. experience in high level programming languages such as java, scala, or python. proficiency with databases and sql is required. experience working with large data sets both sql and nosql databases . experience building etls and data pipelines using tools such as apache airflow and spark. experience working with cloud technologies . demonstrated etl or data programming skills . experience with devops practices, ci or cd, managing production deployments, git and github. ability to communicate design, concepts and decisions both verbally and in writing. ability to mentor other data engineering talent in the team. experience with large scale data warehousing, mining or analytic systems. ability to work with analysts to gather requirements and translate them into data engineering tasks. awareness of security, performance, high availability and fault tolerance and best practices. aptitude to independently learn new technologies. nice to have skills proficiency in data processing using technologies like spark streaming, spark sql, or map or reduce. experience building real time data pipelines using apache kafka. experience with virtualization, containers, and orchestration . knowledge of data visualization and reporting tools like tableau. experience with aws emr, aws dms, talend, apache airflow, stitch. experience with amazon web services rds, ec2, s3, lambda, amazon redshift. about pni media at pni, we re fueled by fun times, great experiences, and passion for the work we do. over 25 million consumers use our platform each day to create and order millions of products from leading brand companies, and we re committed to delivering customers a high quality experience. we know that healthy, happy people create amazing things, so we deliver a top tier experience for our employees, too creative perks and benefits a dynamic work environment and a culture that honours diversity, wellbeing, community interaction and employee development. we re proud of pni s achievements, our people, and our place at the top of the market. contract length 14 16 months job types full time, temporary salary 2.00 4.00 per year benefits casual dress company events work from home schedule 8 hour shift monday to friday covid 19 considerations remote virtual interviews, and covid 19 precautions in place for in person interviews. education bachelor s degree experience data engineering or similar 7 years work remotely temporarily due to covid 19","['high availability', 'databases', 'tableau', 'emr', 'big', 'data infrastructure', 'ci', 'technical design', 'data visualization', 'big data', 'java', 'map', 'github', 'sql', 'python', 'data processing', 'cd', 'scala', 'reporting', 'talend', 'data science', 'analytics', 'data', 'programming', 'aws', 'data engineering', 'data warehousing', 'nosql', 'apache airflow', 'amazon web services', 'data pipelines', 'automation', 'apache kafka', 'programming languages', 'devops', 'fault tolerance', 'security', 'git', 'computer science', 'virtualization', 'optimization', 'etl']","['high availability', 'databases', 'tableau', 'emr', 'big', 'big data', 'rds', 'java', 'map', 'sql', 'python', 'scala', 'talend', 'data', 'programming', 'aws', 'nosql', 'apache airflow', 'amazon web services', 'apache kafka', 'programming languages', 'git']","['data infrastructure', 'ci', 'technical design', 'data visualization', 'dms', 'github', 'distributed', 'data processing', 'cd', 'reporting', 'data science', 'analytics', 'data', 'data engineering', 'data warehousing', 'exploratory analysis', 'data pipelines', 'etls', 'automation', 'devops', 'fault tolerance', 'security', 'computer science', 'virtualization', 'optimization', 'etl']","['environment', 'events', 'education', 'design', 'architecture']"
193,233,"Educator, Data Scientist","brainstation is the global leader in digital skills training and development, offering a 12 week accredited diploma program in data science. brainstation is currently seeking a full time data science professional to lead the delivery of our program through online and in person teaching. brainstation educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education. responsibilities lead our 12 week data science diploma program help build a world class technical team deliver lectures and mentor the next wave of data science talent co create brainstation s full time data science program that will positively impact the lives and careers of hundreds of individuals across our campuses actively work on writing and researching new content to teach the most up to date skills in data science to our students apply brainstation s agile education methodologies to the program to continuously improve the educational experience for students constantly improve your own skills, and apply these skills in collaboration with other brainstation educators in order to build the digital platform and tools needed to effectively deliver educational material define the education experience of the future successful candidates will have 4 years experience as a data scientist or analytics professional and at least a master s degree relevant to the subject matter experience building and leading teams strong command of querying and programming languages , and visualization tools , as well as experience applying various methods of numerical and categorical modeling and machine learning principles practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job an empathetic, friendly, and approachable demeanor a proven ability to work under pressure and meet deadlines ability to teach the entire program in english teaching experience in canada preferred while not required, a phd would be preferred. perks and benefits flexible vacation policy health wellness programs culture of learning development new shiny device upgrades compensation includes an annual salary commensurate with experience full health and medical benefits, and rrsp matching. about brainstation brainstation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state of the art campuses in new york, london, toronto, and vancouver. founded in 2012, brainstation has worked with over 400 instructors from the most innovative companies, developing cutting edge, real world digital training for more than 100,000 professionals and some of the largest corporations in the world. by 2025, brainstation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 ceos, and the newest wave of disruptive innovators, on campuses and online. have you been to a campus or joined an online learning opportunity we are actively seeking individuals that believe in lifelong learning and that have taken part in our on campus or online offerings . note only those applicants under consideration will be contacted. please accept our utmost appreciation for your interest. brainstation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. all qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. if you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.","['visualization', 'machine learning', 'programming languages', 'data science', 'analytics', 'modeling']",['programming languages'],"['visualization', 'machine learning', 'data science', 'analytics', 'modeling']","['environment', 'events', 'compensation', 'education', 'genetics', 'material', 'art', 'educational', 'hiring', 'higher education', 'workshops', 'mentoring']"
194,234,Lead Data Scientist,"while people dream of a better energy future, peak power is building it. founded in 2015, peak has developed a comprehensive software platform that alleviates strain on the electricity grid and drives value to owners of clean energy assets, buildings, and electric vehicles through electricity markets. our synergy software platform optimizes the operation of distributed energy resources by forecasting and predicting the behavior of electricity markets. reporting to the vp of innovation, you will have the opportunity to work with a talented group of data scientists, data engineers, and business stakeholders in a fast paced and exciting environment. as a lead data scientist, you will guide a team on a mission to provide insights and predictions to our customers. using large volumes of data from our production applications, you will use your people, process, and technology skills to solve fascinating problems. this work matters. even a small change to optimize power utilization can significantly impact our customers, our electrical grid, and our environment. we re building something that will have a lasting, positive impact. our new lead data scientist will lead the development of machine learning models, such as energy demand prediction, to provide insights and automation for our customers and have a good understanding of the company s business model or strategy lead analytics projects involving multiple analysts and business stakeholders to optimize the accuracy of predictions have a global vision of the whole projects as well as the company s goal collaborate and lead the teams in feature extraction, data representation, and automatic data pipeline and collection design, as well as data quality assurance monitoring provide an expert opinion on data related topics such as validation of assumptions, use of advanced statistical techniques and hypothesis testing, and product decisions related to data use data visualization tools to deliver insights to stakeholders to create new business opportunities. stay current with the latest cloud computing, machine learning, and data science technologies experiment with new models and techniques and be able to provide model improvement solution continuously what you bring to peak power master s degree in data science, computer science, applied math, or a related technical field 5 years of experience with applied data science, from requirement gathering to serving models, to solve business problems and create value for customers experience with sql and nosql databases working with large data sets and familiar with big data platforms such as hadoop, pyspark, and kubernetes, etc. solid understanding of machine learning, deep knowledge of advanced statistical techniques and concepts, machine learning techniques, and expertise in their applications with advanced knowledge of languages or libraries such as pandas and scikit learn experience with computer vision and familiar with significant computer vision libraries such as tensorflow or keras, pytorch, and opencv experience building machine learning pipelines, such as with amazon sagemaker strong people, process, and technical leadership abilities excellent communication and collaborative problem solving skills continuously learning new frameworks and technologies to generate innovative solutions so why peak power we are focused on solving problems that impact energy markets both locally and around the world. we are a growth stage clean technology company that has partnered with major names in real estate, electricity, and smart city spaces. to work with us is not only to work with an exciting company, but to also be on the cutting edge of the global transition to distributed, clean, and carbon free energy. join us peak power is an equal opportunity employer. we welcome people of different backgrounds, experiences, abilities, and perspectives. accommodations are available on request for candidates taking part in all aspects of the selection process. cutswx48r1","['prediction', 'databases', 'pyspark', 'tensorflow', 'data visualization', 'big data', 'technical leadership', 'kubernetes', 'sql', 'keras', 'software', 'reporting', 'computer vision', 'data science', 'pandas', 'data', 'analytics', 'pipelines', 'cloud computing', 'nosql', 'machine learning', 'forecasting', 'automation', 'pytorchc', 'data representation', 'hadoop', 'computer science', 'hypothesis testing']","['kubernetes', 'sql', 'databases', 'keras', 'opencv', 'pyspark', 'pipelines sagemaker', 'pytorch', 'hadoop', 'data quality assurance', 'pandas', 'big data', 'nosql']","['prediction', 'hypothesis', 'tensorflow', 'data visualization', 'technical leadership', 'software', 'reporting', 'computer vision', 'data science', 'analytics', 'data', 'cloud computing', 'machine learning', 'testing', 'applied data', 'forecasting', 'automation', 'computer science', 'feature']","['validation', 'electricity', 'environment', 'design', 'electrical', 'real estate', 'buildings', 'energy markets']"
195,235,Senior Data Scientist,"come to work for realtor.com a leader in online real estate and backed by industry experience and the news corp brand, realtor.com s vision is to be the leading destination to discover and create your perfect home, and today millions of unique users visit our company s website and mobile apps monthly. what you can do at realtor.com has the potential to touch people in a real and meaningful way. at realtor.com, we process terabytes of data everyday and transform that data into information that powers decisions for millions of home buyers, sellers, renters, dreamers, and real estate professionals. you ll engage with some of the best and the brightest co workers and leaders, learn and contribute, and have a great time. if you enjoy working in a fast paced, dynamic, cutting edge work environment and desire to make a meaningful contribution to the business, then make the move we seek a highly seasoned ml practitioner to join our data science machine learning team and help take it to the next level. we use advanced ml to build recommender systems and matching models, search relevance ranking systems, user personalizations and consumer segmentation models. we also leverage the latest advancements in deep learning on images and nlp to build rich, next gen experiences for our users. as a key member of the team, you will be responsible for the development and deployment of innovative concepts, research, predictive modeling, and machine learning algorithms. you will also serve as a mentor for the junior members on the team and provide guidance on their projects. responsibilities research, build and deploy machine learning and deep learning algorithms. design and build solutions leveraging the wealth of consumer clickstream data, real estate property data, images and text data of realtor.com. create scalable machine learning models classification regression , forecasting, clustering, neural networks that integrate into batch, streaming and real time systems. build end points to serve ml models in production. ml ops . effectively partner with product and engineering teams to ideate and build new data driven and machine learning based features for enriching the experience of home shoppers. drive a or b multivariate tests and design of experiments to facilitate testing of new product and design features, with focus on improving engagement, retention, and conversion. help improve the scope of our data sets by identifying new data collection and procurement opportunities on an ongoing basis. generate descriptive visualizations and presentations to communicate insights and results. mentor the team on data exploration, machine learning, deep learning and developing data oriented products. work with a sense of ownership and urgency, advocate for experimentation based, agile culture. requirements ms or phd in machine learning, computer science, applied mathematics or related fields. 5 years of relevant work experience in the industry building and productionizing ml models. proficient in python, scikit learn, xgboost, pytorch or tensorflow, and other languages and frameworks appropriate for ml modeling and deployment. proficiency in recommender systems or consumer classification modeling is a plus proficiency in deep learning is a plus experience with relational databases and large scale distributed systems. comfortable with experiment design and a or b and multivariate tests. exposure to docker and containerization. knowledgeable of core cs concepts such as structured and unstructured data, data management and querying, common data structures and algorithms. strong creative thinking and problem solving skills. excellent oral and written communication and presentation skills. about realtor.com at realtor.com , we believe that everyone deserves a home of their own. we re a community of nearly 2,000 employees who work hard to ensure that from the moment someone starts dreaming about a new home, to the moment they walk in the door and beyond, we re there to lend a helping hand. every month, over 85 million people trust us with their journey home by visiting our site and mobile apps, and we d love to have you join our team to help. we ve got great offices in the u.s. and canada with lots of sweet jobs to choose from, so we re hoping you ll join us on our journey to make buying, selling, renting, and living in homes easier and more rewarding for everyone. let s make a difference, together. for real.","['unstructured data', 'pytorch', 'tensorflow', 'containerization', 'distributed systems', 'python', 'data science', 'ops', 'machine learning', 'relational databases', 'testing', 'data collection', 'algorithms', 'forecasting', 'deep learning', 'data structures', 'neural networks', 'nlp', 'computer science', 'modeling', 'applied mathematics', 'data management']","['pytorch', 'python', 'containerization', 'nlp']","['unstructured data', 'tensorflow', 'classification', 'distributed systems', 'recommender', 'tests', 'data science', 'ops', 'machine learning', 'relational databases', 'testing', 'data collection', 'predictive', 'algorithms', 'forecasting', 'deep learning', 'data structures', 'neural networks', 'computer science', 'modeling', 'applied mathematics', 'data management']","['procurement', 'environment', 'presentations', 'design', 'real estate']"
196,236,"Senior Data Scientist TORONTO, ONSOFTWARE","who we are tonal is the smartest home gym and personal trainer. it has completely revolutionized the way people work out at home, with its sleek design and advanced a.i. technology. we ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging. with this in mind, we want to bring that same innovative approach to the workplace. at tonal, we continue our shift of emphasis by growing our instrumental team. we collectively weave our knowledge and creativity, as we redefine the future of fitness. we are passionate about building products that transform lives, and building teams that transform the status quo. together, we can be our strongest. what you will do architect and build ai and machine learning models provide expert input on architecture of tonal s data collection, analytics, infrastructure, and learning systems identify innovative opportunities for data driven features develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more. develop algorithm to recommended weights to users over time recommend workouts that users are likely to enjoy improve real time rep and set detection from sensor data analyze user behavior and engagement to inform feature roadmap and marketing collaborate with ml, front end, back end, and firmware engineers to implement algorithms who you are advanced degree in mathematical field or equivalent experience 5 years data science experience knowledge of machine learning and signal processing algorithms knowledge of data filtering, and cleansing techniques strong knowledge of python, sql, and one of java, c or c , kotlin, or go team player with high integrity open to feedback and constantly striving to improve high degree of self awareness extra credit experience with gyros and accelerometers, computer vision, or control theory experience as a software engineer tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. should you have any accommodation requests, please reach out to us via our confidential email, all requests will be addressed and responded to in accordance with tonal s accessibility policy and local legislation.","['go', 'c', 'cleansing', 'control theory', 'java', 'sql', 'python', 'kotlin', 'software', 'computer vision', 'data science', 'analytics', 'integration', 'machine learning', 'data collection', 'algorithms', 'motion', 'signal processing', 'firmware', 'ai']","['go', 'sql', 'python', 'kotlin', 'c', 'control theory', 'java']","['machine learning', 'signal processing', 'learning systems', 'software', 'computer vision', 'firmware', 'data collection', 'data science', 'analytics', 'cleansing', 'integration', 'algorithms', 'ai']","['marketing', 'legislation', 'design', 'architecture']"
197,237,"Data Analyst, Customer Success","who we are we are power factors, developer of the world s leading cloud platform for renewable energy companies. our saas platform, drive, is used to manage over 35 gigawatts of renewable energy across the planet . we re tackling one of the world s most important challenges in making renewable energy the world s leading source of power by driving down the cost to operate wind and solar power plants. our company is going through accelerated growth fueled by the unprecedented transition to clean, renewable energy. the drive platform continues to extend throughout the renewable energy market. our platform collects millions of iot and other data points, cleanses the data, detects occurring issues, identifies leading indicators to predict future issues, and adds a full advanced analytic capability on top of this rich, high value dataset. in addition to issue detection and analytics, drive adds the toolsets needs to take analytic insights to action such as case management and work order management. to our customers, we deliver excellent customer service and a high value system of engagement that provides the results they are looking for lower operations costs and higher output from their renewable energy power plants. we are an agile development company, big enough to make an impact, but small enough to move quickly to execute in a growing industry and take advantage of rapidly evolving technology. to our employees, we provide a culture that values respect, teamwork, transparency, and achievement. the role power factors is seeking a qualified candidate to join our company in the role of data analyst, customer success. in this role, you will be responsible for the design, development, and implementation of tools that aims at automating tasks and optimize processes and increase efficiency. more precisely, you will write scripts and develop helper applications to automate repetitive tasks. you will work on identifying new process improvement opportunities, tracking the most important metrics to diagnose problems, develop and tool filter and categorize issues and prioritize cases . ultimately, you will ensure the workflows, reports, and tools implemented are constantly improving the level of service of the customer success department. in this position, you will report to the director, technical solutions and you will be working from home, in canada. important note power factors is applying covid 19 preventive measures to safeguard the health and safety of our employees, customers, business partners, and communities where we have offices. please note that the selected candidate will be working from home for the duration of said applicable measures. responsibilities design, develop, and implement tools and applications for the customer success helpdesk team to automate repetitive tasks independently take a project from idea to functional application work in partnership with helpdesk teams to gather, process, and interpret case information and workflows to formulate business impact analysis support with broader ticket analysis. report writing and presenting findings and propose workflow solutions translate business requirements into well designed solution tools that best leverage our platform interpreting data, analyzing results using statistical techniques work with management to prioritize business and information needs. identify, propose, and actively participate in process improvement and other projects as required. requirements bachelor s in software engineering or college technical degree in a related field minimum of 5 years of significant experience working as a data analyst or data scientist or business data analyst in a software company strong knowledge of analytics tools and processes strong understanding of reporting packages or spreadsheet tools , databases , programming good working knowledge with osisoft s pi system, sql, salesforce, and microsoft power bi is beneficial familiar with cloud based technologies azure, aws, rackspace itil or lean six sigma certification is considered an asset. key competencies accountability agility effective communication critical thinking problem analysis process development project management decision making or judgement equal opportunity employer power factors is an equal opportunity employer committed to engaging a diverse workforce and sustaining an inclusive culture. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. ind123","['microsoft power', 'sql', 'databases', 'order management', 'software', 'bi', 'iot', 'reporting', 'rackspace', 'six sigma', 'interpreting data', 'problem analysis', 'analytics', 'saas', 'programming', 'aws', 'business', 'itil']","['microsoft power', 'sql', 'databases', 'spreadsheet', 'bi', 'iot', 'rackspace', 'programming', 'aws']","['order management', 'software', 'reporting', 'six sigma', 'interpreting data', 'process development', 'problem analysis', 'report', 'saas', 'agile development', 'analytics management', 'analytics', 'itil']","['customer service of', 'and safety', 'customer success', 'metrics', 'process improvement', 'design', 'project management', 'renewable energy']"
198,238,Senior Data Engineer,"position summary the smartthings big data team in vancouver is looking for a senior data engineer who is passionate on big data technology and delivering data solutions. the senior data engineer will work closely with our business strategy, cloud engineering, client engineering, ux design, consumer insights and marketing teams to make decisions on how we should invest in specific data driven features and products. you are a team player and know how to work well with others. you have a strong analytical mind and you like to see the whole picture. you have passion for solving complex problems and have a high degree of aptitude when it comes to learning new technologies. you love data and numbers and understand how important your role is in helping with business decisions. if you want to work for one of the most recognized brands in the world and one of the top 100 employers in canada, then please keep reading what we offer competitive salary employer paid health coverage employee purchase program discounts social and wellness events employee referral program we want great talent like you role and responsibilities be responsible for data engineering activities including data ingestion, data modelling, data processing data governance analyze different data in the ecosystem and create meaningful topics analysis reports. work with team to improve the data pipeline to process large scale data efficiently be a data steward to educate and promote the data importance and data driven culture. collaborate with other groups worldwide to assist in product design, business strategy and user experience research, etc. be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data skills and qualifications 5 years of experience in big data engineering have deep understanding on data engineering principles hands on experience of large scale and high availability systems strong knowledge of sql and preferably experience with nosql databases proficient in at least one programming language and scripting languages experience with various aws services hadoop ecosystem knowledge bs or ms in computer science or equivalent experience bonus skills experience with ariflow, eks, emr, redshift, olap experience with git and circleci devops skills create build install scripts, terraform, unix based systems management, release management, production monitoring, etc. agile or scrum software development methodologies please note that this position is a 12 month contract. samsung is an equal employment opportunity employer. we thank you for your interest in working for samsung only candidates selected for an interview will be contacted. indhigh li dj1","['high availability', 'databases', 'emr', 'user experience', 'big data', 'systems management', 'olap', 'terraform', 'sql', 'data processing', 'scripting', 'unix', 'data', 'programming', 'aws', 'data engineering', 'nosql', 'scrum', 'software development methodologies', 'ux', 'devops', 'hadoop', 'data solutions', 'git', 'computer science']","['terraform', 'sql', 'high availability', 'databases', 'emr', 'big', 'hadoop', 'git', 'unix', 'programming', 'big data', 'aws', 'ari', 'circleci', 'nosql']","['ux', 'data processing', 'data ingestion', 'user experience', 'scripting', 'devops', 'data solutions', 'scrum', 'computer science', 'data', 'software development methodologies', 'release management', 'data engineering', 'systems management', 'olap']","['events', 'product design', 'marketing', 'design', 'business strategy', 'governance']"
199,240,Data Engineer/ETL Developer,"our client is looking for a data engineer or etl developer to join their growing team of data and bi experts. our client has embarked on a journey to build next generation data platform to support the growing need of data from business intelligence and analytics. the candidate will be responsible designing, developing and productionizing etl jobs to ingest data into data lake, load data to data marts and extract data to integrate with various business applications. roles and responsibilities design and develop etl pipeline to ingest data into hadoop from different data sources using informatica bdm parse unstructured data, semi structured data such as json, xml etc. using informatica data processor. analyze the informatica powercenter jobs and redesign and develop them in bdm. design and develop efficient mapping and workflows to load data to data marts. perform the gap analysis between various legacy applications to migrate them to newer platforms or data marts. write efficient queries in hive or impala and postgresql to extract data on adhoc basis to do the data analysis. identify the performance bottlenecks in etl jobs and tune their performance by enhancing or redesigning them. work with hadoop administrators, postgres dbas to partition the hive tables, refresh metadata and various other activities, to enhance the performance of data loading and extraction. performance tuning of etl mappings and queries. write simple or medium complex shell scripts to preprocess the files, schedule etl jobs etc. identify various manual processes, queries etc. in the data and bi areas, design and develop etl jobs to automate them. participate in daily scrums work with vendor partners, qa team and business users in various stages of development cycle. skill required 7 years of experience in designing and developing etl jobs 3 years of experience working on informatica bdm platform experience on various execution modes in bdm such blaze, spark, hive, native. 3 years of experience working on hadoop platform, writing hive or impala queries. 5 years of experience working on relational databases and writing sql queries. should have deep knowledge on performance tuning of etl jobs, hadoop jobs, sql s, partitioning, indexing and various other techniques. experience in writing shell scripts. experience in spark jobs is an asset. 1 years of experience with working on aws technologies for data pipelines, data warehouses minimum 5 years of experience with building etls to load data warehouse, data marts awareness of kimball and inmon data warehouse methodologies nice to have knowledge on all the products of informatica such as idq, mdm, idd, bdm, data catalogue, powercenter etc. must have experience working in agile scrum methodology, should have used jira, bit bucket, git, jenkins to deploy the codes from one environment to other. experience working in diverse multicultural environment with different vendors, onsite or offshore vendor teams etc. p c insurance industry knowledge will be an added asset certifications in informatica product suite as a developer nice to have 2 years of experience with aws data stack iam, 33, kinesis stream, kinesis firehose, lambda, athena, glue, redshift and emr exposure to other cloud platforms such as azure and gcp are acceptable as well","['unstructured data', 'emr', 'jenkins', 'c', 'data loading', 'hive', 'performance tuning', 'glue', 'sql', 'gcp', 'postgresql', 'json', 'analytics', 'data marts', 'aws', 'execution modes', 'informatica', 'data pipelines', 'relational databases', 'scrum', 'gap analysis', 'metadata', 'business intelligence', 'data analysis', 'athena', 'etls', 'jira', 'iam', 'bi', 'hadoop', 'git', 'structured data', 'xml', 'etl']","['emr', 'jenkins', 'c', 'hive', 'glue', 'sql', 'gcp', 'postgresql', 'mdm', 'json', 'aws', 'business intelligence', 'athena', 'jira', 'iam', 'bi', 'hadoop', 'git', 'impala', 'xml']","['methodology', 'informatica', 'data pipelines', 'relational databases', 'scrum', 'unstructured data data', 'analytics', 'data marts', 'gap analysis', 'metadata', 'data analysis', 'data loading', 'etls', 'performance tuning', 'etl']","['environment', 'catalogue', 'offshore', 'design', 'business applications', 'insurance']"
200,246,Data Engineer,"what you ll do as a data engineer, you will provide input into architectural design decision, develop code to meet business needs and ensure the applications built are meeting high standards of quality and support ability. this position will be part of the data science team and will require high collaboration within and across the different unioncrate teams. primary responsibilities collaborate with the different teams to normalize client data to unioncrate standards write python code to improve and optimize complex etl process for batch data processing from a variety of sql and non sql data sources take loosely defined business questions and translate them into clearly defined technical or data specifications for implementation ensure that data pipelines are scalable, repeatable and secure add to our portfolio of client libraries that interface with 3rd party api s assist the data science team in optimizing newly developed algorithms work with the cloud engineering team to improve our current deployment process ensure all deliverables and processes are of high quality throughout the project by adhering to best practices mentor less experienced members of the team qualifications or requirements 2 3 years of hands on experience designing and implementing large scale, complex etl applications using industry leading products or platforms 4 5 years of experience using sql to perform complex data manipulation 1 year experience with python ability to deal with ambiguity and work with rapidly changing business data team player, great communicator, collaborative and optimistic by nature comfortable working in a startup environment with remote colleagues across the globe familiarity with common programming tools and best practices such as unit testing, git, and jira nice to have exposure to time series data or signal processing experience writing client api libraries experience working with docker containers experience working with functional programming paradigms experience in any of the more popular clouds application deadline 2021 06 22 job type permanent pay 90,000.00 120,000.00 per year benefits dental care paid time off stock options vision care work from home schedule monday to friday education bachelor s degree experience etl 2 years python 4 years work remotely yes","['sql', 'python', 'signal processing', 'data processing', 'architectural design', 'data pipelines', 'jira', 'data manipulation', 'data science', 'api', 'git', 'specifications', 'programming', 'less', 'unit testing', 'algorithms', 'etl']","['sql', 'python', 'jira', 'functional', 'data manipulation', 'api', 'git', 'programming', 'less']","['signal processing', 'data processing', 'architectural design', 'data pipelines', 'data science', 'specifications', 'unit testing', 'algorithms', 'etl']","['environment', 'education']"
201,248,Data Engineer,"company description as one of the largest professional services firms in atlantic canada, mariner has a team of 200 management and technology consultants working with our public and private sector clients throughout atlantic canada and beyond.our team delivers specific strengths in the areas of digital transformation, digital health, organizational change management, and in key technical areas including cybersecurity, it infrastructure, bi analytics. job description mariner s data engineers work with extended team ofdata architects, software architects, business owners, and other specialists to implement, build, and operate datarelated solutions for mariner s clients in public sector, utilities, telecommunications, and other industrial sectors. the successful candidates will be well versed in all phases of the consulting cycle from pre sales through the design and delivery. he or she will be comfortable presenting complex technical concepts at an appropriate level for a wide range of audiences . qualifications our data engineering consultants requires extensive technical skills across most of all of the following database architecture and data warehousing. data modeling and mining. statistical modeling and regression analysis. data lakes design, implementation, and maintenance azure based data technologies databricks snowflake etl tools and techniques devops process pipeline data architecture experience in on premises, cloud, andhybrid environments. other basic qualifications include bachelor or masters degree in computer science, computer engineering or related field. 5 years professional experience in a large enterprise or professional services environment. exceptional oral, written, and listening communication skills. specific experience working with public service, utility, and telecommunication organizations of all sizes . additional information why mariner partners we believe in making a positive impact in the communities where we live and work our team is located in major cities all across canada, throughout the us and internationally. we are proud to be headquartered here, and are passionate about growing a strong technology sector here in atlantic canada and beyond. we offer competitive compensation benefits packages and training and development. we recognize that empowered employees are more innovative, more efficient, deliver better customer service and can flat out perform conventional organizations. our people have built products for national deployments at the world s largest tv and internet companies and leading real estate, financial and government organizations. we are looking for passionate it professionals who are curious about data, who love solving problems for customers and who want to grow their careers. join our growing team i m interested","['cybersecurity', 'digital health', 'regression analysis', 'software', 'database', 'analytics', 'data', 'data engineering', 'data warehousing', 'computer engineering', 'statistical', 'bi', 'devops', 'digital transformation', 'computer science', 'modeling', 'telecommunications', 'snowflake', 'etl']","['data lakes', 'bi', 'telecommunications', 'snowflake']","['regression analysis', 'cybersecurity', 'software', 'devops', 'computer engineering', 'database', 'computer science', 'analytics', 'data', 'statistical', 'modeling', 'data engineering', 'data warehousing', 'digital transformation', 'etl']","['utilities', 'environment', 'change management', 'large', 'professional services', 'design', 'sales', 'customer service', 'consulting', 'digital', 'government', 'compensation', 'public sector', 'private sector', 'architecture']"
202,249,Senior Data & Applied Scientist,"are you interested in building personalized recommendation for billions of users, especially in finance domains finance recommendation team in content service organization is building personalized recommendation in finance domains in various product, including msn and edge default home page, etc. our team focus on whole recommendation stack building, especially the modeling parts in different recommendation layers, including document understanding, segment recall, user profile modeling, personalized ranking, diversity optimization, etc. if you re looking for one team to utilize your ml skills to optimize user engagement of real product, grow your ml skills by iterating against users feedbacks and resolving real product challenges, then this is the team for you responsibilities as one applied scientist in the team, your major responsibilities including thinking through the product scenarios and goals, identify key challenges and design experimental process for iteration and optimization. offline model training and optimizing, collaborating with platform team on online serving and perf optimization for shipping. keeping on track of research trends in the fields of personalized recommendation, deep learning and ai. work independently and collaboratively with other research teams and product teams. qualifications required master or phd in computer science or related fields focus on machine learning and ai. 3 years experiences in areas of machine learning, natural language processing or large scale data mining. solid coding skill and good experience on deep learning framework like pytorch, tensorflow, cntk, etc. preferred working or research experiences on recommendation areas is good plus. good communication skills and self motivated. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work. contentservices webxt","['deep learning', 'data mining', 'machine learning', 'language processing', 'pytorch', 'tensorflow', 'computer science', 'optimization', 'modeling', 'ai']",['pytorch'],"['deep learning', 'data mining', 'machine learning', 'language processing', 'tensorflow', 'per', 'computer science', 'natural', 'optimization', 'modeling', 'ai']","['user engagement', 'design', 'finance', 'legal', 'recruiting', 'regulations']"
203,251,Senior Data Scientist,"qui sommes nous buspatrouille est une entreprise sp cialis e dans la technologie de s curit . titre de principal fournisseur international de dispositifs visant faire respecter le bras d arr t des autobus scolaires, notre mission principale est d am liorer la vie des l ves o qu ils se trouvent. la technologie de buspatrouille a t d ploy e sur un plus grand nombre d autobus et a t utilis e pour d livrer un plus grand nombre de constats d infraction relatifs au bras d arr t des autobus scolaires que toute autre technologie des autres entreprises existantes l chelle mondiale. notre technologie exclusive transforme les autobus scolaires en autobus intelligents quip s de cam ras vid o, de gps, de t l m trie, de traitement de donn es et d archivage. de cette mani re, nous permettons aux comt s et aux districts scolaires d am liorer la s curit des enfant buspatrouille est en pleine croissance. nous sommes donc la recherche d un.e scientifique de donn es principal.e pour int grer notre service de veille strat gique . si vous aimez travailler dans un environnement dynamique avec des coll gues talentueux, ce poste est pour vous. responsabilit s le poste de scientifique de donn es principal.e a une grande influence et n cessite de travailler en troite collaboration avec les clients ainsi qu avec les quipes des ventes et de l exploitation afin d aider prendre des d cisions fond es sur les donn es de mani re stimuler une croissance efficace de buspatrouille. si vous aimez la communication narrative et le fait d influencer les d cisions op rationnelles au moyen des chiffres, nous voulons faire votre connaissance il s agit d un poste de premier plan qui vous permettra d interagir r guli rement avec les chefs d entreprise, de d finir la feuille de route de l quipe et de recenser les besoins pour fournir des solutions innovantes. la personne id ale est autonome, tr s analytique, curieuse et a de la facilit plonger dans de grands ensembles de donn es afin d en tirer des enseignements. notre environnement volue rapidement et requiert une personne enthousiaste, flexible, soucieuse du d tail, analytique et l aise pour travailler avec plusieurs quipes et des priorit s concurrentes. mettre en pratique d excellentes comp tences en mati re d analyse et de r solution de probl mes pour prendre des d cisions d affaires dans un environnement dynamique afin de fournir des avantages aux clients et des analyses de performance. travailler de mani re ind pendante et en collaboration avec d autres scientifiques, des ing nieurs, des concepteurs, des d veloppeurs en veille strat gique et des gestionnaires de produits sur des projets complexes qui g n rent de la valeur pour buspatrouille. poss der d excellentes aptitudes la communication et tre capable de structurer un sc nario convaincant pour pr senter une narration l aide de donn es exploitables. tre capable de conceptualiser des probl matiques ou des occasions d affaires, de formuler des hypoth ses et des objectifs, de d finir des indicateurs cl s de performance et de faire des recommandations ad quates. construire des mod les prescriptifs et pr dictifs de calibre international pour r soudre des probl mes commerciaux dans un environnement qui volue rapidement. tirer parti des donn es internes et externes pour synth tiser des id es int ressantes qui expliquent les tendances sous jacentes de l cosyst me de l application automatis e des lois. rep rer les possibilit s d automatisation pour favoriser l volutivit et am liorer tant l efficacit que la productivit de l quipe largie. poss der de solides comp tences en communication crite et verbale, avec la capacit de synth tiser efficacement des id es pour les pr senter la haute direction ou des clients. en temps voulu, embaucher, former, encadrer et diriger une solide quipe d analyse de donn es pour buspatrouille exigences un dipl me d tudes sup rieures en conomie, en finance, en statistique ou dans un autre domaine quantitatif. plus de huit ans d exp rience pertinente. une exp rience av r e de la manipulation d un large ventail de sources et de syst mes de donn es pour fournir des analyses et des visualisations qui ont des r percussions sur l activit . une solide compr hension th orique et une expertise concr te des bases de donn es, des structures de donn es, des m gadonn es, de l apprentissage automatique et des m thodes . une expertise dans les approches analytiques de pointe et les plateformes . une grande ma trise de sql, r ou python. des comp tences analytiques exceptionnelles et un sens aigu des affaires. d excellentes comp tences en communication, avec la capacit d influencer les d cideurs et d obtenir un consensus au sein des quipes. une curiosit intellectuelle, une grande autonomie et un esprit d quipe. r mun ration et avantages un salaire concurrentiel. des avantages sociaux complets, notamment une assurance soins m dicaux, soins dentaires et soins de la vue. un poste de direction au sein d une entreprise qui se d veloppe rapidement et qui est investie d une mission. l occasion de travailler avec une quipe tr s performante l occasion de contribuer la cr ation d une entreprise vou e la s curit des enfants. nous sommes la recherche de membres essentiels de l quipe de buspatrouille qui nous aideront dans notre qu te pour accro tre la s curit des enfants. ce poste joue un r le important dans notre entreprise et constitue une formidable opportunit pour les personnes qui seront retenues. nous offrons un milieu de travail inclusif, diversifi , enthousiaste, int gre et profond ment engag . venez nous aider assurer la s curit des enfants. who we are buspatrol is a safety technology company. our core mission is to improve the lives of students everywhere as the leading international provider for school bus stop arm enforcement buspatrol s technology has been deployed onto more buses and has been used to issue more school bus stop arm citations than any other company in the world. our proprietary technology turns school buses into smart buses equipped with video, gps, telemetry, data processing, and archiving. in this way, we enable counties and school districts to enhance the safety of children in their communities. buspatrol is undergoing rapid expansion. we are looking for a senior data analyst to join our business intelligence. if you thrive working in a fast paced environment with talented peers, this position is for you. responsibilities the senior data scientist is a high impact role that will work closely with our customer, sales, and operations teams to help drive data driven decisions that accelerate buspatrol s efficient growth. if storytelling and impacting operational decisions through numbers is exciting to you, we want to hear from you this is a high visibility role that will be interfacing with business leaders on a regular basis, defining team roadmap and gathering requirements to deliver innovative solutions. the ideal candidate is a self starter, highly analytical, curious, and comfortable diving deep into large data sets to unearth insights. our environment is fast paced, and requires someone who is enthusiastic, flexible, detail oriented, analytical, and comfortable working with multiple teams and competing priorities. apply excellent analytical and problem solving skills to drive business decisions in a dynamic environment to deliver customer benefit and performance analytics work both independently and collaboratively with other scientists, engineers, designers, bi developers, and product managers on complex projects that deliver value to buspatrol excellent communication skills and ability to structure a compelling storyline to present a narrative using actionable data driven insights ability to conceptualize business issues or opportunities, formulate hypotheses and goals, define kpis and make appropriate recommendations build world class prescriptive and predictive models to solve business problems in a fast moving environment leverage internal and external data to synthesize nuggets of insights that explain underlying trends in the automated enforcement ecosystem identify opportunities for automation to drive scalability, improve efficiency and productivity of the broader team strong written and verbal communication skills with ability to effectively synthesize insights to executives and or or customers in time, hire, train, mentor and lead a robust data analytics team for buspatrol requirements an advanced degree in economics, finance, statistics, or other quantitative subject area 8 years relevant experience proven track record navigating across a wide range of data sources and systems to deliver analytics and visualization that deliver business impact strong theoretical understanding and applied expertise with databases, data structures, big data, machine learning, and methods expertise with industry leading analytics approaches and platforms expert proficiency in sql, r, and or or python exceptional analytical skills and strong business acumen outstanding communication skills with the ability to influence decision makers and build consensus with teams intellectually curious, self starter, team player compensation and benefits competitive salary comprehensive benefits including medical, dental and vision insurance leadership role in a rapidly scaling, mission driven organization an opportunity to work with a high performing team an opportunity to help build a company dedicated to children s safety we re looking for critical members of the buspatrol team to assist us in our quest to improve children s safety. this is an important role for us and a great opportunity for the right candidates. our environment is inclusive, diverse, ignited, built on integrity and deeply committed. come and help us keep our children safe.","['analytical skills', 'visualization', 'databases', 'big data', 'sql', 'python', 'data analytics', 'statistics', 'data processing', 'analytics', 'machine learning', 'telemetry', 'business intelligence', 'automation', 'data structures', 'bi', 'economics', 'scalability', 'r']","['sql', 'python', 'databases', 'bi', 'big data', 'business intelligence', 'r']","['data analytics', 'analytical skills', 'visualization', 'telemetry', 'data processing', 'statistics', 'data structures', 'machine learning', 'economics', 'performance', 'scalability', 'analytics', 'archiving', 'automation']","['environment', 'sales', 'finance', 'compensation', 'insurance']"
204,252,Data Scientist / Senior Data Scientist - North American Integrated Analytics,"data scientist or senior data scientist north american integrated analytics in keeping with our global position as an industry leader and innovator, munich re is driving transformative change in the life insurance industry through data science. the north american integrated analytics team in toronto is looking for a data scientist or senior data scientist. location toronto , canada as a data scientist you will apply statistical techniques and machine learning to build solutions to core challenges in the life insurance industry. you will be immersed in real time business problems while engaged in a collaborative approach to delivering world class, innovative solutions for our north american operations and clients. we see the use of data as instrumental in making it easier for people to buy life insurance and to expand the number of people insured. your job apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management help us to drive innovation, enabling new underwriting paradigms, distribution models, and data management build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense proactively research new ways of modeling data to unlock actionable insights or improve processes collaborate across munich re functions and with clients to use analytics to influence business decisions work with existing data science groups at munich re and collaborate with internal partners to leverage capabilities in big data technology. your profile first and foremost, the successful candidate will demonstrate a natural desire to provide exceptional client service through his or her energy, enthusiasm and initiative. in addition, we are looking for the following qualifications undergraduate degree in computer science, engineering, statistics, or applied mathematics, plus 3 years experience or graduate degree in computer science, engineering, statistics, or applied mathematics, plus 1 years experience insurance or financial services background is preferred but not required actuarial examinations or designation is an asset but not required expertise in advanced predictive analytic techniques strong experience working with python, or r working knowledge of sql experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining familiarity with cloud computing platforms familiarity with big data technologies , natural language processing and deep learning frameworks is an asset but not required excellent communication skills, effectively interpreting modeling results, distilling actionable insights and presenting them to partners the ability to learn quickly a drive to make a difference thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines. about us munich re is one of the world s leading reinsurance companies with approximately 45,000 employees in over 50 locations around the globe. as an industry leader, we provide a unique opportunity to be part of a global success story. we offer our employees a diverse and challenging work environment which champions high performance, professional development, innovation and passion and rewards top performers with a highly competitive total rewards package. apply now apply for this job munich re canada is committed to providing a work environment that is inclusive and free of employment barriers and discrimination. accommodations will be made for qualified applicants with a disability throughout the recruitment process. if you receive a request for an interview and you have a disability which will require an accommodation to support your participation, please consult with human resources or contact as soon as practical so that suitable accommodations can be arranged.","['deep learning', 'sql', 'python', 'machine learning', 'statistics', 'language processing', 'testing', 'data science', 'computer science', 'analytics', 'big data', 'modeling', 'applied mathematics', 'data management', 'cloud computing', 'r']","['sql', 'python', 'big data', 'r']","['deep learning', 'machine learning', 'statistics', 'language processing', 'testing', 'data science', 'computer science', 'analytics', 'natural', 'modeling', 'applied mathematics', 'data management', 'cloud computing']","['underwriting', 'environment', 'insurance industry', 'human resources', 'design', 'claims management', 'reinsurance', 'actua', 'financial services', 'insurance']"
205,254,Senior Data Scientist,"senior data scientist london, on, canada req 19 thursday, september 17, 2020 about this position digital extremes is currently seeking a senior data scientist to join our team. you will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. as a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data in a clear and compelling manner that inspires action. as an ideal candidate, you will also have experience with free to play games. responsibilities collaborate closely with the data team improving internal processes. help marketing and development teams to identify trends and opportunities. develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences. architect, implement, deploy, and maintain data science intensive applications. synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies. extract and organize data into a reliable user friendly form and present it to the interested and affected parties on the team. follow up with additional analysis once initiatives have begun to determine success or need for continued improvements. assist in designing and building business intelligence tools for data mining and reporting. suggest improvements in tools and techniques to help scale the team. conduct ad hoc data analysis based on current team needs and management priorities. mentor other data scientists with the team. requirements excellent organizational, communication and interpersonal skills bachelor s degree in a technical or quantitative discipline minimum 3 years of tried and true statistical analysis and data mining experience a passion for video games and understanding of gaming culture experience in the gaming industry, specifically free to play gaming is a plus in depth knowledge of postgres sql, mongo db, python notebooks experience in defining or designing or building or managing a data warehouse is a plus strong quantitative analysis techniques and qualitative methods, as well as predictive modelling demonstrated success presenting complex research data in a clear and compelling manner that inspires action excellent organizational, communication and interpersonal skills self starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas about digital extremes founded in 1993 by james schmalz, digital extremes ranks as one of the world s top independent video game development studios. originating with the co creation of epic games multi million unit selling unreal franchise including unreal and unreal tournament, digital extremes went on to develop dark sector , bioshock for the playstation 3, the bioshock 2 multiplayer campaign, and the darkness ii. the studio has reached its greatest critical and commercial success with the free to play action game, warframe , boasting a global community of 50 million registered players on pc, ps4 , xbox one and nintendo switch . for more information about digital extremes, visit to sign up for warframe, visit why work at digital extremes our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. developing new and existing talent is our long term focus. we are honored that our work environment has been consistently recognized as one of canada s top 100 employers . we summon you to join our elite team the rewards of a career with digital extremes include competitive salary with bonus opportunities excellent benefits and paid time off matching rrsp plan employee assistance program professional development and career support fitness and parking or transit subsidies daily lunches prepared onsite by our in studio executive chef and professional kitchen staff all day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more join us digital extremes is an equal opportunity employer committed to diversity and inclusion. we welcome and encourage applications from people with disabilities. accommodations are available upon request for candidates taking part in all aspects of the recruitment process. we thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted. other details pay type salary","['data mining', 'sql', 'python', 'reporting', 'data science', 'business intelligence', 'data analysis', 'statistical analysis', 'algorithms', 'gaming']","['sql', 'python', 'free', 'xbox switch', 'business intelligence', 'playstation']","['data mining', 'quantitative analysis', 'reporting', 'data science', 'video', 'game development', 'data analysis', 'statistical analysis', 'algorithms', 'ad hoc', 'gaming']","['environment', 'game', 'marketing', 'design', 'therapy', 'hiring']"
206,256,Aerodynamicist/Data Scientist,"company overview gibli tech has developed a patent pending, cutting edge aerodynamic sensor for cycling and triathlon applications. as part of the growing gibli team in halifax nova scotia, you will be a key player in advancing this technology for a global market. responsibilities as the aerodynamicist or data scientist your primary role will be to improve existing algorithms, lead experimental design setup for r d, and data processing. develop experiments derived from fundamental aerodynamics principles lead wind tunnel testing algorithm improvements using test results and data processing techniques statistical analysis of sensor data what we want strong understanding of aerodynamics and engineering fundamentals experimental background strong mathematics background experience in signal processing familiarity with sql and or time series data matlab programming skills python programming skills strong problem solving skills and attention to detail self motivated and can work independently positive attitude with strong communication skills nice to have experience in version control workflow experienced in cfd has worked with embedded systems interest in cycling requirements graduate or undergraduate degree in engineering or related field with focus on aerodynamics how to apply please send a cover letter and resume to","['sql', 'python', 'signal processing', 'experimental', 'data processing', 'testing', 'embedded systems', 'version control', 'mathematics', 'programming', 'statistical analysis', 'algorithms', 'matlab']","['sql', 'python', 'programming', 'matlab']","['signal processing', 'experimental', 'data processing', 'testing', 'embedded systems', 'version control', 'mathematics', 'statistical analysis', 'algorithms', 'cfd']","['wind', 'design', 'aerodynamics']"
207,257,Lead Data Scientist - Core Local Business (Remote),"at yelp, it s our mission to connect people with great local businesses. yelp s unique dataset contains billions of interactions between users and businesses around the globe, from a review of a coffee shop to requesting a repair quote with a photo of a leaky faucet. data scientists at yelp work to make sense of these interactions to deliver impactful analyses and products to our users, business partners and the general public. the data science analytics team performs analyses, builds models, and designs experiments that directly impact yelp s products and users. our teams sit in yelp s central product management organization and work directly with cross functional leaders to understand quantitatively how our products are performing and where the largest opportunities are. we are adept at tasks like modeling user preferences, inference from user and marketplace experiments, and generating insights about the health of local economies. with diverse backgrounds and expertise, we strive for learning and growth in a collaborative environment. we are looking for a lead data scientist to join the core local business team. the team is centrally located within our product organization, and focused on analytics, research, and inference support for product and engineering stakeholders. the core local business team partners with product and engineering teams building the yelp for business owners user experience, from claiming a free business listing, to paid product acquisition, and long term engagement and retention. lead data scientists at yelp are technical and cultural leaders within their teams, and collectively influence the development of shared tools, infrastructure, and processes across the organization. where you come in join a team of data scientists and data science analysts that develop analytical frameworks and reliable measurement strategies for yelp products. design, execute, and analyze complex business and user experiments. partner with other senior data scientists and data engineers to set the vision for and develop our experimentation platform. devise and evaluate models for diverse business needs, such as identifying growth opportunities, estimating the impact of new features on our platforms, and personalizing the user experience. proactively research and build etl pipelines for product and marketplace metrics. communicate key insights from analyses, experiments and data products to stakeholders. what it takes to be successful ms or phd in quantitative field and 3 years of industry experience in a senior quantitative role. ability to apply statistical, analytical and technical expertise to product and business problems. prior experience structuring and leading impactful data science projects independently. oral and written communication skills to mentor colleagues, and work effectively with partners on engineering, product and business teams. expertise in sql, and r or python for data analysis and platform development. enthusiasm for building a culture of learning and development. nice to have product analytics experience with small businesses. prior industry experience building online experimentation and machine learning platforms. local businesses are turning to yelp because we re uniquely positioned to help them reach their customers during these challenging times. our engineering product teams have responded by quickly identifying their needs and building innovative products and features to support them. our commitment to connecting people with great local businesses has never been stronger. li remote at yelp, we believe that diversity is an expression of all the unique characteristics that make us human race, age, sexual orientation, gender identity, religion, disability, and education and those are just a few. we recognize that diverse backgrounds and perspectives strengthen our teams and our product. the foundation of our diversity efforts are closely tied to our core values, which include playing well with others and authenticity. we re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition or disability. we are committed to providing reasonable accommodations for individuals with disabilities in our job application process. if you need assistance or an accommodation due to a disability, you may contact us at or 415 969 8488. note yelp does not accept agency resumes. please do not forward resumes to any recruiting alias or employee. yelp is not responsible for any fees related to unsolicited resumes.","['sql', 'python', 'machine learning', 'platform development', 'user experience', 'data science', 'data analysis', 'product management', 'analytics', 'product', 'modeling', 'pipelines', 'etl', 'r']","['pipelines', 'sql', 'python', 'r']","['machine learning', 'platform development', 'user experience', 'data science', 'data analysis', 'product management', 'analytics', 'modeling', 'etl']","['environment', 'education', 'metrics', 'product acquisition', 'design', 'recruiting']"
208,258,Data Engineer,"about pinterest millions of people across the world come to pinterest to find new ideas every day. it s where they get inspiration, dream about new possibilities and plan for what matters most. our mission is to help those people find their inspiration and create a life they love. in your role, you ll be challenged to take on work that upholds this mission and pushes pinterest forward. you ll grow as a person and leader in your field, all the while helping pinners make their lives better in the positive corner of the internet. the mission of the business intelligence team is to empower high impact decisions at pinterest by engineering data driven solutions. we are looking for a software engineer who will design, build and maintain the most critical data sets and visualizations for our company. aligned to one of our verticals like ads, shopping, infrastructure, sales and finance you ll be working directly with the analysts, data scientists and business leaders in that area to ensure they have the data they need. what you ll do understand the business drivers and analytical use cases and translate these to data products explore new technologies and learn new techniques to solve business problems creatively think big and drive the strategy for better data quality within pinterest design, implement and maintain pipelines that produce business critical data reliably and efficiently using cloud technology become the voice of business within engineering, and of engineering within business create data visualizations that allow easy consumption of the data learnings and insights collaborate with many teams from product, engineering and business to produce relevant data solutions that can be used across multiple use cases what we re looking for 4 years of experience with big data , scripting language and data visualization technologies hands on experience in principled data warehouse design, data visualization and data pipeline design and development prior experience working with business stakeholders in the technology space is a plus great communication skills. you should be able to directly communicate with senior business leaders, embed yourself with business teams, and present solutions to business stakeholders experience in working independently and driving projects end to end strong analytical skills li mj1 not specified 0","['analytical skills', 'pipelines', 'software', 'data products', 'scripting', 'data solutions', 'data visualization', 'big data', 'business intelligence', 'data quality']","['data quality', 'big data', 'business intelligence', 'pipelines']","['analytical skills', 'use cases', 'software', 'data products', 'scripting', 'data solutions', 'data visualization']","['finance', 'design', 'sales']"
209,259,Data Analyst - Data Science,"job title data analyst location remote reports to senior director, data science the role as an analyst in data science, you will analyze and interpret the results of survey research studies that measure customer satisfaction, and provide technical programming expertise working with python, r, sas, excel, and other automation tools. your job is to work closely with other researchers and scientists in the execution of programs to run advanced statistical modeling, data mining and analysis on survey and non survey data. the impact you will support syndicated studies that address industry level consumer needs and serve as customer satisfaction benchmarks in a variety of industries such as automotive, financial services, insurance, energy, and telecom. the outcome of your work will be used by clients to help them understand what is important to consumers, how their brand performs relative to their competition, what their brand needs to do to improve and the financial benefit of making these improvements. responsibilities organized, detail oriented, and analytical thinker with experience in data modeling or mining, analysis, and reporting. able to leverage broad scope of knowledge including business rules and methodologies when performing basic and advanced analyses on datasets creates and maintains scripts or codes to clean and manipulate data, develop models, accurately calibrate model parameters, validate model performance, and create analytical outputs applies basic quantitative analytical skills for specific projects or studies able to take ownership of projects and work with other individuals and teams to ensure project accuracy and timeliness of information to clients qualifications python , r, sas, spss bachelors or masters in data science, statistics, math, computer science, engineering, economics or related fields 2 years of an advanced understanding of statistics and or or machine learning methods must be able to work effectively and collaboratively in a team oriented, global, and multi cultural environment. fluent in english the career opportunity you will have the opportunity to work with industry experts to learn how different industries are structured and how they leverage consumer information to guide product development and service improvement efforts. you will also have the opportunity to strengthen your research design and statistical skills by daily exposure to senior research staff at jd power. the team or the business data science has global responsibility for the research design, analyses planning and execution of all advanced analytics at jd power. additionally, the team is responsible for establishing and monitoring the adherence of research best practices that serve as the basis for the quality of all research products at jd power. our role is critical to the success of not only individual studies, but to the strength and credibility of the jd power brand. you will report directly to the data science sr. director and join a team of highly educated and enthusiastic researchers and data scientists that collaborate regularly with each other and with other teams across the firm. our hiring manager says i m looking for someone who can work as part of a broader engagement team and can use our data to help companies understand what drives customer satisfaction for their industry. this individual also has to work independently to analyze data using analytic packages . if you re right for this role, you are a self starter who is able to develop creative solutions to problems, not be afraid to ask questions as you learn our company s culture and do it all with enthusiasm. j.d. power is a global leader in consumer insights, data, analytics, and advisory services that helps clients drive growth and profitability. the company s industry benchmarks and reputation for independence and integrity have established it as one of the world s most well known and trusted brands. truth that transforms at j.d. power, we amplify the voice of the consumer, and help brands improve the value of their products and services. our capabilities empower everyone in the global commerce ecosystem, enabling better purchase decisions and better business results. we understand that the customer experience is vital and that simply measuring it is not enough. our analysts focus on driving results that improve customer loyalty and advocacy. our success is driven by how much we help companies improve the customer experience. but data is only as powerful as the analysis and insights tied to it and we put that power in the hands of our clients through our interactive reporting platforms. the data, analytics, insights, best practices, and action plans clients need are available whenever and wherever they need them, to help them make data driven decisions that will improve their customer experience and drive positive financial results. j.d. power s recruitment efforts are aligned with the company s commitment to provide opportunities rooted in diversity, inclusion, and equality. our vision to be the leader in providing advanced data solutions that empower industry transformation. our mission we unite industry leading data and insights with world class technology to solve our clients toughest challenges. our values we are truth finders, change makers and team driven. we are dedicated to leverage comprehensive and equitable practices which contribute to the overall success of the company and its employees. we invite you to learn more about our de i efforts. to all recruitment agencies j.d. power does not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes. lv sv1","['analytical skills', 'automotive', 'python', 'statistics', 'reporting', 'data science', 'data', 'programming', 'analytics', 'sas', 'data mining', 'machine learning', 'statistical', 'automation', 'economics', 'datasets', 'technical', 'data solutions', 'computer science', 'modeling', 'r']","['python', 'programming', 'sas', 'r']","['data mining', 'automotive', 'analytical skills', 'machine learning', 'statistics', 'reporting', 'datasets', 'technical', 'economics', 'data science', 'data solutions', 'computer science', 'statistical', 'data', 'analytics', 'modeling', 'automation', 'planning']","['environment', 'commerce', 'design', 'customer experience', 'service improvement', 'customer satisfaction', 'financial services', 'product development', 'business', 'hiring', 'insurance']"
210,261,Data Engineer,"what is the opportunity the dna group is responsible for enabling rbc to become a data driven organization. as part of this mission, dna works with various lines of business to create and build data driven solutions to serve our clients better. the dna data services team will build data driven products and services or api s, tackle challenging and interesting data related problems using rbc s massive internal datasets and strategically partner with the business to enable client interactions to be informed by artificial intelligence . what will you do take full ownership of work outcomes including design and implementation of api or microservices and backend components of our domain driven machine learning and ai services apply design thinking and an agile mindset in working with other engineers, data scientists and business stakeholders to continuously experiment, iterate and deliver on new initiatives. leverage best practices in continuous integration and delivery, with a strong commitment to leading with quality explore new capabilities and technologies to drive innovation. participate in code reviews for the engineers on your team, ensuring our delivery of clean, well tested, and performant software what do you need to succeed must have bachelor s degree in computer science, software engineering, or equivalent experience in developing scalable, configurable applications using python or java or scala and application frameworks experience with streaming or messaging technologies experience leveraging big data technologies to build data products and services strong foundational knowledge of relational databases and nosql stores experience in building scalable, high available and performant microservices a passion for simplifying and automating work, making things better, continuous learning, solving open ended problems, improving efficiency and helping others strong communication skills with ability to work cross functionally to articulate, measure and solve issues nice to have knowledge of public cloud environments experience deploying to and running applications on kubernetes or openshift experience building or executing machine learning pipelines experience building operational rest apis knowledge of vulnerability mitigation, identity management, public and private cloud security risks, and security best practices what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. we care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual. a comprehensive total rewards program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable leaders who support your development through coaching and managing opportunities work in a dynamic, collaborative, progressive, and high performing team flexible work or life balance options opportunities to take on progressively greater accountabilities opportunities to building close relationships with business partners learn more about rbc tech jobs","['openshift', 'design thinking', 'data services', 'big data', 'java', 'kubernetes', 'python', 'software', 'scala', 'integration', 'pipelines', 'microservices', 'cloud', 'nosql', 'machine learning', 'relational databases', 'data products', 'artificial intelligence', 'rest', 'datasets', 'security', 'api', 'computer science', 'public cloud', 'ai']","['kubernetes', 'python', 'openshift', 'scala', 'api', 'public cloud', 'big data', 'pipelines', 'java', 'nosql']","['machine learning', 'design thinking', 'relational databases', 'continuous', 'software', 'data products', 'cloud security', 'datasets', 'data services', 'security', 'computer science', 'artificial intelligence', 'integration', 'microservices', 'rest', 'ai']","['rbc', 'compensation', 'private', 'design']"
211,262,Fraud Data Analyst,"mistplay is the first loyalty program for mobile gamers. players use our platform to play games, connect with friends, and earn awesome rewards such as amazon gift cards and prepaid visas. we leverage a wealth of in game data and machine learning to recommend the best games to our users and coach developers of all sizes to help them build games. we use our marketing expertise and platforms to make sure our studio partners games reach millions of players around the world. with a growth of over 10 million users in under 3 years, mistplay is one of the fastest growing companies in north america. join us as we continue to level up as a fast growing tech start up, you can jump right into the action and deep dive directly into the open ai challenges we are facing. join our skilled team of data scientists, engineers and analysts to help us improve our ai products with a real time impact on our business. each day will bring new challenges and opportunities to work on different components of our platform. we are looking for people that are passionate about ai and our product. technical ability is important, but so is being able to add to our culture. a can do attitude and growth mindset will take you a long way with mistplay what you ll be doing work on a daily basis with our fraud team of data analysts, data scientists and operation manager to track and identify fraudulent users work with a rich database that will push your creativity into engineering novel features that will have direct impact on the company help us keep track of our current models in production by building dashboards assist in investigation of suspicious users that exhibit bot behaviour qualities collaborate with our content team to review monthly fraud reports coming from our clients what we re looking for a bachelors degree in science, computer science, statistics, economics, business analytics or any quantitative related field is required ability to explore our rich database, continuously uncover new channels of fraud and propose newly engineered features to boost the performance of our models strong analytical and statistical analysis skills in order to extract insights and recommendations strong knowledge of sql for analytics, data mining and data manipulation. python or r is a solid bonus data visualizations such as tableau is a solid bonus what we offer generous stock option package we match 20 of your contribution to your retirement plan monthly public transportation stipend annual gym membership dialogue membership unlimited free video calls and texts with nurses and doctors anytime they ll even help you book irl appointments weekly happy hour frequent team outings and off sites private healthcare includes massages we work hard to make our work atmosphere as inviting and fun as possible working at mistplay is coupled with a whole array of perks that we ve adopted virtually and in person team lunches, game nights, company wide events, and so much more. our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. we utilize data to constantly learn, improve, and adapt. we foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life. think you have what it takes we d love to meet you","['sql', 'python', 'machine learning', 'statistics', 'technical ability', 'tableau', 'economics', 'dashboards', 'data manipulation', 'computer science', 'analytics', 'statistical analysis', 'business', 'r', 'investigation', 'ai']","['sql', 'python', 'tableau', 'data manipulation', 'r']","['machine learning', 'statistics', 'technical ability', 'economics', 'dashboards', 'computer science', 'analytics', 'statistical analysis', 'investigation', 'ai']","['environment', 'private', 'events', 'healthcare', 'marketing', 'retirement', 'growing companies']"
212,263,Data Engineer,"uberflip is a marketing technology company with 140 employees founded in toronto, canada in 2012. our content experience platform empowers marketing and sales to create engaging, relevant content destinations quickly for every campaign, audience, and stage of the customer journey. marketing teams use our platform to scale how they incorporate content into every touchpoint and remove friction from the customer journey by surfacing the right content at the right time. we re on the search for a data engineer reporting into our bi manager, you will be working with the team to support our leaders in making more strategic decisions for our business. what you will be doing work in a collaborative manner and interact with other engineering team members, solution architects, project managers, and business analysts. you ll play a key role in our b.i. and product analytics roadmap by implementing and maintaining data flows to transfer and transform data from or to multiple cloud based sources and destinations. you will be maintaining and creating new business model mappings for our internal or external users using our b.i. platform. you will be relying on advanced sql skills to accurately handle reporting requirements. you will be involved in supporting many aspects of our databases solution ecosystem. we want to talk to you if you have experience with 3 years of software development experience with an emphasis in database development solid sql skills to support our reporting needs using sql and occasionally python. knowledge in extracting data from various flat files, rdbms, and third party api s. familiar with aws environment front end experience working with bi platforms to create logical layers. data warehouse or bi platforms snowflake or looker third party software salesforce, catalyst, pendo, zendesk usage of code collaboration tools jira, confluence, git, and github what you will love about us great company culture inclusive and collaborative work environment competitive health benefits for you and your family starting day one wellness programs including company paid counselling flexible working hours or remote work flexibility employee stock option program additional paid l.u.v and wellness days parental leave top up program learning credits to put towards your professional development regular standups, demos, and socials to keep us aligned and connected and so much more uberflip is committed to building a team that represents a variety of backgrounds, perspectives, and skills. we believe that the more inclusive we are, the better our work will be. if you re smart and good at what you do, come as you are","['databases', 'rdbms', 'confluence', 'github', 'sql', 'python', 'looker', 'software', 'reporting', 'software development', 'analytics', 'product', 'aws', 'zendesk', 'jira', 'demos', 'bi', 'database development', 'api', 'project managers', 'git', 'snowflake']","['sql', 'python', 'databases', 'looker', 'zendesk', 'jira', 'demos', 'bi', 'rdbms', 'api', 'confluence', 'git', 'aws', 'snowflake']","['software', 'database development', 'reporting', 'project managers', 'software development', 'analytics', 'github']","['marketing', 'environment', 'sales']"
213,266,Senior Data Scientist,"clearco is a company built by founders for founders, and we re laser focused on our mission to help entrepreneurs succeed. the senior data scientist will have the opportunity to create models, build advanced analytics, and leverage machine learning to help clearco s founders improve their understanding of their data and grow their businesses. application deadline june 22, 2021 please be advised someone from the recruitment team will be in touch shortly after the application deadline. what your day to day will look like you will collaborate and influence senior leadership to ensure data science directly impacts strategy as your first task, you will leverage nlp techniques for web scraping to build a custom email automation platform that maximizes incoming company sales leads you will draw connections about a domain s change in facebook followers and it s likelihood to take a capital infusion and so much more you will analyze and build models on data, but will have the autonomy to collect their own data via purchase, web scraping , and manual collection you will conduct original analyses to advise and influence product, engineering, and operations efforts you will thrive if you have exceptional time management and organization skills you can manage project ambiguity, complexity, and interdependencies excellent interpersonal skills you are able work with and influence a diverse group of stakeholders a self starter mindset you enjoy discussing a problem and after the discussion is over, you can t wait to get started on the execution of a project the ability to think outside the box and understand the bigger picture you are an innovative thinker demonstrated the ability to thrive in a fast paced environment, while collaborating with and influencing business partners to achieve strategic goals technical requirements 4 years of experience in a statistician, researcher, machine learning engineer, data engineer, or data analyst role a bachelor s master s, and or or phd in statistics, machine learning, mathematics, computer science, economics or any other related quantitative field experience with python, kubernetes or docker, version control or git, snowflake or sql, analytics, and statistics experience with spacy, word embedding, web scraping for data collection clearco is an equal opportunity employer. we celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. at clearco, we re committed to developing and upholding an inclusive, transparent, and comfortable environment for all. we create a space where every voice, perspective, and idea is heard and acknowledged. we embrace differences, and know that our diverse team is our strength and what drives our innovation. clearco is committed to developing a barrier free recruitment process and work environment. if you require any accommodation, please email us at and we ll work with you to meet your accessibility needs.","['kubernetes', 'sql', 'python', 'machine learning', 'statistics', 'economics', 'nlp', 'data science', 'git', 'technical requirements', 'analytics', 'mathematics', 'computer science', 'data collection', 'web scraping', 'version control', 'snowflake', 'automation']","['kubernetes', 'sql', 'python', 'spacy', 'git', 'nlp', 'clearco', 'web scraping', 'snowflake']","['machine learning', 'statistics', 'economics', 'data science', 'data collection', 'technical requirements', 'analytics', 'mathematics', 'computer science', 'version control', 'automation']","['capital', 'environment', 'laser', 'sales']"
214,267,Data Visualization Analyst,"about us our information technology department is seeking a highly motivated and career minded individual to join our team as a data visualization analyst roadside. the focus of this position is to work closely with business systems analysts and data scientists to gain in depth understanding of business strategy, processes, services, roadmap and the context in which the business operates to create meaningful reports and dashboards based on various large sets of information. this role will be key to combining data from multiple sources to create meaningful actionable reports for business use. who we are as canada s largest automobile association, we are passionate about keeping our members safe whether they are on the road, at home, or travelling abroad. meeting the diverse needs of our two million members requires high performing, forward thinking, and innovative people who work collaboratively to keep propelling our business forward. life at caa club group is fast paced, performance driven and rewarding. we value our associates career growth and ongoing professional development and we regularly recognize their achievements and outstanding results. caa club group is known for providing stellar emergency roadside assistance to our motoring members and non members. we work hard and play hard. we re about doing what s right and feeling good about it. position details what you will do design, develop and test dynamic and informative data visualizations through actionable reports and dashboards combine large datasets from multiple sources to deliver transform data for visualizations which are easy to interpret, and can be used to identify trends and correlations collaborate with stakeholders to document business requirements to generate functional requirements for data visualizations research to identify relevant data to support various projects participate in roadmap development sessions for future visualization products and dashboards participate in machine learning modeling projects by compiling data visualization requirements and creating relevant visualizations diligently support and lead where needed, various activities between the teams to ensure the business and technical requirements and objectives are met. participate and contribute to the overall system design. who you are strong attention to detail proficient in querying oracle and sql databases 1 2 years experience with data visualization libraries, frameworks and tools ability to establish and apply data visualization best practices and graphical design principles possesses excellent oral and written communication skills team player with strong interpersonal skills and ability to take a leadership role when necessary problem solving and analytical skills comfortable with handling large datasets experience with batch scripting and linux commands are an asset our commitment we are an equal opportunity employer and are committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act, 2005 . caa ccg will provide accommodations to job applicants with disabilities throughout the recruitment process. if you require an accommodation, please notify us and we will work with you to meet your needs.","['sql', 'analytical skills', 'visualization', 'business systems', 'machine learning', 'databases', 'linux', 'datasets', 'scripting', 'dashboards', 'data visualization', 'modeling', 'technical requirements', 'information technology']","['sql', 'databases', 'linux']","['analytical skills', 'visualization', 'business systems', 'machine learning', 'datasets', 'scripting', 'dashboards', 'data visualization', 'ca', 'modeling', 'technical requirements', 'batch', 'information technology']","['business strategy', 'design']"
215,268,HEAD OF ANALYTICS & INSIGHTS/DATA SCIENTIST,"for over 25 years we ve been helping our community with essential oil blends that actually work. these essential oil blends treat stress, pain, gut, balance, and support in relaxation prior to sleep, and for symptoms of coughs and colds. we know that a life committed to wellness is greater than one focused on illness, and believe that reaching for natural can enhance your long term health and wellness, every day. we have been ranked by canadian business and profit as one of canada s fastest growing companies. to support us on our journey, we are seeking diverse, purpose lead people to join our team. get ready to celebrate global wellness with us. description the role of the head of analytics insights or data scientist, will be to help us unlock the key insights that will drive our business decisions not only through analysis coming from the team, but also through the enablement of the right data and clear insights for leaders across the marketing and commercial organizations. responsibilities analytics insights lead cross functional projects using advanced data modeling and analysis techniques to discover insights that will guide strategic decisions and uncover future growth opportunities and business strategies. manage the process to uncover insights in business operations seeking to increase insight clarity, as well as efficiency in the process of data management lead our community member analytics supporting the definition of kpis and targets, and using audience and segmentation strategies to increase our acquisition effectiveness and foster brand loyalty in partnership with the head of growth, direct the performance marketing analytics strategy developing targets and uncovering key insights, and determining business and data requirements for omni infrastructure lead the reporting and analysis of ecommerce performance metrics and support the head of ecommerce in strategic planning and setting targets, measurement of new features, business performance insights, and leadership for testing, consumer connects, and a or b tests partner with marketing and channel leads to measure reach effectiveness through the funnel from brand awareness, impressions, followers, channel traffic, and support clear identification of return on investment analyze market trends, research, and opportunities monitor competitor marketing outcomes identify key external trends and performance indicators to support the strategic direction for marketing and wider leadership including brand and product support the development of performance models for new business development, collaborations, and channel expansions integrate qualitative feedback into analysis in partnership with voc, ux, stores, surveys and more data reporting partner with it to represent the business in the development of key performance marketing and customer data and reporting infrastructure to develop a 360 view of our consumer build, develop and maintain data models, reporting systems, data automation systems, dashboards and performance metrics support that support key business decisions partner with cross functional leadership to identify key data challenges and determine technical and process solutions ensure accuracy and accessibility of data, with clear data definitions for cross functional leaders process team management develop a team of data analysts that help inform the future business strategies. build on key reporting frameworks, cadences and process for weekly, monthly and quarterly business reviews identify key tools, platforms and training required to ensure that marketing and commercial leaders can uncover key insights for their business and manage their performance develop data visualization tools for teams to support presentation of insights, and support the preparation of communication on business results and strategic direction for executive and management teams. ensure accuracy of data and on time delivery of deliverables support teams with management of data intake process, and clear prioritization framework develop and implement quality controls and departmental standards to ensure quality standards, organizational expectations, and regulatory requirements anticipate future demands of initiatives related to people, technology, budget and business within the organization to support an insights driven approach applicant requirements bachelor s degree in business, consumer behavior, market research or quantitative discipline 15 years of experience in marketing, market research, and customer strategy experience in utilizing new digital techniques and methodologies to understand changing consumers including social listening, digital testing, building a customer panel experience includes complex, strategic research projects and using innovative methodologies experience with multivariate statistics, predictive modeling, regression models experience in media measurement and creative testing experience with managing and executing within the perimeters of a budget skilled at influencing, generating consensus and negotiating at the executive level strong leadership and team building skills. excellent verbal and written communication and presentation skills excellent organizational and prioritization skills excellent problem solving skills strong collaborator, with a track record of building cross functional relationships and alignment to strategic creative approach","['ux', 'statistics', 'reporting systems', 'reporting', 'testing', 'data models', 'dashboards', 'data visualization', 'analytics', 'data', 'digital', 'modeling', 'data management', 'enablement', 'automation', 'customer']",['data models'],"['reporting systems', 'dashboards', 'data visualization', 'statistics', 'tests', 'reporting', 'analytics', 'data', 'customer data', 'testing', 'performance', 'predictive', 'automation', 'planning', 'ux', 'strategic', 'modeling', 'data management', 'enablement']","['business development', 'regulatory requirements', 'market research strategy', 'metrics', 'new', 'marketing', 'brand', 'performance', 'business operations', 'market research', 'surveys', 'growing companies', 'performance indicators', 'product support', 'return on investment']"
216,270,Data Scientist Lead,"avenue code is the leading software consultancy focused on delivering end to end development solutions for digital transformation across every vertical. we re privately held, profitable, and have been on a solid growth trajectory since day one. we care deeply about our clients, our partners, and our people. we prefer the word partner over vendor , and our investment in professional relationships is a reflection of that philosophy. we pride ourselves on our technical acumen, our collaborative problem solving ability, and the warm professionalism of our teams. about the opportunity we re looking for a passionate, talented, and innovative data scientist with a strong machine learning background to help build industry leading ai or ml enabled applications for retail or commerce platforms. as a data scientist you will be working with big data to solve real world problems for customers partners, will design and run experiments, research new ai or ml algorithms techniques, and find new ways of optimizing risk, opportunities,profitability, and customer experience. required qualifications hands on experience in leveraging data science and analytics to solve business problems industry experience in machine learning or related fields extensive experience in python and sql programming experience in spark framework and pyspark hands on experience with scikit learn, pandas, and at least one of the deep learning frameworks pytorch, keras, or tensorflow experience with different recommender systems and frameworks experience with building systems from scratch, putting them into production, and performing a b testing experience with machine learning orchestration frameworks . nice to have knowledge of scala familiarity with modern approaches to computer vision problems knowledge of google cloud platform familiarity with agile does this sound like you apply now to become an avenue coder li remote","['pyspark', 'pytorch', 'tensorflow', 'big data', 'sql', 'python', 'keras', 'software', 'scala', 'computer vision', 'data science', 'pandas', 'analytics', 'programming', 'machine learning', 'testing', 'google cloud platform', 'algorithms', 'deep learning', 'digital transformation', 'ai']","['sql', 'python', 'keras', 'pyspark', 'scala', 'pytorch', 'google cloud platform', 'pandas', 'programming', 'big data']","['deep learning', 'machine learning', 'tensorflower', 'software', 'testing', 'computer vision', 'data science', 'analytics', 'algorithms', 'digital transformation', 'ai']","['retail', 'commerce', 'design', 'customer experience']"
217,271,Clinical Scientist / Scientifique clinique,"the clinical scientist is responsible for medical writing activities at innovaderm. the individual will author or contribute to development of clinical and regulatory documents , as well as scientific publications. this role will be perfect for you if you are a strong medical writer with demonstrated ability to produce high quality scientific documents to support clinical research. you enjoy learning continuously and keeping yourself informed. having an impact within a growing company with momentum motivates you. responsibilities is accountable for own medical writing deliverables, including quality, stakeholder communication, resolution of project issues, and timeline management collaborates to clinical development of phase 1 or first in man studies, proof of concept trials, phase 2b 3 studies, and phase 4 or registry trials. contributes to study design and writes or reviews clinical study protocols or amendments reviews informed consent or assent forms, study reference manuals, statistical analysis plans, and mock shells of statistical tables or figures or listings reviews, analyzes, and interprets study data based upon scientific expertise and industry standard practices writes or reviews narratives and clinical study reports prepares scientific abstracts, posters, and manuscripts performs on line literature searches provides documents with high quality in terms of scientific content, organization, clarity, accuracy, format and consistency may perform quality control review of documents prepared by other team members participates in process improvement efforts of the department. requirements ideal profile education msc in life sciences phd is an asset experience experience in writing clinical or regulatory documents such as study protocols and clinical study reports experience analyzing and reporting on study data knowledge and skills good knowledge of good clinical practices, and applicable health canada and food and drug administration regulations or guidelines. good knowledge of drug development process advanced english writing skills strong english communication skills french is an asset strong proficiency of word ability to handle varied and multiple tasks, organize own work, and prioritize workload has excellent attention to detail client focused attitude quick learner, good adaptability, and versatile. our company the work environment at innovaderm, you will work with brilliant and driven colleagues. our values are collaboration, innovation, reliability and responsiveness. we offer a stimulating work environment and attractive advancement opportunities. as a clinical scientist, you will be eligible for the following perks flexible work schedule permanent full time position complete benefits offices near public transportation possibility of working from home or our office in montreal in accordance with company policies and public health directives ongoing learning and development about innovaderm innovaderm is a contract research organization specialized in dermatology. since its beginnings in 2000, our organization has benefited from a solid reputation for the quality of its research and services exceeding the expectations of its clients. based in montreal, innovaderm continues to grow and expand in north america and europe. innovaderm is committed to providing equitable treatment and equal opportunity to all individuals. as such, innovaderm will provide accommodations throughout the recruitment and selection process to applicants with disabilities, upon request. innovaderm only accepts applicants who can legally work in canada. description fr le scientifique clinique est responsable des activit s de r daction m dicale chez innovaderm. cette personne r digera ou contribuera l laboration de documents cliniques et r glementaires , ainsi que de publications scientifiques. ce poste sera parfait pour vous si vous tes un r dacteur m dical exp riment avec une habilet d montr e produire des documents scientifiques de haute qualit pour supporter la recherche clinique. vous aimez apprendre continuellement et vous garder inform sur les nouveaut s dans le domaine. avoir un impact au sein d une compagnie en pleine croissance et en pleine lanc e vous motive. responsabilit s est responsable de ses propres livrables de r daction m dicale, y compris la qualit , la communication avec les parties prenantes, la r solution des probl mes du projet et la gestion du calendrier collabore au d veloppement clinique des tudes de phase 1 or essais de premi re administration , des essais de preuve de concept , des tudes de phase 2b 3 et des essais de phase 4. contribue la conception de l tude et r dige et examine les protocoles et amendements des tudes cliniques r vise les formulaires de consentement clair et d assentiment, les manuels de r f rence des tudes, les plans d analyse statistique et les coquilles simul es des tableaux or figures or listes statistiques r vise, analyse et interpr te les donn es d tude en fonction de l expertise scientifique et des pratiques standard de l industrie r dige et r vise les rapports d tudes cliniques pr pare des r sum s, posters et manuscrits scientifiques effectue des recherches de litt rature en ligne fournit des documents de haute qualit en termes de contenu scientifique, d organisation, de clart , d exactitude, de format et de coh rence peut effectuer un examen de contr le de la qualit des documents pr par s par d autres membres de l quipe participe aux efforts d am lioration des processus du d partement requirements fr profil recherch ducation ma trise en sciences de la vie un doctorat repr sente un atout. exp rience exp rience en r daction de documents cliniques et r glementaires tels que les protocoles d tude et les rapports d tudes cliniques exp rience en en analyse et communication des donn es d tude aptitudes et connaissances bonne connaissance des bonnes pratiques cliniques et des r glements or lignes directrices applicables de sant canada et de la food and drug administration . bonne connaissance du processus de d veloppement des m dicaments excellentes comp tences en r daction anglaise solides comp tences en communication anglaise le fran ais est un atout excellente ma trise de word capacit g rer des t ches vari es et multiples, organiser son propre travail et prioriser la charge de travail excellente attention aux d tails attitude ax e sur le client capacit apprendre rapidement, bonne adaptabilit et polyvalent. our company fr notre entreprise l environnement de travail chez innovaderm, vous travaillerez avec des collaborateurs comp tents et dynamiques. nos valeurs sont la collaboration, l innovation, la fiabilit et la r activit . nous offrons un environnement de travail stimulant et des possibilit s d avancement int ressantes. dans le poste de scientifique clinique, vous b n ficierez des conditions suivantes flexibilit sur l horaire poste permanent temps plein gamme d avantages sociaux bureau proximit du transport en commun possibilit de travail au bureau montr al, ou la maison en fonction des politiques de l entreprise et des directives de la sant publique formation et d veloppement continu propos d innovaderm innovaderm est une entreprise de recherche clinique contractuelle sp cialis e en dermatologie. depuis ses d buts en 2000, notre entreprise taille humaine b n ficie d une solide r putation autant pour la qualit de la recherche effectu e que pour la qualit des soins offerts, d passant les attentes de ses clients. bas montr al, innovaderm continue aujourd hui sa croissance en am rique du nord et en europe. innovaderm s engage assurer une approche quitable ainsi que des opportunit s quivalentes pour tous les candidats. ce titre, innovaderm fournira sur demande des accommodations aux candidats ayant un handicap, et ce, travers toutes les tapes du processus de recrutement, si demand . innovaderm accepte uniquement les candidats pouvant l galement travailler au canada. le genre masculin est utilis sans discrimination et dans le seul but d all ger le texte.","['administration', 'proof of concept', 'reporting', 'clinical development', 'statistical analysis', 'quality control', 'r']",['r'],"['clinical', 'administration', 'proof of concept', 'reporting', 'clinical development', 'statistical analysis', 'quality control']","['environment', 'manuals', 'education', 'public health', 'process improvement', 'forms', 'design', 'life sciences', 'contract research', 'derology', 'clinical research', 'regulatory documents', 'drug administration', 'drug development', 'stake', 'regulations']"
218,273,Applied Scientist,"1 years of hand on modeling experience in the area of predictive modeling, nlp, personalization, recommendation system deep understanding of statistical modeling and deep learning techniques. strong problem solving ability strong written and verbal communication skills and data presentation skills. 1 year experience in python and sql about us inclusive team culture here at amazon, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team puts a high value on work live balance. it isn t about how many hours you spend at home or at work it s about the flow you establish that brings energy to both parts of your life. we believe striking the right balance between your personal and professional life is critical to life long happiness and fulfillment. we offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. mentorship career growth our team is dedicated to supporting new members. we have a broad mix of experience levels and tenures, and we re building an environment that celebrates knowledge sharing and mentorship. our senior members enjoy one on one mentoring and thorough, but kind, code reviews. we care about your career growth and strive to assign projects based on what will help each team member develop into a better rounded engineer and enable them to take on more complex tasks in the future. amazon science gives you insight into the company s approach to customer focused scientific innovation. amazon fundamentally believes that scientific innovation is essential to being the most customer centric company in the world. it s the company s ability to have an impact at scale that allows us to attract some of the brightest minds in artificial intelligence and related fields. our scientists continue to publish, teach, and engage with the academic community, in addition to utilizing our working backwards method to enrich the way we live and work. please visit https or or for more information. are you interested in helping amazon ensure that customers make great purchase decisions and that the world s most recognized brands using amazon are successful listing and selling their products the brand protection team designs and builds high performance software systems using machine learning that identify and prevent abuse on behalf of brand owners worldwide. we are looking for a highly talented scientist to help build of our vision for brand protection. as a applied scientist on the team, you will interface directly with product and engineer to build hands of the wheel solutions to determine how selling partners list on our catalog. you will work backwards from data insights and customer feedback to build the right machine learning solutions, and resourceful in finding innovative solutions to unsolved problems. this is a global role that will include interaction with brands, sellers and internal teams in countries outside of the united states, requiring a strong ability to communicate effectively and understand the different needs of global customers. you should have extensive experience leading multiple machine learning initiatives, from conception to launch in a rapidly evolving environment. amazon s growth requires leaders who move fast, have an entrepreneurial spirit to create new solutions, have an unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems. major responsibilities understand business challenges by analyzing data and customer feedback collaborate with tech and product teams on model building strategies and model experiment, implementation and continuous improvement analyze and extract relevant information from large amounts of both structured and unstructured data to design strategies to solve business problems. use cv, nlp and state of the art machine learning techniques to create scalable solutions for business problems create business and analytics reports and present to the senior management teams research and implement novel machine learning and statistical approaches 3 years of hand on modeling experience in the area of deep learning, nlp or computer vision understanding of software development life cycle and project planning or execution skills including estimating and scheduling. ability and willingness to multi task and learn new technologies quickly. familiar with aws machine learning technologies such as sagemaker. strong program skills in c or c , java, and or or matlab amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. if contacted for an employment opportunity, advise human resources if you require accommodation, including in order to apply for a position.","['personalization', 'https', 'model building', 'unstructured data', 'c', 'java', 'sql', 'python', 'computer vision', 'data', 'analytics', 'aws', 'machine learning', 'software development life cycle', 'statistical', 'artificial intelligence', 'project planning', 'matlab', 'model', 'deep learning', 'nlp', 'software systems', 'modeling']","['https', 'sql', 'python', 'nlp', 'c', 'aws', 'predictive', 'java', 'matlab']","['personalization', 'deep learning', 'model', 'unstructured data', 'machine learning', 'software development life cycle', 'computer vision', 'software systems', 'statistical', 'data', 'artificial intelligence', 'analytics', 'modeling', 'project planning']","['environment', 'continuous improvement', 'affinity', 'human resources', 'design', 'art', 'team culture', 'legislation', 'mentoring']"
219,274,Principal Clinical Data Scientist Lead,"do you want to watch clinical development change, or do you want to be the one to shape it because we re hoping you re here for the latter. who are we we are pra. we are 20,000 employees strong, operating in more than 90 countries. we are committed to saving lives and we are constantly striving to be the best at what we do. our impact is real and we see it every single day. we help get life saving drugs into the hands of those who need them most. principal clinical data scientist lead overview leads end to end data review activities performed on a clinical trial. accountable for achieving clinical data management deliverables on time, with high quality and to agreed financial metrics. responsible for applying advanced analytics to centrally aggregate and analyze data from disparate sources to identify risks and issues impacting data integrity, patient safety and or or regulatory compliance. triages and assigns data review findings to the appropriate project team role for follow up and resolution. communicates trending analyses and a summary of findings to internal and external stakeholders to support the on time delivery of data fit for analysis. responsibilities serves as the primary contact for internal and external team members regarding clinical data management data review activities and leads these review activities to ensure the delivery of data fit for analysis. provides input into clinical system development activities, to ensure systems support the data review needs of the study, focusing on critical data and processes, and identified risks. ensures clinical data management review requirements are put into production per the study s protocol risk evaluation and integrated data review plan , and that ongoing data review activities are compliant with study plan requirements. contributes to the development and maintenance of study plans documents specifying data review strategy and applicable procedures on assigned protocols or projects, including but not limited to data management plan. develops and oversees timeliness of clinical data management activities during the life cycle of studies as it relates to data review and data delivery milestones. centrally reviews clinical data at aggregate level, using analytic reporting tool to support the identification of risks and data patterns or trends. mitigates risks by using signal detection and quality indicators. communicates and triages issues to appropriate roles for follow up and action to address root cause. proactively identifies out of scope clinical data management activities to the study project managers to be implemented in required change orders. leads and hosts the data monitoring meetings, communicating issues to the internal and external stakeholders in a meaningful way such as summarizing the data and representing the information visually. leads clinical data management activities on more complex projects with diverse scope. accountable for creating and maintaining clinical data management timelines, to oversee and achieve high quality interim and final contractual deliverables for more advanced projects. using detailed knowledge of the protocol, identifies critical data and processes from protocol review, and supports protocol risk evaluation process. works with assigned project teams to communicate, address and resolve complex datarelated questions and recommends potential solutions escalates issues which potentially impact patient safety or study analysis. trains and mentors new and less experienced team members. participates in sponsor and or or third party audits. develops tools or analytics used to monitor compliance and identify trends. actively seeks new business opportunities with assigned clients and collaborates with internal colleagues for new business initiatives. develops and maintains data review study documentation as appropriate to facilitate data validation and analytics. performs complex analytic reviews as defined in the scope of work and functional plan, focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretations of the final analysis. identifies root cause to systematically resolve complex data issues. sets expectations and ensures consistency in data review approach and compliance and identifying trends. may help to write articles for industry publications and give presentations at industry conferences. qualifications bachelor s degree in quantitative, scientific or health related field required. 8 years of relevant experience required. knowledge and or or understanding of analytic open source and or or enterprise level etl and analytic tools and practices sound knowledge of analytic modeling methods such as regression, classification and clustering strong programming skills in applicable systems, e.g., r, sql, python, sas skill to efficiently navigate through large volumes of complex data, to interpret complex data problems, and to apply technical solutions. ability to analyze a complex data issue and design paths to effective potential solutions, understanding the impact of suggested solutions and to help the project team make better decisions. in depth knowledge of the drug development process including risk based monitoring principles, clinical and biometrics procedures, workflows, and software systems. expertise in interpreting protocols and identifying risks and appropriate mitigation strategies for clinical studies excellent skill in aggregate data review and interpretation using visualization or analysis software, e.g., jreview,tableau, sas exellent project management and leadership skills excellent written and verbal communication and presentation skills ability to work collaboratively and effectively in a crossfunctional and culturally diverse team advanced ability to proactively represent data management internally and externally for all study related items and find pragmatic solutions in compliance with regulatory requirements and policies. to qualify for a position located in the united states, u.s. applicants must be legally authorized to work in the united states, and should not require, now o options apply for this job onlineapply share sorry the share function is not working properly at this moment. please refresh the page and try again later. share on your newsfeed connect with us","['visualization', 'tableau', 'data integrity', 'root cause', 'documentation', 'clinical data', 'less', 'risk', 'sql', 'python', 'software', 'reporting', 'data review trends', 'project managers monitoring', 'analytics', 'data', 'programming', 'sas', 'data review', 'protocol', 'clinical development', 'clinical data management', 'software systems', 'modeling', 'data management', 'etl', 'r']","['system development', 'sql', 'python', 'tableau', 'programming', 'documentation', 'less', 'sas', 'r']","['visualization', 'analysis', 'clinical data review', 'data integrity', 'root cause', 'clinical data', 'signal', 'software', 'reporting', 'analytics', 'data', 'data review review', 'identifying trends', 'data review', 'clinical', 'protocol', 'data monitoring', 'clinical development', 'data review delivery', 'clinical data management', 'project managers', 'software systems', 'modeling', 'data management', 'etl']","['validation', 'and compliance', 'regulatory requirements', 'biometrics', 'metrics', 'new', 'business initiatives', 'change orders', 'presentations', 'design', 'project management', 'drug development', 'triages', 'regulatory compliance']"
220,275,Applied Scientist 1,"in the bing image search team, we use machine learning, deep learning and nlp to model user queries and return the content that best satisfies their intents. it s more than just finding a web page that matches a query it s about training sophisticated machine learnt models to drive ranking and triggering, using sentence embeddings and deep learning to understand the quality of matches, online learning to react quickly to change, natural language processing to understand queries. we take advantage of big data and signals from millions of people across the web, pulling together and combining information from multiple sources to provide the user with results that best match their intent. machine learning, deep learning, natural language processing, computer vision, big data mining and information retrieval it s all part of the job. this is a fun and fast paced environment, where developers are empowered to collaborate and innovate. this is a great opportunity to work on something highly strategic to microsoft, and an opportunity to directly impact millions of users in an exciting area. as a team dedicated to building and promoting a diverse and inclusive team and environment, we look forward to receiving applications from qualified individuals of all backgrounds responsibilities build multi lingual text embeddings, machine learning and deep learning models from big data, to solve multimedia related classification and ranking problems, including query classification and intent prediction. build text classification models leveraged by multiple teams throughout microsoft. ml fundamentals data mining, wrangling, processing, visualization, model training, analysis. contribute ideas and techniques to shape decisions and improve search quality metrics. participate in design, implementation and execution with a team of engineers, applied scientists and product managers. qualifications required qualifications bs or higher degree in computer science, statistics or applied mathematics, data science, machine learning or similar technical field or equivalent practical experience 1 years of experience with general purpose programming language 1 years of experience in the areas of machine learning, deep learning, information retrieval, natural language processing or data mining good communication skills and ability to work in a collaborative environment preferred qualifications knowledge of information retrieval, natural language processing techniques and semantic embeddings experience with semi supervised learning, active learning, outlier detection clearly demonstrated record of accomplishment in delivering results. passion, creative problem solving skills, and ability to ramp up in new areas. scientific publications and experience of peer review for journals or conferences microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['prediction', 'deep learning', 'data mining', 'language processing', 'machine learning', 'visualization', 'statistics', 'information retrieval', 'computer vision', 'nlp', 'data science', 'computer science', 'programming', 'big data', 'legal', 'applied mathematics']","['programming', 'big', 'big data', 'nlp']","['prediction', 'deep learning', 'data mining', 'model', 'language processing', 'machine learning', 'visualization', 'statistics', 'information retrieval', 'deep learning learning', 'computer vision', 'wr', 'data science', 'computer science', 'natural', 'applied mathematics']","['environment', 'metrics', 'design', 'legal', 'recruiting', 'regulations']"
221,276,Data Engineer,"who is ratehub.ca we re a company on a mission. every single team member, from product engineering, to sales marketing, finance, operations and everything in between is obsessed with one thing helping canadian s make better financial choices. and we re pretty great at it, too. via our digital application technology and our award winning in house brokerages, we help over 1m canadian s per month make a positive impact on their finances. 365 days a year we deliver our users the best online mortgage experience, personalized credit card options, and cheaper auto home insurance policies than they typically get from their existing financial adviser. changing how people make financial choices isn t easy, though. we know that achieving our mission is full of challenges challenges that can be complex and often unexpected, but that are always interesting, rewarding and fun to solve as a team. this is where you come in. we are on the hunt for the right kind of people to join us and help lead us forward to continued growth. we re looking for a data engineer to join our growing team, in downtown toronto . reporting to the director of analytics, the data engineer is an integral member of ratehub s analytics team. this role will be responsible for building automations for unstructured manual processes in the different functions such as finance, marketing and sales to increase efficiency of the overall business. in addition, the role is also responsible for working with business stakeholders to enable data self service and support them with adhoc analytics where needed. this is an exciting opportunity to join a high performing team, directly impacting the business as well as the design and evolution of the organization s internal processes and infrastructure. your responsibilities partner with internal stakeholders to determine requirements, anticipate future needs, and identify areas of opportunity to drive efficiency and scalability develop data pipelines from various internal and external sources and build robust and scalable automations for manual processes develop a good understanding of how data will flow and be stored through the organization across multiple applications such as crm, broker sales tools, finance or accounting tools, backend etc build new etl scripts to integrate additional data sources as needed by the business setup, maintain and roll out data self service for our business stakeholders support the business with adhoc analytical requests as required your qualifications post secondary degree we value intelligence over relevance, but a bachelors in computer science would be looked upon favorably 3 years of similar work experience advanced sql knowledge experience in building and maintaining etl pipelines and managing them through distributed job schedulers experience in working with aws infrastructure familiarity with data visualization tools like tableau, power bi, looker familiarity with excel and or or google sheets beyond the technical you are detail oriented high standard of data quality and integrity resourceful you don t have all the answers, but you know how to get them strong problem solving skills and critical thinking abilities adaptable to a fast paced environment and able to pivot quickly to align with changing priorities culture fit fun you bring your whole self to work and make an effort to contribute to our workplace culture in a positive way do the right thing you are able to assess both customer and company needs to make good business choices growth mindset you love to learn and try new things willing to help you care about your team members and are willing to help out outside your realm of expertise. impact orientated you are motivated by results and track to completion job perks competitive salary we know it s expensive to live or work in toronto flexible hours enjoy a couple more hours of sleep in the morning, if you want benefits health is wealth a benefits package with no employee contribution required perks rrsp matching program, individual training allowance, access to financial literacy training and resources casual dress code if it s good enough for you, it s good enough for us fun team socials ratehub welcomes and encourages applications from people with disabilities. accommodations are available upon request for candidates taking part in all aspects of the selection process. p0wa2cwvex","['sql', 'looker', 'google sheets', 'data pipelines', 'tableau', 'bi', 'reporting', 'data visualization', 'product engineering', 'scalability', 'computer science', 'analytics', 'data quality', 'aws', 'crm', 'pipelines', 'etl']","['sql', 'looker', 'google sheets', 'tableau', 'bi', 'data quality', 'aws', 'pipelines']","['data pipelines', 'reporting', 'data visualization', 'product engineering', 'scalability', 'computer science', 'analytics', 'crm', 'etl']","['environment', 'accounting', 'marketing', 'design', 'finance', 'sales', 'insurance']"
222,280,Senior Data Scientist/Manager,"about cerebri ai cerebri ai cvx platform uses the best artificial intelligence , operation research , and software to provide what is required in our digital age value a customer s commitment to a brand and related products. it then uses these insights to then drive the selling of products and services. we use ai to answer the fundamental questions of the digital age who talks to the customer who understands the customer how do we do this at scale when we have millions of customers cerebri ai cvx platform includes a streaming capable ai software pipeline that processes data intake thru to producing insights and actions presenting them via our apis, in our customers systems, or our ux. one customer journey per customer means all models targeting cx and revenue kpis and related next best offers use the same journeys. we work with companies selling to over 200 million consumers and have 26 patents filed on the cerebri cvx platform. we now have 35 employees in three offices in austin, toronto, and washington dc . over 80 of the staff are in technical roles in data science and software engineering. how do we do this we hire the best data scientists, mathematicians, and software developers and work as a cross disciplinary team or gang or clan. we work hard, laugh hard, and impress our peers and clients. because we can. and because we want to. to learn more, visit cerebriai.com. in the meantime, if you think you have what it takes, give us a spin and upload resume. cerebri ai was recognized as 2019 cool vendor for customer journey analytics by gartner. the ideal candidate the ideal candidate is adept at leveraging large data sets to find patterns and using modelling techniques to test the effectiveness of different actions. s or he must have strong experience using various data mining or data analysis methods, using a variety of data tools, building and implementing models, using or creating algorithms, creating or running simulations, and testing its real time implication. s or he must be comfortable working with a wide range of stakeholders and functional teams, trading off design to help others. responsibilities for senior or principal data scientist design, develop, test, advocate, evangelize and build data driven modeling approaches assess the effectiveness and performance of modeling and data enhancement techniques perform feature analysis develop ontology for key market segments develop outcome or event taxonomy for key business models coordinate with different functional teams to implement data engineering, models and monitor outcomes build utility code and handle miscellaneous support tasks documenting projects and maintaining project documentation qualifications strong problem solving skills with an emphasis on product development 6 year experience working with and creating data architectures experience with artificial intelligence, natural language processing, machine learning excellent understanding of machine learning techniques supervised or unsupervised or semi supervised learning, svm, tree based methods, neural networks, naive bayes, k nn, ensemble methods, cnn, rnn, nlp, feature engineering, hyperparameters optimization, data visualization knowledge of advanced statistical techniques and concepts experience using statistical computer languages and conventional data science toolkits, such as pandas, weka, numpy, matlab experience with nosql databases knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations excellent written and verbal communication skills project management a drive to learn and master new technologies and techniques tools we use confluence jira spark azure, aws, kubernetes python, scala keras, scikit learn, pandas, numpy bit bucket, github jupyter notebook postgress, parquet, mysql javascript, airflow, pulsar nice to haves ph.d. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline experience in operations research, applied statistics, algorithmic complexity, rds experience with time series, econometrics experience with streaming systems experience with object oriented modeling or mvc design patterns how do we do this we hire the best data scientists, mathematicians, and software developers and work as a cross disciplinary team or gang or clan. we work hard, laugh hard, and impress our peers and clients. because we can. and because we want to. to learn more, visit cerebriai.com. in the meantime, if you think you have what it takes, give us a spin and upload resume. specify your location preference","['databases', 'data visualization', 'confluence', 'javascript', 'mysql', 'github', 'kubernetes', 'cnn', 'python', 'statistics', 'keras', 'software', 'scala', 'physics', 'data science', 'pandas', 'analytics', 'aws', 'data engineering', 'econometrics', 'nosql', 'data mining', 'jupyter', 'machine learning', 'design patterns', 'software development life cycle', 'testing', 'numpy', 'mvc', 'artificial intelligence', 'data analysis', 'algorithms', 'matlab', 'airflow', 'ux', 'project documentation', 'language processing', 'jira', 'neural networks', 'nlp', 'simulations', 'ontology', 'optimization', 'modeling', 'feature', 'ai']","['databases', 'confluence', 'rds', 'javascript', 'mysql', 'kubernetes', 'cnn', 'python', 'keras', 'scala', 'bayes', 'pandas', 'aws', 'nosql', 'jupyter', 'numpy', 'mvc', 'matlab', 'airflow', 'nlp', 'jira spark']","['data visualization', 'natural', 'github', 'statistics', 'software', 'physics', 'data science', 'analytics', 'data engineering', 'econometrics', 'data mining', 'machine learning', 'design patterns', 'software development life cycle', 'testing', 'artificial intelligence', 'data analysis', 'algorithms', 'feature engineering', 'ux', 'project documentation', 'language processing', 'feature analysis', 'neural networks', 'simulations', 'ontology', 'optimization', 'modeling', 'ai']","['taxonomy', 'trading', 'design', 'project management', 'operations', 'product development']"
223,282,Data Analyst,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or work in an office it s up to you. the role veeva is looking for an all star data analyst to grow a global data platform for customer relationship management and other applications. we re looking for a high energy, passionate individual with experience working with and mining data to discover trends and derive business important insights. in this role, you will be responsible for creating standard reports as well as custom analysis, as required, based on changing business conditions within a therapeutic area or country. you will need a good understanding of the life sciences industry on how field sales, medical, and marketing work. you will help create and work with benchmarks to make the industry promotional and scientific exchange efforts more productive, which will impact patient treatment and outcomes. you need to be able to think big data with a global data set, but also small data and be good with details as trending can be very localized. what you ll do collaborate closely with product management, data scientists, and data engineers to build the data platform create standard reports and run reports for various stakeholders investigate data and propose a business rationale for behavior based on an understanding of the life sciences industry build and maintain reference data groupings such as therapeutic areas, indications, etc. derive meaningful and impactful insights from the data, and communicate possibilities unearthed through data. have a good intuition on when data cannot be taken at face value, and build context and meaning around metrics. proactively suggest new ideas and ways of operating educate others and be a champion of how to use this data set requirements excellent communication skills written, verbal and formal presentation ba or bs degree in computer science, engineering, math, or related technical field 2 years of hands on data analysis experience 3 years or more of experience with enterprise software energized by working through complex problems and love working with data experience with commercial aspects of the life sciences industry nice to have experience with veeva crm worked on global life science programmes perks benefits conveniently located in downtown toronto snacks, beverages, and weekly lunches from local restaurants team events and rec league sports teams allocations for continuous learning development health wellness programs weekly yoga classes ping pong and other games veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['crm', 'software', 'enterprise', 'computer science', 'product management', 'data analysis', 'big data', 'reference data']","['san', 'big data']","['crm', 'software', 'enterprise', 'computer science', 'product management', 'data analysis', 'reference data']","['customer success', 'environment', 'events', 'metrics', 'marketing', 'sales', 'life sciences', 'therapeutic areas', 'regulations', 'customer']"
224,284,Senior Clinical Data Scientist Lead,"do you want to watch clinical development change, or do you want to be the one to shape it because we re hoping you re here for the latter. who are we we are pra. we are 20,000 employees strong, operating in more than 90 countries. we are committed to saving lives and we are constantly striving to be the best at what we do. our impact is real and we see it every single day. we help get life saving drugs into the hands of those who need them most. principal clinical data scientist lead overview leads end to end data review activities performed on a clinical trial. accountable for achieving clinical data management deliverables on time, with high quality and to agreed financial metrics. responsible for applying advanced analytics to centrally aggregate and analyze data from disparate sources to identify risks and issues impacting data integrity, patient safety and or or regulatory compliance. triages and assigns data review findings to the appropriate project team role for follow up and resolution. communicates trending analyses and a summary of findings to internal and external stakeholders to support the on time delivery of data fit for analysis. responsibilities serves as the primary contact for internal and external team members regarding clinical data management data review activities and leads these review activities to ensure the delivery of data fit for analysis. provides input into clinical system development activities, to ensure systems support the data review needs of the study, focusing on critical data and processes, and identified risks. ensures clinical data management review requirements are put into production per the study s protocol risk evaluation and integrated data review plan , and that ongoing data review activities are compliant with study plan requirements. contributes to the development and maintenance of study plans documents specifying data review strategy and applicable procedures on assigned protocols or projects, including but not limited to data management plan. develops and oversees timeliness of clinical data management activities during the life cycle of studies as it relates to data review and data delivery milestones. centrally reviews clinical data at aggregate level, using analytic reporting tool to support the identification of risks and data patterns or trends. mitigates risks by using signal detection and quality indicators. communicates and triages issues to appropriate roles for follow up and action to address root cause. proactively identifies out of scope clinical data management activities to the study project managers to be implemented in required change orders. leads and hosts the data monitoring meetings, communicating issues to the internal and external stakeholders in a meaningful way such as summarizing the data and representing the information visually. leads clinical data management activities on more complex projects with diverse scope. accountable for creating and maintaining clinical data management timelines, to oversee and achieve high quality interim and final contractual deliverables for more advanced projects. using detailed knowledge of the protocol, identifies critical data and processes from protocol review, and supports protocol risk evaluation process. works with assigned project teams to communicate, address and resolve complex datarelated questions and recommends potential solutions escalates issues which potentially impact patient safety or study analysis. trains and mentors new and less experienced team members. participates in sponsor and or or third party audits. develops tools or analytics used to monitor compliance and identify trends. actively seeks new business opportunities with assigned clients and collaborates with internal colleagues for new business initiatives. develops and maintains data review study documentation as appropriate to facilitate data validation and analytics. performs complex analytic reviews as defined in the scope of work and functional plan, focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretations of the final analysis. identifies root cause to systematically resolve complex data issues. sets expectations and ensures consistency in data review approach and compliance and identifying trends. may help to write articles for industry publications and give presentations at industry conferences. qualifications bachelor s degree in quantitative, scientific or health related field required. 8 years of relevant experience required. knowledge and or or understanding of analytic open source and or or enterprise level etl and analytic tools and practices sound knowledge of analytic modeling methods such as regression, classification and clustering strong programming skills in applicable systems, e.g., r, sql, python, sas skill to efficiently navigate through large volumes of complex data, to interpret complex data problems, and to apply technical solutions. ability to analyze a complex data issue and design paths to effective potential solutions, understanding the impact of suggested solutions and to help the project team make better decisions. in depth knowledge of the drug development process including risk based monitoring principles, clinical and biometrics procedures, workflows, and software systems. expertise in interpreting protocols and identifying risks and appropriate mitigation strategies for clinical studies excellent skill in aggregate data review and interpretation using visualization or analysis software, e.g., jreview,tableau, sas exellent project management and leadership skills excellent written and verbal communication and presentation skills ability to work collaboratively and effectively in a crossfunctional and culturally diverse team advanced ability to proactively represent data management internally and externally for all study related items and find pragmatic solutions in compliance with regulatory requirements and policies. to qualify for a position located in the united states, u.s. applicants must be legally authorized to work in the united states, and should not require, now or in the future, sponsorship for employment visa status. pra is an eeo or aa employer and is committed to providing opportunities to minorities, women, veterans, and individuals with disabilities. options apply for this job onlineapply share sorry the share function is not working properly at this moment. please refresh the page and try again later. share on your newsfeed connect with us","['visualization', 'tableau', 'data integrity', 'root cause', 'documentation', 'clinical data', 'less', 'risk', 'sql', 'python', 'software', 'reporting', 'data review trends', 'project managers monitoring', 'analytics', 'data', 'programming', 'sas', 'data review', 'protocol', 'clinical development', 'clinical data management', 'software systems', 'modeling', 'data management', 'etl', 'r']","['system development', 'sql', 'python', 'tableau', 'programming', 'documentation', 'less', 'sas', 'r']","['visualization', 'analysis', 'clinical data review', 'data integrity', 'root cause', 'clinical data', 'signal', 'software', 'reporting', 'analytics', 'data', 'data review review', 'identifying trends', 'data review', 'clinical', 'protocol', 'data monitoring', 'clinical development', 'data review delivery', 'clinical data management', 'project managers', 'software systems', 'modeling', 'data management', 'etl']","['validation', 'and compliance', 'regulatory requirements', 'biometrics', 'metrics', 'new', 'business initiatives', 'change orders', 'presentations', 'design', 'project management', 'sponsorship', 'drug development', 'triages', 'regulatory compliance']"
225,287,Data Engineer,"about makersights makersights is a saas or mobile product intelligence platform that is transforming the retail product development process by combining digital engagement and predictive analytics. makersights enables brands to make better, data driven decisions throughout the entire product development lifecycle. types of insights and decisions makersights enables include quantifying consumer sentiment on product designs, optimization of the product portfolio, product demand estimation, pricing strategies and go to market decisions . our customers include some of the largest retail brands such as, levi s, allbirds, shinola, and many more. what you ll do literally craft the foundation of our data environment take our data pipeline to the next level. build quality data transformations in python for our sql data warehouse. improve the quality and reliability of existing pipelines. own the evolution of the data architecture. build custom data integrations with retail brands discover novel data sets and data sources. make new data sets available for modeling. build an environment for data scientists to train, evaluate and deploy machine learning models to enable quicker experimentation. solve computationally intensive simulation challenges experiences which confidently represent you you have extensive software engineering experience with python, including testing and architecting software systems. you have experience designing and querying sql schemas. you ve built, deployed and run etl or data pipelines with python or pandas, ideally with airflow on aws. you have worked on projects that require attention to detail and are comfortable shipping production ready code every week. you ve built data integrations that pull in and harmonize external data sources with the internal data architecture. you have worked productively in unstructured environments.","['go', 'schemas', 'sql', 'python', 'software', 'pandas', 'analytics', 'saas', 'data', 'aws', 'pipelines', 'demand', 'machine learning', 'data pipelines', 'testing', 'airflow', 'software systems', 'optimization', 'modeling', 'etl']","['go', 'sql', 'python', 'pandas', 'product', 'predictive', 'aws', 'pipelines', 'airflow']","['machine learning', 'schemas', 'data pipelines', 'software', 'demand estimation', 'testing', 'software systems', 'analytics', 'saas', 'data', 'optimization', 'modeling', 'etl']","['product development', 'retail', 'environment', 'architecture']"
226,288,Data Scientist Technical Lead (Toronto),"how do you imagine life at an insurance company its people, its culture, its offices we bet that if you join intact, you will be in for quite a surprise with offices in downtown toronto, montreal and quebec city, the intact lab is an innovation hub bringing together data scientists, machine learning experts, ai developers, software engineers, actuaries and a meteorologist who work together to propose and implement innovative solutions to the complex issues facing us. merging the speed and culture of a start up with the resources and means of a large enterprise, the intact lab is a dynamic team offering exciting challenges, inspiring colleagues and great career opportunities about the role are you a machine learning expert who believes we are only in the infancy of artificial intelligence are you passionate about advanced analytics and big data do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools we have the perfect opportunity for you hiring manager amine mahmoudi workplace toronto your contribution be the technical leader that help defining data science problems and developing innovative solutions using machine learning and advanced statistics help achieve long term business goals by identifying and implementing solutions to subtle or ambiguous problems with the highest scientific rigour influence the lab technical direction by making actionable recommendations based on scientific and business findings to management coaching and mentoring of senior data scientists on technical matters and act as a technical reference for management review machine learning solutions and identify their corresponding scientific debt, and ultimately assess readiness for production deployment help the teams maintain a high scientific level by monitoring the application of data science standards of practice and participate in their evolution keep pace with new approaches and trends and use them in your own solutions work with other departments to promote the adoption of analytical principles within the organization qualifications your assets your master s or phd s degree in a relevant discipline your 8 years of experience in the field of advanced statistics, data mining and text mining strong communication, time management, great teamworking and organization skills expert level understanding of the underlying theory of machine learning expert level understanding in either computer image analysis, natural language processing or artificial intelligence a multi platform production experience with commercial and open source data mining frameworks like python, r, github, etc. your ability to focus on vaguely defined issues requiring the application of a creative approach here are a few reasons why others have joined our team an award winning, inspiring workplace that supports its people and recognizes great work stimulating, challenging projects and development opportunities to help you grow your skills and career flexibility in how and where you work a comprehensive financial rewards program that recognizes your success an extensive, flexible benefits package an industry leading employee share purchase plan where we match 50 of net shares purchased a casual dress for your day culture that encourages you to be yourself a 350 annual wellness account that promotes an active lifestyle closing statement we are an equal opportunity employer at intact, our value of respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. we value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard. if we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the talent acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs. background checks as an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. we want intact to be a great place to work this means that internal and external candidates will be asked to consent to background checks so we can learn more about you. please note that for positions with access to financial data or funds, your credit must be in good standing. internal candidates for internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. please note we may have identified other internal candidates through our employee development program, and that the selection process may also be opened to external applicants. eligibility to work in canada it s important that you are legally eligible to work in canada at the time an offer of employment is made. you may be requested to provide proof of eligibility at that time. referral bonus this role is eligible for employee referral bonus. myreferrals3000 linkedin sponsored li quebecit","['data mining', 'python', 'machine learning', 'statistics', 'language processing', 'github', 'financial data', 'software', 'technical direction', 'production experience', 'data science', 'analytics', 'artificial intelligence', 'big data', 'text mining', 'r', 'machine learning analysis', 'ai']","['python', 'big data', 'r']","['data mining', 'machine learning', 'statistics', 'language processing', 'financial data', 'software', 'technical direction', 'data science', 'analytics', 'artificial intelligence', 'natural', 'text mining', 'image analysis', 'github', 'ai']","['actuaries', 'background checks', 'large enterprise', 'financial services', 'linkedin', 'adoption', 'hiring', 'insurance', 'mentoring']"
227,289,Senior Data Scientist,"soti is committed to providing its employees with endless possibilities learning new things, working with the latest technologies and making a difference in the world. job title senior data scientist location mississauga who we are over the last 20 years, we have been a global leader in enterprise mobility technology, with over 1000 talented employees in 25 countries and 10 offices around the world. soti s two decades of success has built strong partnerships with leading mobile platform providers and device manufacturers. these relationships give us unparalleled insight into new technology and industry trends before they happen. the soti one platform software helps businesses remove functional silos, eliminate downtime, build apps faster, manage all mobile and iot devices in one place and deliver actionable insights. when everything is connected, the soti one platform makes mobile and iot business operations simpler, smarter and more reliable at the same time, enables companies to securely manage any device or endpoint with any form factor and any operating system throughout their entire lifecycle from deployment to retirement. we are looking for an experienced data scientist to join our data analytics team to work on machine learning and ai projects using the vast wealth of data that we collect today. what s in it for you the people from our humble origins in our founder s basement, to our industry leading position today, soti has worked hard to foster a company culture that we can all believe in. a culture that emphasizes personal growth, continuous innovation and fun. the growth our environment fosters new ideas, fresh perspectives, and the ability to take them over the goal line. soti is a fast paced environment with a global reach that encourages you to make your mark and be part of something big the technology you ll get the chance to work with leading edge technologies and take on complex and interesting projects, as part of highly collaborative and agile teams. you will work alongside soti s partners which include leading tech giants that will keep you on the cusp of emerging technologies. what you ll do collaborate with various business units and other stakeholders to identify opportunities to drive business value by leveraging business intelligence, data visualization and machine learning best practices develop innovative and effective approaches and apply statistical and predictive modelling techniques to solve analytics problems and communicate results and methodologies to business clients and senior members of the analytics team stay current with trends in the data science space translate those trends into actionable strategic and tactical objectives for the company lead end to end design and implementation of machine learning and data analytics solutions own and deliver projects of diverse scope. oversee the work several junior data scientists research, define, and develop data science capabilities into product experience partner effectively with software engineers, designers, and product managers to deliver those capabilities experience you ll bring expert in python programming to write production ready code strong data profiling, cleaning, mining, and technical documentation skills 5 years of experience in building machine learning models 3 years of experience with nlp, classification, and predictive modeling in production environments 2 years of experience with time series analysis, forecasting, and anomaly detection a deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems strong knowledge and experience of different deep neural networks architectures experience with ml ai solutions developed on large cloud computing infrastructure providers such as azure and aws graduate degree in computer science, software engineering, data science, statistics, or equivalent industry experience. about soti soti is the world s most trusted provider of mobile and iot management solutions, with more than 17,000 enterprise customers and millions of devices managed worldwide. soti s innovative portfolio of solutions and services provide the tools organizations need to truly mobilize their operations and optimize their mobility investments. soti extends secure mobility management to provide a total, flexible solution for comprehensive management and security of all mobile devices and connected peripherals deployed in an organization. at soti, we celebrate the uniqueness of our global teams and are proud to be an equal opportunity workplace. we are curious problem solvers who are committed to bringing the best mobile and iot management solutions to market. we offer careers with endlesspossibilities. what are you waiting for apply today https or or or careers if you want to bring your ideas to life, apply at soti today. we are committed to providing accessible employment practices that are in compliance with the requirements under the human rights code and the accessibility for ontarians with disabilities act . if you require accommodation during any stage of the recruitment process, please notify people culture at . please note that soti does not accept unsolicited resumes from recruiters or employment agencies. in the absence of a signed services agreement with agency or recruiter, soti will not consider or agree to payment of any referral compensation or recruiter fee.","['https', 'data visualization', 'data profiling', 'machine', 'data analytics', 'python', 'statistics', 'time series analysis', 'software', 'data science', 'analytics', 'programming', 'anomaly detection', 'aws', 'cloud computing', 'machine learning', 'iot', 'mobile devices', 'business intelligence', 'forecasting', 'peripherals', 'neural networks', 'security', 'nlp', 'computer science', 'technical documentation', 'modeling', 'ai']","['https', 'python', 'iot', 'nlp', 'programming', 'aws', 'business intelligence']","['data visualization', 'data profiling', 'machine', 'data analytics', 'statistics', 'time series analysis', 'software', 'data science', 'analytics', 'anomaly detection', 'cloud computing', 'management', 'machine learning', 'mobile devices', 'predictive', 'forecasting', 'peripherals', 'neural networks', 'security', 'computer science', 'technical documentation', 'modeling', 'ai']","['environment', 'business value', 'design', 'business operations', 'retirement', 'investments', 'compensation', 'business units', 'refer']"
228,291,Senior Data Scientist,"bachelor s degree 5 years of experience with data scripting languages or statistical or mathematical software 4 years working as a data scientist experience processing, filtering, and presenting large quantities of data experience with statistical analysis, data modeling, machine learning, optimizations, regression modeling and forecasting, time series analysis, data mining, and demand modeling experience applying various machine learning techniques, and understanding the key parameters that affect their performance excellent written and verbal communication skills. strong ability to interact, communicate, present, and influence within multiple levels of the organization. experience with predictive analytics and prescriptive analytics amazon s sponsored products advertising business is one of the fastest growing areas in the company. have you ever wondered what happens behind that sponsored label you see in search results on amazon hint it involves a lot of interesting tech delivered by a great team. the sponsored products marketplace team optimizes the systems and ad placements to match demand with supply using a combination of data driven product innovation, machine learning, big data analytics, and low latency or high volume engineering. by the time organic search results are ready, we ve processed all of the potential ads and determined which ones are going to be shown. we do that billions of times per day, resulting in millions of engagements with products that might otherwise not have been seen by shoppers. the business and technical challenges are significant. fortunately, we have a broad mandate to experiment and innovate, and a seemingly endless range of new opportunities to build a big, sustainable business that helps amazon continuously innovate on behalf of all customers. we re looking for customer obsessed, innovative, professional data scientist who can help us take our products to the next level of functionality, quality and performance. we embrace leaders with a startup mentality those who seek a disruptive yet clear mission and purpose, have an unambiguous owner s mindset, and are relentlessly obsessed with delivering amazing products. as a sr. data scientist on our team, you will be responsible for building and managing modeling projects, identifying data requirements, and delivering methodology and tools that are statistically grounded around our advertiser facing products such as new targeting controls, ad sourcing techniques, automated optimization strategies, and advertiser facing recommendations. you should have superb analytical, technical, business and communication skills to be able to work with business and technology leaders to define and prioritize key business questions, build data acquisition processes, data sets, statistical models and analyses that answer those questions. if this sounds like your sort of challenge, read on. characteristics indicative of success in this role highly analytical you solve problems in ways that can be backed up with verifiable data. you focus on driving processes, tools, and statistical methods which support rational decision making. technically fearless you aren t satisfied by performing as expected and push the limits past conventional boundaries. your dial goes to 11 . engaged by ambiguity you re able to explore new problem spaces with unique constraints and non obvious solutions. team obsessed individual contributor you help grow your team members to achieve outstanding results. you ve learned that big plans generally involve collaboration and great communications. quality obsessed you recognize that professional engineers ship complete, tested software to avoid getting trapped in a sea of technical debt. you balance speed with quality. humbitious you re ambitious, yet humble. you recognize that there s always opportunity for improvement. you use introspection and feedback from teammates and peers to raise the bar. master s degree in operations research engineering, statistics or related field 10 years professional experience in large scale data science or advanced analytics experience with aws and data oriented tools such as redshift, spark, emr experience in online advertising domain experience as team leader amazon is an equal opportunity affirmative action employer minority or female or disability or veteran or gender identity or sexual orientation.","['emr', 'statistical analysis', 'data analytics', 'regression', 'statistics', 'time series analysis', 'software', 'data acquisition', 'data science', 'data', 'analytics', 'aws', 'data mining', 'machine learning', 'sourcing', 'forecasting', 'low latency', 'optimization', 'modeling']","['emr', 'big', 'aws', 'predictive']","['modeling', 'statistical analysis', 'data analytics', 'regression', 'statistics', 'time series analysis', 'software', 'data acquisition', 'scripting', 'data science', 'data', 'analytics', 'modeling data', 'demand', 'data mining', 'machine learning', 'sourcing', 'forecasting', 'low latency', 'optimization', 'methodology']","['online', 'advertising', 'operations', 'functionality', 'engagements']"
229,292,Junior GCP Data Engineer - Mississauga,"one of our retail clients is looking for a junior data engineer with experience in the google cloud platform. some of the main responsibilities include design and build an ecosystem of modern data technologies on premise and on gcp cloud develop high performance data processing pipelines create and maintain quality code, provide support during testing cycles and post production deployment motivation to address and resolve highly complex and multifaceted development related issues, often independently. advantages large retail client working on the google cloud platform along with technical product managers, data scientists, and data engineers responsibilities design and build an ecosystem of modern data technologies on premise and on gcp cloud develop high performance data processing pipelines create and maintain quality code, provide support during testing cycles and post production deployment motivation to address and resolve highly complex and multifaceted development related issues, often independently. qualifications a computer science degree or diploma or any other technical or business degree is preferred. summary the client is looking for a data engineer with experience in gcp. de will be designing, building and operationalizing large scale enterprise data solutions and applications using one or more of gcp data and analytics services designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using spark, python, scala etc.","['python', 'gcp', 'data processing', 'data pipelines', 'scala', 'testing', 'data solutions', 'google cloud platform', 'enterprise', 'computer science', 'analytics', 'big data', 'pipelines']","['python', 'gcp', 'scala', 'google cloud platform', 'big data', 'pipelines']","['data processing', 'data pipelines', 'testing', 'data solutions', 'enterprise', 'computer science', 'analytics']","['retail', 'design', 'architecture']"
230,293,"Data Scientist Technical Lead (Montreal), Intact Lab","who needs insurance everybody. that keeps us busy. very busy. at the intact lab, we use machine learning, data science, software engineering, ai, agility, ux and design thinking to transform the customer experience for millions of canadians. simplifying insurance takes creativity, empathy and hard work. we explore, take risks, make mistakes, and learn all day, every day. here, innovation is everyone s job. ready to make your mark about the role are you a machine learning expert who believes we are only in the infancy of artificial intelligence are you passionate about advanced analytics and big data do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools we have the perfect opportunity for you hiring manager amine mahmoudi workplace montreal your contribution be the technical leader that help defining data science problems and developing innovative solutions using machine learning and advanced statistics help achieve long term business goals by identifying and implementing solutions to subtle or ambiguous problems with the highest scientific rigour influence the lab technical direction by making actionable recommendations based on scientific and business findings to management coaching and mentoring of senior data scientists on technical matters and act as a technical reference for management review machine learning solutions and identify their corresponding scientific debt, and ultimately assess readiness for production deployment help the teams maintain a high scientific level by monitoring the application of data science standards of practice and participate in their evolution keep pace with new approaches and trends and use them in your own solutions work with other departments to promote the adoption of analytical principles within the organization qualifications your assets your master s or phd s degree in a relevant discipline your 8 years of experience in the field of advanced statistics, data mining and text mining strong communication, time management, great teamworking and organization skills expert level understanding of the underlying theory of machine learning expert level understanding in either computer image analysis, natural language processing or artificial intelligence a multi platform production experience with commercial and open source data mining frameworks like python, r, github, etc. your ability to focus on vaguely defined issues requiring the application of a creative approach here are a few reasons why others have joined our team an award winning, inspiring workplace that supports its people and recognizes great work stimulating, challenging projects and development opportunities to help you grow your skills and career flexibility in how and where you work a comprehensive financial rewards program that recognizes your success an extensive, flexible benefits package an industry leading employee share purchase plan where we match 50 of net shares purchased a casual dress for your day culture that encourages you to be yourself a 350 annual wellness account that promotes an active lifestyle closing statement we are an equal opportunity employer at intact, our value of respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. we value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard. if we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the talent acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs. background checks as an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. we want intact to be a great place to work this means that internal and external candidates will be asked to consent to background checks so we can learn more about you. please note that for positions with access to financial data or funds, your credit must be in good standing. internal candidates for internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. please note we may have identified other internal candidates through our employee development program, and that the selection process may also be opened to external applicants. eligibility to work in canada it s important that you are legally eligible to work in canada at the time an offer of employment is made. you may be requested to provide proof of eligibility at that time. referral bonus this role is eligible for employee referral bonus. myreferrals3000 linkedin sponsored li quebecit","['design thinking', 'technical direction', 'big data', 'github', 'python', 'statistics', 'financial data', 'software', 'data science', 'analytics', 'text mining', 'data mining', 'machine learning', 'ai', 'artificial intelligence', 'image analysis', 'ux', 'language processing', 'r']","['python', 'big data', 'r']","['data mining', 'ux', 'machine learning', 'design thinking', 'statistics', 'language processing', 'financial data', 'software', 'technical direction', 'data science', 'analytics', 'artificial intelligence', 'natural', 'computer', 'text mining', 'image analysis', 'github', 'ai']","['customer experience', 'background checks', 'financial services', 'linkedin', 'adoption', 'hiring', 'insurance', 'mentoring']"
231,295,Data Engineer,"company finning international inc. number of openings 1 worker type permanent position overview data is deeply embedded in the product and engineering culture at finning, to maximize productivity and safety of finning engineers and our customers. the data engineer will be focused on building a state of the art data foundation to solve real world business challenges and optimizing finning processes across a wide range of areas including supply chain, marketing, pricing, and sales. as part of the finning global digital services team, you will be working closely with cross functional teams using agile methodologies and tools, building reliable and scalable data driven solutions for optimizing maintenance, inventory, fuel, scheduling, and other services for finning customers. this position will require a background and love for data modeling, building batch processes, and working with data architects and infrastructure team to build end to end data processing pipelines. the data engineer will work under the mentorship of senior data engineers and other leaders on the team and work in collaboration with other members on the finning digital teams, including project managers, product managers, visual analysts, and architects, software engineers and more as we continue to explore new areas inside and outside of business, on our digital journey. job description extract, transform and load data from internal and external systems to azure services using a combination of azure data factory, azure data lake, azure sql, azure data warehouse, azure databricks, t sql, and spark sql. work with the business and non technical stakeholders to discover and document technical requirements and to understand the core problem monitors, troubleshooting and resolving of issues with our hybrid data platform drive the continually improvement of ongoing reporting and analysis processes, automating and or or simplifying support. stay abreast of innovations in cloud infrastructure, business intelligence, analytics and data warehouse tools and technologies design, develop, and maintain data pipelines create automated metrics using complex distributed databases and sources education experience bachelor s or master s degree in computer science or equivalent experience 5 years of software development experience 3 years of experience in azure, aws, or gcp 3 years of experience in developing data injection, consumption, etl, and data sanitization processes practical experience with azure data lake, azure synapse analytics, azure sql and sql data warehouse, and azure databricks services. w e are committed to diversity at finning, to building and sustaining a diverse and inclusive workforce and as an equal opportunity employer we encourage applications from all qualified individuals. finning does not discriminate against applicants based on genders, races, national and ethnic origins, religions, ages, sexual orientation, marital and family status, and or or mental or physical disabilities.","['databases', 'troubleshooting', 'technical requirements', 'modeling', 'data injection', 'sql', 'gcp', 'data processing', 'hybrid data', 'software', 'reporting', 'software development', 'data', 'analytics', 'aws', 'pipelines', 'data pipelines', 'business intelligence', 'digital services', 'agile methodologies', 'azure', 'project managers', 'computer science', 'cloud infrastructure', 'etl']","['sql', 'databases', 'gcp', 'azure data lake', 'azure data warehouse', 'azure databricks', 'azure data factory', 'azure sql', 'business intelligence', 'aws', 'pipelines']","['agile methodologies', 'data processing', 'data pipelines', 'software', 'reporting', 'hybrid', 'cloud infrastructure', 'project managers', 'troubleshooting', 'technical requirements', 'data', 'analytics', 'computer science', 'software development', 'modeling', 'digital services', 'etl', 'data injection']","['and safety', 'education', 'metrics', 'marketing', 'design', 'art', 'sales']"
232,296,Lead Data Scientist,"our people love the exciting and meaningful work they do, the cutting edge resources and technology they have access to, the benefits we offer and the great community we ve built. want to join them consultant data scientist the job as a consultant data scientist in kainos, you ll be responsible for leading teams and developing high quality solutions that use ai and ml technologies to delight our customers and impact the lives of users worldwide. it s a fast paced environment so it is important for you to make sound, reasoned decisions. you ll do this whilst learning about new technologies and approaches, with talented colleagues that will help you to learn, develop and grow. as the technical leader in the team, you will also interact with customers, share knowledge and mentor those around you. essential experience a minimum of a 2.1 degree in computer science, machine learning, data science, statistics or in a similar highly quantitative field. a proven ability to solve complex problems with demonstrable ability to learn new business concepts and domains quickly. expertise in developing models in languages including python or r expertise using machine learning libraries significant experience in cleansing, filtering and re factoring complex data from different sources . expertise of working with relational databases, nosql and various visualisation techniques. experience in delivering ai or ml projects to production through leadership and mentoring of junior team members strong interpersonal skills with the ability to lead client projects and establish requirements in non technical language. desirable experience an advanced degree in computer science, machine learning, operational research, statistics or in a similar highly quantitative field. multiple examples of delivering data science projects and predictive solutions to live in an industry production environment. experience of containerisation and cloud deployment. experience of deep learning architectures who you are determined you re flexible and overcome obstacles to get the job done to achieve personal and team goals. creative you actively look for better ways to do things using the latest ai technologies to find fresh solutions to complex problems honest always constructive when giving or receiving feedback, being transparent and truthful when dealing with others respectful you treat others as you would like to be treated being encouraging, accepting and supportive to everyone you deal with cooperative you share information, knowledge and experience, understanding the mutual benefits of team working who you are our vision is to enable outstanding people to create digital solutions that have a positive impact on people s lives. our values aren t abstract they are the behaviours we expect from each other every day and underpin everything that we do. we expect everyone to display our values by being determined in how obstacles are overcome honest when dealing with others respectful of how you treat others creative to find solutions to complex problems and cooperative by sharing information, knowledge and experience. these values, applied collectively, help to produce an outstanding kainos person, team and culture.","['deep learning', 'python', 'machine learning', 'statistics', 'relational databases', 'data science', 'computer science', 'cleansing', 'containerisation', 'r', 'nosql', 'ai']","['python', 'nosql', 'r']","['deep learning', 'machine learning', 'statistics', 'relational databases', 'data science', 'computer science', 'cleansing', 'ai']","['environment', 'mentoring']"
233,298,Machine Learning Scientist,"bachelor s degree in computer science, statistics, data science, or any other quantitative field. 2 years of non internship professional experience with machine learning, statistical modeling, data mining, and or or analytics techniques. 2 years of experience with python, r, or other scripting languages. advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management. are you interested to disrupt and redefine the way customers buy beauty products online are you interested in using the latest advances in machine learning, computer vision, and augmented reality to build online customer experiences for beauty products that can equal or even surpass an in store experience we are looking for talented and innovation driven scientists who are passionate about building improved customer experiences by leveraging data science and machine learning technologies. you will have an opportunity to revolutionize the customer shopping experience across the world s most extensive catalog of beauty products. you will be directly responsible for leveraging machine learning or computer vision algorithms and data science techniques to drive innovation. you will collaborate with product managers, software engineers, ux designers, scientists, and the broader amazon tech community to build solutions that enhance the beauty shopping experience across all surfaces, including desktop, mobile devices, and other amazon devices. about the team the amazon beauty tech is a brand new team that is rapidly expanding. we are a small group of engineers, scientists, product managers, and designers who drive technological innovation to improve customer experience. we have a startup like work culture where innovation is encouraged we are never afraid to propose grand ideas for fear of failing we build computer vision and augmented reality experiences we bring exciting experiences directly to the customer s mobile phone using their cameras and combinations of facial recognition and ar. personalization using machine learning we will be working with machine learning technologies such as data classification and reinforced learning models to provide better personalized shopping experiences. elevated customer experiences we will create beautiful and dynamic customer experiences that require deep knowledge of relevant ui technologies and user centric design patterns. amazon scale systems all our technology needs to work at amazon scale, serving millions of customers with millisecond level latency. data pipeline and analytics tools amazon is data driven, and a robust data backbone is necessary for our systems. we build on robust and scalable data pipelines and tools using core aws services. master s degree or phd in a highly quantitative field . experience applying various machine learning techniques, and understanding the key parameters that affect their performance. familiarity with deep learning algorithms and or or computer vision. familiarity with at least 1 2 popular ai or ml frameworks and tools tensorflow, pytorch, mxnet, scikit learn, opencv, arcore, and arkit. expertise in estimation, experimental design, hypothesis, and a or b testing. experience partnering with engineering teams to build and test production systems. familiarity with aws services such as ec2, dynamodb, rds, aws lambda, and amazon sagemaker. ability to achieve stretch goals in a highly innovative and startup like environment.","['personalization', 'data classification', 'tensorflow', 'python', 'statistics', 'ar', 'software', 'scripting', 'computer vision', 'data science', 'analytics', 'aws', 'pytorchv', 'data mining', 'machine learning', 'design patterns', 'data pipelines', 'ai', 'testing', 'mobile devices', 'statistical', 'production systems', 'algorithms', 'deep learning', 'ux', 'experimental', 'augmented reality', 'computer science', 'modeling', 'r']","['python', 'ar', 'arkit', 'opencv', 'augmented reality', 'pytorch', 'sci', 'aws', 'rds', 'aws lambda', 'amazon sagemaker', 'r']","['personalization', 'tensorflow', 'statistics', 'software', 'scripting', 'computer vision', 'data science', 'analytics', 'data mining', 'machine learning', 'design patterns', 'data pipelines', 'testing', 'mobile devices', 'production', 'statistical', 'algorithms', 'deep learning', 'ux', 'level late', 'experimental', 'computer science', 'modeling', 'ai']","['environment', 'design', 'customer experience']"
234,300,"Data Scientist, Liquidity and Funding Management","address 100 king street west job family group data analytics reporting applies knowledge of advanced analytic algorithms and technologies to deliver better predictions and or or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. applies strong communication and story telling skills to summarize statistical or algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business or groups. drives innovation through the development of data ai products that can be leveraged across the organization and establishes best practices in in alignment with data ai governance frameworks of bmo. qualifications acts as a trusted advisor to assigned business or group. influences and negotiates to achieve business objectives. recommends and implements solutions based on analysis of issues and implications for the business. assists in the development of strategic plans. identifies emerging issues and trends to inform decision making. understands and analyzes complex business problem, then formulates data driven hypotheses to drive business value. builds effective relationships with internal or external stakeholders and ensures alignment. supports data collection, integration, and retention requirements for data. develops experimental design approaches to validate findings or test hypotheses. defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets. diagnoses and resolves predictive or analytical model performance issues while monitoring system performance and implementation of efficiency improvements. applies innovative and best practices to advanced analytics services to ensure high quality standards. sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work. develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs. provides advice and guidance to assigned business or group on implementation of analytical solutions. works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and or or decisions. works with various data owners to discover and select available data from internal sources and external vendors to fulfill analytical needs. applies scripting or programming skills to assemble various types of source data into well prepared datasets with multiple levels of granularities . develops agreed analytical solution by applying suitable statistical machine learning techniques to test, verify, refine hypotheses. summarizes statistical findings and draws conclusions, presents actionable business recommendations. presents findings recommendations in a simple, clear way to drive action. documents data flow, systems and processes in data collection to improve efficiency and apply use cases. performs experimental design approaches to validate finding or test hypotheses. uses the appropriate algorithms to discover patterns. builds effective relationships with internal or external stakeholders and ensures alignment. supports development of tools and delivers training for data analytics and ai. supports development and execution of strategic initiatives in collaboration with internal and external stakeholders. leads or participates in the design, implementation and management of core business or group processes. focus is primarily on business or group within bmo may have broader, enterprise wide focus. provides specialized consulting, analytical and technical support. exercises judgment to identify, diagnose, and solve problems within given rules. works independently and regularly handles non routine situations. broader work or accountabilities may be assigned as needed. typically between 5 7 years of relevant experience and post secondary degree in related field of study or an equivalent combination of education and experience. advanced degree in computer science, mathematics, physics, engineering, statistics, or other quantitative disciplines and or or equivalent experience experience with distributed computing language cloud technologies . experience with programming languages and machine learning or deep learning algorithms or packages . deep proficiency in statistical analysis, quantitative analytics, forecasting or predictive analytics, multivariate testing, and optimization algorithms. deep knowledge and technical proficiency gained through extensive education and business experience. verbal written communication skills in depth. collaboration team skills in depth. analytical and problem solving skills in depth. influence skills in depth. data driven decision making in depth. we re here to help at bmo we are driven by a shared purpose boldly grow the good in business and life. it calls on us to create lasting, positive change for our customers, our communities and our people. by working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world. as a member of the bmo team you are valued, respected and heard, and you have more ways to grow and make an impact. we strive to help you make an impact from day one for yourself and our customers. we ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. from in depth training and coaching, to manager support and network building opportunities, we ll help you gain valuable experience, and broaden your skillset. to find out more visit us at https or or jobs.bmo.com or ca or en . bmo is committed to an inclusive, equitable and accessible workplace. by learning from each other s differences, we gain strength through our people and our perspectives. accommodations are available on request for candidates taking part in all aspects of the selection process. to request accommodation, please contact your recruiter.","['https', 'computing', 'data flow', 'statistical analysis', 'data analytics', 'statistics', 'reporting', 'scripting', 'physics', 'data', 'analytics', 'integration', 'programming', 'machine learning', 'pattern detection', 'testing', 'quantitative', 'data collection', 'statistical', 'algorithms', 'forecasting', 'automation', 'deep learning', 'experimental', 'programming languages', 'technical proficiency', 'datasets', 'data solutions', 'computer science', 'mathematics', 'optimization', 'system performance', 'ai']","['https', 'programming languages', 'programming', 'predictive', 'model performance', 'system performance']","['computing', 'multivariate', 'data flow', 'technical support', 'statistical analysis', 'distributed', 'data analytics', 'statistics', 'reporting', 'scripting', 'physics', 'analytics', 'integration', 'machine learning', 'quantitative', 'testing', 'data collection', 'algorithms', 'forecasting', 'automation', 'deep learning', 'use cases', 'experimental', 'datasets', 'data solutions', 'computer science', 'mathematics', 'optimization', 'pattern detection', 'ai']","['education', 'business value', 'design', 'customer experience', 'business strategy', 'governance', 'consulting', 'strategic initiatives']"
235,301,Data Intern (Scientist/Analyst/Engineer/DevOps),"during the internship at procogia, the intern will get involved in a wide variety of data related projects. procogia are proud partners of rstudio pbc, amazon apn and snowflake. through these partnerships the intern will gain exposure to a wide spectrum of activities. activities can vary from data analytics, science, engineering and devops types of activities depending on the intern and the available projects. primary accountabilities or responsibilities the intern is to deliver outcomes that can be used directly by the business for its own needs or for demonstrative purposes to potential and existing customers. develop applications, dashboards, reports and other materials for demonstrative purposes. assis the product development team in developing novel data based software microservices. see appsedia.com for one such example. build impactful presentations to illustrate our deliverables at customer sites. develop in house analytical solutions such as but not limited to o develop machine learning models for business operations, o develop analytics dashboard for the financial forecasting, o deploy a data warehouse for the company s business systems, o develop cloud automation scripts to deploy analytic environments. the intern may also assist on some customer facing projects to gain real world experience. these activities could be wide ranging depending on the intern and the active projects. examples could be such as below, but not limited to this assist consultants in the data cleansing, preparation, analytics and ml phases, assist in writing efficient etl scripts for engineering applications, develop customer facing dashboards and reports, assist in the install, configuration and management of cloud hosted data services. the ultimate goal of the internship program is to ready individuals for life as an fte at procogia. the right intern will demonstrate during their time at procogia their embodiment of our values growth mindset we are constantly learning and improving. there is no failure, just an opportunity to learn and grow. leadership we take initiative, assume ownership and drive our customers forward. stewardship we are diligent and resourceful. we show integrity and courage through our actions. customer first we strive to earn and keep our customer s trust by doing what s right and delivering the best results. excellence we go above and beyond in everything we do and deliver outstanding solutions. unified we support, respect and trust each other. we are stronger together. when one of us wins, we all win. innovation we take a proactive approach to embrace innovation, willingly take risks and adapt to changes. key skills or experience required candidate would ideally have or be in the process of finalizing a msc or phd in mathematics, statistics, computer science or other relevant technical area. candidates should be proficient in the following o r or python o command line scripting o powerbi or other gui based dashboarding software. data engineering or data devops interns should have some experience with o aws or snowflake. o ansible or other automation tools. o python, scala or similar language. o terraform or other cloud infrastructure tool. all candidates should have excellent written and verbal communication skills.","['go', 'business systems', 'data services', 'dashboards', 'cleansing', 'business', 'terraform', 'data analytics', 'python', 'statistics', 'software', 'scala', 'scripting', 'analytics', 'aws', 'microservices', 'data engineering', 'cloud', 'machine learning', 'forecasting', 'automation', 'ansible', 'dashboard', 'devops', 'computer science', 'mathematics', 'cloud infrastructure', 'snowflake', 'etl', 'r']","['dashboard', 'go', 'terraform', 'python', 'scala', 'aws', 'snowflake', 'ansible', 'r']","['business systems', 'data services', 'dashboards', 'cleansing', 'data analytics', 'statistics', 'software', 'scripting', 'analytics', 'data', 'data engineering', 'microservices', 'machine learning', 'gui', 'forecasting', 'automation', 'devops', 'computer science', 'mathematics', 'cloud infrastructure', 'etl']","['materials', 'business operations', 'presentations', 'product development']"
236,304,Data Scientist - Performance Engineering - Toronto Hub,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or in our toronto office it s up to you. managing the performance needs of veeva vault, a complex and industry standard saas system supporting life sciences requires analyzing data from our performance testing and production systems. it requires a careful analysis of test results and production metrics. the sheer amount of data generated in production and testing makes manual analysis a considerable challenge and error prone. you will be helping to automatically detect performance degradations and correlate them to causes and find areas for improvement. as a data scientist for the veeva vault performance engineering team, you focus on designing and building automated analysis tools to improve overall operational excellence and derive valuable and actionable information from data. you are excited about statistics and applied data science on large datasets, exploratory data analysis, projection methodologies, anomaly detection, and more. you design and build computationally efficient and practical statistical algorithms while keeping the business problems we are solving in mind. while ml is an integral part of your toolkit, it s not your only skill. the ability to dissect the situation and to select from a variety of techniques is vital. this position is an excellent opportunity for someone excited about using their statistics and data science expertise to design and build algorithms and models. collaborate closely with engineering to create a highly performant product and see the impact of your work on the life sciences industry. what you ll do use exploratory data analysis and visualization techniques to simplify analyzing large scale performance data and extract actionable insights. collaborate closely with the team of performance engineers, developers to innovate, discover and deliver novel solutions for operational excellence. rapidly build prototype product solutions, communicate findings, iterate enhance. draw from prior experience and technical expertise to identify product improvements and inform testing plans break overall objectives down into underlying problems, prioritize and solve work with product and engineering teams to implement performance improvements. apply machine learning, data mining, and statistical analysis techniques where appropriate requirements 5 years of hands on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects b.s, m.s. or ph.d. in applied statistics, mathematics, computer science, machine learning or other quantitative disciplines highly proficient in python and sql experience working with aws preferred experience working with large quantities of data to develop models that work in a stable, production approach with live data advanced knowledge of statistical analysis and data mining techniques experience working with engineering to roll out software to production including monitoring, and documentation comfortable about ambiguity and breaking goals down into tangible and actionable work plans strong communication skills and ability to work across internal teams perks benefits flexible pto allocations for continuous learning development health wellness programs li remote veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['visualization', 'documentation', 'statistical analysis', 'sql', 'python', 'statistics', 'software', 'data science', 'saas', 'anomaly detection', 'aws', 'data mining', 'machine learning', 'testing', 'performance', 'statistical', 'data analysis', 'production systems', 'vault', 'toolkit', 'algorithms', 'datasets', 'computer science', 'mathematics', 'performance engineering']","['sql', 'python', 'san', 'documentation', 'aws']","['visualization', 'exploratory', 'manual analysis', 'statistical analysis', 'statistics', 'software', 'data science', 'saas', 'anomaly detection', 'data mining', 'machine learning', 'testing', 'statistical', 'data analysis', 'production systems', 'vault', 'toolkit', 'algorithms', 'performance testing', 'datasets', 'computer science', 'mathematics', 'performance engineering']","['customer success', 'environment', 'metrics', 'regulations', 'design', 'life sciences', 'operational excellence', 'projection']"
237,305,Data Engineer,"coursera was launched in 2012 by two stanford computer science professors, andrew ng and daphne koller, with a mission to provide universal access to world class learning. it is now one of the largest online learning platforms in the world, with 82 million registered learners as of march 31, 2021. coursera partners with over 200 leading university and industry partners to offer a broad catalog of content and credentials, including guided projects, courses, specializations, certificates, and bachelor s and master s degrees. more than 6,000 institutions have used coursera to upskill and reskill their employees, citizens, and students, including in high demand fields such as data science, technology, and business. coursera became a b corp in february 2021. data engineering is unique at coursera. our team doesn t simply build reports on demand. rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better. we re looking for a talented and driven senior data engineer with a keen eye for data and business to help us build and scale our platform. our ideal candidate is an independent, analytically minded individual with strong data modeling and software engineering skills, who shares our passion for education. in this role, you ll directly work with cross functional teams to design, develop, and deploy data solutions for our enterprise learners and admins. responsibilities architect scalable data models and build efficient and reliable etl pipelines to bring the data into our core data lake design, build, and launch visualization and self serve analytics products that empower our internal and external customers with flexible insights build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high fidelity data partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently work cross functionally to support new product and feature launches basic qualification 1 years experience in a data related field, including data engineering, data warehousing, business intelligence, data visualization, and or or data science preferred qualifications strong software engineering skills and at least one scripting language proficient with relational databases and sql familiarity and experience with big data technologies preferred ability to communicate technical concepts clearly and concisely independence and passion for innovation and learning new technologies if this opportunity interest you, you might like these courses on coursera big data specialization big data essentials hdfs, mapreduce and spark data warehousing for business intelligence coursera is an equal employment opportunity employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class. if you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at please review our ccpa applicant notice here.","['visualization', 'data visualization', 'big data', 'sql', 'software', 'scripting', 'data science', 'data', 'analytics', 'data models', 'pipelines', 'data engineering', 'data warehousing', 'relational databases', 'core', 'business intelligence', 'data solutions', 'computer science', 'modeling', 'etl']","['sql', 'big data', 'business intelligence', 'data models', 'pipelines']","['visualization', 'relational databases', 'software', 'scripting', 'data solutions', 'data science', 'data visualization', 'computer science', 'data', 'analytics', 'modeling', 'data engineering', 'data warehousing', 'etl']","['business rules', 'design', 'education']"
238,306,Senior Data & Applied Scientist - Content Recommendation,"the microsoft news feeds team is looking for self motivated and experienced data applied scientists for the content recommendation team a team that has the potential to define the future of content services for microsoft. we connect 500m users with the content they care about, not only to help them to stay informed and entertained but also empower them to start conversations with their friends, family, and colleagues. we bring together premium publishers and the best of the web into a personalized, intelligent feed that never stops. we are available globally and across the microsoft ecosystem, in windows, in edge browser, on msn.com, or on your phone. whether its news, sports, shopping, videos, finance, weather or esports, we have something for everyone. at our core is our large scale personalized recommendation system, large scale distribution platform jw1 , data intelligence, and immersive experiences. we are a passionate, user focused r d team with world class engineers, scientists, and product managers. in this role, you will build a large scale personalized recommendation system scaling globally to 1b users. you will work on problems such as recommendation, user modeling, ranking, content diversity, natural language processing, data mining and platforms, and topic modeling. you will provide thought leadership to scientists, and engineers to deliver highly quality personalized recommendations that will engage and delight our users. you will work with teams of talented scientists, and help recruit the best scientists in machine learning, e.g. personalized recommendation, nlp, data science. as a senior member of the team, you are expected to be able to bring structure to ambiguous business problems and use science, logic, and practical experience to decompose them into straightforward, scalable solutions. you will set the standard for scientific excellence and make decisions that affect the way we build and integrate algorithms. your solutions are exemplary in terms of algorithm design, clarity, model structure, efficiency, and extensibility. you tackle intrinsically hard problems you re interested in learning and you acquire skills and expertise as needed. if you are seeking an iterative, fast paced environment where you can drive innovation, apply state of the art technologies to solve extreme scale real world delivery challenges, and have business impact on global scale, this is your opportunity. responsibilities you will be building state of the art personalized recommendation systems. you will leverage state of the art approaches across recommendation, nlp, data science. you will train models, run experiments, build data pipelines, and define measurements and metrics all in the pursuit of delighting 1b users through recommendation. set strategic direction and plan of execution based on insights gained through data analysis and customer feedback to drive meaningful business results. you will mentor with potential to tech lead teams of data and applied scientists and software engineers to successfully execute on our roadmap and achieve your strategic objectives. drive collaboration and partnership with other r d teams in microsoft to deliver an outstanding product. qualifications required qualifications 6 years of industry experience in a data scientist, applied scientist or related role. 6 years of hands on experience in one or more of the following areas recommendation, deep learning, machine learning, text analysis, information retrieval, nlp, computer vision with a strong understanding of both practical and theoretical aspects. 3 years of experience with large scale data processing infrastructure such as spark, hadoop, or similar. preferred qualifications advanced degree in cs or ce or ee or data science or related areas experience developing in python or r or c or c ability to own machine learning systems end to end from data pipelines and training to real time prediction engines. ability to independently drive cross team collaborations and ship production features in a fast paced startup environment. excellent communication and presentation skills, both verbal and written. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work. recommendation machinelearning personalization nlp webxt bigdata contentservices","['prediction', 'personalization', 'c', 'algorithm design', 'python', 'data processing', 'software', 'computer vision', 'data science', 'windows', 'data', 'data mining', 'machine learning', 'data pipelines', 'data analysis', 'data intelligence', 'algorithms', 'measurements', 'deep learning', 'language processing', 'information retrieval', 'hadoop', 'nlp', 'modeling', 'r']","['python', 'hadoop', 'nlp', 'windows', 'c', 'r']","['prediction', 'personalization', 'natural', 'algorithm design', 'data processing', 'software', 'computer vision', 'data science', 'data', 'feed', 'data mining', 'machine learning', 'data pipelines', 'data analysis', 'algorithms', 'measurements', 'user', 'deep learning', 'text analysis', 'language processing', 'information retrieval', 'modeling']","['environment', 'metrics', 'art', 'finance', 'legal', 'recruiting', 'regulations', 'r']"
239,307,Data Scientist - AML - 312972,"business analyst on behalf of our client in the banking sector, procom is looking for a business analyst. business analyst job description reporting to the advanced analytics manager, the data scientist i will be conducting all analytical activities related to aml transaction monitoring systems provide maintenance of transaction monitoring scenarios, and analytical queries in support of the bank s strategic efforts to mitigate money laundering and terrorist financing risk conduct activities related to aml or atf scenario performance review and tuning help maintain a structured documentation process to demonstrate an effective scenario review program to satisfy audit, compliance, and regulatory requirements with assistance from management, assist with scenario related issues or questions from global aml members, audit, and other partners provide solutions where there is a need for advanced quantitative, statistical, and analytical skills undertake ad hoc data mining research projects to find hidden patterns and potential anomalies within data partner with gaml teams to implement changes to existing solutions and or or the implementation of alternative solutions use statistical and data mining techniques to build and maintain effective and efficient transaction monitoring, customer behavior, and risk scoring machine learning models communicate results to various stakeholders and ensure they fully understand implications of relevant measures business analyst mandatory skills masters degree or higher in statistics, computer science or software engineering expert knowledge of sas, sql, r python are essential ability to apply statistical techniques and data mining tools to solve business problem 3 years of experience in data modeling or machine learning experience in query optimization, debugging and automation strong knowledge of microsoft office suite, including excel and powerpoint excellent written and oral communication, analytical and interpersonal skills, including ability to communicate with individuals from various backgrounds excellent multi tasking skills, ability to adapt to and manage changing priorities business analyst nice to have skills aml knowledge is an asset business analyst assignment start date asap 20 months to start business analyst assignment location toronto, on work remotely","['analytical skills', 'documentation', 'sql', 'python', 'statistics', 'software', 'reporting', 'analytics', 'data', 'sas', 'data mining', 'financing', 'machine learning', 'debugging', 'automation', 'banking', 'computer science', 'optimization', 'modeling', 'r']","['sql', 'python', 'documentation', 'debugging', 'sas', 'r']","['data mining', 'financing', 'analytical skills', 'machine learning', 'banking', 'transaction monitoring', 'performance review', 'statistics', 'software', 'reporting', 'analytics monitoring', 'computer science', 'data', 'optimization', 'modeling', 'scenario review', 'automation']","['research projects', 'regulatory requirements', 'microsoft office']"
240,308,"Senior Data Scientist, KPMG Lighthouse","overview you ve got big plans. we have opportunities to match, and we re committed to empowering you to become a better you, no matter what you do. when you join kpmg you ll be one of over 219,000 professionals providing audit, tax, advisory and business enablement services across 147 countries. with the support to do things differently, grow personally and professionally and bring your whole self to work, there s no limit to the impact you can make. let s do this. the opportunity innovate. collaborate. shine. lighthouse kpmg canada s center of excellence for data valorization, advanced analytics applies data science to solve real word business problems, operationalize ai and optimize emerging technologies for its mission. join a diverse team which is always curious and learning, thinking independently, working collaboratively, has a passion to solve difficult problems, and has fun doing it. kpmg lighthouse qu bec has an exciting opportunity for a senior data scientist to join our team this role will be a rewarding experience for you if you thrive on challenges and work best in a fast paced environment where each day is different work well in a project team environment and have strong collaboration and interpersonal skills have a permanent figure it out mindset what you will do work closely with clients in understanding key business issues. gather and analyze requirements to develop impactful recommendations and solutions. utilize advanced analytical technics to solve challenging business problems. leverage a diverse set of technologies and tools to deliver insights. solve problems through the application and the development of suitable statistical models, machine learning, deep learning, reinforcement learning algorithms techniques such as clustering, neural networks, causal inference, probabilistic models, natural language processing , computer vision, time series algorithms, etc. work with large volumes of data . investigate and perform deeper analysis to produce impactful algorithms to achieve targeted outcomes. perform quantitative analysis of data issues. effectively communicate orally and in writing with peers within lighthouse, kpmg and the client. what you bring to this role university degree in mathematics, statistics, machine learning, computer science, operations research, engineering or econometrics, other quantitative disciplines and or or equivalent combination of education in related disciplines. 5 years of professional experience in a related field. expert knowledge in advance modeling techniques and mathematical models, algorithm use and optimization, and data science technologies. understanding of the full spectrum of data feature retrieval, selection, and engineering model technique selection and integration interpretation of outputs, and development of recommendations. capability of identifying commonalities across seemingly disparate analytics use cases, in order to identify unique ways of approaching modeling. strong experience in data mining, mathematics, statistics, machine learning . strong communication in english and french and interpersonal skills. keys to your success understanding the top issues faced by clients related to data and analytics through discussions with peers, clients, etc., and by following business media, industry issues reports, etc. ability to understand engagement objectives including understanding the client s business problem. how the engagement helps address the client s business problem. explain the business value of addressing the business problem. learn more about where a career at kpmg can take you. our values, the kpmg way integrity, we do what is right excellence, we never stop learning and improving courage, we think and act boldly together, we respect each other and draw strength from our differences for better, we do what matters kpmg in canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier free workplace that allows all of our people to reach their full potential. a diverse workforce is key to our success and we believe in bringing your whole self to work. we welcome all qualified candidates to apply and hope you will choose kpmg in canada as your employer of choice. if you have a question about accessible employment at kpmg, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact kpmg s employee relations service team for support at email or phone 416 777 8002 or toll free 1 888 466 4778 option 3. for general recruitment related inquiries, please contact the hr delivery centre at","['statistics', 'computer vision', 'data science', 'analytics', 'integration', 'econometrics', 'data mining', 'machine learning', 'causal inference', 'algorithms', 'deep learning', 'language processing', 'neural networks', 'computer science', 'mathematics', 'optimization', 'modeling', 'enablement', 'reinforcement learning', 'ai']",[],"['natural', 'computer vision series', 'statistics', 'data science', 'analytics', 'integration', 'econometrics', 'data mining', 'machine learning', 'quantitative analysis', 'operations research', 'causal inference', 'algorithms', 'deep learning', 'language processing', 'use cases', 'neural networks', 'computer science', 'mathematics', 'optimization', 'modeling', 'enablement', 'reinforcement learning', 'ai']","['environment', 'business valueg', 'education', 'employee relations', 'hr', 'business media']"
241,310,Data Science Instructor,"about the position exciting things are happening at juno college we re in the midst of building out our data science career pathway and are seeking a full time instructor to join our data science team in may. we re looking for someone who is collaborative, empathetic, and passionate about teaching, with a strong background in data science. this is a flexible role that ll allow you to inspire and lead others, mould new pedagogies, research and test innovative ways of delivering content, and support the growth of our data science program offerings, while also still having the chance to practice your craft by taking on data science projects for juno, exploring our various data sets, and delivering insights that can change the trajectory of our business. we are currently offering all of our courses live online, and will only move back to in person learning when it s safe to do so. we anticipate having most, if not all, courses live online for all of 2021 and so this role is remote friendly. about us founded in 2012, juno college of technology is a well loved provider of hands on, project based training for people who want to launch new careers in tech from our 12,000 square foot office in downtown toronto to our live online classrooms, we run bootcamps and continuing education courses year round. with thousands of alumni and 1,000 students a year, there s a large community of people ready to welcome you to juno responsibilities work with a team of instructors and mentors to lead data analytics and data science courses, helping students learn through lessons, code alongs and interactive exercises work directly with our students in the classroom and give project support help resolve issues, and coach through debugging and technical problem solving provide a thoughtful, stimulating, and positive classroom experience participate in supporting student events create, update and refine curriculum using student feedback and new developments in the data science field according to our curriculum roadmap collaborate with the team to create and review program improvements and innovations contribute expertise to in house data science projects using juno s data sets other tasks as required about you as a private career college, all of our instructors are required to have at least 2 years of practical, real world experience as data analysts, data scientists or similar. candidates who do not have the required experience will not be considered for this position. it would be great if you also have any experience as a teacher, instructor, or mentor, in any discipline. your qualifications hold a degree, diploma, or certification from an ontario college, university, private career college, or equivalent, and have 24 months occupational data science experience or have 36 months of teaching data science experience, and have 24 months occupational data science experience or have 48 months of occupational data science experience you could be a great fit if you are an excellent public speaker and written communicator are passionate about teaching data science and data fluency skills have demonstrable hands on industry experience in data science are collaborative, energetic, and empathetic, and a great technical problem solver have expertise in using python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization have practical knowledge of working with big data, performing customer segmentation, and using cloud services are comfortable using git, github, google docs, sheets, and drive have a positive attitude and a desire to help others. salary, perks, and benefits position type full time, permanent starting salary 70,000 85,000 clear growth paths three weeks paid vacation plus extra time off in december seven paid personal days each year health spending account refreshed annually more visit our careers page here for a full list of perks benefits.","['data analytics', 'python', 'machine learning', 'statistics', 'github', 'project support', 'data wrangling', 'data visualization', 'data science', 'git', 'debugging', 'big data', 'data analysis', 'solver', 'cloud services']","['python', 'git', 'debugging', 'big data', 'solver']","['data analytics', 'machine learning', 'statistics', 'exploratory', 'project support', 'data wrangling', 'data visualization', 'data science', 'data analysis', 'github', 'cloud services']","['curriculum', 'continuing', 'events', 'private', 'education', 'developments']"
242,311,Data Engineer,"about us the kraft heinz company is one of the largest food and beverage companies in the world, with eight 1 billion brands and global sales of approximately 25 billion. we re a globally trusted producer of high quality, great tasting, and nutritious foods for over 150 years. our brands are truly global, with products produced and marketed in over 40 countries. these beloved products include condiments and sauces, cheese and dairy, meals, meats, refreshment beverages, coffee, infant and nutrition products, and numerous other grocery products in a portfolio of more than 200 legacy and emerging brands. we spark joy around mealtime with our iconic brands, including heinz, kraft, bull s eye, hp, lea and perrins, quero, abc, master, banquete, plasmon, orlando, benedicta, honig, pudliszki, wattie s among others. no matter the brand, we re united under one vision to sustainably grow by delighting more consumers globally . bringing this vision to life is our team of 39,000 food lovers, creative thinkers, and high performers worldwide. together, we help provide meals to those in need through our global partnership with rise against hunger. we also stand committed to responsible, sustainable practices that extend to every facet of our business, our consumers, and our communities. every day, we re transforming the food industry with bold thinking and unprecedented results. if you share our passion and are ready to create the future, build a legacy, and lead as a global citizen there s only one thing to do join our table and let s make life delicious our culture of ownership, meritocracy collaboration we re not afraid to think differently. embrace new ideas. dream big. we empower our people at every level from entry level intern to senior leader to own their work. we share a responsibility to think like owners to be mindful of the collective and sustained success of kraft heinz which we apply to every situation, every day. as part of kraft heinz, you re supported to grow and achieve. you re expected to bring your authentic self to work every day, to lead with humility, and drive outstanding performance at every level and you ll be rewarded. you re given opportunities to leave a mark and build a legacy. but you won t do it alone. you re supported by passionate teammates along the way, and our collective, collaborative spirit fuels our incredible progress. job description as a data engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. these solutions will generate insights from our connected data, enabling kraft heinz to advance data driven decision making capabilities across the enterprise. you will have a deep understanding of data architecture, data engineering, data analysis, and reporting and a basic understanding of data science techniques and workflows, as well as the business processes supported by the data pipeline. examples of problems you will tackle include helping r d determine the next generation of household products, revolutionizing consumer engagement with personally relevant content, and reinventing our supply chain to eliminate food waste. responsibilities design, develop, optimize, and maintain data architecture and pipelines that adhere to etl principles and business goals solve complex data problems to deliver insights that helps our business to achieve their goals create data products for business intelligence engineers, business analyst and data scientist team members to improve their productivity advise, consult, mentor and coach other data and analytic professionals on data standards and practices foster a culture of sharing, re use, design for scale stability, and operational efficiency of data and analytical solutions lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes partner with machine learning engineers, business intelligence engineers and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. learn about machine learning, data science, computer vision, artificial intelligence, statistics, and or or applied mathematics. qualifications bachelor s degree required computer science, mis, or engineering preferred expertise in etl and data analysis and experience with sql and at least one programming language experience developing and maintaining data warehouses in big data solutions e.g. snowflake experience with developing solutions on cloud computing services and infrastructure in the data and analytics space database development experience using hadoop, spark or bigquery and experience with a variety of relational, nosql, and cloud database technologies worked with bi tools such as alteryx, tableau, power bi, looker conceptual knowledge of data and analytics, such as dimensional modeling, elt, reporting tools, data governance, data warehousing, structured and unstructured data. big data development experience using hive, impala, spark and familiarity with kafka familiarity with the linux operating system exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and or or applied mathematics an agile learner who brings strong problem solving skills, and enjoys working as part of a technical, cross functional team to solve complex data problems a hard worker and consensus gainer who brings a strong numbers sense you are intellectually curious and willing to adjust your position based on additional information kraft heinz is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. all qualified candidates will be considered for our opportunities regardless of race religion faith creed age ethnicity marital status gender identity sexual orientation or disability. job seekers with disabilities who require accommodation during the recruitment process or would like more details about accessibility should contact . ind123 li location toronto on location don mills","['linux', 'tableau', 'alteryx', 'operational efficiency', 'big', 'data standards', 'hive', 'sql', 'looker', 'statistics', 'reporting', 'computer vision', 'data science', 'data', 'programming', 'analytics', 'pipelines', 'data engineering', 'cloud computing', 'data warehousing', 'nosql', 'unstructured', 'machine learning', 'data pipelines', 'data products', 'mis', 'artificial intelligence', 'business intelligence', 'data analysis', 'bi', 'hadoop', 'data solutions', 'computer science', 'modeling', 'applied mathematics', 'snowflake', 'etl']","['sql', 'looker', 'linux', 'tableau', 'bi', 'alteryx', 'mis', 'big', 'hadoop', 'data standards', 'programming', 'business intelligence', 'pipelines', 'hive', 'snowflake', 'nosql', 'big data development', 'r']","['unstructured data', 'operational efficiency', 'statistics', 'reporting', 'computer vision', 'data science', 'data', 'analytics', 'data engineering', 'cloud computing', 'data warehousing', 'machine learning', 'data pipelines', 'data products', 'artificial intelligence', 'data analysis', 'data solutions', 'computer science', 'modeling', 'applied mathematics', 'analytics development', 'etl']","['environment', 'education', 'design', 'sales', 'food industry', 'governance', 'waste', 'architecture']"
243,312,"Applied Scientist, Machine Learning","your role we are seeking an applied scientist who will join our machine learning team in the quantum simulation division. in this role, you will be developing and deploying state of the art machine learning algorithms to improve the performance of electronic structure calculations. you will collaborate with the members of our r d and software teams to deliver end to end machine learning solutions on the cloud. this is a unique opportunity to be part of an ambitious and growing team that aims at accelerating applications in advanced material science and life science. this is a permanent, full time role. what you ll do participate in the design for various stages of the machine learning lifecycle. implement and develop end to end machine learning pipelines on the cloud, including data management, training, tuning, and debugging machine learning models as well as interpreting model results. use your experience with different machine learning frameworks and mlops solutions to identify suitable tools for integration into our platform. use and encourage best coding practices within the machine learning team. stay up to date with recent advancements in the field of deep learning and mlops collaborate with colleagues from science, engineering, and business backgrounds. what you ll bring members of our team bring a confluence of personality, skills, and goals that contribute to their individual development and our collective growth as an organization. the following criteria outline the complementary knowledge and mindset you ll bring to our team a master s or doctorate degree in computer science, engineering, mathematics, or statistics, or equivalent work experience. 2 years of professional experience building and deploying machine learning solutions, . proficiency in python and supporting numeric libraries. experience writing unit and integration tests for your code. experience with ml frameworks and mlops solutions . familiarity with a broad set of ml approaches and techniques including deep learning and transfer learning. active learning and message passing neural networks is a plus. experience training and containerizing ml models on the cloud. experience with big data processing and database management. being comfortable providing feedback to team members, soliciting and acting on feedback to improve your performance. proactiveness in seeking out opportunities to help move projects forward and contribute to their improvement. an eagerness to learn about new trends, tools, and technologies, and to continually consider how these will influence our projects in terms of opportunities and challenges. excellent verbal or written communication skills, including an ability to effectively collaborate with research and technical teams. who we are as part of the quantum simulation division, you will work in a dynamic environment where you will be challenged to solve scientific problems. being in the field of bringing novel solutions to complex industry problems, you will constantly be challenged to both use your existing knowledge as well as learn new methods to solve problems. we also value open discussion of ideas with the firm belief that together we will get to the destination faster. about 1qbit 1qbit is a global leader in advanced computing, with three innovation hubs located in vancouver, waterloo, and sherbrooke. along with its partners, 1qbit takes on computationally intensive problems across a variety of fields, including advanced materials, life sciences, energy, and finance. trusted by fortune 500 companies and top research institutions, 1qbit develops novel solutions by building on its broad expertise in hardware innovation, quantum computing, ai, and commercial application development. 1qbit offers unique deep tech career opportunities through advanced internships, full time positions, and a steadfast investment in our team s expertise. working at 1qbit means applying your thinking and skills to tackle exciting and relevant challenges. why work at 1qbit you will have a chance to be part of a diverse and collaborative team and enjoy perks including eligibility to take part in our options plan, full health and wellness benefits, extra long long weekends, plenty of social events, and flexible work from home options.","['computing', 'confluence', 'python', 'statistics', 'data processing', 'software', 'coding', 'integration', 'pipelines', 'application development', 'machine learning', 'debugging', 'hardware', 'algorithms', 'deep learning', 'neural networks', 'computer science', 'mathematics', 'data management', 'calculations', 'ai']","['python', 'big', 'confluence', 'debugging', 'hardware', 'pipelines']","['computing', 'database management', 'statistics', 'tests', 'data processing', 'software', 'mlops', 'integration', 'application development', 'machine learning', 'algorithms', 'deep learning', 'neural networks', 'quantum', 'computer science', 'mathematics', 'data management', 'calculations', 'ai']","['material science', 'environment', 'events', 'design', 'art', 'acting', 'materials', 'life sciences', 'finance']"
244,313,"Data Engineer, Omnia AI (CDC)","job type permanent primary location montreal, quebec, canada all available locations montreal learn from deep subject matter experts through mentoring and on the job coaching. be encouraged to deepen your technical skills whatever those may be. partner with clients to solve their most complex problems you have a passion for analytics and advanced data management you want to build solutions that will allow customers to go further with the best of the existing data solutions you are ready to uncover the possibilities of ai in your career and set the foundation for success tomorrow then we have an opportunity waiting for you what will your typical day look like as a data engineer within our omnia ai canadian delivery center , you will be a team player to a portfolio of deloitte s omnia ai engagements . you will have the opportunity to be involved in the full life cycle over ai projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. you will be able to work on the largest and most advanced analytics projects on the market 2019, 2020, 2021 gartner data analytics service provider leader. specifically, you will bring your expertise to customers who want to transform their company into a data driven organization. you will be able to leverage all the existing assets created by deloitte around ai applications, and combine them with your knowledge to build perfectly tailored applications for each customer work with high profile clients on a variety of canadian and international engagements, including opportunity to travel across canada and internationally about the team deloitte omnia ai, deloitte s artificial intelligence practice is comprised of specialized experts with hands on experience, and cutting edge information assets that facilitate successful artificial intelligence transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. our omnia canadian delivery center team helps clients design and implement the data platform architectures be it in the cloud or on premise required to enable cutting edge ai solutions. we work closely with the omnia ai strategy, data modernization analytics, ai insights and ai factory teams to drive successful business outcomes. you will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on big data, bi or dw, data integration, data governance, master data and analytics applications. each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. to support our continued growth, we are looking to add many team players with hands on work experience ideally in the data, analytics and or or ai domains. enough about us, let s talk about you you are someone with strong interest to bring artificial intelligence and advanced analytics to enterprise applications 2 years of experience in data related projects like modeling and etl processes within enterprise systems modern analytic platforms data lake, data warehouse, datamart, dimensional models, etl processes. an experience writing sql queries or python scripts, extracting and importing disparate data from source systems to analytics platforms. team player attitude intellectual curiosity, and strong analytical skills college or cegep or undergraduate studies in business or engineering or mathematics or computer science postgraduate studies in computer science related specializations advantageous differentiators but not required projects experiences with the following azure data lakes, snowflake, databricks and agile development methods in data oriented projects bilingual able to obtain government of canada security clearance if you believe you have what it takes to be a successful member of our team, please apply now. we know your career is important to you and it s important to us, too. this role is just the first step of a highly successful career we can help you build. the time is right for you to join deloitte. get your career off to great start. what impact will you make why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities deloitte encourages applications from all qualified candidates that represents the full diversity of communities across canada. this includes candidates from indigenous communities in support of living our values and our commitments to our reconciliation action plan . we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally. deloitte canada has 30 offices with representation across most of the country. we acknowledge our offices reside on traditional, treaty and unceded territories as part of turtle island and is still home to many first nations, m tis, and inuit peoples. we are all treaty people.","['go', 'analytical skills', 'big', 'master', 'data analytics', 'sql', 'python', 'enterprise', 'analytics', 'data', 'integration', 'modernization', 'enterprise systems', 'artificial intelligence', 'bi', 'data solutions', 'security', 'computer science', 'mathematics', 'modeling', 'data management', 'snowflake', 'etl', 'ai']","['go', 'sql', 'python', 'azure', 'bi', 'data lakes', 'big data', 'master data', 'snowflake']","['modernization', 'data analytics', 'analytical skills', 'data solutions', 'enterprise systems', 'security', 'enterprise', 'computer science', 'analytics', 'artificial intelligence', 'data', 'integration', 'modeling', 'mathematics', 'agile development', 'data management', 'etl', 'ai']","['subject matter experts', 'project delivery', 'design', 'governance', 'engagements', 'government', 'mentoring']"
245,314,Data Engineer,"job title data engineer location downtown, toronto type full time permanent salary negotiable benefits focus on data architecture, best practices, reliability, security, and compliance improve and extend etl, data processing, and analytics processes facility with powerbi, including creating dashboards and data sources developing high complexity, fast performing select queries. developing t sql procedures, functions, triggers, jobs, scripts, etc. development of advanced t sql such as temporal tables, pivots, recursive table expressions and more. modeling and implementing data mart solution for power bi analytics managing indexes, statistics, query plans alerts, database activity, and overall performance activity. in depth experience working with relational databases, such as microsoft sql server or postgresql enthusiasm for applying good data design, testing, documentation, and support practices experience building and optimizing data pipelines, architectures, and data sets knowledge of message queueing, stream processing, and data stores or warehouses working knowledge of aws products related to data engineering bachelor s degree in computer science, software engineering or an equivalent excellent communication skills both written and verbal ability to speak in spanish is a bonus to apply please send an email to","['dashboards', 'documentation', 'sql', 'statistics', 'data processing', 'postgresql', 'software', 'analytics', 'data', 'aws', 'data engineering', 'microsoft sql server', 'data pipelines', 'relational databases', 'testing', 'stream processing', 'bi', 'security', 'computer science', 'modeling', 'etl']","['microsoft sql server', 'sql', 'postgresql', 'bi', 'documentation', 'aws']","['statistics', 'data processing', 'relational databases', 'data pipelines', 'software', 'testing', 'security', 'dashboards', 'stream processing', 'computer science', 'analytics', 'data', 'modeling', 'data engineering', 'data design', 'etl']","['and compliance', 'architecture']"
246,315,Data Engineer,"here at rakuten kobo inc. we offer a casual working start up environment and a group of friendly and talented individuals. our employees rank us highly in terms of commitment to work or life balance. we realize that for our people to be innovative, creative and passionate they need to have healthy minds and bodies. we believe in rewarding all our employees with competitive salaries, performance based annual bonuses, stock options and training opportunities. if you re looking for a company that inspires passion, personal, and professional growth join kobo and come help us make reading lives better. the role rakuten kobo inc. is looking for a data engineer to join a new data operations team we are building that will help transform and govern our data. you will rewrite the process to ensure we use the data in the most flexible, effective manner possible to help the business achieve its goals. not only will you build out the tools, you will be designing, implementing, and maintaining different data architectures. the role also includes managing the flow of data from methods of input and its life cycle. responsibilities create document efficient data pipelines write and optimize complex queries on large data sets transform data and map them to more valuable and understandable sets for consumption create tooling to help with day to day tasks troubleshoot issues related to data accuracy and create the source of truth help remove the friction from other members of the organization and allow them to focus on their primary objective introduce new technologies to the environment through research and pocs reduce toil by automation the skillset a generalist who can jump on any problem where no level of work is beneath them. a problem solver believer of automation, reducer of toil one who loves to apply all their learnings to advance themselves, the team and ultimately the company one who enjoys sharing knowledge mentoring other team members highly adaptive to changes, fun and supportive motivated, creative, organized with attention to detail must haves advanced experience with python, sql, including, spark, and hive experience working with rest apis and python data analysis tools such as pandas or numpy. experience building etl and big data pipelines with workflow management tools airflow or luigi experience with stream processing systems storm, flume, rabbitmq, kafka, etc. ability to prioritize competing requests and multiple tasks in a fast paced, deadline driven environment experience managing a project backlog and working cross functionally with multiple stakeholders ability to work effectively on a self organizing team with minimal supervision initiative in communicating with co workers, asking questions and learning excellent oral and written communication skills proactive and creative problem solver with the ability to multitask and manage tight deadlines nice to haves experience with continuous integration or deployment tools . experience with schema design and dimensional data modeling. exposure to containerized applications . the perks flexible hours and unlimited work from home full benefits starting from your first day paid volunteer days, unlimited sick days, and 3 rrsp matching monthly commuting allowance internet allowance flexible health spending account talent and development training budget free kobo device free weekly e book or audiobook weekly kobo tech university sessions weekly virtual happy hours maternity or paternity leave top up about rakuten kobo inc. owned by tokyo based rakuten and headquartered in toronto, rakuten kobo inc. is one of the most advanced global ecommerce companies, with the world s most innovative ereading services offering more than 6 million ebooks and audiobooks to 30 million customers in 190 countries. kobo delivers the best digital reading experience through creative innovation, award winning ereaders, and top ranking mobile apps. kobo is a part of the rakuten group of companies. rakuten kobo inc. is an equal opportunity employer. accessibility accommodations for candidates with disabilities participating in the selection process are available on request. any information received related to accommodation needs of applicants will be addressed confidentially. rakuten kobo would like to thank all applicants for their interest in this role however only qualified candidates will be shortlisted","['big', 'modeling', 'hive', 'map', 'sql', 'python', 'pandas', 'data', 'integration', 'solver', 'data pipelines', 'numpy', 'stream processing', 'toil', 'data analysis', 'rest', 'automation', 'airflow', 'schema', 'data operations', 'rabbitmq', 'etl']","['sql', 'python', 'big', 'numpy', 'pandas', 'toil', 'rabbitmq', 'hive', 'solver', 'map', 'airflow']","['data pipelines', 'continuous', 'stream processing', 'schema', 'data', 'modeling', 'integration', 'data operations', 'data analysis', 'rest', 'automation', 'etl']","['environment', 'design', 'mentoring']"
247,316,Data Engineer - Python Developer,"join unbounce and help the world experience better marketing. we re a people first, customer obsessed company focused on helping employees do their best work. our landing page and conversion platform empowers digital marketing teams and agencies to launch campaigns, increase conversions and get significantly better roi on their marketing spend in a way that nobody else does today. the data engineering team enables other teams by creating the ecosystem upon which data processing is built. we believe in working the devops way from owning the infrastructure to writing tooling and building pipelines. we believe in fostering an environment that promotes growth, engagement, team ownership, responsibility, initiative and empowerment. note on remote due to covid we are currently all working remotely . while unbounce has shifted to be remote first, we hope to work together in the same dog friendly space again for that irreplaceable personal touch. what you ll be doing work closely with the rest of the team to build high quality, complex systems. contribute to our analyst and data science enablement ecosystems by building tooling and pioneering best practices. develop etl pipelines and supporting infrastructure for data driven insights. contribute to team ownership of our infrastructure upon which we run all our work. grow technical skills within and outside the team through code reviews, pairings, demos etc. set and maintain standards around data governance, code quality and efficient communication and to evangelize best practices within the team and company. a little bit about you experience writing production level python and sql proficiency in database management, data warehouse design and distributed systems experience in building production level infrastructure for data processing to run on you understand data governance you have built systems that provide available, correct and secure data additional skills these are skills that will help you hit the ground running, but if you don t have them, you will have the opportunity to learn aws tools mysql, postgres, dynamodb python api development spark kubernetes airflow infrastructure as code ci or cd kafka what s in it for you 4 weeks vacation plus christmas holiday closure you re entitled to the week of christmas off with pay through to and including jan 1st 12 personal wellness days vacation bonus 1,000.00 health and wellness budget 500.00 networking budget 500.00 a paid day off for your birthday one paid volunteer day per year one day every 2 weeks of dedicated professional development time unbounce welcomes everyone to apply at unbounce we celebrate everyone and their multiple intersecting identities. we believe a panorama of experience allows us to make better decisions together and inspires innovation so that we can better serve our customers and community. our goal is for every unbouncer to feel deeply connected to their team through mutual value, respect, and understanding. please let us know if you require any accommodations or support during the recruitment process q411asvcjd","['ci', 'distributed systems', 'mysql', 'kubernetes', 'sql', 'python', 'data processing', 'cd', 'complex systems', 'data science', 'data', 'aws', 'pipelines', 'data engineering', 'rest', 'airflow', 'demos', 'devops', 'api', 'networking', 'enablement', 'etl']","['kubernetes', 'sql', 'python', 'demos', 'api', 'aws', 'pipelines', 'mysql', 'airflow']","['hit', 'data processing', 'cd', 'complex systems', 'devops', 'ci', 'data science', 'database management', 'networking', 'data', 'distributed systems', 'data engineering', 'enablement', 'infrastructure as code', 'rest', 'etl']","['environment', 'marketing', 'design', 'team ownership', 'governance', 'digital', 'campaigns']"
248,317,Actuarial Data Engineer,"about swiss re corporate solutions swiss re is one of the world s leading providers of reinsurance, insurance and other forms of insurance based risk transfer. we anticipate and manage risks, from natural catastrophes and climate change to cybercrime. swiss re corporate solutions is the commercial insurance arm of the swiss re group. we offer innovative insurance solutions to large and midsized multinational corporations from our approximately 50 locations worldwide. we help clients mitigate their risk exposure, whilst our industry leading claims service provides them with additional peace of mind. swiss re corporate solutions offers a flexible working environment where curious and adaptable people thrive. are you interested in joining us about the role to lead or assist in the creation and management of data pipelines to enable actuarial services or data science in the development of visualizations and advanced analysis that support business operations and decision making processes. responsibilities will include gain trust and working relationship with business stakeholders and internal partners conduct interviews with the swiss re accident health clients to assess pain points, define visions of future products, and implement solutions that deliver value across people, process, data, and technology review and analyze business workflows and user data needs design and implement business performance dashboards write customized queries or programs to generate automatic periodical reports highlighting all the key performance indicators visualize the correct metrics in the dashboard and use appropriate data forecasting models in order to aid the teams to make better business decisions and control risk more efficiently analytics engineering in close collaboration with data engineers, data scientists, business users and technical experts to provide high quality deliverables and timely submissions improve systems by evaluating current practices and designing modifications. support the modernization of the existing tools by replacing and rebuilding systems and overall move towards more predictive analytics utilize knowledge of database management system software, object oriented programming development, system architecture and components and various programming languages build applications using sql and or or python scripts to manipulate data, monitor and help to improve data quality design, build and maintain end to end data solutions supporting our processes with the right data architecture handle data pipelines while testing for data curation, parsing, cleaning, transformation and enrichment of data development and support of data pipelines. have working knowledge of apache spark, big data processing and building products on distributed cluster computing framework work with fundamentals of data processing, data pipeline, data lineage and etl methodologies implement the project according to the software development life cycle and programming by using fast paced agile methodology, involving task completion, user stories ensure compliance with internal group controls and guidelines shape and contribute to appropriate data governance along the whole data lifecycle construct workflow charts and diagrams and writing specifications documentation of end to end data pipeline process documentation of data assets for information management purposes develop cost estimate models to support roi metrics ad hoc team or business support as needed exploration and evaluation of new technologies and platforms. about you bachelors or equivalent degree computer science, data science, statistics or another relevant quantitative field 5 years of insurance industry experience sql stack sql server management studio , sql server integration services , sql server analysis services microsoft msbi stack power query, powerpivot, powerbi microsoft access familiarity with relational database concepts detail oriented, analytical and inquisitive highly organized with strong time management skills ability to work independently and collaborate well with others ability to affect smooth organizational transformations. other details position type permanent full time36.5 hours per week rate of pay 113,500.00 to 120,000 cad per year benefits group insurance benefits, defined contribution retirement plan, employee savings plan, global share plan, paid time off location westport insurance corporation, 150 king street west, suite 1000, toronto, ontario, canada m5h 1j9. teleworking is allowed during the pandemic. swiss re is an equal opportunity employer. it is our practice to recruit, hire and promote without regard to race, religion, color, national origin, sex, disability, age, pregnancy, sexual orientations, marital status, military status, or any other characteristic protected by law. decisions on employment are solely based on an individual s qualifications for the position being filled. during the recruitment process, reasonable accommodations for disabilities are available upon request. if contacted for an interview, please inform the recruiter or hr professional of the accommodation needed.","['parsing', 'computing', 'dashboards', 'documentation', 'etl', 'data curation', 'sql', 'python', 'statistics', 'data processing', 'software', 'diagrams', 'data science', 'data', 'analytics', 'programming', 'integration', 'modernization', 'data pipelines', 'software development life cycle', 'testing', 'apache spark', 'sql server', 'microsoft access', 'specifications', 'data quality', 'forecasting', 'information management', 'dashboard', 'programming languages', 'data solutions', 'system', 'computer science', 'cluster']","['dashboard', 'sql', 'python', 'programming languages', 'object oriented', 'apache spark', 'big', 'sql server', 'microsoft access', 'programming', 'documentation', 'programming development', 'predictive', 'sql server management', 'data quality']","['computing', 'data lineage', 'dashboards', 'cluster', 'data curation', 'statistics', 'data processing', 'software', 'diagrams', 'data science', 'database', 'analytics', 'data', 'integration', 'modernization', 'data pipelines', 'software development life cycle', 'testing', 'specifications', 'forecasting', 'information management', 'parsing development', 'data solutions', 'system', 'computer science', 'methodology', 'etl']","['environment', 'actuarial', 'metrics', 'insurance industry', 'business support', 'forms', 'design', 'business operations', 'retirement', 'reinsurance', 'climate change', 'governance', 'architecture', 'key performance indicators', 'hr', 'law', 'insurance']"
249,318,Analytical Development Associate Scientist,"title associate scientist analytical development the analytical development associate scientist supports the development of new pharmaceutical dosage forms in addition to improving existing products and procedures. these activities will be achieved by using knowledge and innovation of science, technology and chemistry to investigate the properties, components and abilities of chemicals and processes in the development of efficient manufacturing procedures and the development of appropriate analytical methodologies to create prototype formulations and clinical supplies. this position performs activities assigned by the manager or upper management to meet the company s goals within the specified timelines. this position also requires documenting, reviewing, analysing and interpreting data, and interpreting scientific problems in support of hc, fda, emea and anvisa submissions in a timely manner while complying with departmental sop s and guidelines set out by the regulatory agencies and ich . this will be achieved by working very closely with the analytical development and r d qa teams. key job responsibilities and duties responsible and accountable for designing, planning and executing all aspects of assigned projects through scientific rationale using quality by design principles to develop new products per departmental sop s and ich guidelines. this should be done in consultation with senior peers development scientists, manager or upper management. applies analytical or problem solving skills and utilizes available resources to identify process and or or formulation deficiencies and propose solutions to be implemented. in addition to working with more experienced colleagues to troubleshoot and resolve challenges during the development of analytical methodologies. supports writing the summary of pharmaceutical development reports including analytical method development, method validation, related substances identification, force degradation studies, stability reports and all other information required in the cmc sections of ctas, nds and s or nds, in a timely fashion. furthermore, provides the required information to support fda, emea and anvisa submissions. supports internal projects and external contract manufacturing organization projects in alignment with biolab s objectives and initiatives. communicates or interacts as indicated by management with qc or contract laboratory during transfer of analytical methodologies from r d in a timely fashion. collaborates with regulatory documents, and team efforts to define formulation, manufacturing process and drug product specifications. ensures all analytical activities meet good laboratory practices and company s policies. ensures the availability of chemicals, reagents, apparatus, hplc columns, solvents, etc. needed to carry out all task in the analytical development area. performs data collection and analysis, discuss conclusions regarding progress of work, and effectively communicates information to peers and management in the form of presentations and reports. education and experience requirements canadian equivalent to master of science, phd or bachelor of science degree, preferably in pharmacy, chemistry or pharmaceutical chemistry. more than three years of relevant hands on pharmaceutical experience in product development. demonstrates knowledge and experience of analytical chemistry by developing analytical methods such as assay, dissolution and related substances. understanding of doe, risk based assessment tools, quality by design, method validation, equipment troubleshooting and technical transfer. experience with chromeleon software is preferred. demonstrated ability to work independently or as a part of a team, and to coach less experienced colleagues. highly motivated and have the skills to handle multiple projects and prioritize the work. excellent communication skills and interpersonal skills are required application deadline 2021 06 30 expected start date 2021 07 19 job types full time, permanent salary 54,000.00 66,000.00 per year benefits casual dress dental care disability insurance employee assistance program extended health care flexible schedule life insurance on site parking vision care schedule 8 hour shift day shift monday to friday no weekends covid 19 considerations we are following all covid19 guidelines from peel public health education bachelor s degree experience canadian pharmaceutical industry 5 years language english work remotely no","['software', 'chemistry', 'interpreting data', 'data collection', 'troubleshooting', 'specifications', 'less', 'analytical', 'design principles', 'hplc']","['less', 'r']","['doe', 'analytical', 'software', 'chemistry', 'interpreting data', 'data collection', 'troubleshooting', 'specifications', 'method', 'design principles', 'planning']","['reagents', 'public health', 'fashion', 'forms', 'fda', 'education', 'assessment', 'validationc', 'validation', 'sop', 'presentations', 'design', 'product development', 'insurance', 'ich', 'emea', 'manufacturing', 'hplc', 'r']"
250,320,Data Engineer,"requisition id 105205 join a purpose driven winning team, committed to results, in an inclusive and high performing culture. the team the risk technology group plays a critical role in enabling global enterprise technology to deliver against its mission to bring innovation and value to the bank with confidence and reliability, by acting as a key player in regulatory risk management across the division. the role as a data analyst, risk technology, you will play an active role in regulatory risk projects by collaboratively assessing, analyzing and implementing large scale data applications. you will leverage and gain a thorough understanding of enterprise data platforms housing credit and insurance portfolios, contribute to design controls, data mappings and assisting in their implementation. part of a strategic and comprehensive risk technology function, you will ensure control implementation in accordance with regulatory expectations, risk appetite, organizational risk practices and evolving business practices. some of the key accountabilities include champions a customer focused culture to deepen client relationships and leverage broader bank relationships, systems and knowledge. conducting data discovery, data requirements and gap analysis. capturing and documenting of source to target mapping in support of procurement and development efforts. participate in the solution, design, plan, coordination and management of various data asset initiatives with varying scope and complexity. provide support to development and operations team to resolve production issues perform assessment, root cause analysis, and formulating proposed solutions or remediation strategies. performs quality assurance activities to ensure handling, storage, and collection of data complies with bank policy and regulatory requirements. lead and take ownership on multiple simultaneous data integration projects. managing relationships with upstream and downstream data or technology partners. assessing various dataflow architecture and developing strategies to optimize data availability, quality and performance. work with upstream source providers and downstream consumers for change request and release management. be curious, constantly learning about new trends in it enterprise technologies especially in the area of ci or cd and devops and share the knowledge with end users and team members. work effectively in a remote team environment maintaining collaboration with other team members, internal customers and other scotiabank teams acquiring knowledge from peers and continuous self learning. coaching other team or department members on the areas of expertise actively participate in team s huddles what you will bring to succeed bsa and data analysis. 5 years of experience experience with sql server, hive or hadoop, db2, and complex sql queries. 5 years of hands on experience experience with etl tools such as ssis, python, informatica, sas and datastage with ability to understand, investigate and reverse engineer code. experience with documenting data mappings from source to target. 3 years of hands on experience data analytics and visualisation excellent communication and presentation skills written verbal sdlc, change management, ci or cd, devops and agile project methodology. assets to have experience with cloud environments azure. experience with coding and data formats logical and physical data modelling experience with credit risk and insurance data. the workplace we are technology partners who help the business transform how our employees around the world work we have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success you ll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world we foster an environment of innovation and continuous learning we care about our people, allowing them to design how they work to deliver amazing results we offer a competitive total rewards package, including a performance bonus, company matching programs , and generous vacation scotiabank as canada s international bank, we are a diverse and global team. we speak more than 100 languages with backgrounds from more than 120 countries. we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted. is this role not the exact fit sign up to stay in touch we ll let you know when we have new positions on the team. location canada ontario toronto scotiabank is a leading bank in the americas. guided by our purpose for every future , we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['quality assurance', 'ci', 'remediation', 'hive', 'sql', 'python', 'data analytics', 'cd', 'data', 'integration', 'sas', 'informatica', 'gap analysis', 'data analysis', 'visual', 'enterprise data', 'banking', 'sdlc', 'devops', 'hadoop', 'root cause analysis', 'ssis', 'etl']","['sql', 'python', 'quality assurance', 'hadoop', 'sas', 'hive', 'ssis']","['ci', 'dataflow', 'enterprise technology', 'remediation', 'release management', 'data applications', 'data mapping', 'data analytics', 'cd', 'data', 'integration', 'informatica', 'gap analysis', 'data analysis', 'enterprise data', 'banking', 'sdlc', 'devops', 'root cause analysis', 'methodology', 'etl']","['procurement', 'internal customers', 'environment', 'change management', 'regulatory requirements', 'private', 'design', 'acting', 'design controls', 'architecture', 'investment banking', 'capital markets', 'risk management risk', 'assessment', 'regulatory', 'insurance']"
251,321,Python/Django Data Portal Developer,"position title python or django data portal developer classification casual six month contract, with opportunities for extension division temerty faculty of medicine department temerty centre for ai research and education in medicine about us t cairem at the university of toronto is an interdepartmental centre that serves a s a focal point for collaboration between computer scientists, healthcare providers, trainees, medical basic science researchers and industry to advance health through machine learning. the mission of the centre is to advance research, education, knowledge dissemination and digital infrastructure in the field of ai in medicine. your opportunity python data portal developer will support the development of a django based data sharing platform to support clinical research. platform features that will need development include interfacing with cloud computing services, managing encryption keys to securely store data objects, authentication with external identity providers, and designing models for user workflows. essential qualifications education certification bachelor s degree in science or engineering. experience extensive experience in development using the python web framework django. experience in programming and systems development and design. experience trouble shooting and resolving technical issues. strong proficiency in python or sql. comfort in collaborative development using source code control . experience with amazon aws preferred. responsibilities duties supporting the planning and development of the data sharing platform. programming new and existing data systems. trouble shooting and testing highly complex systems. developing unit tests. collaborating within a small team. writing complex code. expected start date 2021 07 05 job types full time, casual salary 70,914.00 133,027.00 per year schedule 8 hour shift work remotely yes","['sql', 'python', 'machine learning', 'dissemination', 'amazon', 'complex systems', 'testing', 'authentication', 'web framework', 'data', 'encryption', 'programming', 'aws', 'data systems', 'django', 'cloud computing', 'medicine', 'ai']","['sql', 'python', 'programming', 'aws', 'django']","['dissemination', 'machine learning', 'tests', 'complex systems', 'testing', 'authentication', 'web', 'data', 'encryption', 'planning', 'data systems', 'cloud computing', 'medicine', 'ai']","['clinical research', 'design', 'education', 'healthcare']"
252,323,Applied Scientist - Machine Learning,"applied scientist machine learning the intelligent conversation and communications cloud ai group applies machine learning to problems in advanced teleconferencing scenarios that are used by hundreds of millions of customers worldwide . we develop technologies and do applied research and development that enables state of the art customer experiences for real time collaboration. we are seeking a highly capable applied scientist or engineer who is passionate about data, machine learning applications and driven to make an impact for millions of customers. ic3 m365core responsibilities develop and deploy machine learning solutions that improve skype or teams real time collaboration quality and reliability design, develop, and own components, tools, platforms, and systems for real time media communication and collaboration. understand and leverage core concepts of video or audio processing and real time communication drive independent investigations resulting in shipping product code, patents, and publications. qualifications required qualifications minimum of 2 years of experience developing and shipping machine learnt software solutions. ph.d. in computer science, mathematics, physics, electrical engineering, or masters plus equivalent work experience. preferred qualifications deep knowledge of machine learning principals to solve complex problems. strong system software development skills, with a long range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems ability to meet microsoft, customer and or or government security screening requirements are required for this role. these requirements include, but are not limited to, the following specialized security screenings microsoft cloud background check this position will be required to pass the microsoft cloud background check upon hire or transfer and every two years thereafter. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['audio processing', 'machine learning', 'electrical engineering', 'complex systems', 'physics', 'security', 'software development', 'computer science', 'screening', 'mathematics', 'software solutions', 'ai']",[],"['electrical engineering', 'machine learning', 'complex systems', 'physics', 'security', 'software development', 'computer science', 'screening', 'mathematics', 'software solutions', 'ai']","['design', 'art', 'recruiting', 'government', 'regulations']"
253,325,Senior Applied Data Scientist,"what is yammer microsoft yammer is the industry defining social network for the enterprise. millions of employees, including 85 of fortune 500 companies use yammer every day, to build community and culture, share knowledge, and connect with their leaders and each other. why yammer yammer was one of the first startup unicorns this past decade and was acquired by microsoft in 2012. today, this means we get the benefits of a startup rapid innovation, cutting edge technology, outsized individual impact with the advantages of working for one of the most successful software companies in the world. we work together in small, cross functional teams engineers, product managers, designers, data scientists to design, deliver and operate delightful end user experiences to our tens of millions of users spread across the world. we ve always been mission driven in this post covid world, yammer has become even more indispensable than ever as employees have a deep need for connection and a sense of belonging. we ve been growing rapidly and need your help to take yammer to the next level. you will have autonomy and freedom to innovate choice of the best of open source and microsoft internal technology the ability to experiment, a or b test, and make data driven decisions tons of opportunity for outsized impact as part of a small but mighty team on a rapidly growing product needed now more than ever at the same time, you also have the benefits of working at a top tier tech company like microsoft compensation, benefits, and perks internal resources, technology, and opportunities for learning and growth brand and networking opportunity for massive scale as part of a suite with hundreds of millions of users about this job as a senior applied data scientist, you will be building predictive models that help connect individuals with each other and knowledge across organizations. we focus on discovery, recommendations, and relevance across yammer by building machine learning models that leverage both yammer data and data from across office 365. what makes this role special opportunity to create a vision around the yammer machine learning platform and roadmap and help us make it a reality. opportunity for massive scaleas yammer has tens of millions of users today and is expanding rapidly to reach all of office 365 tight knit, high performing team means tons of ability to have impact. social enterprise unique and interesting analytics problems responsibilities build and iterate on machine learning models to be used to power recommendations for the yammer feed. work with large, complex data sets. solve difficult, non routine analysis problems, applying advanced analytical methods as needed conduct end to end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables and presentations. utilize excellent communication skills to clearly distill the essence of your technical work to audiences of all levels and across multiple functional areas. develop deep product intuition that you leverage to influence future product roadmaps and drive decision making. work with product and engineering to craft experiments and test hypotheses. navigate complex situations and influence across multiple product areas by leveraging leadership acumen. qualifications required qualifications bachelors, masters or advanced degree in computer science or related field 5 years of industry experience applying machine learning techniques 2 years of experience coding in python, c , c , c or java preferred qualifications masters or phd with 5 years work experience doing quantitative analysis. work experience in the social networking space. applied experience with machine learning on large datasets. built recommender systems used in production at scale. customer focused, strategic, drives for results, is self motivated, and has a propensity foraction. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['python', 'machine learning', 'software', 'datasets', 'applied data', 'c', 'networking', 'analytics', 'computer science', 'java']","['c', 'python', 'java']","['machine learning', 'data gathering', 'recommender', 'quantitative analysis', 'software', 'datasets', 'networking', 'analytics', 'computer science', 'feed']","['office 365', 'compensation', 'presentations', 'design', 'legal', 'recruiting', 'regulations']"
254,327,Data Engineer,"data engineer halifax, ns, canada montreal, qc, canada ottawa, on, canada toronto, on, canada winnipeg, mb, canada req 20 wednesday, april 14, 2021 the company audienceview is an organization of people who are passionate about the business of live events. we create industry leading software solutions that fuel attendee engagement, ticket sales, and advertising solutions for close to 8,000 higher education, music, and theatre venues in 15 countries around the world. audienceview employees share a vision to help entertainment organizations deliver exceptional experiences for people who love live events. we achieve this through innovative technology, popular media brands, effective distribution strategies and a dedicated team of experts that help propel our clients success every single day. the position we are looking for a senior data engineer who will support a small team of developers to deliver a data warehouse solution working within the agile scrum framework. as a successful candidate, you will bring extensive expertise in the design, framework methodology of data warehousing, and possess experience in the full stack life cycle from etl to the visualization. additionally, you must possess a unique blend of business and industry savvy a big picture vision, and the drive to make that vision a reality. you must enjoy spending time in all business areas to understand their problems, and find innovative solutions for the organization. responsibilities design implement a data warehouse solution using best practices and reusable design patterns and processes. create and implement full stack framework and methodology understand and manage the implementation of any tools required to bring value to the process of product and feature creation work with a cross section of teams including architects engineering to define and fill knowledge gaps, to ensure the best possible solution for a solution that satisfies the business. work with the business to identify feature gaps support the director, business data where necessary qualifications 5 years experience as a senior data engineer with azure data components eg spark or databricks, delta lake, data factory, python and sql. designing implementing data pipelines, etl or elt processes writing unit integrations tests good knowledge of sql and transact sql ability to effectively collaborate with diverse groups of people ability to thrive in a fast paced rapid development environment excellent written and verbal communication skills excellent public speaking skills experience in the ticketing or live event industry advantageous results driven and focused, proving the success of any initiative you take part in. why audienceview audienceview is the leading provider of e commerce solutions to some of the world s biggest ticket resellers and venues who are shaping the future of ticket sales and event promotions. specialized in end to end e commerce ticketing and event crm across multiple markets. company repositioning for rapid paced growth ensuring great career opportunities for motivated professionals. located in the heart of downtown toronto a respected hub of the toronto tech community. competitive salary with performance review and personal growth. excellent benefits. flexible hours and work remote opportunities. employee social lounge and dynamic social events team. partner with customers who are leaders in online ticketing sales around the world. exciting customer markets in sports, performing and more diversity and inclusion have always been at the core of our values at audienceview. a diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. we welcome applications from qualified individuals from all backgrounds. persons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e mail a request to other details pay type salary","['sql', 'python', 'visualization', 'design patterns', 'data pipelines', 'scrum', 'crm', 'software solutions', 'data warehousing', 'etl']","['azure data', 'sql', 'python']","['crm', 'visualization', 'design patterns', 'data pipelines', 'tests', 'performance review', 'scrum', 'methodology', 'software solutions', 'data warehousing', 'etl']","['environment', 'commerce', 'events', 'advertising', 'e commerce', 'job postings', 'design', 'sales', 'theatre', 'higher education', 'live']"
255,328,Data Engineer,"appnovation helps brands thrive through innovative, people inspired experiences and solutions. by embracing the powerful combination of technology and agility, we seamlessly integrate strategy, experience, design, development and analytics. we create standout digital experiences by collaborating with brands to understand the individual challenges and goals for every initiative. focusing on our clients customers, we effectively combine empathy, evidence and real world insight so that solutions are derived from truth and meaning. appnovation is an award winning team dedicated to inspiring possibility. you will have an opportunity to design, develop, and maintain cloud based data solutions and file based data repositories to support analysis, visualization, and decision making for the owners of digital assets and it operations. create and maintain essential metadata establish master data management practices for core data shared across projects provide hands on leadership and oversight for internal data quality, insights, and predictive services within the service development and innovation team at appnovation support return on investment measurement for investments in our operations, frameworks, processes, and infrastructure, and for investments in optimizing our clients digital assets with closed loop data driven testing of our initiatives success lead cross functional working sessions to understand stakeholder data and insight challenges operational analytics to support lean six sigma principles including dashboard and framework management, process evolution, tool integration and tool configuration build manage and refine control thresholds and develop predictive models design and publish interactive control centres, dashboards, and reports leveraging data visualization techniques and real time alerts partner with internal and client teams to cleanse, analyze and find insights in data and influence ways of working to improve data hygiene conceive, plan, and prioritize data projects across a variety of business verticals and levels of complexity research and evaluate leading and visionary new models, tools and techniques, perform experiments and develop the business case for bringing them to appnovation who you are regularly create dashboards, queues, and data visualizations in looker, data studio, and tableau. happy to work alone or with other data analysts and stakeholders to solve problems excellent attention to detail with the ability to take in the bigger picture familiarity with digital web presence analytics and agile software development practices and metrics. comfortable with working in a global company with stakeholders in different timezones proficient with relational database management, vba, javascript, sql, etl, rest apis, big data, data integration, data warehousing, data governance, data lakes, and batch and streaming data pipelines proficient in performing statistical analysis and machine learning using tools like einstein, databricks, rapidminer, datarobot, h2o.ai or similar tools familiarity with redshift and salesforce preferred strong collaborative and communication skills degree in a related field and 5 years experience working in a data analytics environment thank you for your interest in a career with appnovation technologies please note that only those selected for an interview will be contacted. appnovation is an equal opportunity employer and committed to diversity and inclusion. we encourage applications from all qualified candidates and accommodations are available upon request throughout the recruitment process.","['visualization', 'tableau', 'vba', 'big', 'dashboards', 'data visualization', 'javascript', 'statistical analysis', 'sql', 'looker', 'data analytics', 'six sigma', 'software development', 'analytics', 'data', 'integration', 'data warehousing', 'core data', 'machine learning', 'data pipelines', 'testing', 'metadata', 'agile', 'data quality', 'master data management', 'rest', 'dashboard', 'digital assets', 'data solutions', 'it operations', 'etl']","['dashboard', 'sql', 'looker', 'repositories', 'tableau', 'vba', 'digital assets', 'data lakes', 'big data', 'data quality', 'javascript', 'core data']","['visualization', 'dashboards', 'data visualization', 'statistical analysis', 'data analytics', 'six sigma', 'software development', 'analytics', 'data', 'integration', 'data warehousing', 'machine learning', 'data pipelines', 'testing', 'metadata', 'agile', 'master data management', 'rest', 'data solutions', 'it operations', 'etl', 'ai']","['hygiene', 'environment', 'service', 'metrics', 'design', 'evidence', 'governance', 'investments', 'return on investment']"
256,329,Data Engineer,"uncage your ambition as a data engineer we are flighthub group , an ambitious team of people that created flighthub and justfly . our brands have grown to become two of the top ranked travel agencies in north america. we now serve over 3 million customers per year, totaling 3 billion dollars in sales, and, whereas the pandemic may have slowed us down a little, we are coming back even stronger. we dream big, pursue passionately, and follow through with resolute self belief and rigorous commitment. we are a group of individuals sharing a common vision and values, having come together to pursue a collective mission overtaking the 1 spot in the world. we are looking for a data engineer with 3 years of experience to join our team. working alongside henri, cro, in our revenue team, you will be responsible for contributing to our data engineering roadmap in an effort to support our company s growing data needs and volume. play a key role in building solutions to help various teams access data via 3rd party analytics platforms , while managing and structuring data that will encourage collaboration. monitor overall performance and stability of systems, while simultaneously supporting our marketing automation tools and running ad hoc queries and reports as needed. many career paths can prepare you for this life changing opportunity, but preferably, you re highly skilled in working with cloud platforms such as kubernetes kafka, and databases such as mysql, clickhouse building analytics tools that utilize the data pipeline to provide actionable insights identifying ways to improve data reliability, efficiency and quality auditing data to validate accuracy working with stakeholders including the executive, product, data and design teams to assist with data acquisition, data related technical issues and other analytics needs working in a fast paced and technological environment, with strong communication skills. please note this position is in montreal, quebec. show us your drive and join our team check us out https or or flighthubgroup.com or takeoff li cv1","['https', 'kubernetes', 'databases', 'auditing', 'data acquisition', 'analytics', 'data engineering', 'mysql', 'automation']","['https', 'kubernetes', 'databases', 'mysql']","['auditing', 'data acquisition', 'quality', 'analytics', 'data engineering', 'automation']","['environment', 'marketing', 'design', 'sales', 'cro']"
257,330,Sr. Data & Applied Scientist,"do you want to be on the leading edge of using big data and help drive development decisions for the biggest productivity software on the planet office experience organization has embarked on a mission to delight our customers by using data informed engineering to develop compelling products and services. oxo is looking for an experienced data scientist with a passion for maximizing the return on investment from collecting petabytes of telemetry data to infer deep user and product insights. the data scientist would leverage statistical modeling, experimentation, forecasting and data visualization techniques to identify core drivers of user engagement in productivity applications. the role involves working with application teams , other data scientists, data engineers and program managers to continuously improve understanding usage, retention and user satisfaction. we are looking for a strong data scientist with a proven track record of solving large, complex data analysis and machine learning problems in a real world product development setting. ideal candidates should be able to identify a business or engineering problem and translate it to a data science problem, dig out sources of data, conduct the analysis that would reveal useful nuggets and help engineering teams to operationalize the solution. responsibilities core skills identifies data sources, integrates multiple sources, or types of data, and applies expertise within a data source to develop methods to compensate for limitations and extend the applicability of the data. applies tools and pipelines to efficiently collect, clean, and prepare massive volumes of data for analysis. transforms formulated problems into implementation plans for experiments by applying the appropriate methods, algorithms, and tools, and statistically validating the results against biases and errors. interprets results and develops insights into formulated problems within the business or customer context and provides guidance on risks and limitations. acquires and uses broad knowledge of innovative methods, algorithms, and tools from within microsoft and from the scientific literature and applies his or her own analysis of scalability and applicability to the formulated problem. validates, monitors, and drives continuous improvement to methods, and proposes enhancements to data sources that improve usability and results. qualifications requirements expert in one or more statistical software like r, sas, etc. expert in one or more scripting languages like perl, python, scala, or sql solid foundation of statistical modeling and machine learning algorithms and experimental design deep understanding of big data systems including map reduce technologies like hadoop and spark. b.s. and or or m.s. in computer science, statistics, operations research, or similar quantitative field. 5 years plus of applying statistical modeling, ml, and data mining algorithms to real world problems. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we also consider qualified applicants regardless of criminal histories, consistent with legal requirements. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['data visualization', 'big data', 'usability', 'map', 'sql', 'python', 'statistics', 'software', 'scala', 'scripting', 'data science', 'perl', 'data systems', 'pipelines', 'sas', 'data mining', 'machine learning', 'telemetry', 'statistical', 'data analysis', 'algorithms', 'forecasting', 'experimental', 'hadoop', 'scalability', 'computer science', 'modeling', 'r']","['sql', 'python', 'scala', 'big', 'hadoop', 'perl', 'big data', 'pipelines', 'sas', 'map', 'r']","['data mining', 'machine learning', 'telemetry', 'experimental', 'statistics', 'usability', 'software', 'data systems', 'scripting', 'data visualization', 'data science', 'scalability', 'data analysis', 'statistical', 'computer science', 'modeling', 'algorithms', 'forecasting']","['continuous improvement', 'user engagement', 'design', 'operations', 'legal', 'recruiting', 'product development', 'regulations', 'return on investment']"
258,332,Data Engineer,"celtx is an ambitious and fast growing software development company that offers an industry leading, one of a kind product. our cloud based celtx studios brings together creative teams and facilitates full spectrum collaboration on film, video and game production. our data team is responsible for all of the reporting, analytics and data driven insights within our quickly growing company. we ve got a lot of data, and we re looking for someone to help us get the most out of it. as a data engineer, you will work with our data analysts, data scientists and development team to build and maintain a world class data infrastructure. your work here will directly help our business grow, help our customers succeed, and continuously improve the way we operate. what you ll do in this role work extensively with google cloud platform and amazon web services where our data and product infrastructure is hosted. approve pull requests of other team members and help inform best practices on data structures that optimize for performance and cost work closely with our development team to ensure that new and existing features are enabled for tracking and monitoring, by directly contributing to aspects of the code base and technical integrations key skills and experience 5 years experience working as a data engineer or architect prior experience architecting solutions on any of the major cloud data platforms google cloud platform, aws or azure strong sql skills fluent in python, node.js, or other scripting languages a good understanding of query optimization and data lake performance nice to have previous experience working in a high growth saas business experience using a dashboarding tool such as looker, data studio, tableau, etc. work remotely we are open to candidates who can work physically from our st. john s office or who are willing to work remotely in the eastern or atlantic time zones. this is a new, permanent, full time position to join our dedicated and energetic team. we offer generous health and dental benefits, extended maternity and parental leave, competitive pay and flexible vacation time. our main offices are based in st. john s, newfoundland and labrador, however consideration will be given to remote applicants within the eastern or atlantic time zones. we foster an open, innovative, and forward thinking atmosphere. at celtx, everyone is given a seat at the table and an opportunity to have their voices heard. we all share a common mission to cultivate a workshop of ideas that will help keep celtx ahead of the curve. it s engaging, dynamic, and fun. we offer competitive compensation and generous perks.","['sql', 'amazon web services', 'python', 'looker', 'tableau', 'data structures', 'reporting', 'scripting', 'data infrastructure', 'google cloud platform', 'software development', 'analytics', 'saas', 'aws', 'optimization']","['sql', 'python', 'amazon web services', 'looker', 'tableau', 'google cloud platform', 'aws']","['data structures', 'reporting', 'scripting', 'data infrastructure', 'software development', 'analytics', 'saas', 'optimization']",['compensation']
259,333,Data Engineer,"streetlight data, the pioneer in big data for mobility, is revolutionizing transportation and urban planning to help the world better deploy infrastructure and adapt to new forms of mobility. from legacy systems to ride sharing and bike sharing to autonomous vehicles, our platform powers 6,000 mobility projects every month for government and private clients, and we re just getting started. streetlight data is seeking a strong data engineer to be part of our growing engineering team. this team member will work on processing data at scale, and productizing new analytics into the streetlight insight platform. this position reports to the manager of data science. key responsibilities design and implement components within the streetlight insight data processing pipeline tune the streetlight insight processing pipeline for performance and scalability, and automate it to allow for hands off operations develop new analytics algorithms, using a deep understanding of the raw data implement customized analytics for clients in collaboration with sales work with product management and application teams to productize data analytics algorithms into the streetlight insight web application contribute to data science projects as appropriate. skills qualifications bs or ms in computer science, mathematics, or an engineering discipline from a top university 5 years experience as a software or data engineer at an enterprise software or analytics company 5 years experience with relational databases and sql, including strong understanding of concepts strong understanding of algorithms, and 3 years experience in java and or or python good communication skills both written and verbal knowledge of geospatial data is a plus knowledge of statistics and or or science is a plus quick learner, and a strong team player streetlight data is an equal opportunity or affirmative action employer. streetlight data provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.","['geospatial data', 'big data', 'java', 'data analytics', 'sql', 'python', 'statistics', 'data processing', 'software', 'data science', 'enterprise', 'analytics', 'product management', 'relational databases', 'legacy systems', 'algorithms', 'scalability', 'computer science', 'mathematics']","['sql', 'python', 'legacy systems', 'big data', 'java']","['geospatial data', 'data analytics', 'statistics', 'data processing', 'relational databases', 'software', 'data science', 'scalability', 'enterprise', 'computer science', 'analytics', 'product management', 'mathematics', 'algorithms']","['private', 'genetics', 'forms', 'urban planning', 'design', 'sales', 'government']"
260,335,"Data and Analytics, Student","job title data and analytics location toronto, oakville and or or calgary term fall 2021 canadian tire corporation is adhering to government regulations for covid 19 as we are taking all actions and protocols to ensure our employees are safe. as this pandemic is unpredictable, we have listed the office location of this current opportunity but will continue to follow safety protocols and will provide further information closer to the fall 2021 term. help us boldly shape retail in canada canadian tire corporation s rich heritage of serving canadians from coast to coast dates back to 1922. our vision is to become the 1 retail brand in canada by 2022 and we are focused on innovating and making important investments in our business, especially when it comes to our people. to reach our goal, we need the best talent to help us evolve and drive change across the business and boldly help shape canada s retail industry. as we strive to be at the forefront of a complex and vastly changing retail industry, it is an exciting time to join the canadian tire family of companies. our data analytics team is embedded into all areas of our business including it, marketing, loyalty, supply chain, and human resources and is comprised of a diverse and dynamic team of analysts, data scientists, developers, and consumer researchers who deliver customer focused analytical solutions and insights that enable lasting and meaningful customer and employee relationships. using the latest data technologies and advanced analytical techniques, they demystify shopper behaviour and embed those insights deep within the fabric of the business. what you ll do as a data analytics student you ll gain valuable insight into how predictive analytics, modelling and insights are used to us make more informed business decisions across our entire enterprise. whether you re assisting with data preparation, reconciliation and analysis, developing reports, or making data supported recommendations that drive business change you ll play a part in helping us deliver better, faster, and in more meaningful and impactful ways to our customers and employees. roles we are currently recruiting for retail insights, student this team is focused on using data driven approaches to increase space productivity across the retail network. we are a team that is constantly evolving to better suit our associate dealers needs. what you ll do work with senior analysts to conduct comprehensive store level analysis to generate actionable insights and recommendations. create presentations and supporting documents to summarize analysis for key business stakeholders and decision makers. enhance team understanding of retail execution by analyzing and summarizing store level data. assist in the development of new reports or tools that capitalize on better understanding retail execution across the retail network. data insights, student the co op role will support our objective of driving linear productivity through collaborating with product owners on the design, testing and implementation of productivity reporting tools including our productivity dashboard, pulse objective reporting and smartpack pog packing model. what you ll do collaborate with senior consultants on the development and testing of priority projects contribute to the identification of potential opportunities within our current process pull and analyze data as required who you are exceptional communication skills with the confidence and passion to share knowledge creative thinker who is observant to seek new opportunities and perceptive to abstract ideas goal driven individual to seek out continuous improvement opportunities the ability to take a collaborate approach to build strong relationships and have positive team experiences flexible and dynamic individual who is able to adjust and prioritize accordingly to adapt to business demands and requirements solid foundation of relevant technical skills demonstrates behaviours of transparency, accountability, agility and learning from others that will support your success what you bring undergraduate degree in cs, math, statistics, information technology or engineering experience querying large databases using python, sql, knime and or or spark experience building machine learning and mathematical models competency in data analysis and interpretation of results detail oriented with a problem solving mind set and impeccable attention to detail ability to prioritize tasks with some guidance working knowledge of standard desktop tools experience with other analytical platforms and tools considered an asset some experience in a retail or loyalty analytics role is desirable about canadian tire corporation canadian tire and its family of companies are boldly shaping retail in canada and we continue to deliver a positive experience for our customers. as one of the most trusted brands in canada, our employees take pride in the work we do across the country. it s more than the iconic triangle that keeps our employees around. from benefits and perks, to learning and development opportunities, to our commitment to jumpstart these are some of the many reasons why canadian tire corporation is one of canada s top employers. to learn more about this team and the canadian tire family of companies follow us on linkedin. canadian tire is an equal opportunity employer. we are committed to a diverse and inclusive workplace for all. we recognize that our future success depends on the perspectives and contributions of all our employees their diverse backgrounds, abilities and experiences make our business stronger. if you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. all accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. store support operations ontario toronto temporary work full time job posting may 12, 2021, 11 33 40 am","['dashboard', 'data analytics', 'forefront', 'data preparation', 'analytical techniques', 'statistics', 'databases', 'python', 'sql', 'machine learning', 'testing', 'reporting', 'data analysis', 'analytics', 'smartpack', 'information technology', 'knime']","['dashboard', 'sql', 'forefront', 'databases', 'python', 'smartpack', 'predictive', 'knime']","['data analytics', 'analytical techniques', 'data preparation', 'statistics', 'machine learning', 'testing', 'reporting', 'data analysis', 'analytics', 'information technology']","['continuous improvement', 'retail', 'marketing', 'human resources', 'presentations', 'design', 'recruiting', 'government', 'investments', 'regulations', 'linkedin']"
261,338,Data Engineer,"position description cgi helps clients take an enterprise approach to accelerate and maximize their return on technology investments through relevant applied innovation. we are looking for an exceptional data engineer to join our team. your future duties and responsibilities undergraduate or master s degree in math, engineering, or computer science 4 years work experience in a data analytics or data engineering role designing or architecting or maintaining data pipelines for etl or elt passionate about producing clean, maintainable and testable code experience with developing pipelines that ingest and transform 10 6 events per minute and terabytes of data per day. experience developing pipelines with unstructured data experience working with cloud technologies required qualifications to be successful in this role experience in structured problem solving ability to communicate complex ideas effectively both verbally and in writing in english. exceptional research and information gathering skills equipped with the ability to distill knowledge. active listening skills, exposure to client facing environments an asset. ability to work effectively with people at all levels in an organization. proven record of leadership in a work setting and or or through extracurricular activities. ability to work collaboratively in a team environment. highly motivated, highly ambitious, and able to work with little direction. independent, self starter, experience writing and delivering reports. skills engineering what you can expect from us build your career with us. it is an extraordinary time to be in business. as digital transformation continues to accelerate, cgi is at the center of this change supporting our clients digital journeys and offering our professionals exciting career opportunities. at cgi, our success comes from the talent and commitment of our professionals. as one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. all of our professionals benefit from the value we collectively create. be part of building one of the largest independent technology and business services firms in the world. learn more about cgi at no unsolicited agency referrals please. cgi is an equal opportunity employer. in addition, cgi is committed to providing accommodations for people with disabilities in accordance with provincial legislation. please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.","['unstructured data', 'data analytics', 'data pipelines', 'digital transformation', 'computer science', 'digital', 'pipelines', 'data engineering', 'cgi', 'information gathering', 'etl']","['pipelines', 'cgi']","['unstructured data', 'data analytics', 'data pipelines', 'computer science', 'data engineering', 'digital transformation', 'information gathering', 'etl']","['environment', 'events', 'return on', 'referrals', 'investments', 'legislation']"
262,339,Scientifique des données / Data Scientist,"role and responsibilities lorsque vous prenez l avion, peu importe la destination, il y a de fortes chances que le pilote ait t form par cae. nous sommes le partenaire de choix en formation partout dans le monde. le point focal tant les clients, l quipe acc l rateur num rique s engage rehausser l exp rience de formation afin de s assurer que les pilotes soient les meilleurs possible. joignez vous au moteur de changement cae notre prochain horizon de croissance passe avant tout par l innovation num rique afin d appuyer la r ussite de nos clients. voici quelques raisons pour lesquelles les membres de notre personnel aiment travailler au sein de notre entreprise travail significatif qui favorise le perfectionnement professionnel. possibilit d entrer dans l industrie technologique et de s y panouir. environnement de travail ax sur la collaboration. quipe de haut niveau. ce que nous avons offrir r gime d assurance collective souple r gime de retraite prestations d termin es r gime d achat d actions du personnel r gime enregistr d pargne retraite collectif programme pour le bien tre physique programme d aide aux employ s prestations de maternit compl mentaires horaire de travail variable vendredis californie tout au long de l ann e votre mission en tant que membre de l quipe de la science des donn es, vous analyserez et r sumerez l information pour comprendre les enjeux, d terminer les options, et soutenir une prise de d cision clair e. vous produirez des m thodes et des solutions novatrices et viables. vous comprenez comment appliquer des connaissances et des comp tences fonctionnelles et techniques en vue d atteindre des objectifs de travail dans un environnement agile. en tant que candidat id al, vous tes adepte de l utilisation de grands ensembles de donn es pour chercher optimiser les produits et les processus, et de l utilisation de mod les pour valuer l efficacit de diff rents plans d action. nous sommes la recherche d une personne capable de r aliser les t ches suivantes extraire et analyser les donn es se trouvant dans les bases de donn es de l entreprise afin d optimiser et d am liorer le d veloppement des produits, les techniques de marketing et les strat gies commerciales. valuer l efficacit et l exactitude des nouvelles sources de donn es et techniques de collecte de donn es. laborer des algorithmes et des mod les de donn es personnalis es appliquer aux ensembles de donn es. utiliser une mod lisation pr dictive pour accro tre et optimiser l exp rience des clients, les revenus g n r s, le ciblage publicitaire et d autres r sultats op rationnels. laborer un cadre de tests a or b pour l entreprise et mettre l essai la qualit du mod le. coordonner diff rentes quipes fonctionnelles pour mettre en uvre des mod les et surveiller les r sultats. laborer des processus et des outils pour le contr le et l analyse du rendement des mod les et de l exactitude des donn es. voici les caract ristiques de notre candidat id al titulaire d une ma trise ou d un doctorat en statistique, informatique, analyse des syst mes de gestion ou autre domaine connexe. au moins 5 ans d exp rience en science des donn es ou en statistiques appliqu es. bilinguisme requis solides aptitudes pour la r solution de probl mes, et surtout le d veloppement de produits. exp rience dans l utilisation de langages informatiques statistiques pour manipuler les donn es et extraire des renseignements de grands ensembles de donn es. exp rience dans la manipulation d ensembles de donn es et l laboration de mod les statistiques. connaissance de diverses techniques d apprentissage automatique et de leurs avantages et inconv nients dans le monde r el. connaissance de techniques et de concepts statistiques sophistiqu s , exp rience dans leur application. exp rience dans l utilisation et la cr ation d architectures de donn es. exp rience dans l utilisation de services web redshift, s3, azure, spark, digitalocean, etc. exp rience dans l analyse de donn es provenant de fournisseurs tiers microsoft application insights, google analytics, site catalyst, coremetrics, adwords, crimson hexagon, facebook insights, etc. exp rience dans la visualisation et la pr sentation de donn es pour des intervenants, l aide de periscope, microsoft power bi, business objects, d3, ggplot, etc. penchant naturel pour l apprentissage et la ma trise des nouvelles technologies et techniques. exp rience de direction d initiatives ax es sur le client. exp rience de travail dans un environnement agile, un atout. excellentes aptitudes pour la communication verbale et crite en vue de la coordination des quipes. rejoignez une organisation qui fait la diff rence chaque jour if you ve taken a plane to any destination in the world, chances are, your pilot was trained by cae. our company is the worldwide training partner of choice, and with good reason. with its strong customer focus, the digital accelerator team is dedicated to elevating the training experience to make pilots the best they can be. join the engine that is changing cae, pointing towards the next horizon of growth through digital innovations to support our customers in their success. here are the reasons why folks love working here meaningful work that drives professional development ability to enter and grow within the technology industry working in a collaborative environment being part of a high performance team what we have to offer flexible group insurance plan defined benefits retirement plan employee stock purchase plan group registered retirement savings plan physical wellness plan employee assistance plan supplementary maternity plan flextime california fridays all year your mission as a member of the data science team, you will analyze and synthesize information to understand issues, identify options, and support sound decision making. you will be generating viable, new approaches and solutions. you have an understanding of applying functional and technical knowledge and skills to accomplish work objectives in an agile environment. as the ideal candidate, you are adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. we are looking for people who can mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. assess the effectiveness and accuracy of new data sources and data gathering techniques. develop custom data models and algorithms to apply to data sets. use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. develop company a or b testing framework and test model quality. coordinate with different functional teams to implement models and monitor outcomes. develop processes and tools to monitor and analyze model performance and data accuracy. as our ideal candidate you will also have a master or phd in statistics, computer science, business analytics or a related field possess at least 5 years experience in data science or applied statistics. bilingualism required strong problem solving skills with an emphasis on product development. experience using statistical computer languages to manipulate data and draw insights from large data sets. experience manipulating data sets and building statistical models. knowledge of a variety of machine learning techniques and their real world advantages or drawbacks. knowledge of advanced statistical techniques and concepts and experience with applications. experience working with and creating data architectures. experience using web services redshift, s3, azure, spark, digitalocean, etc. experience analyzing data from 3rd party providers microsoft application insights, google analytics, site catalyst, coremetrics, adwords, crimson hexagon, facebook insights, etc. experience visualizing or presenting data for stakeholders using periscope, microsoft power bi, business objects, d3, ggplot, etc. a drive to learn and master new technologies and techniques. experience leading customer driven initiatives. experience working in an agile environment an asset. excellent written and verbal communication skills for coordinating across teams. join an organization making a difference everyday position type regular cae thanks all applicants for their interest. however, only those whose background and experience match the requirements of the role will be contacted. equal employment opportunity at cae, everyone is welcome to contribute to our success. with no exception. as captured in our overarching value one cae , we re proud to work as one passionate, boundaryless and inclusive team. at cae, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age. the masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.","['databases', 'business', 'agile environment', 'statistics', 'data science', 'analytics', 'data models', 'machine learning', 'agile environmente', 'google analytics', 'testing', 'web services', 'ggplot', 'algorithms', 'microsoft power', 'bi', 'microsoft', 'computer science', 'optimization', 'modeling', 'r']","['microsoft power', 'databases', 'google analytics', 'bi', 'microsoft', 'ggplot', 'd3', 'data models', 'cae', 'r']","['algorithms', 'agile environment', 'machine learning', 'statistics', 'tests', 'testing', 'data science', 'modeling', 'computer science', 'business', 'optimization', 'predictive', 'cae', 'analytics', 'web services', 'data gathering']","['environment', 'marketing', 'accro', 'retirement', 'product development', 'insurance']"
263,340,Software Data Engineer - Analytics Engineering,"summary posted may 21, 2021 role number 200196998 the apple media products engineering team is one of the most exciting examples of apple s long held passion for combining art and technology these are the people who power the app store, apple tv, apple music, apple podcasts, and apple books. and they do it on a massive scale, meeting apple s high expectations with high performance to deliver a huge variety of entertainment in over 35 languages to more than 150 countries.these engineers build secure, end to end solutions. they develop the custom software used to process all the creative work, the tools that providers use to deliver that media, all the server side systems, and the apis for many apple services. thanks to apple s unique integration of hardware, software, and services, engineers here partner to get behind a single unified vision. that vision always includes a deep commitment to strengthening apple s privacy policy, one of apple s core values. although services are a bigger part of apple s business than ever before, these teams remain small, forward thinking, and cross functional, offering greater exposure to the array of opportunities here. key qualifications 5 years experience in high level programming languages such as java, scala. proficiency with databases and sql is required. proficiency in data processing using technologies like spark streaming, spark sql, or map or reduce. expertise in hadoop related technologies such as hdfs, azkaban, oozie, impala, hive, and pig. expertise in developing big data pipelines using technologies like kafka, flume, or storm. experience with large scale data warehousing, mining or analytic systems. ability to work with analysts to gather requirements and translate them into data engineering tasks aptitude to independently learn new technologies. description as a senior member of the data engineering team, you will have significant responsibility and influence in shaping its future direction. this role is inherently cross functional and the ideal candidate will work across disciplines. we are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline.this position involves working on a small team to develop large scale data pipelines and analytical solutions using big data technologies. successful candidates will have strong engineering skills and communication, as well as, a belief that data driven processes lead to phenomenal products. you will need to have a passion for quality and an ability to understand sophisticated systems. education experience bachelor s degree or equivalent work experience in engineering, computer science, business information systems.apple is an equal opportunity employer that is committed to inclusion and diversity. we take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other legally protected characteristics.","['databases', 'big data', 'hive', 'java', 'map', 'sql', 'data processing', 'software', 'scala', 'app', 'integration', 'data engineering', 'data warehousing', 'data pipelines', 'hardware', 'programming languages', 'hadoop', 'information systems', 'computer science']","['sql', 'databases', 'programming languages', 'scala', 'azkaban', 'hadoop', 'big', 'app store', 'big data', 'hardware', 'hive', 'java', 'map']","['data pipelines', 'data processing', 'software', 'information systems', 'computer science', 'integration', 'data engineering', 'data warehousing']","['business', 'server', 'art', 'education']"
264,341,Data Engineer,"14787 bev123 data engineer contract toronto strong knowledge of python, spark, and sql database, storage, collection and aggregation models, techniques and technologies and how to apply them in business experience in structured problem solving ability to use technology to aim business problems using one or more microsoft analytics services for building data pipelines, data streams, and system integration knowledge of azure tools such as azure data factory, azure data lake, azure sql dw or azure sql knowledge of big data tools such as hadoop or azure hdinsight spark, azure cosmos db, azure databricks, azure stream analytics experience preparing data for data science and machine learning about bevertec for 35 plus years bevertec has been at the forefront of providing top level technology professionals to our clients across the greater toronto hamilton area, canada and beyond. bevertec specializes in technology professionals but looks to fill all professional roles that help expand and grow our client s business and advance our candidates careers. remaining at the forefront of providing staffing solutions has been no easy task for us, that why we depend on top caliber candidates like yourself and our team of business development managers to provide you with the opportunities to work with leaders within the it realm to meet your aspirations. as proof of our continued success bevertec places candidates with leaders in the public and private sector and continuous remains a vender of record with large organizations across the country. learn more at how to apply click the apply to job button and follow the instructions to submit your resume or contact nizam hafiz at or 416 695 7525 ext 2227 thank you for your interest in your next great opportunity with bevertec only those selected for an interview will be contacted, bevertec is committed to employment equity and encourages applications from all qualified candidates. in accordance with the accessibility for ontarians with disabilities act bevertec will provide accommodations throughout the recruitment process, should you require such accommodations please contact our human resources department.","['sql', 'python', 'azure', 'machine learning', 'data pipelines', 'forefront', 'hadoop', 'data science', 'system', 'analytics', 'integration', 'big data', 'streams']","['sql', 'python', 'forefront', 'hadoop', 'azure data lake', 'microsoft', 'azure databricks', 'azure data factory', 'big data', 'azure sql']","['machine learning', 'data pipelines', 'data science', 'system', 'analytics', 'data streams', 'integration']","['business development', 'human resources', 'private sector']"
265,343,Data Engineer,"dawn infotek inc. is a professional it consulting team that partners with major financial institutions, investment firms and government sectors. we have been dedicated in delivering cutting edge consulting services and recruiting all levels of it positions for our clients. we are looking for a meticulous and enthusiastic data engineer to join our dynamic team to work at our bank client. type contract or permanent location toronto requirements must have 4 6 years of experience with data engineering skills 4 6 years of hands on experience with sql, shell scripting and python 4 6 years of hands on experience ingesting data using apis 4 6 years of hands on experience with bi tools or big data technologies like hadoop, spark, scala nice to have knowledge of dialogflow es and cx apis, bigquery, google cloud data loss prevention, dataflow for immediate consideration, please apply as soon as possible to this posting by submitting your resume along with your availability date referrals are more than welcome we thank all applicants for your interest and referral. however, only qualified candidates selected for an interview will be contacted. must reside in toronto area. for further information on our company, please visit contract length 4 months job types full time, contract salary 65.00 75.00 per hour benefits work from home schedule monday to friday experience data engineering 4 years sql, shell scripting and python 4 years ingesting data using apis 4 years bi tools or big data technologies 4 years dialogflow es and cx apis, bigquery, dataflow 1 year work remotely temporarily due to covid 19","['sql', 'python', 'shell', 'scala', 'bi', 'hadoop', 'scripting', 'big data', 'data engineering', 'shell scripting']","['sql', 'python', 'scala', 'bi', 'hadoop', 'shell script', 'big data', 'shell scripting']",['data engineering'],"['referrals', 'consulting', 'recruiting', 'government', 'financial institutions']"
266,344,Lead Data Scientist,"epam is committed to providing our global team of more than 41,150 epamers with inspiring careers from day one. epamers think creatively and lead with passion and honesty. our people are the source of our success. we value collaboration, work in partnership with our customers, and strive for the highest standards of excellence. in today s market conditions, we re supporting operations for hundreds of clients around the world remotely. no matter where you are located, you ll join a dedicated, diverse community that will help you discover your fullest potential. description you are curious, persistent, logical and clever a true techie at heart. you enjoy living by the code of your craft and developing elegant solutions for complex problems. if this sounds like you, this could be the perfect opportunity to join epam as a lead data scientist. scroll down to learn more about the position s responsibilities and requirements. we are looking for lead data scientist to join our growing team remotely working in est or cst time zone only. req 230398628 what you ll do convert large volumes of structured and unstructured customer data using. advanced analytical solutions use and fit different mathematical and econometric models, develop descriptive and predictive models that deliver better decisions turn analyzed data into actionable insights and business value create high quality data visualizations communicate effectively with different departments and roles to discuss complex data driven findings and technical matters educate and train others on data science related matters estimate, plan and coordinate the delivery of large projects create data science solution architecture propose data science holistic solutions for customer problems requirements bs degree in an associated field or other advanced certification along with equivalent experience aptitude for problem solving data focused applied mathematics decent communication or presentation skills rdbms or sql knowledge programming experience data analysis tools and libraries such as python , r, sas, spss, matlab, etc big data stack spark or mllib proficiency with at least one of the cloud providers experience with data science solutions productionalization data visualization skills nlp or text mining bachelor s or master s degree in computer science, math, applied statistics or a related field a few years of experience in data mining, statistics or machine learning in depth domain understanding and ability to acquire new what we offer extended healthcare with prescription drugs, dental and vision insurance life and ad d insurance employee assistance program unlimited access to linkedin learning solutions long term disability registered retirement savings plan with company match paid time off critical illness insurance employee discounts","['rdbms', 'data visualization', 'big data', 'sql', 'python', 'statistics', 'data science', 'programming', 'text mining', 'customer data', 'sas', 'data mining', 'machine learning', 'data analysis', 'matlab', 'nlp', 'computer science', 'applied mathematics', 'r']","['mllib', 'sql', 'python', 'rdbms', 'nlp', 'programming', 'big data', 'sas', 'matlab', 'r']","['data mining', 'text mining', 'machine learning', 'statistics', 'applied', 'data visualization', 'data science', 'computer science', 'solution', 'data analysis', 'customer data', 'applied mathematics', 'unstructured']","['large projects', 'healthcare', 'business value', 'retirement', 'architecture', 'linkedin', 'insurance']"
267,345,Data Engineer,"as a data engineer, you d be involved in projects and work with the team to achieve high quality data integrations and responsible for design and development of scalable data solutions. this is your chance to contribute to the ongoing data platform enhancements to support strategic business initiatives. grab the opportunity by applying now. a typical day would involve design and develop data ingestion pipelines, cleanse, and normalize diverse datasets and build structure for previously unstructured data troubleshoot and resolve problems of data services that support business applications systems and provide solutions to pro actively prevent problems from happening. help drive transformation by continuously looking for ways to automate existing processes and optimize for efficiency and data quality you are customer centric you define and measure success through the eyes of your internal customers and anticipate, understand and respond to their evolving needs. demonstrate strong follow through and consistently keep commitments to members and team. results oriented you have a demonstrated ability to engage stakeholders to elicit requirements, analyze findings, generate appropriate solutions, and build deliverables all while securing the team s commitment to these solutions. technology savvy you have education and or or experience supporting technology development or implementation efforts. curious innovative you always do your research and analysis to assess and recommend a course of action based on industry, political and economic trends, you can identify risks and opportunities that may impact the business unit and or designated area. you have bachelor s degree in computer science or a related technical discipline. 3 years of industry experience in data engineering or related field handling data processing and transformation of disparate datasets willingness to work in a highly flexible environment with multiple competing priorities. proven ability to innovate and adapt to the latest development in area of expertise. ability to adapt and grasp new skills and content. bonus points, if you have experience in design and implementation of data integrations in azure data stack such as azure data lake, azure data factory, azure databricks. good understanding of data storage, data mapping and modelling, real time data handling the team in this role, you will report into manager, data engineering posting deadline please apply by 04 00 pm pst, july 5, 2021 about vancity when you join vancity as an employee and a member, you join a movement that believes that when we use money for what s right, we truly are a financial force for change. our vision is to redefine wealth and we are doing so by using the tools of finance to prioritize the wellbeing of our members and our communities by tackling the climate crisis and we are proving every day that sustainable is profitable. we are the largest private sector living wage employer in canada and have been consistently recognized as one of the top employers in canada. come join our team of 2,600 diverse individuals and access competitive rewards benefits, all while knowing you are apart of a greater movement. start your vancity career journey with us even if you re new to financial services we provide in house paid training to gain general financial knowledge, and to learn about our products services. we encourage opportunities to learn develop to prepare you for career success, which in turn continuously impresses how we serve our membership. vancity is committed to a diverse workplace and values integrity, innovation, responsibility and reconciliation. while we review all applicants, we will be prioritizing applicants who self identify as indigenous peoples , members of visible minorities, and persons with disabilities. to learn more about vancity, please visit or aboutvancity.","['unstructured data', 'data processing', 'datasets', 'data services', 'data solutions', 'data quality', 'computer science', 'technology development', 'pipelines', 'data engineering', 'data mapping']","['pipelines', 'azure data', 'azure data lake', 'azure databricks', 'azure data factory', 'data quality']","['unstructured data', 'data processing', 'data ingestion', 'datasets', 'data services', 'data solutions', 'data storage', 'computer science', 'technology development', 'data engineering', 'data mapping']","['internal customers', 'environment', 'education', 'strategic', 'business initiatives', 'design', 'finance', 'financial services', 'business applications', 'private sector']"
268,346,Data Engineer,"hey there just in case you were wondering, this role will be remote and we will revisit the possibility of working back in our hq office come july 2021. a member from our recruitment team can explain this in more detail if selected to move forward to the initial phone screen. we look forward to hearing from you who we are compass digital labs is an organization that drives innovation for compass group na, an 18 billion food hospitality organization. compass group serves over 3 billion meals per year in award winning restaurants, corporate cafes, hospitals, schools, arenas, museums, and more. as the innovation branch of compass group, we re custom built for fast paced transformation at the intersection of hospitality and technology. we re focused on delivering the best experiences possible for our customers and consumers. what we do we are a team of high performing problem solvers with the same vision to drive the digital future in hospitality. as digital experts we are focused on building a diverse set of products and solutions for our consumers. our core products include mobile apps, self serve kiosks, pos and delivery. we also invest in areas like ai, iot and frictionless retail. here we work with the art of the possible ideas, where we explore and develop the future of hospitality and technology. we are looking for a data engineer to join our cross functional teams that is supporting one of our newest data focussed projects. this will be a great opportunity to join a truly passionate team, working on one of our most advanced tech projects in our pipeline what you ll be doing assemble large, complex data sets that meet functional or non functional business requirements build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws technologies create data tools for analytics and data scientist team members that assist them in building and optimizing our products work with stakeholders including the executive, product, data and design teams to assist with data related technical issues and support their data infrastructure needs what you ll bring at least 2 years of experience in a similar role or function skills with python, sql and docker aws familiarity, cloud formation experience is an asset. looking for aws lambda, aws cdk, api gateway, fargate about you strong oral and written communication skills excellent people and management skills to interact with colleagues, cross functional teams and stakeholders a go getter attitude and a passion for your work plmk19yajx","['sql', 'python', 'iot', 'data infrastructure', 'api', 'analytics', 'aws', 'aws lambda', 'ai']","['go', 'sql', 'python', 'iot', 'api', 'getter', 'aws', 'aws lambda']","['analytics', 'data infrastructure', 'ai', 'ki']","['cd', 'retail', 'art', 'design', 'hospitality', 'pos']"
269,348,Digital Data Engineer,"digital data engineer mon17888 description bombardier bombardier is a global leader, creating innovative and game changing planes. our products and services provide world class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. we are a global organization focused on working together with a team spirit. in your role, you will support the end to end process of designing, developing, testing and deploying data integration workflows . support the planning and execution and secure best practice data strategies and approaches. collaborate with stakeholders to develop and improve the current data architecture, data quality, monitoring and data availability schemas. design and building robust data ingest transformation pipelines and solutions needed to acquire, ingest, and process data from multiple sources and systems into modern data platforms. support the restructuration and wrangling data into forms suitable and valuable for a variety of downstream usage including business analytics, machine or deep learning model development, as well as in systems and applications for operational, business and commercial purposes. create and maintaining underlying cloud data infrastructure responsible for managing data flow from ingestion to storage, and to consumption. work cross functionally with our consultants and tech leads to ensure solutions developed aligns comfortably within the organizational preferences on basis of technology and methodology. keep up to date with advancements in data technologies and leveraging the initiatives to improve and scale existing data architectures leading to improved bombardier aviation customers experience. qualifications as our ideal candidate, you possess a bachelor s or master s degree in computer science, engineering, mathematics, or a related technical discipline. you have a minimum of 2 to 6 years of industry experience in data engineering, software development, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets. you have experience with different etl techniques data modeling approaches. you have industry experience using java, scala, python, sql, or similar for data manipulation. you have expertise with data technologies such as s3, parquet, athena, redshift, rds, as well as with integrating with rest apis using json or xml. you possess effective interpersonal, communication and leadership skills, and have the ability to work under pressure and meet strict deadlines you have strong analytic skills related to working with structured or unstructured datasets. you have the ability to effectively articulate recommendations or conclusions verbally and in writing you have an expertise in data engineering or architecture role in a company with large, complex data sources, and have experience working with aws data technologies . you have expertise building or operating highly available, distributed systems of data extraction, ingestion, and processing of large datasets, as well as etl, data modeling, data injection, transformation and processing. bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected characteristics to apply. whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone. join us at https or or bombardier.com or en or careers or career opportunities your ideas move people. job project or program management primary location ca qc montreal dorval organization aerospace schedule full time employee status regular job posting 15.06.2021, 5 18 39 pm unposting date ongoing","['https', 'schemas', 'data flow', 'data infrastructure', 'distributed systems', 'business', 'java', 'data injection', 'sql', 'python', 'scala', 'json', 'data science', 'software development', 'data', 'analytics', 'integration', 'aws', 'pipelines', 'data engineering', 'testing', 'data manipulation', 'business intelligence', 'data quality', 'rest', 'athena', 'model', 'deep learning', 'data extraction', 'datasets', 'computer science', 'mathematics', 'modeling', 'xml', 'etl']","['https', 'data quality availability', 'python', 'sql', 'scala', 'athena', 'json', 'data manipulation', 'rds', 'business intelligence', 'aws', 'pipelines', 'xml', 'java']","['schemas', 'data flow', 'data infrastructure', 'modeling', 'distributed systems', 'business', 'data injection', 'data science', 'software development', 'data', 'analytics', 'integration', 'data engineering', 'cloud', 'unstructured', 'testing', 'data ing', 'rest', 'planning', 'model', 'deep learning', 'data strategies', 'data extraction', 'datasets', 'computer science', 'mathematics', 'methodology', 'etl']","['and safety', 'forms', 'design', 'program management', 'aerospace', 'aviation', 'hiring', 'architecture']"
270,349,Product Data Scientist,"in february 2021, sharethrough and district m entered into a definitive merger agreement to become one of the leading modern omnichannel advertising exchanges. the combined business mission is to build a sustainable advertising ecosystem for journalists, content creators and app developers, connecting publishers and advertisers with true technological innovation supporting all ad formats, devices. and user experiences. we re looking for data scientists who share our passion for building data driven products, as well as the belief data science should be tightly integrated into the engineering and product flow. in this role, you ll pair with your data science and product peers to explore new ways to optimize the 20 billion impressions flowing through our exchange every day. you ll have a dedicated optimization team to implement your ideas. we believe in an experiment driven approach that enables you to test out your ideas. while we ve implemented some tremendously impactful optimization products already, we believe we ve just scratched the surface. about the role analyze sharethrough data to discover patterns, abnormalities, and increased revenue opportunities present findings to key leadership to influence product roadmaps designing and developing algorithms to track important metrics in real time to feed into ml models that power our platform designing and developing machine learning models that classify content, predict behavior, and forecast supply and demand equilibriums work closely with business leadership to integrate data into every part of the product about you 5 years of experience working in an analytics organization degree in statistics, computer science, econometrics, or similar domain competent performing statistical analysis using a scripting language proficient with sql able to create intuitive and readable dashboards using visualization tools strong familiarity with experimental design comfortable pairing with product bonus points experience or familiarity with the adtech ecosystem experience working closely with product teams comfortable collaborating with leadership to distill down high level business goals and provide data driven recommendations experience with machine learning techniques and how they are applied in production systems","['sql', 'machine learning', 'statistics', 'visualization', 'experimental', 'scripting', 'dashboards', 'data science', 'computer science', 'analytics', 'optimization', 'production systems', 'statistical analysis', 'algorithms', 'econometrics']","['sharethrough', 'sql', 'production systems']","['algorithms', 'machine learning', 'statistics', 'visualization', 'experimental', 'scripting', 'dashboards', 'data science', 'computer science', 'analytics', 'optimization', 'statistical analysis', 'feed', 'econometrics']","['design', 'advertising', 'metrics']"
271,350,"Associate Educator, Data Scientist","brainstation is a global leader in digital skills training and development, offering a 12 week diploma program in data science. brainstation is currently seeking a data science professional to lead the delivery of our program through online and in person teaching. brainstation educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education. responsibilities lead our 12 week data science diploma program help build a world class technical team deliver lectures and mentor the next wave of data science talent co create brainstation s full time data science program that will positively impact the lives and careers of hundreds of individuals across our campuses actively work on writing and researching new content to teach the most up to date skills in data science to our students apply brainstation s agile education methodologies to the program to continuously improve the educational experience for students constantly improve your own skills, and apply these skills in collaboration with other brainstation educators in order to build the digital platform and tools needed to effectively deliver educational material define the education experience of the future successful candidates will have 2 years experience as a data scientist or analytics professional and a bachelor s degree relevant to the subject matter or 8 years experience as a data scientist or analytics professional experience building and leading teams strong command of querying and programming languages , and visualization tools , as well as experience applying various methods of numerical and categorical modeling and machine learning principles practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job an empathetic, friendly, and approachable demeanor a proven ability to work under pressure and meet deadlines about brainstation brainstation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state of the art campuses in new york, london, toronto, and vancouver. founded in 2012, brainstation has worked with over 400 instructors from the most innovative companies, developing cutting edge, real world digital training for more than 100,000 professionals and some of the largest corporations in the world. by 2025, brainstation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 ceos, and the newest wave of disruptive innovators, on campuses and online. have you been to a campus or joined an online learning opportunity we are actively seeking individuals that believe in lifelong learning and that have taken part in our on campus or online offerings . note only those applicants under consideration will be contacted. please accept our utmost appreciation for your interest. brainstation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. all qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. if you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.","['visualization', 'machine learning', 'programming languages', 'data science', 'analytics', 'modeling']",['programming languages'],"['visualization', 'machine learning', 'data science', 'analytics', 'modeling']","['environment', 'events', 'education', 'genetics', 'material', 'art', 'educational', 'hiring', 'higher education', 'workshops', 'mentoring']"
272,352,Development Engineer/Scientist,"be part of something altogether life changing working at cytiva in the life sciences industry means being at the forefront of providing new solutions to transform human health. our incredible customers undertake life saving activities ranging from fundamental biological research to developing innovative vaccines, new medicines, and cell and gene therapies. at cytiva you will be able to continuously improve yourself and us working on challenges that truly matter with people that care for each other, our customers, and their patients. with associates across 40 countries, cytiva is a place where every day is a learning opportunity so you can grow your career and expand your skills in the long term. cytiva is proud to work alongside a community of nine fellow danaher life sciences companies. together, we re pioneering the future of science and medicine, developing products that enable researchers in the fight to save lives. what you ll do project execution, as part of a diverse and multi disciplinary team, for process optimization and technology development programs in cell and gene therapy, and regenerative medicine. this includes definition of tasks, experimental planning and execution, data analysis, documentation, standard operating procedures preparation, reporting and preparation of technical recommendations. work closely with cell biologists and bioprocess engineers in the development of new cell therapy processes and product challenges in an emerging industry. engage external customers and partners to understand and overcome workflow challenges. demonstrate continuous integrity, credibility and positivity, and motivate others to do the same. continuously grow and adapt in a fast moving field to keep yourself and the organization at the forefront of the cell and gene therapy and regenerative medicine fields. who you are ph.d., or master s with 5 years of experience with a degree in bioengineering, chemical engineering, bioprocess, biotechnology, cell biology or a related field. expertise in one or more of the following areas immune cells, viral vectors, bioprocess development, pluripotent stem cells and derived progeny, hematopoietic stem cells, or mesenchymal stromal cells. hands on experience working with human primary and or or stem cell cultures. hands on experience working with process controlled bioreactors. experience with cell characterization . demonstrated expertise operating in a cl2 facility. familiarity with developing protocols amenable to a cgmp environment. detail oriented self starter with excellent problem solving, analytical skills and the ability to multitask and succeed in a team environment. excellent english written and oral communication with strong record keeping and documentation skills. excellent proficiency with computer productivity software and a range of technical when you join us, you ll also be joining danaher s global organization, where 68,000 people wake up every day determined to help our customers win. as an associate, you ll try new things, work hard, and advance your skills with guidance from dedicated leaders, all with the support of powerful danaher business system tools and the stability of a tested organization. danaher is committed to a diverse and inclusive culture where everyone feels they belong and all voices are heard. we believe in our associates and the unique perspectives they bring to every challenge, which is why we ll empower you to push the boundaries of what s possible. if you ve ever wondered what s within you, there s no better time to find out. danaher corporation and all danaher companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. the eeo is the law poster is available here .","['forefront', 'chemical', 'analytical skills', 'software', 'reporting', 'vectors', 'technology development', 'documentation', 'optimization', 'data analysis', 'medicine']","['forefront', 'documentation']","['analytical skills', 'software', 'reporting', 'technology development', 'optimization', 'data analysis', 'medicine', 'planning']","['cell', 'bioprocess', 'environment', 'bioengineering', 'biotechnology', 'biology', 'characterization', 'life sciences', 'viral', 'stem cells', 'vectors', 'record keeping', 'gene', 'therapy', 'law', 'chemical engineering']"
273,353,Data Engineer,"procogia has doubled in size over the last two years core to procogia s culture is ensuring we maintain a balanced male to female ratio. we are proud to share our consulting teams consist of 40 50 females compared to the industry standard of 10 20 . our diversity, and differences allow us to create innovative and effective solutions for our clients. at procogia we re passionate about developing data driven solutions that provide highly informed answers to our clients most critical challenges. our projects are varied, from data warehouse builds, deploying cloud data solutions, dashboarding, building predictive models. you may be involved in all stages of the project life cycle, from data engineering or integration to building pipelines right through to advanced analytics. we work with industry leading clients from various sectors including pharmaceuticals, telecommunications, technology, financial services retail. our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal career development. position details our team is establishing cutting edge ai capabilities to support drug discovery, research and development initiatives. this requires an enablement of world class cloud infrastructure and data engineering technologies and practices. the candidate will join our existing data engineering team to build and deploy the data solutions on gcore platform. this platform is built on aws cloud with redshift, s3, glue, talend, alation along with other ai capabilities responsibilities ensuring availability, performance, security, and scalability of aws production systems. system troubleshooting and problem resolution across various application domains and platforms including integrations of data center systems. integrate aws services with enterprise tooling that enable monitoring, alerting, and retention of critical event information. monitoring, triaging and responding to alerts from systems for detected operational issues. creation of documentation for existing automation, systems, processes and services. proactive team member of an agile team education bachelor or master degree in related fields or related fields required skills experience with data engineering in cloud data solutions . experience with scripting, such as python, r, or bash. exquisite attention to details the curator will be responsible for maintaining healthy datasets on which several research projects will depend. experience with high performance computing and proficiency with git. experience with data wrangling, pre processing and handling of large datasets. experience of processing wgs, rna seq, chip seq, atac seq and or or other ngs data good understanding of biological concepts and biostatistical approaches commonly used in molecular biology and interest to learn more excellent communication and organizational skills and ability to work in a highly interactive group. domain knowledge in safety and or or epigenetics. nice to have skills experienced working with ontologies, example uberon, cell ontology and experimental factor ontology .","['computing', 'bash', 'ontologylogy', 'troubleshooting', 'documentation', 'glue', 'python', 'ontologies', 'scripting', 'analytics', 'integration', 'aws', 'pipelines', 'data engineering', 'r', 'telecommunications', 'production systems', 'automation', 'datasetsigen', 'data wrangling', 'datasets', 'data solutions', 'security', 'scalability', 'git', 'cloud infrastructure', 'enablement', 'ai']","['glue', 'ngs', 'python', 'talend', 'gcore', 'high performance', 'git', 'documentation', 'aws', 'production systems', 'pipelines', 'telecommunications', 'r']","['computing', 'bash', 'troubleshooting', 'ontologies', 'scripting', 'analytics', 'integration', 'data engineering', 'automation', 'data wrangling', 'datasets', 'data solutions', 'security', 'scalability', 'system', 'ontology', 'cloud infrastructure', 'enablement', 'ai']","['environment', 'development initiatives', 'research projects', 'education', 'biology', 'retail', 'molecular', 'consulting', 'financial services', 'drug discovery', 'pharmaceuticals', 'rna']"
274,354,"Data Engineer with Backend Java Experience - Spark, AWS, SQL, Java, Linux","the us equites development group is responsible for the architecture, development and support of nasdaqs north american equities market systems, which includes the core trading and post trade systems, surrounding applications, market data feeds, ticker plants, gateways, smart order routers, and monitoring suite. it is a rich and challenging environment as these systems are subject to requirements of high availability, high throughput, ultralow latency, and also have both rich and innovative functionality. development is primarily in java, running on a linux based environment. the position demands a meticulous java software developer with strong sql skills and extensive object oriented programming experience on real time, mission critical systems. the person will work on our data infrastructure team and help design, build and maintain our data pipeline and data lake solutions, as well as etl processing, and reports generation. prior experience with financial data handling is a plus. responsibilities write code to implement new features and improve performance on existing systems actively participate and contribute to the design process enforce best practices and high code standard document new features and associated test scenarios for other teams and stakeholders including the quality assurance and production support groups able to analyze data to identify potential problems and troubleshoot production issues. must have minimum 6 years of experience with java programming on low latency systems sql experience 3 years experience with communication protocols experience working on complex distributed information systems projects experience with linux solid understanding of data types, access and manipulation, strong experience with more than 1 database sql server or my sql or cloud aws or mongo db or nosql, etc. this includes proficient sql experience user with some etl processing background strong business and data analysis skills good communication skills. preferred aws cloud experience hadoop or spark experience parquet and or or avro experience strong linux scripting skills strong background in unit and performance testing techniques working knowledge of a real time transactions processing platform . nasdaq is an equal opportunity employer. we positively encourage applications from suitably qualified and eligible candidates regardless of age, color, disability, national origin, ancestry, race, religion, gender, sexual orientation, gender identity and or or expression, veteran status, genetic information or any other status protected by applicable law.","['high availability', 'linux', 'test scenarios', 'quality assurance', 'data infrastructure', 'java', 'sql', 'financial data', 'software', 'scripting', 'data feeds', 'programming', 'aws', 'nosql', 'market systems', 'routers', 'data analysis', 'avro', 'performance testing', 'high throughput', 'hadoop', 'low latency', 'information systems', 'critical systems', 'etl']","['sql', 'high availability', 'linux', 'quality assurance', 'hadoop', 'av', 'programming', 'aws', 'java', 'nosql']","['test scenarios', 'financial data', 'software', 'performance testing', 'high throughput', 'data infrastructure', 'data feeds', 'production support', 'information systems', 'scripting', 'market', 'critical systems', 'data analysis', 'low latency systems', 'etl']","['environment', 'trading', 'design', 'equities', 'functionality', 'law', 'architecture']"
275,356,Data Engineer,"hope you are doing well, we are urgently looking for the following role. looking for a data engineer resource for our client thoughtworks. if you have the mentioned skill set, please send me resume at duration 6 months contract with a possibility of extension. location canada job description analyzing the method of transforming existing data into a format for the new environment and the loading of this data into other database structures. reviewing existing migration tools and providing recommendations for improving performance of the migration process. develop best practice, processes, and standards for effectively carrying out data migration activities. perform source system data analysis in order to manage source to target data mapping. perform migration and testing of static data and transaction data from one database to another. perform data migration audit, reconciliation, and exception reporting. hands on experience on microservices and event driven architecture. knowledge of perl, python, java and kafka is a must. knowledge on rdbms and related toolsets. knowledge on database systems such as postgresql and mysql. providing necessary change and support documentation. 629w4zpcdk","['python', 'postgresql', 'reporting', 'testing', 'rdbms', 'database systems', 'data migration', 'perl', 'documentation', 'mysql', 'data analysis', 'microservices', 'java', 'data mapping']","['python', 'postgresql', 'rdbms', 'perl', 'documentation', 'mysql', 'java']","['testing', 'reporting', 'database systems', 'data migration', 'system', 'data analysis', 'microservices', 'data mapping']","['environment', 'architecture']"
276,357,"Senior Data Scientist, AWS Security- Ottawa/Toronto","bs degree and 6 years of relevant experience or ms degree and 4 years of experience hands on professional experience with applying machine learning and other data science techniques to mitigate threats at scale in a production environment 2 years of work experience in applying data science to physical security, network security, or fraud related problems industry experience using database languages, such as sql, and common data science software development and statistical analysis tools demonstrated technical leadership in data science and or or machine learning experience leading and coaching junior data scientists to improve their skills and effectiveness come and build innovative services that protect our cloud from security threats. as an aws security senior data scientist, you ll help to build and manage services that detect and automate the mitigation of cybersecurity threats across amazon s infrastructure. you ll work with security engineers, software development engineers, and other data scientists across multiple teams to develop innovative security solutions at massive scale. our services protect the aws cloud for all customers and preserves our customers trust in us. you ll get to use the full power and breadth of aws technologies to build services that proactively protect every single aws customer, both internally and externally, from security threats not many teams can say that mentorship career growth our team is dedicated to supporting new team members. the team has a mix of experience levels, and we re building an environment that celebrates knowledge sharing and mentorship. our senior engineers, data scientists, and managers truly enjoy mentoring junior engineers, junior data scientists, and engineers from non traditional backgrounds through one on one mentoring and thorough, but kind, code reviews. we care about your career growth. we assign projects and tasks based on what will help team members develop into a more well rounded data scientist and enable them to take on more complex tasks in the future. inclusive and diverse culture our team is intentional about attracting, developing, and retaining amazing talent from diverse backgrounds. yes, we do get to build a cool service, but we also believe a big reason for that is the inclusive and welcoming culture we cultivate every day. we re looking for a new teammate who is enthusiastic, empathetic, curious, motivated, reliable, and able to work effectively with a diverse team of peers. we want someone who will help us amplify the positive inclusive team culture we ve been building. here at aws, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and we host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team values work life balance. we are passionate about the capabilities we build, and we are responsible for our on call rotation to ensure our services bring value to our customers. we understand that life is challenging and we have a flexible work environment that enables individuals to adjust their work schedule to accommodate personal needs. ms or phd in a stem field experience extracting large sets of data, and designing etl flows experience designing and deploying large scale analytic processing solutions using spark, scala, etc. strong sense of ownership combined with collaborative approach to overcoming challenges and influencing organizational change meets or exceeds amazon s leadership principles requirements for this role meets or exceeds amazon s functional or technical depth and complexity for this role amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. for individuals with disabilities who would like to request an accommodation, please visit https or or or en or disability or us","['https', 'sql', 'machine learning', 'cybersecurity', 'scala', 'network', 'security', 'data science', 'software development', 'aws', 'statistical analysis', 'technical leadership', 'etl']","['https', 'scala', 'sql', 'aws']","['machine learning', 'cybersecurity', 'network', 'security', 'data science', 'software development', 'statistical analysis', 'technical leadership', 'etl']","['affinity', 'environment', 'team culture', 'mentoring']"
277,358,Data Scientist – Automated Market Making Team,"data scientist automated market making team job number 3169214 posting date may 31, 2021 primary location americas canada quebec montreal job investment banking or sales or trading or research employment type full time job level associate description we offer to work with some of the best professionals in the business for a firm that values individual intellect as much as teamwork state of the art offices that are designed to maximize collaboration flexible working arrangements enriching challenges that provide opportunity for constant learning and advancement an environment which is leveraging technology to its highest potential team profile the institutional equity division is a global leader in the origination, distribution and trading of cash and derivative products. the firm s automated market making group provides liquidity for options in automated markets worldwide. the amm team consists of quantitative traders, strategists, analysts, software developers, hardware developers, infrastructure and networking specialists, and data architects all collaborating to build and expand a cutting edge system that trades over 1,000,000 securities on 2,500 underliers across 16 options exchanges. the desk operates at the intersection of finance and technology, and many of the models and system designs used to drive the engine sit on the forefront of innovation. position description we are looking for truly exceptional talent to join the automated market making team . amm is one of the industry leading on screen market makers for equity options globally. amm is made up of software and hardware developers, traders, data scientists and quantitative strategist. together we train a system to make markets across 14 exchanges in the us and 2 in europe. the system automatically prices, quotes, hedges, and risk manages the position. the data scientist will create innovative solutions to model various aspects of the electronic options market making, such as risk management, volatility fitting, microstructure analysis, and algorithmic trading analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance develop reporting, analytics, and visualization tools work together with other strategists, traders, and technology organization skills required bachelor s with 3 years of experience or advanced degree in a related field prior programming experience in a scripting language such as python or r interest in quantitative work and data analytics excellent communication skills and ability to interact with traders and technology nice to have previous experience in machine learning or modeling is a plus strong programming skills in kdb or q knowledge of c about us morgan stanley is a global financial services firm and a market leader in investment banking, securities, investment management and wealth management services. at morgan stanley montreal, we are shaping the future of our global business and contributing to our local community. our team works across numerous areas. morgan stanley is an equal opportunities employer. we work to provide a supportive and inclusive environment where all individuals can maximise their full potential. our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives and experiences. our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing and advancing individuals based on their skills and talents. knowledge of french and english is required. spotlight on our montreal technology centre https or or or watch v oo5gaxpcwks video dated october 2019. build a career with impact. visit morganstanley.com for more information.","['https', 'visualization', 'c', 'data analytics', 'forefront', 'python', 'software', 'reporting', 'scripting', 'volatility', 'analytics', 'programming', 'kdb', 'investment management', 'machine learning', 'hardware', 'securities', 'market data', 'networking', 'modeling', 'r']","['https', 'python', 'forefront', 'c', 'programming', 'hardware', 'r']","['data analytics', 'investment management', 'visualization', 'machine learning', 'securities', 'software', 'reporting', 'market data', 'scripting', 'microstructure', 'volatility', 'networking', 'analytics', 'algorithmic', 'modeling']","['global business', 'liquidity', 'environment', 'market making', 'risk management', 'trading', 'art', 'sales', 'finance', 'investment banking', 'financial services', 'recruiting', 'fitting']"
278,359,Senior Data Scientist,"at interac, we design products and solutions that give canadians control over their money so they can get more out of life. but that s not all. whether we re leading real time money movement, driving innovative e commerce or commerce solutions like open payments for transit systems, or making advancements in payments fraud detection and new areas like digital identity and open banking, we are playing a key role in shaping the future of the digital economy in canada. want to make a lasting impact amongst a community of creative thinkers, problem solvers, technical gurus and innovators we want to hear from you. interac is on a fast growth path in a very demanding and rapidly changing payments ecosystem and so is the evolution of our data analytics team. our data scientists analyze billions of transactions and signals from across our ecosystem, leveraging advances in machine learning and cloud based technologies to detect emerging threats and respond with solutions that augment our real time decisioning and mitigate fraud. through collaboration with teams across data science, bi, data engineering and architecture, data governance, technology and business groups, we deliver world class analytical products that democratize data, advance learning, prevent financial crimes and accelerate sustainable growth for interac. senior data scientist the senior data scientist will be responsible for providing actionable insights for the business primarily for fraud management and financial crimes practice and be the liaison or relationship management lead for the fraud or financial crimes analytics function. research and analytics related to fraud management will focus on working with the fraud mitigation strategy team to provide actionable insights into rule based fraud detection, feature development, and statistical analysis of new and existing fraud trends. the data scientist will work with the fraud teams to provide deliverables including research insights, data assets, and visualizations to help the end user develop a better understanding of the topic. the senior data scientist has effective consulting, product management relationship management skills to work alongside cross functional teams including product, innovation, fraud strategy etc. to identify, design, develop, execute, and maintain new enterprise grade data analytics product offerings aligned to interac s growth as well as fraud strategy. they may be required to facilitate business requirements, design sessions with large group of participants. you re great at managing challenging and fraud or financial crimes based initiatives or research using advanced machine learning methods focusing on tangible outcomes of fraud detection and prevention. gathering and using business insights to direct root cause analysis of critical operational issues. collaborating proactively with various business units, product owners to identify business opportunities and designing innovative analytical solutions to optimize processes, promote informed decision making producing data driven insights and business recommendations to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives leading research work related to machine learning, computational statistics, analytics practices or techniques as it relates to improving our data driven financial crimes or fraud detection and protection capabilities forming key relationships with the fraud strategy team to streamline data analytics delivery. developing subject matter expert of interac products and processes. understanding of connection and interaction between production systems, processes and data playing a key role in driving corporate priorities and play critical role developing capabilities for market launches of new product offerings . quickly learning and adopting new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises. working with large complex data sets to solve difficult, non routine analysis problems applying advanced analytical methods as needed. conducting end to end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables and presentations. developing, consulting on, deploying and analyzing testing strategies to leverage learnings for future business endeavors. preparing detailed documentation to transfer knowledge and satisfy governance and regulatory concerns. recommending data modeling and design standards, tools, best practices, and related development for enterprise data models working extensively with end users to create plan on how to approach a given problem who are you you have a degree in business, mathematics, computer science or equivalent combination of education and industry experience. you have 3 5 years or more of experience in data science you have 3 years or more of experience using machine learning you have 3 years experience developing comprehensive business cases for data analytics capabilities, strategies, kpi s you are able to understand complex issues and dissect, digest, then generate a data product to help address issues you have sound familiarity with product management, design thinking concepts you have experience with python, oracle, cloudera, pyspark, jupyter, github, aws, redshift 5 or more years of experience in the financial industry is an asset prior consulting experience is preferred financial crimes or fraud analytics or data science experience is an asset you have significant experience working with implementing concepts, such as predictive modeling, profiling, segmentation forecasting, operations research and data mining. you have mathematics, algorithms, and leadership skills, you have excellent oral or written and presentation skills. you have strong data storytelling skills you have strong relationship management and facilitation skills you have expert knowledge of data mining, databases, sql, machine learning you have experience with the following technologies or databases oracle, hdfs, hive, redshift, spark , etl tools , bi tools , python you have strong knowledge of canadian payment industry, payments transaction data and process flows. you have knowledge of it processes and infrastructure required to support analytics. you have experience in developing data analytics strategy how we work... we know that exceptional people have great ideas and are passionate about their work. our culture encourages excellence and actively rewards contributions with connection you re surrounded by talented people every day who are driven by their passion of a common goal. core values they define us. living them helps us be the best at what we do. compensation benefits pay is driven by individual and corporate performance and we provide a multitude of benefits and perks. education to ensure you are the best at what you do we invest in you. about interac interac corp. operates an economical, world class debit payments system with broad based acceptance, reliability, security, and efficiency. the organization is one of canada s leading payments brands and is chosen an average of 16 million times daily to pay and exchange money. for more than 30 years, interac corp. and its predecessors, interac association and acxsys corporation, have facilitated secure financial transactions through the development of innovative and convenient debit and money transfer solutions. a leader in the prevention and detection of fraud, the organization has one of the lowest rates of fraud globally. visit interac.ca or follow interac on twitter. interac corp. has a diverse group of shareholders that includes banks, credit unions, caisses populaires, payment processors and merchants. interac corp. believes in providing an inclusive workplace where all individuals have the opportunity to succeed. we are committed to doing so by providing accessible employment practices. contact a member of the human resources department if you need accommodation at any point in the application process or want more information about our accessibility policy, which is also available online here. cjxlm5vn6y","['design standards', 'databases', 'design thinking', 'pyspark', 'documentation', 'statistical analysis', 'hive', 'etl', 'github', 'data analytics', 'python', 'sql', 'statistics', 'processors', 'data science', 'enterprise', 'data', 'analytics', 'product management', 'aws', 'data models', 'data engineering', 'jupyter', 'data mining', 'machine learning', 'testing', 'fraud detection', 'production systems', 'algorithms', 'forecasting', 'banking', 'bi', 'business insights', 'security', 'computer science', 'mathematics', 'modeling', 'root cause analysis']","['solvers', 'jupyter', 'python', 'databases', 'sql', 'pyspark', 'bi', 'business insights', 'processors', 'documentation', 'aws', 'production systems', 'hive']","['design standards', 'design thinking', 'statistical analysis', 'etl', 'github', 'data analytics', 'statistics', 'data science', 'enterprise', 'data', 'analytics', 'product management', 'data engineering', 'data gathering', 'data mining', 'machine learning', 'testing', 'fraud detection', 'predictive', 'algorithms', 'forecasting', 'routine methods', 'banking', 'computational', 'security', 'computer science', 'analytics management', 'mathematics', 'modeling', 'root cause analysis']","['commerce', 'education', 'operations research', 'human resources', 'design', 'sustainable growth', 'presentations', 'governance', 'consulting', 'compensation', 'business units', 'architecture']"
279,360,Specialist - Data Development / Big data,"at cn, we work together to move our company and north america forward. be part of our information technology team, a critical piece of the engine that keeps us in motion. from enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value added tasks. you will be able to develop your skills and career in our close knit, safety focused culture working together as one team. the careers we offer are meaningful because the work we do matters. join us we are looking for a big data engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. the primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. you will also be responsible for integrating them with the architecture used across the company. responsibilities create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. extraction, transformation, and loading of data from a wide variety of data sources using sql and hadoop technologies. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. work with stakeholders including the executive, product, data and design teams to assist with data related technical issues and support their data infrastructure needs. keep our data separated and secure across the data lake to adhere to industry and regulatory requirements create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. work with data and analytics experts to strive for greater functionality in our data systems. report progress status and issues. apply, and ensure compliance with, all appropriate cn it standards requirements advanced working sql knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases experience building and optimizing hadoop data pipelines, architectures and data sets. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. strong analytic skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. a successful history of manipulating, processing and extracting value from large disconnected datasets. working knowledge of message queuing, stream processing, and highly scalable big data data stores. strong organizational skills and can work autonomously to provide data solutions experience supporting and working with cross functional teams in a fast paced environment. 10 years of experience in a data engineer role, graduate degree in computer science, statistics, informatics, information systems or another quantitative field. should also have experience using the following software or tools experience with big data tools adx, hadoop, spark, kafka, etc. experience with relational sql and nosql databases, including postgres and cassandra. experience with stream processing systems storm, spark streaming, etc. experience with object oriented or object function scripting languages python, java, c , scala, etc. assets experience in development practices and proven methodologies experience with cloudera or mapr or hortonworks hadoop distributions with a preference on hortonworks hortonworks certification is a definite asset experience with nosql databases, such as hbase, cassandra, mongodb is an asset experience with spark is a asset about cn as a leading north american transportation and logistics company, cn is a true backbone of the economy. with a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. we transport us 200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000 mile network spanning canada and mid america. cn is the only canadian company listed in the transportation and transportation infrastructure sector of the dow jones sustainability world index . launched in 1999, the djsi world represents the gold standard for corporate sustainability. at cn, we work as one team, focused on safety, sustainability and our customers, providing operational and supply chain excellence to deliver results. cn is an employment equity employer and we encourage all qualified candidates to apply. we thank all applicants for their interest, however, only candidates under consideration will be contacted. please monitor your email on a regular basis, as communication is primarily made through email.","['databases', 'operational efficiency', 'data infrastructure', 'c', 'big data', 'mongodb', 'information technology', 'sustainability', 'java', 'sql', 'python', 'statistics', 'software', 'scala', 'scripting', 'queuing', 'enterprise', 'analytics', 'data systems', 'nosql', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'metadata', 'cassandra', 'data structures', 'hadoop', 'datasets', 'data solutions', 'information systems', 'scalability', 'computer science', 'root cause analysis']","['mapr', 'sql', 'python', 'databases', 'scala', 'hadoop', 'c', 'adx', 'big data', 'h', 'java', 'nosql', 'cassandra']","['operational efficiency', 'data infrastructure', 'relational', 'mongodb', 'information technology', 'sustainability', 'statistics', 'software', 'scripting', 'queuing', 'enterprise', 'analytics', 'data systems', 'unstructured', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'metadata', 'data structures', 'datasets', 'data solutions', 'information systems', 'scalability', 'computer science', 'methodology', 'root cause analysis']","['environment', 'regulatory requirements', 'customer acquisition', 'metrics', 'design', 'functionality', 'business performance', 'architecture']"
280,361,Primary Care COVID Impact Data Analyst,"date posted 06 or 18 or 2021 req id 4913 faculty or division temerty faculty of medicine department department of family community medicine campus st. george description about us home to over 40 departments and institutes, the university of toronto s temerty faculty of medicine lies at the heart of the toronto academic health science network and is a global leader in ground breaking research and education, spanning clinical medicine, basic science and the rehabilitation sciences sectors. your opportunity utopian is a network that brings together department of family and community medicine researchers, primary care clinicians and practices from all its academic sites to answer important healthcare questions and translate findings into practice. as the primary care covid impact data analyst, you will play an integral role in the utopian team, which is made of data specialists and primary care physicians. you will contribute by selecting methods of analysis for research projects, developing data set creation plans, conducting data analysis using both quantitative and qualitative methods, preparing reports for a variety of audiences, and working with the dsh team to improve data processing and cleaning methods. drawing on a knowledge of clinical epidemiology best practices, along with your solid collaborative, organizational, analytical and critical thinking skills will be key to your success in this role. your responsibilities will include assessing needs, and analysis for research projects, and contributing to the planningof research goals developing project schedules including milestones, critical path, timelines, deliverables and reporting scheduling day to day project activities along with supervising the activities of research assistants, analysts, utopian scientists and other investigators implementing and executing primarily quantitative but possibly also qualitative research methods including conducting systematic literature reviews synthesizing technical, quantitative and contextualresearch data as well as preparing draft statistical reports and summaries planning and estimating financial resources required for programs and or or projects essential qualifications master s degree in health services research, clinical epidemiology or related field or equivalent combination of education and experience minimum five years of relevant and related experience experience working with researchers and research teams. experience working with a variety of data sources. experience writing and contributing to proposals and publications and delivering presentations to large audiences. knowledge of ethical aspects of research, data security and privacy. knowledge and expertise in the principles and methods of clinical epidemiology. strong applied knowledge of statistical techniques such as tests of significance, regression analysis, categorical data analysis, and analysis of variance is required. strong sas and vba programming is required. familiarity with spss, r, stata, or other statistical software is an asset. extensive computer skills in word processing , database management internet, and presentation packages . strong verbal and written communication skills are required. ability to balance multiple priorities and simultaneously working with on several projects. strong interpersonal skills with the ability to establish positive working relationship with research scholars and colleagues. self motivated, team player with strong organizational skills. demonstrated ability to effectively interact with all levels of faculty, staff, researchers, clinicians, healthcare professionals and other collaborators. tact, initiative, good judgment and patience. ability to handle matters of a sensitive and confidential nature. assets experience with emr data and or or administrative data is an asset ph.d is an asset to be successful in this role you will be accountable communicator multi tasker organized team player this is a one year term position closing date 06 or 28 or 2021, 11 59pm et employee group usw appointment type grant term schedule full time pay scale group hiring zone usw pay band 13 74,781 with an annual step progression to a maximum of 95,634. pay scale and job class assignment is subject to determination pursuant to the job evaluation or pay equity maintenance protocol. job category research administration teaching recruiter aarthiga sivakumar","['emr', 'vba', 'qualitative research', 'medicine', 'regression analysis', 'data processing', 'software', 'synthesizing', 'reporting', 'data', 'programming', 'sas', 'epidemiology', 'word processing', 'statistical', 'data analysis', 'administration', 'security', 'summaries', 'r']","['emr', 'vba', 'data', 'programming', 'sas', 'r']","['administration', 'regression analysis', 'data processing', 'tests', 'summaries', 'software', 'reporting', 'security', 'database management', 'qualitative research', 'statistical', 'data analysis', 'medicine', 'statistical reports', 'epidemiology', 'word processing', 'planning']","['research projects', 'synth', 'education', 'healthcare', 'literature reviews', 'presentations', 'health', 'rehabilitation', 'hiring']"
281,362,Data Analyst - Data Products (15 Month Contract),"join unbounce and help the world experience better marketing. we re a people first, customer obsessed company focused on helping employees do their best work. our landing page and conversion platform empowers digital marketing teams and agencies to launch campaigns, increase conversions and get significantly better roi on their marketing spend in a way that nobody else does today. we re looking for a data analyst to join our growing efforts to deliver actionable insights and deep analysis findings to our current and future customers. you ll be part of the data products team, working with our data scientists, machine learning developers and ux designers to mine our datasets for insights, and work with teams such as marketing and engineering to deliver those insights to the market and our customers. what you ll be doing pro actively mine and perform statistical analyses on our varied datasets to find actionable and valuable insights work with multiple teams to ideate and deliver market facing content, utilities and customer facing features act as the bridge and advocate between data products and the market facing teams work as an integral part of our data analyst chapter and data organization by contributing to the overall data ecosystem and improving data literacy throughout unbounce a little bit about you 2 or more years experience as a technical data analyst with a proven track record of generating understandable and actionable insights from the data programming with python and the associated data analysis packages fluent and experienced with sql you are comfortable working independently and finding the place to make the most impact you excel at translating data findings into insights for non technical stakeholders agile development, version control, and code review processes what s in it for you a remote friendly office with flexible hours for this role we will consider all applications from those based in canada with the option to work from our vancouver office 4 weeks vacation plus christmas holiday closure you re entitled to the week of christmas off with pay through to and including jan 1st vacation bonus 1,000.00 12 personal wellness days health and wellness budget 500.00 networking budget 500.00 a paid day off for your birthday one paid volunteer day per year one day every 2 weeks of dedicated professional development time unbounce welcomes everyone to apply at unbounce we celebrate everyone and their multiple intersecting identities. we believe a panorama of experience allows us to make better decisions together and inspires innovation so that we can better serve our customers and community. our goal is for every unbouncer to feel deeply connected to their team through mutual value, respect, and understanding. please let us know if you require any accommodations or support during the recruitment process. ifjjhknigx","['ux', 'python', 'machine learning', 'sql', 'data products', 'datasets', 'networking', 'data', 'programming', 'data analysis', 'version control', 'code review']","['python', 'sql', 'data', 'programming']","['ux', 'machine learning', 'data products', 'datasets', 'networking', 'agile development', 'data analysis', 'version control', 'code review']","['utilities', 'marketing', 'campaigns', 'digital']"
282,363,Senior Data Scientist ML & NLP expert,"senior data scientist ml nlp expert 32711 profession solution development work location americas canada montreal schedule full time description as a sr data scientist nlp ml expert, you will be working in a fast paced environment which needs a mindset of a startup and an entrepreneur that is not hesitant to constantly shift gears, test and learn. you will be part of the company center of excellence in data science ai and you will be working with stakeholders by agile and design thinking methodologies, innovating and improving ati industry with data science ai technology. together with the coe you will deliver everything from state of the art solutions to quicker value proving solutions what you will do build and implement advanced machine learning models for flight arrival and departure prediction research, develop and evaluate advanced text speech processing algorithms and implementations. research, develop and evaluate advanced ati messaging processing algorithms and implementations. utilize machine learning technology for speech processing and air transport messages processing prototype and develop algorithms and advanced machine learning techniques for applications such as speech modeling, qar data modelling rendering, speech recognition, blind source separation, and speaker id. stay up to date with tech, prototype with and learn new technologies, proactive in technology communities learn from peers in data science and engineering community deliver on time with a high bar on quality of research, innovation and engineering create advanced ocr and cognitive data extraction capability as well as its execution responsible for cognitive extraction, technology delivery and operating model setup develop innovative solutions in areas such as machine learning, computational linguistics, natural language processing , advanced and semantic information search, extraction, induction, classification and exploration develop maintain client nlp pipeline for document data extraction semantics and sentiment processing and understanding create products that provide a great user experience along with high performance, security, quality, and stability qualifications who you are master s or phd degree in stem or ai or ml areas 5 years of professional experience as a data scientist or related roles 3 years of work experience in voice related projects and 3 years of work experience in software development experience in setting up supervised unsupervised learning client or nlp models including data cleaning, data analytics, feature creation, model selection ensemble methods, performance metrics visualization knowledge in signal processing techniques including adaptive filtering, filter banks and wavelet processing, speech analysis and synthesis, speech and audio coding. experience in text classification topic mining speech enhancement and speech or audio coding and compression. string experience in prediction using machine learning and deep learning hand on experience in feature extraction techniques for voice recognition and audio event classification. 4 years of work experience with at least one of the following languages python, java, and r, ph. d. preferred 3 years of experience working in agile team environment hand on experience with machine learning techniques such as deep neural nets published research on signal processing nlp , nlu or machine learning related to voice technology or messaging experience working in a cloud environment or a containerized environment good understanding of the complexity of developing and productizing real world ai or ml applications such as prediction, recommendation, computer vision, bots, nlp, sentiment, knowledge and content intelligence, etc. knowledge of text analytics with a strong understanding of client nlp algorithms and models and their underlying computational and probabilistic statistics deep knowledge of some of the popular ml frameworks such as tensorflow, pytorch keras, sparkml, scikit learn, xgboost, h2o etc designing and documenting data architecture at multiple levels and across multiple views providing active hands on architectural guidance and leadership through the entire lifecycle of development projects ability to translate business requirements into conceptual and detailed system architecture and technology solutions ability to develop and lead proof of concepts, deliver practical, working solutions experience in building modern machine learning platforms a big plus being a committer or a contributor to an open source project is a plus design, implement and deploy scalable, distributed solutions to support real time nlp data analytic platform using modern engineering principles and techniques at least 4 years experience building machine learning nlp solutions over open source platforms such as scikit learn,tensorflow, sparkml, torch, caffe, h2o excellent knowledge and demonstrable experience in using open source nlp packages such as nltk, word2vec, spacy, gensim, standford corenlp. at least 2 years experience in designing and developing enterprise scale nlp solutions in one or more of named entity recognition, document classification, document summarization, topic modelling, dialog systems, sentiment analysis, ocr text processing what we offer sita s workplace is all about diversity many different countries and cultures are represented in our workforce, and colleagues who ve been working here for decades collaborate with those just out of college and early in their careers. sita is a place of change and constant improvement, where we re always pushing ourselves to find better ways of doing things smarter, quicker, easier, for us and our customers and for their customers too. and we offer all the good stuff you d expect like holidays, bonuses, flexible benefits, medical policy, pension plan and access to world class learning. welcome to sita sita is the world s leading specialist in air transport communications and information technology. we don t just connect the global aviation industry. we apply decades of experience and expertise to address almost every core business, operational, baggage, and passenger process in air transport. we design, build and support technology solutions all with one vision to create easy air travel every step of the way. as an organization, we cover 95 of all international air travel destinations and work with over 2,800 air transport and government customers in every corner of the globe. are you ready to explore the opportunities sita is an employment equity employer and values a diverse workforce. in support of our employment equity program, women, aboriginal people, members of visible minorities, and or or persons with disabilities are encouraged to apply and self identify in the application process. li sita jg2 job posting mar 12, 2021, 3 11 50 pm","['prediction', 'visualization', 'design thinking', 'wave', 'speech', 'user experience', 'tensorflow', 'pytorch', 'speech analysis', 'data cleaning', 'information technology', 'java', 'qar', 'data analytics', 'python', 'statistics', 'keras', 'speech processing', 'nltk', 'computer vision', 'data science', 'software development', 'analytics', 'data', 'sentiment analysis', 'r', 'text', 'machine learning', 'sentiment processing', 'computational linguistics', 'speech recognition', 'semantics', 'algorithms', 'deep learning', 'language processing', 'signal processing', 'data extraction', 'security', 'nlp', 'system', 'technology solutions', 'modeling', 'ai']","['python', 'keras', 'scikit', 'pytorch', 'sci', 'nlp', 'technology solutions', 'nltkcy', 'r', 'java', 'spark', 'qar']","['prediction', 'visualization', 'design thinking', 'entity', 'speech', 'user experience', 'tensorflow', 'natural', 'data cleaning', 'information technology', 'data analytics', 'statistics', 'speech processing', 'summarization', 'computer vision', 'data science', 'software development', 'analytics', 'data', 'sentiment analysis', 'text', 'machine learning', 'sentiment processing', 'computational linguistics', 'speech recognition', 'algorithms', 'deep learning', 'language processing', 'signal processing', 'data extraction', 'security', 'system', 'solution', 'modeling', 'feature', 'ai']","['environment', 'metrics', 'ocr', 'development work', 'art', 'performance', 'development projects', 'design', 'government', 'aviation', 'architecture']"
283,364,"Senior Data Scientist, Artificial Intelligence Research","in a world of disruption and increasingly complex business challenges, our professionals bring truth into focus with the kroll lens. our sharp analytical skills, paired with the latest technology, allow us to give our clients clarity not just answers in all areas of business. we embrace diverse backgrounds and global perspectives, and we cultivate diversity by respecting, including, and valuing one another. as part of one team, one kroll, you ll contribute to a supportive and collaborative work environment that empowers you to excel. kroll is building an artificial intelligence and machine learning group, and we re looking for you to join our portfolio of ai projects. you will be critical in achieving our vision and strategy for solving complex business problems with cutting edge solutions driven by the latest advancements in artificial intelligence and machine learning. some of our current projects focus on nlp and machine learning for cyber security and due diligence, quantitative analysis and we are actively scaling up across multiple other lines of business. at kroll, your work will help deliver clarity to our clients most complex governance, risk, and transparency challenges. apply now to join one team, one kroll. responsibilities research, explore, implement, and evaluate new machine learning models implement and compare existing cutting edge research works to solve business problems test the model performance with business use cases build prototype models publish research papers produce open source software and packages present ai solutions to the business sponsors requirements phd degree in machine learning or related field or phd student research experience python experience is preferred technical and business communication in english team and technical leadership in order to be considered for a position, you must formally apply via careers.kroll.com. kroll is committed to equal opportunity and diversity, and recruits people based on merit.","['analytical skills', 'machine learning', 'due diligence', 'python', 'software', 'security', 'nlp', 'artificial intelligence', 'technical leadership', 'ai']","['python', 'nlp']","['analytical skills', 'machine learning', 'due diligence', 'use cases', 'quantitative analysis', 'software', 'security', 'artificial intelligence', 'technical leadership', 'ai']","['research papers', 'environment', 'governance', 'business communication']"
284,366,Intermediate Engineer/Scientist – Quality Assurance Operations (Software),"adecco is currently hiring for an intermediate engineer or scientist quality assurance operations for our medical manufacturing client in ottawa west. this is a 2 year contract opportunity offering full time hours, monday friday. the salary for this position will be determined based on education and experience. our client is a diversified health care innovator with a legacy of pioneering work in medical diagnostics and devices. they are dedicated to advancing innovative with patient diagnostic technology to improve patient care and system efficiency by fundamentally changing the way health care professionals process patients through their system. we are seeking an energetic and driven intermediate engineer who will play a key role on the quality operations team supporting validations, verifications and security assessments pertaining to non product software. the successful candidate must have strong attention to detail, excellent communication skills and strong organization skills and ability to follow the quality management system and ensure that protocols and reports meet the intended requirements of the quality management system. responsibilities review protocols and reports pertaining to clinical software changes and updates follow the software validation and verification protocols as outlined in the quality management system assess work completed against the software validation and verification requirements and ensure that gaps are identified and addressed participate in defining, identifying, and classifying critical information assets, assess threats and gaps regarding those assets and implement safeguard recommendations perform threat management, threat modelling, identify threat vectors, and develop use cases for security monitoring coordinate the planning and execution of cybersecurity deliverables with cross functional teams assess quality documentation protocols and reports as required author quality documents provide feedback on operational and procedural documentation with regards to cybersecurity independently execute assigned tasks attend cross functional team meetings to share information keep up to date with the latest technical developments in related areas, assess and integrate appropriate changes to work practices requirements minimum 1 3 years in a scientific or engineering role. bachelor s degree in computer science, information technology, or engineering with software or other scientific focus, or equivalent strong working knowledge of software validation requirements and the software lifecycle strong working knowledge of data analysis and data mining techniques knowledge of cybersecurity tools, technologies and methods ability to assess system vulnerabilities and recommend protective measures familiarity with security frameworks and risk management methodologies is an asset some understanding of networking principles including tcp or ip, wans, lans is an asset demonstrated initiative and problem solving skills critical thinking skills analytical skills, creativity and innovative approach to problem solving ability to collaborate effectively with multidisciplinary team members and also to work independently willingness to work in labs, manufacturing areas, and office environments very strong investigational skills, drive to understand and solve problems propensity to continuous learning and experimentation. to be considered for the intermediate engineer or scientist quality assurance operations position, please click on apply ap1956 a1956","['data mining', 'analytical skills', 'quality assurance', 'cybersecurity', 'software', 'software lifecycle', 'information technology', 'security', 'security monitoring', 'computer science', 'data analysis', 'documentation', 'networking', 'tcp', 'vectors', 'ip', 'system efficiency']","['documentation', 'ip', 'quality assurance']","['data mining', 'analytical skills', 'use cases', 'cybersecurity', 'software', 'software lifecycle', 'quality operations', 'security', 'security monitoring', 'system', 'computer science', 'data analysis', 'networking', 'tcp', 'information technology', 'planning']","['validation', 'patient care', 'education', 'risk management', 'vectors', 'manufacturing', 'hiring', 'developments']"
285,367,Data Engineer,"description hey there, we re article. we re a digital first furniture brand that s working to make everyday living better by providing an easy way for people to furnish their space. we don t have brick and mortar stores, so we re able to deliver better value on beautiful, modern furniture. we ve ranked as one of canada s fastest growing companies for the last three years, we re on the hunt for talented, enthusiastic team members who want to solve meaningful problems, in pursuit of being remarkably better for our customers. we re looking for a data engineer who will help us design, build, and maintain the data foundation that powers our data warehouse. you ll be responsible for building scalable data pipelines infrastructure to deliver data to analytics engineers and data scientists as well as supporting the development of tools for delivery of transformed data to the data analysis and data science teams and other stakeholders. this role can be remote based anywhere in canada. what you ll be doing you ll also build instrumentation for end to end data observability to ensure accurate, timely and high quality data. you ll be collaborating with cross functional engineering teams to create and utilize shared standards to reduce waste. you will be responsible for any data projects driven either by new systems being added, updated or by a new way of delivering large data files etc. you will have significant responsibility and influence in shaping the article data engineering team s future direction. this role reports into software engineering manager and is part of a cross functional technology department. skills knowledge and expertise proficiency in python programming language and sql for data processing. experience working with large data sets both sql and nosql databases in linux environment strong fundamental data integration background working in multiple development environments experience building etls and data pipelines using tools such as apache airflow and pyspark experience with amazon web services rds, ec2, s3, lambda, amazon redshift. experience integrating with real time data feeds using apache kafka demonstrated etl or data programming skills experience with devops practices, ci or cd, managing production deployments, git and github awareness of security, performance, high availability and fault tolerance and best practices ability to communicate design, concepts and decisions both verbally and in writing nice to have skills retail domain experience experience with virtualization, containers, and orchestration knowledge of data visualization and reporting tools like tableau aws emr, aws dms, talend, apache airflow, stitch atlassian bitbucket, jira, confluence education and experience bachelor of computer science or a similar technical degree 3 years of data engineering experience benefits at article, we believe in an ownership mindset where you ll be given autonomy and the ability to own your work. beyond a competitive salary we reward that ownership mindset, so we offer stock options after one year of employment with our fast growth, we have a culture of curiosity, where learning happens on the fly and while having a lot of fun access to dental and health benefits package plus a health or lifestyle spending account for your total physical and mental well being 45 discount on our products so you can experience first hand why our customers love article your choice of state of the art laptops with the tech and tools to easily collaborate most hq employees are working from home due to covid 19. when it s safe to return to the office, we have flexible solutions if you want to be in the office a lot, sometimes, or not at all. when our office is safe to reopen, you ll love that the article hq is a converted warehouse with in house photo studios, an airy open layout, an open kitchen filled with snacks, premium coffees and teas . a dog friendly office. we love our dog friends here at article. if you have a well behaved, well socialized pup, we d love to have them in the office too. onsite fitness equipment, change rooms and bike storage regular extra curricular activities, such as socials, open mics, picnics... even cross country skiing for now, we ve replaced them with creative virtual events for the time being like virtual trivia night or a cooking class through zoom ready to become a particle apply today. we re excited to meet you article is the easiest way to create a beautiful modern space. article started from a desire to improve efficiency and make furniture less expensive for everyone. in 2014 we had 4 employees now we have over 700 and have been growing at about 50 yearly. our office and warehouse space has grown from under 15,000 sq ft to over 1,200,000 sq ft, and our yearly revenue has grown to match. our head office is based in vancouver, canada, an office in ho chi minh city, and warehouses in seattle, los angeles, san francisco, jacksonville, austin, dallas, portland, houston, denver, baltimore, toronto, boston, and new jersey.","['databases', 'linux', 'tableau', 'pyspark', 'emr', 'ci', 'data visualization', 'confluence', 'bitbucket', 'less', 'github', 'sql', 'python', 'data processing', 'cd', 'software', 'reporting', 'talend', 'data feeds', 'data science', 'data', 'analytics', 'programming', 'integration', 'aws', 'amazon redshift', 'data engineering', 'nosql', 'apache airflow', 'amazon web services', 'data pipelines', 'data analysis', 'apache kafka', 'jira', 'devops', 'fault tolerance', 'security', 'git', 'zoom', 'computer science', 'virtualization', 'etl']","['databases', 'linux', 'tableau', 'pyspark', 'emr', 'confluence', 'bitbucket', 'rds', 'less', 'sql', 'python', 'talend', 'data', 'programming', 'aws', 'amazon redshift', 'nosql', 'apache airflow', 'amazon web services', 'san', 'apache kafka', 'jira', 'zoom', 'git']","['ci', 'data visualization', 'dms', 'github', 'data processing', 'cd', 'software', 'reporting', 'data feeds', 'data science', 'analytics', 'data', 'integration', 'functional engineering', 'data engineering', 'data pipelines', 'data analysis', 'etls', 'devops', 'fault tolerance', 'security', 'computer science', 'virtualization', 'etl']","['environment', 'events', 'education', 'retail', 'design', 'art', 'waste', 'growing companies']"
286,368,Market Data Engineer,"what is the opportunity this is a mdoe position fte. to provide solution and support for market data and messaging middleware platforms for rbc business users and applications globally. contribute to the global technical strategies and engineering of those platforms. liaison between developers, technology staff and management to ensure high quality requirements and engineering of market data and messaging platforms. what will you do provide services on all areas of market data technology architecture, engineering, implementation and support. partner with application development team to ensure that market data or messaging dependency risk are minimized and that needs are fully understood and met. participation from stakeholders beyond just the development and operation teams. responsible for the operational support of market data monitoring systems. this includes assessment and communication of outages and incidents to the correct audience partner with itrs monitoring team to ensure monitoring requirements are fully understood and met. ensure documentation on all systems in use for production and disaster recovery and regulatory purposes. ensure production problems, bugs, system problems or changes are documented and requests are acted upon promptly. keep senior management advised of situations that may compromise agreed deliverables and or or affect production systems provide on call support for global clients, rotating amongst all global engineers what do you need to succeed must have hands on knowledge of symphony, reuters trep, bloomberg bpipe, dacs, tibco rv, solace, kafka, and or or other low latency direct exchange feed handlers and distribution platforms. programming knowledge and shell scripting programming with messaging chatbot understanding of market data concepts datafeeds, stock exchanges, market data and messaging middleware or distribution, idbs and vendor reporting requirements nice to have experience of underlying networking and server technologies used in low latency infrastructures unix or linux, windows, android, ios, database knowledge of exchange datafeeds provided by the main north american equity markets and the technologies used to deliver those feeds in both client and co located facilities. experience with data visualization tools . what s in it for you we thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. we care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual. a comprehensive total rewards program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable leaders who support your development through coaching and managing opportunities ability to make a difference and lasting impact work in a dynamic, collaborative, progressive, and high performing team a world class training program in financial services flexible work or life balance options opportunities to do challenging work opportunities to take on progressively greater accountabilities opportunities to building close relationships with clients access to a variety of job opportunities across business and geographies the successful candidate will need to establish and maintain productive working relationships with advisors and individuals at all levels, both internally and externally. join our talent community stay in the know about great career opportunities at rbc. sign up and get customized info on our latest jobs, career tips and recruitment events that matter to you. expand your limits and create a new future together at rbc. find out how we use our passion and drive to enhance the well being of our clients and communities at jobs.rbc.com. job summary city toronto address 155 wellington st west work hours or week 37.5 work environment office employment type permanent career level experienced hire or professional pay type salary variable bonus required travel 0 exempt or non exempt n or a people manager no application deadline 06 or 23 or 2021 platform capital markets req id 374136 ad code","['linux', 'data visualization', 'documentation', 'ios', 'tibco', 'reporting', 'windows', 'unix', 'programming', 'technology', 'disaster recovery', 'application development', 'android', 'production systems', 'rbc', 'shell scripting', 'middleware', 'market data', 'low latency', 'networking', 'operational support']","['linux', 'middleware', 'production systems', 'ti', 'android', 'windows', 'unix', 'documentation', 'programming', 'ios', 'rbc', 'shell scripting']","['disaster recovery', 'reporting', 'market data', 'low latency', 'feeds', 'data visualization', 'networking', 'technology', 'application development', 'operational support', 'feed']","['environment', 'events', 'compensation', 'bloomberg', 'outages', 'financial services', 'capital markets', 'rbc', 'assessment', 'architecture']"
287,369,Principal Data Scientist,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or work in an office it s up to you. the role veeva data cloud is a family of data products aimed at bringing more innovative solutions and greater choice to the life sciences data market. life sciences companies license our data to inform high impact commercial initiatives, such as patient journey mapping, healthcare professional targeting, and field force alignment. veeva data cloud leverages software and cloud technology to develop and deliver better data, faster. as the principal data scientist for the veeva data cloud team, you will be focused on designing and building our methodologies to bring projected data products to life for our customers. you are excited about statistics and data science at scale on big data and taking billions of records to tell a story, from sample curation, projection methodologies, anomaly detection, scaling approaches, clustering, and more. you design and build algorithms in a computationally efficient and statistically effective manner, while being able to keep the business problems we are working to solve in mind. while ml is an important part of your toolkit, it s not your only skill. the ability to dissect the problem and to select from a variety of techniques is key. this is a great opportunity for someone who is excited about using their statistics and data science expertise to design and build the algorithms and models used at the core of launching veeva s projected data products. you ll collaborate closely with the product management and engineering team to productize the methodologies and get to see enterprise life science customers leverage your work every day. what you ll do apply statistical, machine learning, and data mining techniques to large health data sets to build new products and methodologies collaborate closely with a team of data scientists, product managers, software engineers and data engineers to discover and deliver product offerings from prototype to scale, then iterate and enhance explore and find meaning in high volumes of data, identify signals and patterns to identify relationships to infer the universe from imperfect data. important skills include querying, data cleansing, experiment design, solution assessment, identifying scaling challenges. rapidly build prototype product solutions, communicate findings, and iterate draw from prior experience and technical expertise to identify product improvements and inform testing plans break overall objectives down into underlying problems that can be prioritized and solved requirements 10 years of hands on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects m.s. or ph.d. in applied statistics, mathematics, computer science, machine learning or other quantitative discipline highly proficient in python and sql experience working with aws preferred experience working with large quantities of data to develop models that work in a stable, production approach with live data advanced knowledge of statistical analysis and data mining techniques experience working with engineering to productionalize models including scaling, monitoring, and documentation comfortable about ambiguity and breaking goals down into tangible and actionable workplans strong communication skills and ability to work across internal teams nice to have statistician in health related field, such as epidemiology perks benefits flexible pto allocations for continuous learning development health wellness programs veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['cleansing', 'big data', 'documentation', 'machine', 'statistical analysis', 'sql', 'python', 'statistics', 'software', 'data science', 'product management', 'anomaly detection', 'aws', 'epidemiology', 'data mining', 'machine learning', 'data products', 'testing', 'toolkit', 'live data', 'algorithms', 'computer science', 'mathematics']","['sql', 'python', 'san', 'documentation', 'big data', 'aws']","['data mining', 'machine learning', 'statistics', 'software', 'data products', 'testing', 'machine', 'epidemiology', 'data science', 'computer science', 'product management', 'anomaly detection', 'cleansing', 'mathematics', 'toolkit', 'statistical analysis', 'algorithms']","['customer success', 'environment', 'healthcare', 'regulations', 'design', 'life sciences', 'assessment', 'projection']"
288,370,Senior Data Scientist,"tiger analytics is looking for experienced data scientists to join our fast growing advanced analytics consulting firm. our consultants bring deep expertise in data science, machine learning and ai. we are the trusted analytics partner for multiple fortune 500 companies, enabling them to generate business value from data. our business value and leadership has been recognized by various market research firms, including forrester and gartner. we are looking for top notch talent as we continue to build the best global analytics consulting team in the world. as a data scientist, you will apply strong expertise in ai through the use of machine learning, data mining, and information retrieval to design, prototype, and build next generation advanced analytics engines and services. you will collaborate with cross functional teams and business partners to define the technical problem statement and hypotheses to test. you will develop efficient and accurate analytical models which mimic business decisions and incorporate those models into analytical data products and tools. you will have the opportunity to drive current and future strategy by leveraging your analytical skills as you ensure business value and communicate the results. key responsibilities collaborate with business partners to develop innovative solutions to meet objectives utilizing cutting edge techniques and tools. effectively communicate the analytics approach and how it will meet and address objectives to business partners. advocate and educate on the value of data driven decision making focus on the how and why of solutioning. lead analytic approaches integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts and developers. create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products. engineer features by using your business acumen to find new ways to combine disparate internal and external data sources. share your passion for data science with the broader enterprise community identify and develop long term processes, frameworks, tools, methods and standards. collaborate, coach, and learn with a growing team of experienced data scientists. stay connected with external sources of ideas through conferences and community engagements. requirements bachelors degree in data science, computer science, or related field 6 years of data science and machine learning experience required proficiency in python or r. ability to write complex sql queries proficiency with machine learning concepts and modeling techniques to solve problems such as clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets ability to implement ml best practices for the entire data science lifecycle ability to apply various analytical models to business use cases exceptional communication and collaboration skills to understand business partner needs and deliver solutions bias for action, with the ability to deliver outstanding results through task prioritization and time management experience with data visualization tools tableau, r shiny, etc. preferred benefits this position offers an excellent opportunity for significant career development in a fast growing and challenging entrepreneurial environment with a high degree of individual responsibility.","['data mining', 'sql', 'analytical skills', 'machine learning', 'python', 'tableau', 'information retrieval', 'data products', 'data visualization', 'data science', 'computer science', 'analytics', 'anomaly detection', 'optimization', 'modeling', 'r', 'ai']","['tableau', 'sql', 'python', 'r']","['data mining', 'analytical skills', 'machine learning', 'use cases', 'information retrieval', 'data products', 'data visualization', 'data science', 'computer science', 'analytics', 'anomaly detection', 'optimization', 'modeling', 'ai']","['environment', 'business value', 'design', 'market research', 'consulting', 'engagements']"
289,371,Senior Data Scientist,"the data science team is responsible for improving business operations and user experiences. billions of data points are recorded daily from our products. projects include content recommendation and surfacing engines, computer vision tasks, bidding systems, and credit card fraud detection among others. we seek a data scientist to help enhance our current projects and work on fascinating new projects. the ideal candidate should be experienced and interested in owning data driven projects from the first stages of research to the later stages of development and deployment. what you ll be doing research discover solutions to unique data science challenges while satisfying business needs develop and implement full solutions load and clean the data prepare and train the model deploy, monitor and maintain the solution what you ll need to be successful must haves phd in a quantitative stem field with an important data analysis component or msc. in a quantitative stem field with 3 years of experience as a data scientist strong programming skills in python and experience with machine learning tools strong knowledge of data science algorithms and their limitations experience dealing with very large datasets familiarity with database environments and functional sql knowledge experience with unix or linux environments good team player and open to give and receive constructive feedback ability to communicate clearly to non experts nice to haves understanding and or or familiarity with non interpreted programming languages experience with cloud providers data science side projects or kaggle competitions as an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees in this role you may be exposed to adult content","['sql', 'python', 'machine learning', 'linux', 'programming languages', 'datasets', 'computer vision', 'data science', 'unix', 'fraud detection', 'programming', 'data analysis', 'algorithms']","['sql', 'python', 'linux', 'programming languages', 'unix', 'programming']","['machine learning', 'datasets', 'computer vision', 'functional', 'data science', 'fraud detection', 'data analysis', 'algorithms']","['constructive feedback', 'environment', 'business operations']"
290,372,Data Engineer,"gamesys group is one of the world s leading gaming operators, with millions of players and 1500 employees. we believe passionately in what we do. quite simply, we craft entertainment with care, building trusted brands and creating great experiences that always put the player first. our award winning ventures including virgin, jackpotjoy, monopoly, heart and vera john are some of the best known in the industry. join us and you ll be joining a big, international group with some great brands and an exciting future. you ll feel part of one global family, working with smart people, and delivering a great experience for our players. there s one thing we expect from you, over and above everything else. be yourself. one of the values in our dna is stay wonderfully weird and that applies to all of us. gamesys plans to expand into new markets across north america . we are building a new technology team in toronto to accelerate the development of gamesys s internal excite gaming p latform , which will drive our growth across the usa and canada . we re looking for a hands on engineer with a passion for data to work alongside other developers, architects and machine learning engineers in an agile environment. you will be working in a team delivering batch and streaming data pipelines and services on our cloud data platform . you will work with data scrum team members, data architects, product owners and business analysts delivering elegant solutions and troubleshooting problems. you will get to work with large data sets and learn to apply the latest big data technologies on a range of cloud and on premise platforms. an interest or experience in the gaming industry is desirable. responsibilities coding resilient, scalable and elegant strategic solutions which are reusable and easily maintainable. peer reviewing other team member s code. cooperating with architects and other data engineers to develop technical designs and to propose solutions to key stakeholder requirements. attending stand ups with key stakeholders, communicating the status of development and raising any potential risks as early as possible. producing clear and concise documentation where required. attending training as required related to google cloud platform, etl and data pipelines generally. showing an interest in the gaming industry and in playing our games to understand the impact of data on the player experience. some 2nd line on call support. skills required strong sql or procedural sql or data warehousing experience. unix shell scripting experience. knowledge of tdd and ci or cd has worked in a team that adhered to agile principles. has demonstrated self motivation or pro activeness on a previous role. good communication skills, and an ability to explain work well to other team members. a keenness to understand how the technical task at hand translates into business value. someone who is not afraid to put forward ideas for improving team process or suggest new features to the product owner desired skills one or more of the following languages java, python. public cloud experience, google highly desirable. experience of data reporting or business intelligence solutions like tableau, data studio or cognos. experience or demonstrable interest in analytics and or or machine learning. experience with streaming technologies such as kafka, and rest apis. experience building data lakes. benefits we believe this process works both ways, so what can we do for you we offer some of the most competitive benefits in the market including continued personal growth, career development plans and performance bonus. we also believe in providing an environment where employees can flourish you ll be working in a very modern work environment and we will make sure you will also have enough time to unwind with our monthly office events and team building activities. t his is gamesys group and we re here to make gaming everything it should be. you ll have fun making fun every day, and that s a promise.","['tableau', 'ci', 'troubleshooting', 'documentation', 'big data', 'java', 'gaming', 'sql', 'agile environment', 'shell', 'python', 'cd', 'reporting', 'scripting', 'unix', 'data', 'analytics', 'data warehousing', 'machine learning', 'data pipelines', 'scrum', 'google cloud platform', 'business intelligence', 'rest', 'public cloud', 'etl']","['sql', 'shell', 'python', 'tableau', 'google cloud platform', 'unix', 'public cloud', 'documentation', 'big data', 'business intelligence', 'data lakes', 'java']","['agile environment', 'machine learning', 'data pipelines', 'cd', 'scrum', 'scripting', 'ci', 'reporting', 'troubleshooting', 'data', 'analytics', 'rest', 'data warehousing', 'etl', 'gaming']","['environment', 'events', 'business value', 'new markets', 'team building']"
291,373,Data Engineer,"as a leading mobile games developer, jam city is looking to level up our talent for our bingo team in toronto. we re on the hunt for innovators who consider themselves dynamic, collaborative and thrive in a fast paced environment. perks benefits unlimited vacation employer paid benefits parental leave and kin care rrsp matching in office lunch and snacks company events such as movie night, trivia, game shows more fitness allowance, training allowance, phone allowance more only applies to full time positions. about the role we re currently looking for a data engineer to join our jam city toronto team in this role, you will have the opportunity to work alongside a small team of talented individuals using cutting edge technologies to build top notch data pipelines and analytics tools. every day, we strive to break the mold, helping to create better experiences for our players. responsibilities enable our data centric approach to decisions via our in house data and service platforms. think across domains as we build and manage our infrastructure, automation pipelines, and data systems. play a meaningful role in our nimble yet disciplined approach to system architecture and team processes which empowers our small team to manage large systems. analyze and improve efficiency, scalability, and stability of various system resources. automate tasks and streamline processes to easily manage a growing server farm. participate in an on call schedule to ensure optimal uptime. our infrastructure is constantly evolving. you will have the opportunity to learn, build and suggest new tools qualifications passion for the tech industry. whenever there was a technology you did not understand, you ve researched to become familiar with it. enjoys collaborative work, challenging ideas, and being challenged. proven software engineering experience in building maintainable systems. expertise in at least some languages and tools like java, scala, python, docker, spark or hadoop, relational and document databases, and aws services in general. nice to have experience working at a gaming studio, or on games generally. knowledge of measuring, optimizing, and automating everything. strong system admin skills, including linux, networking, databases admin, security, and infrastructure as code tools. our commitment to equity, diversity, inclusion we believe in creating games that unite people across the world and that showcase our commitment to providing an environment that is both inclusive and diverse for our players and employees. we strive to create a workforce that is reflective of our global player community as we know that we are stronger and better when we play together. to help promote an inclusive culture, we celebrate the visible and invisible diversity of our jam citizens through initiatives including employee resource groups, cultural events, trainings, speaker series, and more. jam city is an equal opportunity employer. we enthusiastically accept our responsibility to make employment decisions without regard to race, age, sex , national origin, ancestry, religion, ethnicity, marital, or domestic partnerships status, disability, genetic information , predisposing genetic characteristics, military status, veteran status, domestic violence victim status, sexual orientation, gender identity or expressions, or any other classification protected by federal, state, and local laws. our management is committed to following this policy with respect to hiring, placement, promotion, transfer, demotion, layoff, termination, recruiting, pay, and other forms of compensation, training, and general treatment during employment. about jam city jam city is an award winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience. led by ceo chris dewolfe, former myspace co founder and ceo, and coo josh yguado, former 20th century fox executive, jam city is the creative powerhouse behind some of the highest grossing and most enduring mobile games. jam city s global franchise cookie jam has generated more than half a billion dollars, and panda pop has more than 120 million downloads to date. the company also is the go to studio for hollywood, having developed immersive, narrative rich mobile games around iconic entertainment brands. the company s popular rpg game harry potter hogwarts mystery was the 1 game in more than 40 countries at its launch in april 2018. jam city has nine studios located in los angeles , berlin, buenos aires, bogot , burbank, cedar falls, san diego, san francisco, and toronto. job type full time","['go', 'databases', 'linux', 'java', 'gaming', 'python', 'software', 'scala', 'uptime', 'analytics', 'aws', 'data systems', 'pipelines', 'data pipelines', 'automation', 'rpg', 'hadoop', 'security', 'system', 'scalability', 'networking', 'mobile games']","['go', 'python', 'databases', 'linux', 'scala', 'san', 'hadoop', 'aws', 'pipelines', 'java']","['rpg', 'data pipelines', 'software', 'security', 'uptime', 'system', 'scalability', 'large systems', 'analytics', 'maintainable', 'networking', 'data systems', 'mobile games', 'infrastructure as code', 'automation', 'gaming']","['environment', 'events', 'forms', 'employee resource groups', 'recruiting', 'compensation', 'hiring', 'architecture', 'cultural']"
292,374,Data Engineer,"why join us are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor if so, we would love to tell you our story. at omers we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in toronto, london, new york, singapore, sydney and other major cities across north america and europe. our culture is truly one of a kind. we get stuff done, and have fun doing it we take great pride in contributing to the communities where we live with an ever constant eye to the global investment markets. as a key member of the enterprise data advanced analytics team, the data engineer is passionate, down to earth, takes great pride in delivering next generation full stack solutions that meet and exceed our strategic business goals. driving innovation in the development of advanced capabilities, you are leading with a product management system thinking approach. the candidate will develop end to end data pipelines, with a focus on system integration and cloud to support omers decision makers and collaborate with a community of designers, product managers, data engineers and architects in ideation, design, development, testing, technical support, research and knowledge sharing through the implementation lifecycle. as a member of this team, you will be responsible for designing, d eploying and s ustaining scaled data pipelines to achieve a high level of reliability, scalability and security in supporting business objectives. sourcing, transforming and delivering structured and unstructured assets for use in azure databricks, synapse analytics, power bi, and more. operating in an agile development environment. communicating effectively with other engineers in the same team, with other teams and with various other partners such as product managers, data analysts, it infrastructure specialists, security specialists, enterprise architects and members of senior management. participating in solution build, delivery, support and troubleshooting. leading change and communicating impacts to business partners and fellow team members. exhibiting the ability to work on multiple projects simultaneously and ensuring delivery on time, within scope and within budget. participating in establishing sound data management practices for the team and the organization. identifying, defining and implementing opportunities for improving existing processes. defining and executing technical test plans, perform unit, performance and integration testing and automate regression testing. to succeed in this role, you have professional experience . 3 years solving complex technical data projects using the microsoft azure data stack or equivalent work experience is required . financial industry application is preferred. industry knowledge . the a bility to quickly propose azure data platform solutions by recalling the latest best practices learned from mvp product team articles, msft documentation, whitepapers, and community publications is required. relationship building . proven track record of building deep technical relationships. experience in aligning expectations across various partners . problem solving. the ability to trace data lineage or workflows and resolve technical issues with minimal direction . demonstrated proficiency in understanding and implementing business workflows is a plus. teamwork . motivated and keen to work in a collaborative environment with a focus on team success over and above individual success. technical enterprise scale technical experience with cloud and hybrid infrastructures, architecture designs, and technology management is required . breadth of technical experience and knowledge across the azure data platform, with depth or subject matter expertise in two or more of the following data platform resources is required azure data factory, dedicated synapse sql , azure databricks, azure functions using c , powershell or python, kubernetes and containerization experience automating ci or cd pipelines using azure devops or equivalent work experience is required . experience with the microsoft power platform is preferred . experience developing star schema reporting pipelines using kimball or data vault v2.0 methodologies . experience with gcp and bigquery is preferred. education bachelor s degree in an appropriate field of study or equivalent work experienc e candidates with microsoft azure certifications are desired our story founded in 1962, omers is one of canada s largest defined benefit pension plans, with 105 billion in net assets as at december 31, 2020. omers is a jointly sponsored pension plan, with 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. omers members include union and non union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children s aid societies across ontario. contributions to the plan are funded equally by members and employers. omers teams work in toronto, london, new york, amsterdam, luxembourg, singapore, sydney and other major cities across north america and europe serving members and employers and originating and managing a diversified portfolio of high quality investments in public markets, private equity, infrastructure and real estate. omers is committed to having a workforce that reflects the communities in which we live and work. we are an equal opportunity employer committed to a barrier free recruitment and selection process. at omers inclusion and diversity means belonging. how we create a sense of belonging is through our employees and our vast network of employee resource groups. whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","['ci', 'c', 'troubleshooting', 'powershell', 'documentation', 'containerization', 'microsoft azure', 'kubernetes', 'sql', 'python', 'regression', 'gcp', 'cd', 'reporting', 'product management', 'analytics', 'integration', 'data', 'pipelines', 'data pipelines', 'testing', 'sourcing', 'vault', 'enterprise data', 'microsoft power', 'technology management', 'bi', 'devops', 'security', 'system', 'scalability', 'mvp', 'schema', 'data management']","['kubernetes', 'sql', 'python', 'azure', 'microsoft power', 'gcp', 'azure data', 'bi', 'c', 'mvp', 'azure databricks', 'powershell', 'documentation', 'azure data factory', 'azure functions', 'containerization', 'pipelines', 'microsoft azure']","['data lineage', 'ci', 'technical support', 'troubleshooting', 'regression', 'cd', 'reporting', 'product management', 'analytics', 'integration', 'data', 'un', 'data pipelines', 'testing', 'sourcing', 'agile development', 'vault', 'enterprise data', 'technology management', 'devops', 'security', 'system', 'scalability', 'data management']","['utilities', 'environment', 'education', 'design', 'electrical', 'real estate', 'employee resource groups', 'investments', 'private equity', 'architecture']"
293,375,Data Quality Analyst,"abcellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a motivated and dynamic data quality analyst to join our data management team, where they will work closely with a highly proficient team of lab scientists, data scientists, and software developers to maintain high data quality levels through extensive data quality rules implementation, wrangling and testing activities, and data analysis. the role will focus on understanding data lifecycle and data transformation layers within various data pipelines and advancing data quality best practices throughout the company. contributions by the successful candidate will help build automated data quality management solutions that meet the needs of a rapidly growing and innovative company today and in the future. the successful candidate will be at ease with ambiguity and change, embracing the opportunities and challenges that a quickly evolving and dynamic work environment presents. how you might spend your days developing, operationalizing, and maintaining automated data profiling and dq processes. ensuring dq rules are accurately built using validation tools or custom scripts developing in depth understanding of source systems and edw data structures to further define rules. tracking, investigating, and analyzing the root cause of dq issues, ensuring dq issues and remediation plans are communicated to all data stewards. engaging with and supporting the data stewards and other internal stakeholders, as required, to correct and or or remediate dq issues in systems of record based on business priorities. engaging data stewards and other internal stakeholders to develop and implement data wrangling scripts, dq tests, dq reports and identify defects using dq rules based on prescribed dq dimensions. evaluating the impact of system performance and design on dq. collaborating with data engineers and database administrators to improve data collection and storage processes. documenting processes and maintaining data records. keeping abreast of developments and trends in data quality analysis we d love to hear from you if you have a bachelor s degree in quantitative areas such as computer science, mathematics, statistics, or related fields. minimum 3 years of related experience in data quality management, data analysis and etl procedures with a s trong understanding of data quality monitoring procedures hands on experience writing complex sql queries, including extensive experience querying large, complex datasets demonstrated knowledge of data management and data governance principles and practices. hands on experience writing rest apis experience in one or more programming languages, preferably python . familiarity with data visualization software package such as power bi exceptional analytical and conceptual thinking skills.the ability to work closely with stakeholders to determine acceptable solutions. excellent documentation, organization, and communication skills. experience creating detailed reports and presentations. excellent planning, organizational, and time management skills. competency in microsoft applications including word, excel, and powerpoint. competency in google workspace applications . preferred qualifications familiarity with native aws technologies for data and analytics such as redshift spectrum, athena, s3, lambda, glue, emr, kinesis, sagemaker, etc. or equivalent relevant technologies experience utilizing data quality tools such as talend, informatica data quality, etc. knowledge of data sourcing from nosql databases familiarity with or previous experience in the biotechnology industry offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research, and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21234 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['databases', 'system performance', 'emr', 'data visualization', 'data profiling', 'root cause', 'documentation', 'remediation', 'microsoft applications', 'sql', 'python', 'glue', 'statistics', 'software', 'talend', 'data', 'analytics', 'aws', 'nosql', 'informatica', 'machine learning', 'data pipelines', 'data transformation', 'testing', 'sourcing', 'data collection', 'data analysis', 'data quality', 'rest', 'athena', 'automation', 'data structures', 'programming languages', 'bi', 'data wrangling', 'datasets', 'high throughput', 'computer science', 'mathematics', 'data management', 'etl']","['microsoft applications', 'sql', 'python', 'glue', 'databases', 'programming languages', 'emr', 'bi', 'google workspace', 'data', 'documentation', 'aws', 'data quality', 'athena', 'nosql', 'system performance']","['data visualization', 'data profiling', 'root cause', 'remediation', 'statistics', 'tests', 'software', 'data', 'analytics', 'informatica', 'machine learning', 'data pipelines', 'data transformation', 'testing', 'sourcing', 'data collection', 'data analysis', 'rest', 'automation', 'planning', 'data structures', 'data wrangling', 'datasets', 'high throughput', 'computer science', 'mathematics', 'data management', 'etl']","['validation', 'environment', 'microfluidics', 'biotechnology', 'antibodies', 'genomics', 'design', 'presentations', 'governance', 'compensation', 'tale', 'developments']"
294,376,Senior Data Scientist - Toronto Hub,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or in our toronto office it s up to you. veeva is looking for an all star senior data scientist to join the vault outside life science team. we re looking for a high energy, passionate individual with a deep technical background who is eager to drive product advancement and innovation. in this role, you will be responsible for creating game changing products in the manufacturing industries such as consumer packaged goods, chemical, and cosmetics. if you have a passion for creating world class products and enjoy solving complex problems with simple, elegant solutions, you may be a good fit for this position. what you ll do be involved in sales discussions, potentially fueling the conversation about what ai can do and bringing clarity to the discussion work with customers and implementation teams to build out custom solutions build pocs with aws assistance and consulting pms on opportunities be hands on. design, prototype, configure validate solutions rapidly to ensure we solve the right problems, in the right order be a storyteller. author design high quality specifications and communicate specific, actionable requirements to your engineering teammates be a leader. look for opportunities to innovate, keep up with the latest software, machine learning, manufacturing industries trends, and distill them into product requirements be agile. design, implement, iterate take pride in your work requirements 2 years of software development or architect, product management, or technical consulting role in ai 5 years of professional work experience in agile software development environments demonstrated skills in design, product development, and planning ability to work independently in a fast paced environment, with little direct supervision excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to engineering and customers degree in computer science or engineering experience with ai and machine learning models experience with natural language processing qualified candidates must be legally authorized to be employed in canada. veeva does not provide sponsorship of employment visa for this position. nice to have experience working in the following industries consumer packaged goods, chemical and cosmetics experience working on saas enterprise applications or content management systems experience with api and data exchange schemas experience with data migration experience with search matching algorithms and heuristics experience with python, sql, xml, and json perks benefits conveniently located in downtown toronto snacks, beverages, and weekly lunches from local restaurants team events and rec league sports teams allocations for continuous learning development health wellness programs weekly yoga classes ping pong and other games li remote veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['schemas', 'sql', 'python', 'software', 'json', 'software development', 'enterprise', 'product management', 'saas', 'aws', 'machine learning', 'data migration', 'specifications', 'agile', 'vault', 'algorithms', 'data exchange', 'language processing', 'technical', 'api', 'computer science', 'xml', 'ai']","['sql', 'python', 'san', 'json', 'api', 'aws', 'xml']","['schemas', 'natural', 'software', 'management systems', 'software development', 'product management', 'saas', 'machine learning', 'data migration', 'specifications', 'agile', 'vault', 'algorithms', 'planning', 'data exchange', 'language processing', 'technical', 'computer science', 'ai']","['customer success', 'environment', 'events', 'regulations', 'design', 'sales', 'life sciences', 'sponsorship', 'consulting', 'content', 'product development', 'manufacturing']"
295,378,Associate Scientist - Synthetic Organic/ Medicinal Chemistry,"about admare bioinnovations admare bioinnovations is canada s global life sciences venture, building the canadian life sciences industry from sea to sea. we do this by sourcing therapeutically and commercially promising research from leading academic and biotech partners to create new companies of scale, providing specialized expertise, infrastructure, and capital to help existing companies scale up, and driving the growth of those companies into canadian anchors by training the next generation of highly qualified personnel. admare s 20 portfolio companies have attracted more than 1.2b of investment and have a combined worth of over 3b. job summary we are seeking highly motivated phd and msc level synthetic organic and or or medicinal chemists to join our drug discovery team. associate scientists positions are available to join our montreal facility. highly qualified individuals are expected to have experience in modern organic synthesis with good laboratory skills and a record of high productivity. key requirements of the role include being able to work within a team structure, propose new targets, execute synthetic routes, engage in troubleshooting exercises as needed, and effectively communicate with biology, pharmacology and dmpk colleagues. associate scientists are expected to demonstrate laboratory and scientific proficiency, creativity and a willingness to work in a dynamic group environment. the associate scientist is expected to carry out multistep organic synthesis, purification, and characterization of new molecules. the candidate will be part of a research team and will be expected to interpret sar and adme data and contribute to the design of new targets and to the chemistry strategy. we are a dynamic team that fosters a positive, curiosity driven culture that encourages everyone to contribute intellectually and experimentally to solving complex challenges in drug discovery. we have state of the art laboratories, and we promote a cross functional research environment where colleagues form chemistry, biology, pharmacology and dmpk work closely together to advance drug discovery projects. we offer flexible working hours, competitive salaries, bonuses and benefit package. key duties and responsibilities proficiency in modern organic synthesis and ability to independently perform complex, multi step procedures. experience in the purification of small molecules using a variety of methods such a flash chromatography, hplc purification, distillation and others as needed. structural characterization of small molecules using modern spectroscopic instruments and techniques such as lc ms, 1 and 2d nmr methods and others. contributes signi cantly to patent and or or publication preparation. independently prepares project presentations and presents experimental conclusions at group or department or project team research meetings. interprets sar and adme data and able to propose new targets to address chemistry and or or project issues stays abreast of scientific literature and incorporates new methods and technologies in his or her research. performs other duties as assigned. education and experience ph.d. in chemistry or medicinal chemistry, or master s degree in chemistry or medicinal chemistry with 3 years of relevant employment experience at admare, we are driven by our vision and united by our shared values of courage, collaboration, objectivity, judgment, excellence, and reach. we are committed to growing the talent and potential of our people to drive the development of innovations. we provide a community where you can work with multidisciplinary individuals, explore new ways of thinking, and expand your capabilities through the array of development programs we offer our employees. admare is a diverse community where employees feel a sense of belonging and are valued for the experience and unique perspectives they bring. be a part of life at admare. join our team propos d admare bioinnovations admare bioinnovations est le partenaire d affaires en sciences de la vie au canada, en soutien l industrie d un oc an l autre. pour ce faire, nous identifins aupr s de partenaires acad miques et biotechnologiques de premier plan les d couvertes les plus prometteuses sur les plans th rapeutique et commercial afin de cr er de nouvelles entreprises d envergure. nous fournissons une expertise et les infrastructures ad quates dans le but d aider les entreprises existantes se d velopper, en favorisant leur croissance afin qu elles deviennent des piliers canadiens tout en formant la prochaine g n ration de personnel hautement qualifi . le portefeuille d admare, qui compte pr s de 20 soci t s, a g n r plus de 1,2 milliard de dollars d investissements et repr sente une valeur totale de plus de 3 milliards de dollars. r sum du poste nous sommes la recherche de chimistes organiques synth tiques et or ou m dicinaux poss dant un doctorat ou une ma trise en sciences qui aimeraient faire partie de notre quipe de d couverte de m dicaments. les postes de scientifiques associ s disponibles sont offerts dans nos installations de montr al. les individus tr s qualifi s devraient poss der une exp rience en synth se organique moderne et des aptitudes marqu es en laboratoire en plus d avoir d montr une capacit de productivit lev e. les principales exigences du poste consistent, entre autres, pouvoir fonctionner au sein d une quipe, proposer de nouvelles cibles, suivre une voie de synth se, participer des exercices de diagnostic des pannes en fonction des besoins et communiquer de mani re efficace avec des coll gues dans les domaines, comme la biologie, la pharmacologie, ainsi que le m tabolisme des m dicaments et pharmacocin tique. les scientifiques associ s devront d montrer une ma trise des techniques en laboratoire et dans le domaine scientifique, de la cr ativit et la volont de travailler dans un environnement de groupe dynamique. le scientifique associ devra r aliser une synth se organique en plusieurs tapes, la purification et la caract risation des nouvelles mol cules. le candidat fera partie d une quipe de recherche et devra interpr ter les donn es sur les rapports structure activit et les donn es des tudes absorption distribution m tabolisme excr tion et contribuer la d finition de nouvelles cibles et la strat gie relative aux produits chimiques. nous sommes une quipe dynamique qui favorise une culture positive et ax e sur la curiosit en plus d encourager tout un chacun contribuer sur le plan intellectuel et par des exp riences relever des d fis complexes dans le domaine de la d couverte des m dicaments. nous poss dons des laboratoires ultramodernes et nous encourageons un environnement de recherche interfonctionnel o les coll gues dans les domaines, comme la chimie, la biologie, la pharmacologie et le m tabolisme des m dicaments et pharmacocin tique travaillent en troite collaboration pour favoriser les projets de d couverte de m dicaments. nous offrons des heures de travail flexibles, des salaires concurrentiels, des bonis et un programme d avantages sociaux. t ches et responsabilit s principales ma trise de la synth se organique moderne et capacit de r aliser de mani re ind pendante des proc dures complexes comportant plusieurs tapes. exp rience dans la purification de petites mol cules en ayant recours des m thodes vari es, comme la chromatographie rapide sur colonne, la purification clhp, la distillation et autres en fonction des besoins. caract risation structurale des petites mol cules en faisant appel des instruments et des techniques de spectroscopie modernes, comme les m thodes lc ms 1 et rmn 2d. contribuer grandement la pr paration des brevets et or ou des publications. pr parer de mani re ind pendante des pr sentations de projet et pr senter les conclusions des exp riences lors des r unions de groupe or service ou des r unions de recherche des quipes de projet. interpr ter les donn es sur les rapports structure activit et les donn es des tudes absorption distribution m tabolisme excr tion, et proposer ensuite de nouvelles cibles visant r soudre les probl mes de nature chimique et or ou en lien avec les projets. se tenir au fait de la documentation scientifique et int grer les m thodes et les technologies nouvelles ses recherches. r aliser d autres t ches sur demande. ducation et exp rience doctorat en chimie ou en chimie m dicinale ou ma trise en chimie ou en chimie m dicinale et au moins 3 ann es d exp rience de travail pertinente. chez admare, nous sommes motiv s par notre vision et unis par nos valeurs communes que sont le courage, la collaboration, l objectivit , le jugement, et l excellence. nous sommes d termin s accro tre le talent et le potentiel de nos employ s lorsqu il s agit de promouvoir l innovation. nous offrons une communaut o vous pourrez voluer aux c t s d employ s multidisciplinaires, explorer de nouvelles m thodes de r flexion et accro tre vos capacit s gr ce l ventail des programmes de perfectionnement que nous offrons nos employ s. admare est un univers diversifi o les employ s prouvent un sentiment d appartenance et o ils se sentent valoris s en raison de l exp rience et des points de vue uniques qu ils apportent. venez participer la vie chez admare. faites partie de notre quipe","['troubleshooting', 'documentation', 'sourcing', 'chemistry']",['documentation'],"['di', 'sourcing', 'chemistry', 'troubleshooting', 'installations']","['pharmacology', 'purification', 'environment', 'project', 'team research', 'biology', 'characterization', 'capital', 'education', 'design', 'life sciences', 'art', 'presentations', 'scientific literature', 'chromatography', 'drug discovery', 'hplc']"
296,379,Data Engineer,"on the data engineer skillsets, here are the must have skills azure data factory azure data lake azure kubernetes azure blob storage azure databtricks sql python or c nice to have azure event hub azure iot hub azure devops computer science and statistics backgrounds will be a huge bonus to the work we do for turing impjob job types full time, permanent schedule monday to friday experience data engineer 8 years","['kubernetes', 'sql', 'python', 'statistics', 'iot', 'devops', 'c', 'computer science']","['kubernetes', 'sql', 'azure', 'python', 'c', 'azure data factory', 'iot hub']","['computer science', 'devops', 'statistics']",[]
297,380,Environmental Lead Scientist,"salary 40.00 or hourly job type full time, permanent start date as soon as possible language english minimum education bachelor s degree positions available 4 noc group natural and applied science policy researchers, consultants and program officers noc job title environmental consultant expires in 9 days expires 2021 06 30 posted 2021 04 07 last updated 2021 05 31 job location port moody, british columbia fort st. john, british columbia job description as the environmental lead scientist, you are responsible for assisting the environmental project manager to plan and complete a project. you may be responsible for project budgets, timelines, deliverables, field completion of advanced programs and preparation of technical reports. you will maintain direct connection to the field staff, and work in the field may be required as determined by each project. you will provide direction to the environmental scientist and report to the environmental project manager or environmental account manager. your key responsibilities provide an exceptional client experience consistent with synergyaspen standards. manage project s contract documents, drawings, specifications, and scope of work. support field operations in aspects which may include cost controls, planning, scheduling, and estimating. complete technical report writing and signature on factual technical reports. maintain current knowledge with governing regulatory bodies as it applies to the ogc, meccs. manage data and file compilation for internal and client databases. maintain billable targets as set by supervisor. coordinate with and manage contractors. coordinate and facilitate successful project deliverables. what you offer to synergyaspen energy, intelligence, and integrity. your drive for exceptional client experience is relentless. reliable attention to detail, remarkable accuracy, and professional organizational skills. excellent communication, technical writing, and problem solving skills. demonstrate our corporate values and behaviours. you have knowledge of project execution activities such as planning, project controls, scheduling, and costing. collaborate successfully with your team on various projects of differing complexity. communicate and work effectively with environmental subcontractors. ability to work outside in adverse weather conditions, when required travel for work in potentially remote locations, as needed, according to project demands. b.sc. or m.sc. in a related discipline. registration, or eligibility to register as a professional eit, git, ait, bit, cet. minimum of 4 years industry experience experience in contaminated sites, natural sciences, and reclamation, with preference given to candidates with practical knowledge of bc ogc regulatory guidelines. proficiency in microsoft windows, office, and teams. proficiency with android or ios. what synergyaspen offers to you autonomy, an opportunity to expand your expertise, and work for a company with integrity of purpose. competitive compensation and comprehensive extended health benefits. flexible work hours and remote work options. pet friendly offices. business casual dress code. eligibility for educational and professional membership dues reimbursements. related document lead scientist posting.pdf how to apply expiring jun 30, 2021 email","['databases', 'android', 'git', 'windows', 'compilation', 'specifications', 'ios', 'technical writing', 'technical reports']","['databases', 'eit', 'android', 'git', 'windows', 'ios']","['report', 'specifications', 'technical reports compilation', 'technical writing', 'technical reports', 'planning']","['education', 'regulatory guidelines', 'dues', 'compensation', 'environmental', 'field operations', 'noc']"
298,381,Senior Data Scientist,"about securityscorecard funded by world class investors including silver lake waterman, moody s, sequoia capital, gv, riverwood capital, and others with over 290 million in funding, securityscorecard is the global leader in cybersecurity ratings and the only service with over 2m companies continuously rated. founded in 2013 by security and risk experts dr. aleksandr yampolskiy and sam kassoumeh, securityscorecard s patented rating technology is used by over 16,000 organizations for enterprise risk management, third party risk management, board reporting, due diligence, and cyber insurance underwriting. this is done by measuring your and your vendors cyber health by assigning a security rating of a through f based on outside in, non intrusive data. securityscorecard continues to make the world a safer place by transforming the way companies understand, improve and communicate cybersecurity risk to their boards, employees, and vendors. securityscorecard is headquartered in nyc with over 260 employees globally. our culture has helped us be recognized by inc magazine as a best workplace, best places to work in nyc by crain s ny, and one of the 10 hottest saas startups in ny for two years in a row. about the team the ds team at securityscorecard is composed of highly motivated professionals with diverse technical backgrounds spanning from physics to neuroscience. the team maintains a collaborative style encouraging shared learning, mentoring, and cross team communication and support of other company departments. projects span a wide range from crafting queries to support marketing research to applying advanced machine learning techniques to improve accuracy and draw new insights on cybersecurity risk, to developing ai based capabilities to unlock new functionality that help our users assess and reduce their cybersecurity risk. what you will do we re looking for data scientists to work on our core products to develop new analtyics based on ml and ai.. you will work with one of the largest sets of cybersecurity data in the world, and turn your insights into product enhancements on a continuous basis. the ideal candidate will be a self starter with an advanced degree and background working with data in a quantitative or technical field, experience working with big data, and a proven record in machine learning, from concept development to proof of concept to final implementation. basic qualifications 4 years experience in data science. 4 years of experience manipulating large data sets through sql or python experience with neural network and natural language processing with large data sets. 1 year experience in big data technologies like spark excellent understanding of machine learning techniques and algorithms qualifications proven ability to take a project from concept stage to proof of concept to production team player phd or master s in a technical field preferred experience with common data science toolkits and libraries benefits we offer a competitive salary, stock options, a comprehensive benefits package, including health and dental insurance, unlimited pto, parental leave, tuition reimbursements, and much more securityscorecard embraces diversity. we believe that our team is strengthened through hiring and retaining employees with diverse backgrounds, skillsets, ideas, and perspectives. we make hiring decisions based upon merit and do not discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.","['sql', 'due diligence', 'machine learning', 'python', 'language processing', 'cybersecurity', 'proof of concept', 'reporting', 'physics', 'security', 'data science', 'saas', 'neuroscience', 'big data', 'algorithms', 'ai']","['sql', 'python', 'big data']","['due diligence', 'machine learning', 'language processing', 'cybersecurity', 'proof of concept', 'reporting', 'physics', 'security', 'data science', 'saas', 'natural', 'neuroscience', 'data sciencekit', 'algorithms', 'ai']","['underwriting', 'marketing research', 'capital', 'risk management', 'enterprise risk management', 'functionality', 'startups', 'hiring', 'insurance', 'mentoring']"
299,382,Senior Data Scientist,"h lmetrics is a growing data analytics company in calgary, alberta, seeking to make a difference in the lives of millions of people every day. using machine learning, h lmetrics provides a deep insight into the wellbeing of employees and organizations. h lmetrics helps organizations reduce costs associated with turnover and disengagement, reduce risk around mental health injury, promote healthy workplace culture, and helps companies attract and retain great talent. day to day responsibilities contribute in defining vision and strategy for science aspects of the engineering department innovative solution proposal to translate customer needs into technical specifications constant r d to increase reliability and effectiveness of the product assist in the design and management of data pipelines to ensure proper execution, data cleanliness, and statistical significance of results design and build machine learning models to find patterns across disparate data sources, discover relationships, and test hypotheses work closely with our product team to determine the best course of action for the development technical requirements strong background and professional experience in data science and software development professional experience in all phases of machine learning projects including designing data pipelines, preprocessing mechanisms , modelling, refinement, and deployment strong python programming knowledge and experience in working with data analysis libraries, like pandas, numpy, scikit learn, and data visualization libraries experience in data engineering practices along with strong sql knowledge experience in developing statistical ml models and deep neural networks with strong understanding about underlying statistics experience with cloud computing services and ability to architect solutions by them familiarity with nlp main concepts experience in git, version control, and ci or cd soft skills ability to lead other data scientists, communicate effectively, and determine priorities ability to learn about cutting edge technologies, adapt, discover and test new ideas desire to work in a fast paced and collaborative startup environment","['ci', 'data visualization', 'technical requirements', 'data analytics', 'python', 'sql', 'statistics', 'cd', 'data science', 'software development', 'pandas', 'programming', 'pipelines', 'data engineering', 'cloud computing', 'machine learning', 'data pipelines', 'numpy', 'specifications', 'data analysis', 'neural networks', 'nlp', 'git', 'version control']","['sql', 'python', 'sci', 'numpy', 'nlp', 'git', 'pandas', 'programming', 'pipelines', 'r']","['data analytics', 'machine learning', 'statistics', 'data pipelines', 'cd', 'neural networks', 'data visualization', 'data science', 'ci', 'software development', 'technical requirements', 'specifications', 'data', 'data analysis', 'data engineering', 'version control', 'cloud computing']","['mental health', 'environment', 'design', 'turnover']"
300,383,Machine Learning Scientist - Sequence Space,"abcellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a machine learning scientist sequence space to join our rapidly growing machine learning team. we are a group of motivated people who work in collaboration with life scientists to constantly improve our discovery pipeline. we have a multi faceted antibody discovery and characterization pipeline that is able to rapidly discover next generation antibody therapies. our pipeline generates an immense amount of valuable data which can be used to further develop our pipeline through state of the art machine learning techniques. ultimately, we are all working towards a common goal which we strongly believe will make the world a better place. come join abcellera and help bring new therapeutics to patients around the world how you might spend your days develop nlp style sequence models to automate and improve our drug discovery pipeline investigate data in creative ways to pull out exciting trends and discover useful features work on novel research and development projects to expand our capabilities optimize machine learning and data science pipelines with a focus on scalability work collaboratively with life scientists, bioinformaticians, and software engineers shepherd your machine learning projects from inception all the way through to in house production use we d love to hear from you if bachelor s degree 8 years of work experience in machine learning and or or data science, or master s degree 7 years of work experience in machine learning and or or data science, or phd 5 years of work experience in machine learning and or or data science experience developing production grade machine learning models experience dealing with big data expert in bioinformatics, nlp, tensorflow or keras or pytorch etc. python expertise strong ability to present work and communicate ideas to technical and non technical coworkers a strong desire to work in a collaborative, multidisciplinary environment offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21214 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['python', 'machine learning', 'keras', 'software', 'bioinformatics', 'pytorch', 'tensorflow', 'high throughput', 'data science', 'scalability', 'nlp', 'big data', 'pipelines', 'automation']","['python', 'keras', 'pytorch', 'nlp', 'big data', 'pipelines']","['machine learning', 'software', 'bioinformatics', 'tensorflow', 'high throughput', 'data science', 'scalability', 'micro', 'automation']","['environment', 'characterization', 'antibodies', 'immune', 'genomics', 'art', 'development projects', 'therapeutics', 'compensation', 'drug discovery']"
301,384,Data Engineer/Tableau Developer,"we are looking for a savvy big data engineer or tableau developer to join our growing team of enterprise data and advanced analytics platform. the ideal candidate is an experienced data wizard who enjoys engineering data pipelines within the data lake and building impactful visualizations using tableau. the candidate must have strong business acumen who enjoys working with diverse business lines to on board data into the data lake and then develop visualizations and insights with the data. they must be self directed and comfortable supporting the data needs of multiple teams, systems and products. this role will report into the manager of enterprise data platform. responsibilities create and maintain optimal data pipeline architecture to on board data into the data lake. assemble large, complex data sets that meet functional or non functional business requirements. enhance the existing and build new data pipelines to extract transform data for business users to build data analytics practice established development disciplines such as good code management, branching and merging of code in a git repository. has relevant and highly developed professional and technical skills experienced level of knowledge in field of expertise and strong knowledge of business or context apply tableau development capabilities to transform raw data into relevant information, and help internal clients visualize their data. analyze data, using measurement techniques, drafting kpis and building reports and dashboards to address business questions. partner with business and data quality team members to design relevant data visualizations using tableau and work with team members to build dashboards for data quality and analysis work with subject matter experts and stakeholders to understand business problems and business requirements. translate business requirements into functional use cases to solve business problems support tmx internal or external users for application related inquiries 24 or 7 on call support on a rotational basis qualifications and technical skills university degree, college diploma or relevant job experience in computer science, statistics or mathematics at minimum 5 years of overall it experience and 3 years in big data development or design including the following hadoop ecosystem components hdfs, hive, sqoop, flume, pig, kafka, spark or spark sql, oozie, hue and java programming experience working with big data development platforms like zaloni, talend, pentaho, cloudera is key to this role 3 years experience, beginner to intermediate, working with data visualization tools such as tableau a high degree of competency using sql queries to extract and manipulate complex nested unstructured data, including the ability to use aggregate functions, subqueries, ctes, and window functions. relational database experience understanding of data modeling concepts and sql performance tuning experience with development using agile methodologies good understanding of aws cloud technology and hadoop implementation on aws including s3, ec2 and emr experience in python, scala, ranger is required experience in performance tuning hive tables is required experience in the configuration of yarn, mapreduce for performance, security is a plus experience designing a technology stack for machine learning is a plus basic understanding of statistical concepts is an asset must have excellent interpersonal and communication skills strategic thinker ability to multitask excellent analytical and problem solving skills strong analysis or design experience meticulous attention to detail must be a self starter with ability to follow through on projects assigned tmx is committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and one which reflects the diversity of the community in which we operate. we provide accommodations for applicants and employees who require it.","['unstructured data', 'tableau', 'emr', 'dashboards', 'data visualization', 'big data', 'pentaho', 'hive', 'java', 'performance tuning', 'data analytics', 'sql', 'python', 'statistics', 'scala', 'talend', 'analytics', 'programming', 'data', 'aws', 'machine learning', 'data pipelines', 'data quality', 'enterprise data', 'agile methodologies', 'sqoop', 'hadoop', 'security', 'git', 'computer science', 'mathematics', 'modeling']","['sql', 'python', 'sqoop', 'tableau', 'emr', 'scala', 'hadoop', 'talend', 'git', 'programming', 'big data', 'aws', 'data quality', 'pentaho', 'hive', 'java', 'big data development']","['unstructured data', 'agile methodologies', 'data analytics', 'use cases', 'statistics', 'data pipelines', 'machine learning', 'dashboards', 'data visualization', 'security', 'computer science', 'analytics', 'mathematics', 'data', 'modeling', 'performance tuning', 'enterprise data']","['subject matter experts', 'environment', 'design', 'internal', 'business', 'development disciplines', 'architecture']"
302,385,"Manager, Data Science","job description this role will start off as work from home, gradually you will be required to work in the markham or toronto office location. join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive impactful decisions. the insurance industry has entered a period of unprecedented change, disruption and rapid technological development. aviva recognizes that in this rapidly changing environment building a distinctive capability in data science is critical demonstrating this commitment through the development of our data science practice. this team is exploring the frontiers of the insurance business such as how to harness the data from connected cars to deliver new types of products to customers. this exciting role is at the heart of a high performing data science team that is transforming aviva in the digital age. here, we are creating a long lasting legacy and optimizing every customer s experience. as a data science manager, you will lead a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. you will lead the development of machine learning and statistical models for practical applications that impacts millions of customers. you will manage and guide your peers in novel approaches and provide peer review for their work. what you ll do lead a squad of actuaries, data scientists and engineers in the development of meaningful conclusions and recommendations oversee the development of high performing machine learning and statistical models on very large datasets oversee the development of novel algorithms and innovative data driven solutions to solve business problems help the team excel in the assigned business domain what you need to succeed as a manager, you will need the following skills and experience to succeed in the role experience managing a data science team a teacher of technology and business in a team setting demonstrated ability to mentor team members in all aspects of their duties, communications and leadership serve as an expert throughout the full ds product lifecycle, from inception to delivery and ongoing monitoring university degree in computer science, math, statistics, physics, actuarial science or related field or equivalent. masters or phd strongly preferred 2 3 years of programming experience preferably in python with strong grasp of software engineering standard methodologies such as code reusability, modularity, use of repos, etc. 3 5 years of experience of building machine learning models for business applications advanced level understanding of machine learning fundamentals and model development principles 3 5 years experience with ml or ai technologies, such as scikit learn, keras. tensorflow, pytorch experience mining iot sensor data or telematics data will be considered an asset experience with big data technologies such as spark, databricks, scala will be considered an asset what sets you apart experience leading all stages of data science problem definition, data acquisition wrangling, modelling, feature engineering and deployment. amazing people skills and able to translate and communicate complex algorithms to non technical individuals. someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners. experience leading or working as part of an agile team additional information aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation.","['telematics', 'pytorch', 'tensorflow', 'big data', 'forefront', 'python', 'statistics', 'keras', 'data acquisition', 'software', 'scala', 'physics', 'data science', 'programming', 'machine learning', 'iot', 'algorithms', 'model', 'datasets', 'computer science', 'ai']","['python', 'forefront', 'keras', 'scala', 'pytorch', 'iot', 'programming', 'big data']","['model', 'data acquisitionang', 'machine learning', 'statistics', 'telematics', 'software', 'physics', 'datasets', 'sci', 'tensorflow', 'data science', 'computer science', 'algorithms', 'feature engineering', 'ai']","['actuaries', 'environment', 'actuarial', 'insurance industry', 'business applications', 'hiring', 'insurance']"
303,387,Data Engineer - TW,"the role is going to be data engineer with our client thoughtworks. please find below the job description for the position. please send the following documents to if that interests you and matches your profile. without mandatory documents, we cannot submit a candidate. 1. updated resume in word format 2. skill summary duration 6 months contract with a possibility of extension. job description data engineers develop modern data architecture approaches to meet key business objectives and provide end to end data solutions. you might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. on other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. it could also be a software delivery project where you re equally happy coding and tech leading the team to implement the solution. you ll spend time on the following you will partner with teammates to create complex data processing pipelines in order to solve our clients most ambitious challenges you will collaborate with data scientists in order to design scalable implementations of their models you will pair to write clean and iterative code based on tdd leverage various continuous delivery practices to deploy, support and operate data pipelines advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available develop and operate modern data architecture approaches to meet key business objectives and provide end to end data solutions create data models and speak to the tradeoffs of different modeling approaches seamlessly incorporate data quality into your day to day work as well as into the delivery process here s what we re looking for you have a good understanding of data modelling and experience with data engineering tools and platforms such as kafka, spark, and hadoop you have built large scale data pipelines and data centric applications using any of the distributed storage platforms such as hdfs, s3, nosql databases and any of the distributed processing platforms like hadoop, spark, hive, oozie, and airflow in a production setting hands on experience in mapr, cloudera, hortonworks and or or cloud based hadoop distributions you are comfortable taking data driven approaches and applying data security strategy to solve business problems you re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments working with data excites you you can build and operate data pipelines, and maintain data storage, all within distributed systems assure effective collaboration between thoughtworks and the client s teams, encouraging open communication and advocating for shared outcomes ytridv9rrz","['computing', 'databases', 'data infrastructure', 'distributed systems', 'hive', 'data processing', 'software', 'data', 'data models', 'pipelines', 'data engineering', 'nosql', 'data pipelines', 'continuous delivery', 'data quality', 'airflow', 'hadoop', 'data solutions', 'security', 'modeling']","['hadoop distributions', 'databases', 'pipelines', 'hadoop', 'data', 'data models', 'data quality', 'hive', 'nosql', 'map', 'airflow']","['computing', 'data processing', 'data pipelines', 'continuous delivery', 'software', 'distributed storage', 'data infrastructure', 'data solutions', 'security', 'data storage', 'distributed processing', 'data', 'modeling', 'distributed systems', 'data engineering']","['design', 'architecture', 'acting']"
304,388,Data Engineer,"we are looking for a data engineer to handle all our data operations. the hire will be responsible for collecting data, as well as connecting sources and providing data analysis for cross functional teams. the ideal candidate must be self directed and capable of supporting the data needs across our marketing platforms. this position is 100 remote and only eligible for those who are authorized to work in canada. key responsibilities create mysql queries to retrieve metrics from our database work with bigquery to create a data pipeline use tray.io to fetch, unify and push data create dashboards in our bi tool manage properties from intercom and hubspot that need to be fetched and pushed create a system to monitor and keep data organized job benefits profit sharing, distributed 3 times a year frequent promotions 3 weeks vacation and paid sick days happy hour every friday extended health benefits continued education allowance annual fitness allowance work from anywhere in the world join a bootstrapped, product focused, customer oriented team minimum 3 years of data experience, ideally with saas experience with mysql bigquery experience creating dashboards in a bi tool experience creating workflows experience using tray.io college or university degree about agencyanalytics agencyanalytics is a reporting platform that helps digital agencies automate their client reporting. we have been in business since 2010, are 100 employee owned, and are growing fast. on top of being obsessed with building the best product possible and helping our customers succeed, we also pride ourselves on our company culture. from weekly happy hours, employee of the month awards, profit sharing, fitness allowances, and continued learning...we re always looking for ways to take care of our team. for anyone looking to continue building their career in saas, this is an opportunity to join a team that is dedicated to building a company you ll want to stay at for years to come. agencyanalytics is an equal opportunity employer. we are committed to providing an environment of mutual respect where equal opportunities are available to all applicants regardless of race, color, religion, sex, age, marital status, gender identity, and any other characteristic protected by applicable law. we celebrate diversity and are committed to an inclusive environment among our team.","['bi', 'reporting', 'dashboards', 'hubspot', 'saas', 'data operations', 'data analysis', 'mysql']","['bi', 'mysql', 'hubspot']","['reporting', 'dashboards', 'saas', 'data operations', 'data analysis']","['environment', 'education', 'metrics', 'marketing', 'law']"
305,389,Data Engineer,"like the idea of supporting company wide decisions then jobber might be the place for you we re looking for a data engineer to be part of our business technology team in our business operations department. jobber exists to help people in small businesses be successful. as featured in the globe and mail , we work with home and field service companies to help them better quote, schedule, invoice and collect payments from their customers. having been named the 2 fastest growing software company in canada and one of fast company s most innovative companies in 2020 , it s clear we ve come a long way from our first customer in 2011 but we ve just scratched the surface of what we want to accomplish for our customers . the team business technology is the engineering team within business operations, our internal consulting department they re the decision support mechanism that connects data, business insights and an internal tech stack with the rest of the organization. in essence, bizops is a central function that exists to drive business outcomes in all corners of jobber s ecosystem. the role reporting to the senior manager, business technology, the data engineer will work on our business technology team which develops internal software, integrations and data infrastructure. our work unlocks improved operational outcomes, workflow efficiencies and new business insights across our organization. we help teams leverage data, tools and technology in order to successfully execute on their own mandates. we research, develop and maintain systems which support other internal teams from an operational and analytical perspective. we re looking for people who are ready for their next challenge, and want to use their experience to influence people, processes and decisions. the data engineer will build the foundation of our growth. design, build and maintain batch and real time data pipelines in cloud infrastructure . build scripts, tools, serverless applications and workflows. set up our internal teams for success. internal process improvements such as automating manual processes, building alerting or monitoring tools. collaborate closely with other teams to build tools, frameworks, reports to run experiments, analyze a or b test results, enable insights. be a business accelerator. work with analysts, data scientists and product teams to extract actionable insights from data that shape the direction of the company. participate in strategic planning. lead initiatives to research, analyze and propose new technologies and tooling for our data engineering stack. participate in design and code reviews learn from your peers and teach your peers. solve problems with technology and make decisions backed by data. to be successful, you should have 3 years of experience as a data engineer or a similar role experience in developing and maintaining data pipelines for etl or elt processes experience with data collection and ingestion from external sources, and optimizing data flow between different systems and environments experience in analytics data modelling and data warehousing in the cloud proficient in sql including query performance debugging and tuning skills. solid coder with javascript, python and bash familiar with bi tools experience in developing and operating high volume, high available and scalable environments strong communication skills, with the ability to collaborate with both non technical and technical team members. it would be really great if you had experience working in agile scrum environment using templated sql in your etl pipeline experience with integrations, apis and working within their limitations. what you can expect from jobber having been named 8 on the top 10 best workplaces in canada by great place to work , we walk the talk. here are just some of the great things you can expect from us a total compensation package that includes an extended health benefits package with fully paid premiums, rrsp matching, and stock options. a dedicated learning and development function, including development coach, to help you reach your career goals and fullest potential. support for your breaks from three weeks vacation to rest and recharge, your birthday off, and parental leave top ups to support your growing family. a unique opportunity to build, grow, and make an impact on a 400 billion industry that has no dominant player...yet. to work with a group of people who are humble, supportive, and give a sh t about our customers. we believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. we welcome people of diverse backgrounds, experiences, and perspectives. we are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring. a bit more about us job by job, we re transforming the way service is delivered. your lawn care provider, home cleaning service, plumber or painter could use jobber to better connect with their customers, save time in the office, invoice faster, and get paid we re bringing tens of thousands of people together with technology to deliver over 6 billion a year in services to happy customers. jobber exists to help make these small businesses successful, and when they re successful we all win","['bash', 'data flow', 'data infrastructure', 'javascript', 'sql', 'python', 'software', 'reporting', 'analytics', 'data engineering', 'data warehousing', 'data pipelines', 'scrum', 'data collection', 'debugging', 'rest', 'bi', 'business insights', 'cloud infrastructure', 'etl']","['sql', 'python', 'bi', 'business insights', 'debugging', 'javascript']","['bash', 'data pipelines', 'data flow', 'strategic', 'software', 'reporting', 'data engineering', 'data infrastructure', 'scrum', 'data collection', 'analytics', 'cloud infrastructure', 'rest', 'data warehousing', 'etl', 'planning']","['environment', 'design', 'business operations', 'consulting', 'compensation', 'hiring']"
306,392,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","requisition id 108086 join a purpose driven winning team, committed to results, in an inclusive and high performing culture. data engineer, analytics and business planning canadian business banking purpose contributes to the overall success of business intelligence and mis in canadian business banking ensuring specific individual goals, plans, initiatives are executed or delivered in support of the team s business strategies and objectives. ensures all activities conducted are in compliance with governing regulations, internal policies and procedures. supports development, ongoing management and enhancement of business banking data infrastructure to enable development and management of business intelligence, business analytics and data science vision for the business bank. this role sits at the intersection of business and technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. this position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization. accountabilities champions a customer focused culture to deepen client relationships and leverage broader bank relationships, systems and knowledge. supports the development and management of database and business intelligence for business banking build data architecture for business banking develop new or enhance features across the platform data pipelines, new datasets, efficient interfaces, and interactive visualizations using business intelligence tools such as power bi and tableau architect the generation of powerful datasets to bring successful analytics to market ensure data architecture encompasses all business lines and segments for business banking, 30 source systems as well as all data dimensions including but not limited to client demographics, balance sheet revenue information, operational sales activity data learn the business strategy and generate ideas for insightful tools ensure data integrity and timely availability of data for generation of accurate and timely business intelligence and analytics ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems work with data users to ensure datasets produced are meet their analytic needs ensure data is available on a timely basis for generation of daily, weekly, monthly business intelligence as well as adhoc analytic needs enable quick speed to market for new data needs for the business bank manage hardware environment and analytical playground for the business bank manage hardware environment and software requirement for the database ensure analytic environment supports high powered computing, multiple software applications, multi tenancy, data storage, data backup and other infrastructure needs for the analytics team bring cutting edge data solutions and next generation technology to scotiabank keep abreast with latest database technology and data solutions actively bring new cutting edge solutions to scotiabank understands how the bank s risk appetite and risk culture should be considered in day to day activities and decisions. actively pursues effective and efficient operations of his or her respective areas in accordance with scotiabank s values, its code of conduct and the global sales principles, while ensuring the adequacy, adherence to and effectiveness of day to day business controls to meet obligations with respect to operational, compliance, aml or atf or sanctions and conduct risk. educational requirements bachelor s degree in computer science or related field or relevant experience master s degree in computer science preferred experience 5 years of data engineering and software experience in a banking environment required strong communication skills for internal stakeholder collaboration experience with large data sets and working with hadoop, nosql databases, and or or graph databases experience with python and or or scala hands on development in a distributed data environment an asset experience with rdbms, cassandra, hdfs, and or or graph databases an asset detailed experience in the following unix, mainframe, sql, sas, other programming tools experience with business intelligence tools power bi, tableau advanced proficiency with excel previous banking experience is an asset skills excellent verbal and written communication skills are required strong prioritizing and analytical skills high degree of knowledge of commercial products and profit drivers the role requires a high degree of collaboration across wide ranging groups global banking markets gbp finance, wealth management, retail small business, and various business banking areas. works with various partners using influence and negotiation skills to ensure objectives are met. strong technical skills in math, computer science or related fields excellent design and delivery capabilities location canada ontario toronto scotiabank is a leading bank in the americas. guided by our purpose for every future , we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['computing', 'analytical skills', 'databases', 'tableau', 'financial reporting systems', 'rdbms', 'data infrastructure', 'data integrity', 'mainframe', 'business', 'interfaces', 'python', 'sql', 'software', 'scala', 'data science', 'unix', 'analytics', 'data', 'programming', 'data engineering', 'sas', 'nosql', 'data pipelines', 'mis', 'business intelligence', 'hardware', 'graph', 'cassandra', 'banking', 'bi', 'datasets', 'hadoop', 'data solutions', 'computer science']","['sql', 'python', 'databases', 'tableau', 'scala', 'bi', 'rdbms', 'mis', 'hadoop', 'unix', 'programming', 'business intelligence', 'hardware', 'sas', 'nosql', 'cassandra']","['computing', 'analytical skills', 'financial reporting systems', 'data infrastructure', 'data integrity', 'mainframe', 'business', 'interfaces', 'software', 'data science', 'analytics', 'data', 'data engineering', 'data pipelines', 'data storage', 'banking', 'datasets', 'data solutions', 'computer science']","['business planning', 'environment', 'private', 'retail', 'business banking', 'negotiation', 'sales', 'finance', 'business strategy', 'design', 'investment banking', 'capital markets', 'regulations', 'business', 'architecture', 'business lines']"
307,398,Data Engineering Intern (Fall 2021) - Toronto,"are you ready to join a team of tech savvy music lovers and thrive in an exciting, fast paced, and innovative work environment our team is currently looking for a data scientist to contribute on a variety of products, related to in store music and digital experiences, broadcast and connected tv channels and our different product applications. as part of the brand new data science and artificial intelligence team at stingray, your mission will be to contribute to the organic growth of all of stingray s products. in collaboration with the product team and the development teams, you will find new and creative ways to improve stingray s products by using the latest ai technologies. using a data first approach, you will help find growth opportunities and propose innovative solutions to improve stingray s line of products. what you ll do analyze large datasets to find patterns. find opportunities in data and propose improvements to products. implement, train, and validate machine learning models. create dashboards and visualizations to communicate results. assist data engineers and software developers to integrate trained models into stingray products. who you are degree in data science, computer science, or similar. experience in python and common data science toolkits numpy, pandas, etc. experience with machine learning frameworks such as tensorflow, keras, pytorch. proficiency in sql and relational databases. knowledge of big data processing frameworks and etl languages google cloud dataflow, apache beam, java. benefits share purchase plan breakfasts and snacks offered every day on site cafeteria offering lunches at a very reasonable price generous contribution by stingray to the cdm gym fees on site free yoga lessons offered twice a week and much more stingray s offices are located in the old port of montreal just minutes from the lachine canal bike path, a prime location for picnics or a jogging at lunch time. we are a young, energetic company committed to the well being of our employees and who ensures it through benefits such as breakfasts, snacks, coffee for all tastes, free treats and fridays. we also have access to virtual health care what else to say if you are looking for an exceptional workplace and have what it takes to fill this role, please send us your resume at not the job for you check out our careers page to consult other available positions and learn more about stingray. we re always on the lookout for new talent. stingray supports the principles of employment equity and is committed to ensuring our workforce is representative of the communities we serve and in which we operate. women, aboriginal peoples, persons with disabilities and visible minorities are encouraged to apply and to self identify so we can work towards full representation of those groups within our company.","['pytorch', 'tensorflow', 'dashboards', 'java', 'sql', 'python', 'keras', 'data processing', 'software', 'data science', 'pandas', 'machine learning', 'relational databases', 'numpy', 'artificial intelligence', 'datasets', 'computer science', 'etl', 'ai']","['sql', 'python', 'keras', 'pytorch', 'big', 'numpy', 'pandas', 'apache beam', 'java']","['machine learning', 'data processing', 'relational databases', 'software', 'datasets', 'tensorflow', 'dashboards', 'data science', 'computer science', 'artificial intelligence', 'etl', 'ai']","['environment', 'cdm']"
308,399,"Educator, Data Scientist","brainstation is a global leader in digital skills training and development, offering a 12 week diploma program in data science. brainstation is currently seeking a data science professional to lead the delivery of our program through online and in person teaching. brainstation educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education. responsibilities lead our 12 week data science diploma program help build a world class technical team deliver lectures and mentor the next wave of data science talent co create brainstation s full time data science program that will positively impact the lives and careers of hundreds of individuals across our campuses actively work on writing and researching new content to teach the most up to date skills in data science to our students apply brainstation s agile education methodologies to the program to continuously improve the educational experience for students constantly improve your own skills, and apply these skills in collaboration with other brainstation educators in order to build the digital platform and tools needed to effectively deliver educational material define the education experience of the future successful candidates will have 3 years experience as a data scientist or analytics professional and a bachelor s degree relevant to the subject matter or 8 years experience as a data scientist or analytics professional experience building and leading teams strong command of querying and programming languages , and visualization tools , as well as experience applying various methods of numerical and categorical modeling and machine learning principles practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job an empathetic, friendly, and approachable demeanor a proven ability to work under pressure and meet deadlines about brainstation brainstation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state of the art campuses in new york, london, toronto, and vancouver. founded in 2012, brainstation has worked with over 400 instructors from the most innovative companies, developing cutting edge, real world digital training for more than 100,000 professionals and some of the largest corporations in the world. by 2025, brainstation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 ceos, and the newest wave of disruptive innovators, on campuses and online. have you been to a campus or joined an online learning opportunity we are actively seeking individuals that believe in lifelong learning and that have taken part in our on campus or online offerings . note only those applicants under consideration will be contacted. please accept our utmost appreciation for your interest. brainstation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. all qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. if you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.","['visualization', 'machine learning', 'programming languages', 'data science', 'analytics', 'modeling']",['programming languages'],"['visualization', 'machine learning', 'data science', 'analytics', 'modeling']","['environment', 'events', 'education', 'genetics', 'material', 'art', 'educational', 'hiring', 'higher education', 'workshops', 'mentoring']"
309,400,Data Engineer,"build resilient systems at scale with high velocity and high volume data flows. champion the practice of data democratization. reimagine the way we source, process, contextualize, and model our data. build near real time streaming pipelines. implement event driven data ingestion methodologies with snowflake. build elt processes. mpi does not discriminate on the basis of race, religion, sex, sexual orientation, gender identity or expression, age, disability, marital status, or based on an individual s status in any group or class otherwise protected under applicable human rights legislation. mpi encourages applications from minorities, women, the disabled and all other qualified applicants 3 years of experience in the development and evolution of modern data pipelines, business intelligence, and advanced analytics applications. experience with etl or elt software such as ssis, talend, informatica, snowpipe, 5tran or other preferred. experience working with large datasets and volumes . experience in the full data pipeline, from extraction to grooming, modeling, loading, and dashboarding or bi. experience with data structures, encodings, and storage formats and the tradeoffs between the options. fluency in data modeling and warehousing. a leading high growth start up a competitive package","['informatica', 'snowpipe', 'data pipelines', 'data structures', 'software', 'bi', 'datasets', 'talend', 'ssis', 'analytics', 'data', 'business intelligence', 'modeling', 'pipelines', 'snowflake', 'etl']","['5tran', 'bi', 'snowflake', 'talend', 'business intelligence', 'pipelines', 'ssis']","['informatica', 'data pipelines', 'data structures', 'software', 'data ingestion', 'datasets', 'analytics', 'data', 'modeling', 'etl']","['human', 'legislation']"
310,403,Data Engineer,"ebay classifieds group is an innovative leader in online classifieds. our sites help people find whatever they re looking for in their local communities whether it s a job, an apartment, a sofa, a car, a concert ticket, financial services or new friends. every connection made or item found makes a difference by crafting a world where people share more and waste less. people who want to connect and trade visit our sites because they re fun, easy to use and built on trust. about the team at ebay classifieds group we are re inventing the way we approach and tackle information retrieval and findability, to transform the way we connect buyers and sellers. as a global leader in online classifieds with major properties including kijiji.ca, kijijiautos.ca, ebay kleinanzeigen.de, mobile.de and marktplaats.nl the solutions of the finding science team impact millions of users across the world. the role as a data engineer in the fisci team, you will be instrumental in the execution of our vision, working closely with a specialized group of engineers, machine learning specialists and architects. are you passionate about search technology and solving tough findability problems then this role is for you your primary focus will be on building and evolving search profiling apis to power our local markets with real time, lightning fast search intelligence capabilities. some of these capabilities include dominant category, popular attributes, trending or popular or related searches and vision. responsibilities building mission critical search intelligence services prototyping and researching solutions to problems as part of product discovery and scoping productionizing ml solutions in spark and tensorflow collaboratively with ml specialists, and fellow engineers refining, scoping and guiding requirements with product managers presenting and communicating internally and sometimes externally at meetups and hosted events active participation in continuous improvement of fisci s engineering processes and infrastructure mentoring and coaching more junior engineers and participating in code and design reviews travelling within europe and the united states to assist with technical integrations and search initiatives minimum qualifications b.sc. or m.sc. in computer science or equivalent demonstrated ability to learn new problem domains and technologies proficient in java and linux environments strong foundation in web programming and application data formats and protocols well versed in micro service architectures and concepts such as service discovery, chassis, bounded contexts, and load balancing basic knowledge of machine learning concepts in supervised and unsupervised learning comfortable debating ideas with others to arrive at sound decisions preferred qualifications professional experience in the ecommerce domain previous experience developing data driven platforms and use cases at scale professional experience with scala, docker and python proficiency working with big data ml systems such as hadoop or spark keras or tensorflow benefits benefits are an essential part of your total compensation for the work you do every day. whether you re single, in a growing family, or nearing retirement, ebay offers a variety of comprehensive and competitive benefit programs to meet your needs. we create opportunities for others by connecting people from widely diverse groups of backgrounds, perspectives and geographies. being diverse and inclusive isn t just something we strive for, it is who we are we want to ensure that as an employee, you feel ebay is a place where, no matter who you are, you feel safe, included, and that you have the opportunity to bring your unique self to work. to learn about our diversity inclusion click here https or or or company or diversity inclusion or covid 19 people are the heart of the ebay classifieds business, and their health and well being are our first priority. we continue to monitor local government guidance and partner closely with medical advisors to determine the safest and best next steps for everyone. as a result, most teams are working remotely, with a few teams able to collaborate in person with enhanced safety procedures. we will discuss the particular case for your region during the interview process. as a general rule, interviews will be completed remotely over video calls. we will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. please contact us to request accommodation. ebay inc. is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. if you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at we will make every effort to respond to your request for disability assistance as soon as possible.","['https', 'assistive technology', 'python', 'machine learning', 'prototyping', 'linux', 'keras', 'information retrieval', 'scala', 'tensorflow', 'hadoop', 'web', 'computer science', 'programming', 'big data', 'less', 'java', 'load balancing']","['https', 'python', 'linux', 'keras', 'scala', 'hadoop', 'programming', 'big data', 'lightning', 'less', 'java']","['assistive technology', 'machine learning', 'prototyping', 'use cases', 'information retrieval', 'tensorflow', 'web', 'computer science', 'load balancing']","['local', 'product discovery', 'continuous improvement', 'events', 'design', 'retirement', 'financial services', 'waste', 'government', 'compensation', 'mentoring']"
311,404,Data Engineer,"company description wish is a mobile e commerce platform that flips traditional shopping on its head. we connect hundreds of millions of people with the widest selection of delightful, surprising, and most importantly affordable products delivered directly to their doors. each day on wish, millions of customers in more than 160 countries around the world discover new products. for our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market. we re fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. if you ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place. job description our engineers move extremely fast, while solving unique and challenging problems. our team is small and nimble. we release every day to ensure that engineers are able to iterate quickly, and make an impact immediately. we re looking for engineers to work on our massive semi structured datasets. you ll develop software to process, transform and analyze the data to identify signals from billions of events we collect every day. you ll provide insights that improve the experience of hundreds of millions of users worldwide. you should be results driven, highly motivated, and have a track record of using data analytics to drive the understanding, growth, and success of a product. what you ll be doing design and develop data collecting and processing systems to handle large data sets. you ll have the opportunity to design innovative data solutions and solve challenging problems. design, develop and support highly parallel, and fault tolerant applications. build and integrate scalable backend systems, services, platforms, and tools contribute to the design and code of complex data pipelines operating on production data optimize current approaches to efficiently handle ever increasing volumes of data build proof of concept using modern technologies and convert them into production grade implementation. create best practice reports and dashboards based on data mining, analysis, and visualization qualifications 5 years of experience as a software engineer or data engineer using python, java or any other programming language expertise with sql and data storage systems experience and knowledge of modern data warehouse, pipeline and reporting or analytic techniques and tools such as airflow, presto or hive, spark, or any other scheduling frameworks, tableau or other reporting tools experience working on amazon web services or other cloud computing platforms bachelor s degree in computer science or related field. preferred qualifications experience in data visualization a plus. li bd1 additional information wish values diversity and is committed to creating an inclusive work environment. we provide equal employment opportunity for all applicants and employees. we do not discriminate based on any legally protected class or characteristic. employment decisions are made based on qualifications, merit, and business needs. if you need assistance or accommodation due to a disability, please let your recruiter know. for job positions in san francisco, ca, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records. individuals applying for positions at wish, including california residents, can see our privacy policy here.","['visualization', 'tableau', 'dashboards', 'data visualization', 'hive', 'java', 'data analytics', 'python', 'sql', 'software', 'reporting', 'data', 'programming', 'cloud computing', 'storage systems', 'data mining', 'amazon web services', 'data pipelines', 'proof of concept', 'airflow', 'datasets', 'data solutions', 'computer science']","['sql', 'python', 'amazon web services', 'tableau', 'san', 'programming', 'hive', 'java', 'airflow']","['data mining', 'data analytics', 'visualization', 'data pipelines', 'proof of concept', 'software', 'reporting', 'datasets', 'data solutions', 'dashboards', 'data visualization', 'computer science', 'data', 'cloud computing', 'storage systems']","['commerce', 'environment', 'events', 'design']"
312,405,Scientist - Synthetic Organic /Medicinal Chemistry,"about admare bioinnovations admare bioinnovations is canada s global life sciences venture, building the canadian life sciences industry from sea to sea. we do this by sourcing therapeutically and commercially promising research from leading academic and biotech partners to create new companies of scale, providing specialized expertise, infrastructure, and capital to help existing companies scale up, and driving the growth of those companies into canadian anchors by training the next generation of highly qualified personnel. admare s 20 portfolio companies have attracted more than 1.2b of investment and have a combined worth of over 3b. job summary we are seeking highly motivated phd and msc level synthetic organic and or or medicinal chemists to join our drug discovery team. scientists positions are available to join our montreal facility. highly qualified individuals are expected to have experience in modern organic synthesis with good laboratory skills and a record of high productivity. key requirements of the role include being able to work within a team structure, propose new targets, execute synthetic routes, engage in troubleshooting exercises as needed, and effectively communicate with biology, pharmacology and dmpk colleagues. scientists will be expected to work with a high degree of independence with a proficiency at interpreting sar and adme data and developing a research strategy to advance projects to meet key milestones. responsibilities may include the design and synthesis of small molecule targets within a project. candidates should also be able to design alternative approaches to achieve desired outcomes. scientists may also take on project leadership responsibilities, coordinate the chemistry efforts within the project, and work within a multi disciplinary team environment. we are a dynamic team that fosters a positive, curiosity driven culture that encourages everyone to contribute intellectually and experimentally to solving complex challenges in drug discovery. we have state of the art laboratories, and we promote a cross functional research environment where colleagues form chemistry, biology, pharmacology and dmpk work closely together to advance drug discovery projects. we offer flexible working hours, competitive salaries, bonuses and benefit package. key duties and responsibilities proficiency in modern organic synthesis and ability to independently perform complex, multi step procedures. experience in the purification of small molecules using a variety of methods such a flash chromatography, hplc purification, distillation and others as needed. structural characterization of small molecules using modern spectroscopic instruments and techniques such as lc ms, 1 and 2d nmr methods and others. contributes signi cantly to patent and or or publication preparation. excellent communication skills, both written and oral, and able to effectively communicate with diverse audiences. independently prepares project presentations and presents experimental conclusions at group or department or project team research meetings. stays abreast of scientific literature and incorporates new methods and technologies in his or her research. demonstrated ability to analyze and interpret dmpk and biological data and to establish chemistry and project strategies as needed. project leadership experience and ability to effectively lead a chemistry research team. education and experience ph.d. in chemistry and 5 years of relevant experience in a drug discovery organization, or master s degree in chemistry or related science and 8 years of relevant employment experience at admare, we are driven by our vision and united by our shared values of courage, collaboration, objectivity, judgment, excellence, and reach. we are committed to growing the talent and potential of our people to drive the development of innovations. we provide a community where you can work with multidisciplinary individuals, explore new ways of thinking, and expand your capabilities through the array of development programs we offer our employees. admare is a diverse community where employees feel a sense of belonging and are valued for the experience and unique perspectives they bring. be a part of life at admare. join our team propos d admare bioinnovations admare bioinnovations est le partenaire d affaires en sciences de la vie au canada, en soutien l industrie d un oc an l autre. pour ce faire, nous identifins aupr s de partenaires acad miques et biotechnologiques de premier plan les d couvertes les plus prometteuses sur les plans th rapeutique et commercial afin de cr er de nouvelles entreprises d envergure. nous fournissons une expertise et les infrastructures ad quates dans le but d aider les entreprises existantes se d velopper, en favorisant leur croissance afin qu elles deviennent des piliers canadiens tout en formant la prochaine g n ration de personnel hautement qualifi . le portefeuille d admare, qui compte pr s de 20 soci t s, a g n r plus de 1,2 milliard de dollars d investissements et repr sente une valeur totale de plus de 3 milliards de dollars. r sum du poste nous sommes la recherche de chimistes organiques synth tiques et or ou m dicinaux poss dant un doctorat ou une ma trise en sciences qui aimeraient faire partie de notre quipe de recherche de m dicaments. des postes de scientifiques disponibles sont offerts dans nos installations de montr al. les individus tr s qualifi s devraient poss der une exp rience en synth se organique moderne et des aptitudes marqu es en laboratoire en plus d avoir d montr une capacit de productivit lev e. les principales exigences du poste consistent, entre autres, pouvoir fonctionner au sein d une quipe, proposer de nouvelles cibles, suivre une voie de synth se, participer des exercices de diagnostic des pannes en fonction des besoins et communiquer de mani re efficace avec les coll gues dans les domaines, comme la biologie, la pharmacologie, ainsi que le m tabolisme des m dicaments et pharmacocin tique. les scientifiques devront faire preuve d un niveau lev d ind pendance et ma triser l interpr tation des donn es sur les rapports structure activit et les donn es des tudes absorption distribution m tabolisme excr tion en laborant une strat gie de recherche pour faire avancer les projets de mani re atteindre les jalons importants. les responsabilit s peuvent comprendre la conception et la synth se des petites mol cules cibl es dans le cadre d un projet. les candidats devraient aussi tre en mesure d laborer des approches alternatives pour atteindre les r sultats d sir s. les scientifiques peuvent galement assumer des responsabilit s en mati re de leadership des projets, coordonner les efforts chimiques dans le cadre du projet et collaborer dans un environnement d quipe multidisciplinaire. nous sommes une quipe dynamique qui favorise une culture positive et ax e sur la curiosit en plus d encourager tout un chacun contribuer sur le plan intellectuel et par des exp riences relever des d fis complexes dans le domaine de la d couverte des m dicaments. nous poss dons des laboratoires ultramodernes et nous encourageons un environnement de recherche interfonctionnel o les coll gues des domaines, comme la chimie, la biologie, la pharmacologie et le m tabolisme des m dicaments et pharmacocin tique, travaillent en troite collaboration pour favoriser les projets de recherche de m dicaments. nous offrons des heures de travail flexibles, des salaires concurrentiels, des bonis et un programme d avantages sociaux. t ches et responsabilit s principales ma trise de la synth se organique moderne et capacit de r aliser de mani re ind pendante des proc dures complexes comportant plusieurs tapes. exp rience dans la purification de petites mol cules en ayant recours des m thodes vari es, comme la chromatographie rapide sur colonne, la purification clhp, la distillation et autres en fonction des besoins. caract risation structurale des petites mol cules en faisant appel des instruments et des techniques de spectroscopie modernes, comme les m thodes lc ms 1 et rmn 2d. contribuer grandement la pr paration des brevets et or ou des publications. aptitudes excellentes pour la collaboration crite et orale et capacit de communiquer de mani re efficace avec des publics vari s. pr parer de mani re ind pendante des pr sentations de projet et pr senter les conclusions des exp riences lors des r unions de groupe or service ou des r unions de recherche des quipes de projet. suivre l actualit dans la documentation scientifique et int grer les m thodes et les technologies nouvelles ses recherches. capacit d montr e d analyser et d interpr ter les donn es sur le m tabolisme des m dicaments et la pharmacocin tique, ainsi que les donn es biologiques pour tablir des strat gies dans le domaine de la chimie et dans le cadre des projets. exp rience en mati re de leadership de projets et capacit de diriger de mani re efficace une quipe de recherche dans le domaine chimique. ducation et exp rience doctorat en chimie et au moins 5 ann es d exp rience au sein d une organisation s occupant de la d couverte de m dicaments ou ma trise en chimie ou dans une science connexe et au moins 8 ann es d exp rience dans un emploi pertinent. chez admare, nous sommes motiv s par notre vision et unis par nos valeurs communes que sont le courage, la collaboration, l objectivit , le jugement, et l excellence. nous sommes d termin s accro tre le talent et le potentiel de nos employ s lorsqu il s agit de promouvoir l innovation. nous offrons une communaut o vous pourrez voluer aux c t s d employ s multidisciplinaires, explorer de nouvelles m thodes de r flexion et accro tre vos capacit s gr ce l ventail des programmes de perfectionnement que nous offrons nos employ s. admare est un univers diversifi o les employ s prouvent un sentiment d appartenance et o ils se sentent valoris s en raison de l exp rience et des points de vue uniques qu ils apportent. venez participer la vie chez admare. faites partie de notre quipe","['sourcing', 'chemistry', 'troubleshooting', 'documentation', 'r']","['documentation', 'r']","['di', 'sourcing', 'chemistry', 'troubleshooting', 'installations']","['pharmacology', 'purification', 'environment', 'characterizationr', 'team research', 'biology', 'education', 'capital', 'research', 'design', 'life sciences', 'art', 'presentations', 'd', 'chromatography', 'scientific literature', 'drug discovery', 'hplc']"
313,406,Data Engineer,"toronto, on medianet is a digital consultancy purpose built to help our clients integrate media, data and technology to drive growth, improve efficiency and evolve the ways they work. we deliver industry leading services and technologies to empower businesses in the areas of marketing intelligence, performance media management and digital experience. we are looking for a data engineer to join our growing analytics practice. joining our team will feel right for you if you are passionate about turning data into capability that drives business performance. in this role, not only will you be designing, implementing and maintaining different data architectures and pipelines, you will also have the opportunity to work with internal and client stakeholders to understand data related technical requirements and solve for their needs. our team will want to hear about your experience developing pipelines that drive efficiencies, and about your approach to transforming data to meet a project s needs. we ll also want you to tell us about a time when you built an automation to save yourself or someone else time. what you ll be doing work with business stakeholders to understand data related technical requirements and solve for their needs develop, document and maintain data pipelines design, document and implement etl processes design, document and implement data visualizations to support self service analytics write and optimize complex queries on large data sets transform data and map them to more valuable and understandable sets for consumption implement process improvements and create tooling to automate and improve the efficiency of day to day tasks troubleshoot issues related to data accuracy conduct research and develop new approaches and solutions to industry and client challenges develop your skills explore and analyze client data to generate insights that will improve business outcomes other duties and responsibilities as assigned what you need to apply experience working with rest apis and python data analysis tools such as pandas or numpy experience building and maintaining etl pipelines experience building data visualizations using power bi or tableau or similar tools a high degree of accuracy, vigilance and attention to detail advanced sql knowledge proven ability and appetite to learn new technologies quickly bachelor s degree in computer science, engineering or a related technical or quantitative field 2 5 years of similar work experience ability to work effectively on a self organizing team with minimal supervision excellent oral and written communication skills proactive and creative problem solver with the ability to multitask and manage tight deadlines excellent diagnostic, troubleshooting and data interpretation skills gcp cloud architect, data engineer or cloud engineer certification at minimum an interest in, but ideally knowledge and understanding of digital advertising and web analytics concepts high professional standards and a commitment to service and operational excellence what we would love to see experience working with google cloud platform familiarity with schema design and dimensional modelling familiarity with google marketing platform technologies who you are you care about your team members and are willing to help outside your realm of expertise no task is below you you have strong problem solving skills and critical thinking abilities you take initiative communicating with co workers and asking questions you may not have all the answers, but you know how to get them you enjoy a fast paced environment and are able to pivot quickly when priorities change you love to learn and try new things you are able to assess both client and company needs to make good choices you enjoy sharing knowledge with your team members what we offer tight knit, teamwork culture training and development flexible hours remote work options comprehensive benefits casual dress code team socials stocked office kitchen beautiful, open, pet friendly environment in a vibrant location location and working conditions while we are operating remotely, we are taking extra steps to ensure a smooth experience for new team members tailored virtual onboarding it equipment and supplies delivered to your doorstep about our culture the medianet work environment is warm, inviting and collaborative. everyone at medianet has a voice, and we encourage new ways of thinking that will lead to improved operational excellence and client success. medianet team members are empowered with development, support and mentoring opportunities that push critical thinking out to the edges of our organization. if you are passionate about what you do and the difference you can make in this role, then we would love to hear from you how to apply along with your resume, please apply by telling us what interests you most about this position and how you can make a difference as part of our team. we thank all applicants for their interest, however only those candidates selected for interviews will be contacted.","['tableau', 'google platform', 'troubleshooting', 'technical requirements', 'google', 'map', 'sql', 'python', 'gcp', 'pandas', 'analytics', 'pipelines', 'solver', 'data pipelines', 'numpy', 'web', 'data analysis', 'rest', 'automation', 'bi', 'computer science', 'schema', 'etl']","['sql', 'python', 'gcp', 'tableau', 'bi', 'numpy', 'google cloud platform', 'pandas', 'pipelines', 'solver', 'map']","['data pipelines', 'web', 'troubleshooting', 'technical requirements', 'analytics', 'computer science', 'schema', 'data analysis', 'rest', 'automation', 'etl', 'data interpretation']","['environment', 'advertising', 'marketing', 'onboarding', 'design', 'operational excellence', 'mentoring']"
314,407,Lead Data Scientist - RACE21,"reporting to the manager of data science as part of the race21 digital transformation team, the lead data scientist will design, plan, develop, and deliver advanced analytics solutions as part of an integrated team to improve performance of teck s coal and base metals operations. you will work closely with a variety of business and technical stakeholders to define technical problems and corresponding hypotheses, develop efficient and accurate analytical models, perform regular testing and maintenance of analytical models to improve efficiency and ensure alignment with changing business needs. this will require data exploration and preparation, modelling, implementation of the advanced analytical tools and integration into a suite of products to achieve business value. who you are you are a highly effective and customer obsessed advanced analytics professional you are passionate about product innovation and creating a step change leveraging the power of cloud, big data and advanced analytics you have experience working on data intensive projects, using modern data platforms and tools and advanced analytics methods and approaches you are comfortable working with minimal direction and exercising considerable latitude in determining objectives and leading other data scientists responsibilities be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures actively seek and assess opportunities to apply advanced analytics to optimize performance across teck s operations in north and south americas partner with and elevate a team of data scientists, providing leadership through consulting and coaching on a regular basis lead end to end design and implementation of machine learning and data analytics solutions for 2 3 use cases at a time to optimize productivity, safety and sustainability work with a variety of business stakeholders to identify and prioritize use cases identify, profile and analyze large, complex, multi dimensional datasets with a variety of tools to draw relevant insights use data science techniques to find data patterns, anomalies and optimization opportunities through analytical solutions solve complex business problems by designing, developing and implementing sustainable advanced analytics solutions plan model operationalization and rollout of solutions to business users plan projects and communicate project status, emerging issues, and next steps to relevant stakeholders in the organization identify new ways of piloting models, actively sourcing and incorporating feedback with learnings from the field provide expert guidance on teck s data, systems and environment to external partners and vendors providing data science and data engineering services write highly optimized and reusable code extending our internal data science toolkit and contributing to an enterprise wide platform for advanced analytics called galileo support hiring and onboarding of new data scientists in collaboration with manager of data science and hr team willingness to travel up to 40 of the time to teck s operations across north and south americas key competencies phd or master s degree in the field of computer science, machine learning, applied statistics, mathematics or equivalent 7 years of relevant industry work experience developing advanced analytics solutions a deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems demonstrated proficiency with programming languages such as python, r, sql experience with popular machine learning frameworks, libraries and utilities experience with popular optimization framework and libraries experience working with large data sets and distributed computing tools experience with a wide range of data collection systems including edge computing technologies working knowledge of at least one enterprise grade cloud computing platforms such as microsoft azure, amazon web services or google cloud platform exceptional organizational and time management skills with the ability to meet deadlines and balance multiple projects excellent analytical and critical thinking skills, combined with the ability to present your ideas clearly and compellingly to both technical and non technical audiences demonstrated ability to work well as part of agile, multidisciplinary teams strong interpersonal skills and previous experience coaching and mentoring data scientists interest in gaining the knowledge of mining industry and systems used in engineering, operations, process control and maintenance functions experience or education in mineral processing, maintenance, process control or supply chain would be an asset experience with real time systems that support asset health, dispatch and or or processing workflows would be an asset at teck, we value diversity. our teams work collaboratively and respect each person s unique perspective and contribution. qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically. we wish to thank all applicants for their interest and effort in applying for the position however, only candidates selected for interviews will be contacted. your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. teck respects the privacy of all applicants and the confidentiality of personal information. teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, zinc and energy. headquartered in vancouver, canada, its shares are listed on the toronto stock exchange under the symbols teck.a and teck.b and the new york stock exchange under the symbol teck. the pursuit of sustainability guides teck s approach to business. teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. in 2019, teck was named to the dow jones sustainability world index for the tenth straight year, indicating that teck s sustainability practices rank in the top 10 per cent of the world s 2,500 largest public companies in the s p global broad market index. learn more about teck at or follow teckresources li an1","['computing', 'big data', 'sustainability', 'microsoft azure', 'data analytics', 'python', 'sql', 'statistics', 'reporting', 'data science', 'analytics', 'integration', 'data engineering', 'cloud', 'amazon web services', 'machine learning', 'testing', 'sourcing', 'google cloud platform', 'computing collection', 'process', 'toolkit', 'process control', 'programming languages', 'datasets', 'computer science', 'mathematics', 'data patterns', 'optimization', 'digital transformation', 'r']","['sql', 'python', 'amazon web services', 'programming languages', 'google cloud platform', 'big data', 'microsoft azure', 'r']","['computing', 'sustainability', 'distributed', 'data analytics', 'statistics', 'reporting', 'data science', 'analytics', 'integration', 'data engineering', 'cloud computing', 'machine learning', 'data collection systems', 'testing', 'sourcing', 'process', 'toolkit', 'use cases', 'datasets', 'computer science', 'mathematics', 'data patterns', 'optimization', 'digital transformation']","['utilities', 'environment', 'education', 'onboarding', 'business value', 'design', 'business units', 'consulting', 'hr', 'coal', 'environmental', 'hiring', 'disclosure', 'mentoring']"
315,408,Data Engineer,"connect with us linkedin, instagram, facebook, twitter thinking about a change the digital data engineering division brings together the teams who enable ellisdon to leverage technology in every aspect of its business, to push beyond traditional industry positions and drive change. our objective is simple to be leaders in technology just as we are leaders in building. our core values empower people to deliver great careers to one another and develop creative solutions for complex problems for our cradle to grave services, construction operation and our clients. we are a group of professionals with a variety of expertise within software engineering, product management, data management and analytics, professional services, virtual design, construction, and it operations. to learn more, check out our digital data engineering services and hear from our team directly about what a career at ellisdon could look like for you. as you can see, we are a diverse bunch. above all, we are a group of individuals with unique experiences, and, at ellisdon, we choose to celebrate the strength in our differences, every day. ellisdon s commitment to inclusive diversity is to work together to create an environment where every employee feels safe to be their true and authentic self. ultimately, ellisdon s purpose is to provide people with similar values the opportunity to achieve to their full potential to deliver that opportunity for great careers to one another and to contribute meaningfully to the community we share with others. in case you re curious, here s what the industry thinks of us and some of the impacts we ve made to the communities we work in. you as a data engineer will primarily be responsible for the delivery and availability of high quality and usable data to a variety of stakeholders and consumers across the organization work with relevant stakeholders to identify sources of data and map out processes or data flow while researching opportunities for data acquisition and innovative new uses for existing data design, construct, install, test, and maintain highly scalable data management systems while integrating new data management technologies and techniques into existing structures develop integration processes to move internal and external data into ellisdon s external cloud based data lake develop separate integration processes to move data from data lake to data warehouse implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it monitor and take proactive measures to ensure high availability existing pipelines and jobs continually improve our data pipelines and find innovative ways to maximize automation while recommending ways to improve data reliability, efficiency, and quality. is this the right role for you degree in computer science, software engineering, or related technical field. minimum five years of progressive experience in a similar or related role. proficient knowledge and extensive experience with the following programming languages python, scala or java, sql integration techniques and data management toolsets third party cloud native open source . cloud ecosystems and solutions data warehousing , data storage , relational or non relational database data modelling and design working knowledge of concepts within the following data management domains data governance, data architecture, security, mdm, metadata management, and data quality comfortable working in a fast paced and collaborative environment. ellisdon is proud to provide this unique career opportunity that provides continuous learning, opportunity for growth, and a competitive compensation package within an environment that is committed to inclusion and respects diversity. go ahead and be yourself. we ll pay you for it we are an equal opportunity employer. we welcome people of any age, culture, subculture, gender identity or expression, sexual orientation, nationality, ethnicity, race, size, mental or physical status, veteran status, religion, language, political opinion, working style preference, family status, education, and socio economic status. the ellisdon core values of integrity and mutual respect welcomes everyone, at work and in the community, and our value of mutual accountability, means that we all have a role to play. as an ellisdon employee, this will ultimately be your commitment to inclusive diversity. accommodation for applicants with disabilities will be made during the recruitment process when requested. we are committed to providing a positive candidate experience and ensuring timely updates are provided to all candidates. if you haven t already, be sure to create a profile on our careers page here to remain up to date on the status of your application and learn about new career opportunities as they arise.","['go', 'metadata management', 'high availability', 'data flow', 'java', 'map', 'sql', 'python', 'data acquisition', 'software', 'scala', 'product management', 'analytics', 'digital', 'data', 'integration', 'pipelines', 'data engineering', 'data warehousing', 'data pipelines', 'data quality', 'automation', 'programming languages', 'security', 'computer science', 'data management', 'it operations']","['go', 'sql', 'high availability', 'python', 'pipelines', 'programming languages', 'scala', 'mdm', 'data quality', 'java', 'map']","['metadata management', 'data flow', 'data acquisition', 'software', 'management systems', 'product management', 'analytics', 'digital', 'data', 'integration', 'data engineering', 'data warehousing', 'data pipelines', 'data storage', 'automation', 'security', 'computer science', 'data management', 'it operations']","['environment', 'professional services', 'design', 'education experience', 'governance', 'architecture', 'construction', 'compensation', 'linkedin']"
316,409,Intermediate Data Engineer,"real estate works rew started as one of the largest real estate newspapers of its kind anywhere in the world, circulating more than half a million copies, each with hundreds of pages, every week across vancouver. today, rew.ca is the best real estate search platform in canada, and the leading marketplace in bc with an audience twice the size of its nearest rival. it has grown by offering people simple, effective home search, augmented with relevant real estate data to empower better decision making. but rew is more than rew.ca, it s a team of creative people, driven to improve the property process, one digital experience at a time. vision for the role data is at the heart of everything we do at rew. every day, our data platform ingests feeds from dozens of sources to compile, composite, and augment the inventory of listings that the thousands of rew users search in their quest for the perfect home. our listings need to be accurate, comprehensive, and highly available or our users will go elsewhere. listings are only part of the puzzle. rew also tracks market behaviour to help inform our own next steps, and to empower the agents, landlords, and property developers who count on rew to give them an edge. we are looking for a highly motivated and driven data engineer to join our technology team to help us maintain rews heart but also help us prepare for the challenges that lie ahead. this individual would join a small team in maintaining rew s existing platform which might include responding to upstream changes from some of our feed providers, optimizing performance to respond to increased demand, or troubleshooting integrity issues. as this individual grows in their role, they ll earn the opportunity to take on more complex problems and own all aspects of developing end to end data flows including gathering requirements, data modeling, etl script development, and data quality control. we work on an agile data platform built on cloud hosted databases and data processing scripts . we also use specialized services such as google bigquery for website event analytics. our data engineers act as key database platform technical resources, assisting with the development of the architecture, creating and executing data import data export scripts and apis as necessary, assessing data accuracy, and helping to ensure the ongoing data and operational integrity of the data platform. responsibilities maintaining and enhancing rew s data platform debug and optimize etl flows data processing, data modeling and expanding data platform service. collaborate with product development teams to provide data platform service to power new features develop reports or data visualization tools for internal use to help support the rew s sales and marketing efforts create visualizations and views of data to provide editorial content for information platforms participate in project planning and analysis as needed education, skills and experience minimum 2 years of professional experience with data analysis and big data tech stacks. bachelor of computer science, a similar technical degree, or equivalent experience proficiency in python or a similar language for data processing with exposure to other scripting and object oriented programming languages strong experience in database development and data modeling proven experience in one of the major cloud platforms strong understanding of data analysis concepts such as data visualization, dashboard design, data mining next steps if you are interested in working with a rapidly growing real estate tech company with a very well established brand, we would very much like to hear from you. to apply please submit your cover letter and r sum to with, intermediate data engineer , in the subject line. life at rew mission we believe real estate can be one of life s great adventures, and we exist to inspire and equip people for that journey. values people over profits. profits are important, they keep the lights on, but we will not compromise the quality of our work or make ourselves miserable in pursuit of financial gain. we solve problems. creativity is in our dna, we approach problems with real enthusiasm and look for the many ways we could add value and make a positive impact on the people we serve. the experience matters. we do work that matters for people that care and we take pride in the work that we do. if it doesn t make the grade, we go back to the drawing board. adventure requires courage. uncertainty is part of life, we don t pull back from the edge, we take the risk and stretch ourselves. it s not only about the outcome, but the thrill that comes with the adventure of it all. no jerks allowed, be humble. we operate in a climate of mutual respect, and we treat each other well. we don t elevate ideas above people, if you re a jerk then you ain t welcome here. we show up for each other. we hire smart people, give them great work, and treat them like adults. no matter how we each choose to approach the day, we show up when we re needed and we deliver for the team.","['go', 'databases', 'big', 'data visualization', 'troubleshooting', 'quality control', 'python', 'data processing', 'scripting', 'data', 'analytics', 'data mining', 'operational', 'project planning', 'agile', 'data analysis', 'dashboard', 'programming languages', 'database development', 'computer science', 'uncertainty', 'modeling', 'script', 'etl', 'r']","['go', 'dashboard', 'python', 'databases', 'programming languages', 'database development', 'data', 'big data', 'r']","['data mining', 'data processing', 'scripting', 'data visualization', 'operational integrity', 'troubleshooting', 'script development', 'data', 'analytics', 'project planning', 'data analysis', 'modeling', 'computer science', 'uncertainty', 'feed', 'quality control', 'etl']","['education', 'marketing', 'design', 'sales', 'real estate', 'editorial', 'product development', 'pages', 'architecture']"
317,410,Data Engineer,"company description at thinking capital, we re changing the landscape of financial technology simply put, our mission is to empower canadian small businesses through innovative financial services. at the heart of our offering is our digital experience, which is powered by our proprietary software platform, our real time connections to a multitude of data sources and our advanced data science models. we are squarely in the corner of owners and entrepreneurs, providing for them, and at the right moment, the financial support they need to grow and thrive. we are looking for a talented data engineer who can bring their passion to our team job description where others see chaos, you see patterns and emerging structures. you have a passion for the collection, management and analysis of data to discover the patterns hidden within. you thrive on helping your teammates make sense of the data and enabling them to make effective use of the data. as a data engineer you will be key member of our development team where your passion for data will help us design, develop and deploy our data platform, the foundation of our digital financing platform data modeling, governance and stewardship data pipeline to support our bi, data science and machine learning activities maintaining data veracity and quality help develop and maintain elt processes learn and adapt emerging data technologies and operational best practices to real problems qualifications what you bring extensive schema and data modelling experience development experience python, pandas, sci kit snowflake, presto, hive or other data warehousing technologies airflow, dbt sql working autonomously and being highly resourceful bachelors, msc or phd in computer science, engineering, or related field experience working on aws other valued skills knowledge git or other version control systems security machine learning experience working with kubernetes additional information why join us great team surround yourself with high performing, energetic and passionate group of people dedicated to the thinking capital mission fintech revolution be part of a team that is revolutionizing the financial system and redefining how canadian small businesses access capital fast paced environment take on complex projects in a start up like collaborative environment amazing culture amazing work spaces, advanced technology tools and the flexibility to do your best work diversity of thought join a team that values diversity and harmony. job type full time","['financial technology', 'hive', 'kubernetes', 'sql', 'python', 'software', 'data science', 'pandas', 'data', 'aws', 'data warehousing', 'financing', 'machine learning', 'airflow', 'bi', 'security', 'git', 'computer science', 'modeling', 'version control', 'snowflake']","['kubernetes', 'sql', 'python', 'bi', 'chaos', 'git', 'pandas', 'aws', 'hive', 'snowflake', 'airflow']","['financing', 'machine learning', 'software', 'security', 'data science', 'version control', 'financial technology', 'data', 'modeling', 'computer science', 'data science support', 'data warehousing']","['environment', 'fintech', 'capital', 'design', 'governance', 'financial services', 'dbt']"
318,411,Computer scientist in Bioinformatics,"computer scientist in bioinformatics my intelligent machines is looking for a highly talented computer scientist to join a dynamic team building a world class platform for life scientists integrating bioinformatics, systems biology and ai. in this role, you will work closely with systems biologists, bioinformaticians, data scientists, ai and software engineers to build solutions for the top biopharma and agritech companies in the world. this full time position will focus on workflow design, development and implementation, data visualization, quality assessment and mentoring of junior bioinformaticians in software development. responsibilities design and implement workflows using state of the art bioinformatics, and biostatistics provide templates for data visualization for the interface and the documentationpr maintain mims common core bioinformatics libraries report quality assurance and tests on bioinformatic and biostatistic. create appropriate documentation mentor junior team members particularly in software development qualifications m.sc. or ph.d. with 5 years of experience in computer sciences with extensive experience in software development at least 2 year experience in bioinformatics, biostatistics or computational biology experience with bioinformatics resources, databases, tools and common standard formats demonstrated programming skills using either python, c or r in a linux environment knowledge of xml, json and nosql databases excellent verbal and written communication skills experience and enthusiasm towards mentoring junior bioinformaticians be highly proactive, self motivated and detail oriented demonstrated graphical representation skills would be an asset submission please submit your resume or any questions you may have to if you are not sure you fit the requirements for this position or don t have all the qualifications, please contact us regardless.","['databases', 'linux', 'data visualization', 'c', 'documentation', 'biostatistics', 'python', 'software', 'systems biology', 'bioinformatics', 'json', 'software development', 'programming', 'quality assuranceinform', 'nosql', 'computational biology', 'ai', 'xml', 'r']","['python', 'databases', 'linux', 'quality assurance', 'json', 'c', 'programming', 'documentation', 'xml', 'nosql', 'r']","['biostatistics', 'testsstatistic', 'software', 'systems biology', 'bioinformatics', 'computational biology', 'data visualization', 'quality', 'software development', 'mi', 'ai']","['environment', 'design', 'art', 'templates', 'team building', 'assessment', 'mentoring']"
319,412,Senior Data Scientist,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or work in an office it s up to you. the role veeva data cloud is a family of data products aimed at bringing more innovative solutions and greater choice to the life sciences data market. life sciences companies license our data to inform high impact commercial initiatives, such as patient journey mapping, healthcare professional targeting, and field force alignment. veeva data cloud leverages software and cloud technology to develop and deliver better data, faster. as the senior data scientist for the veeva data cloud team, you will be focused on designing and building our methodologies to bring projected data products to life for our customers. you are excited about statistics and data science at scale on big data and taking billions of records to tell a story, from sample curation, projection methodologies, anomaly detection, scaling approaches, clustering, and more. you design and build algorithms in a computationally efficient and statistically effective manner, while being able to keep the business problems we are working to solve in mind. while ml is an important part of your toolkit, it s not your only skill. the ability to dissect the problem and to select from a variety of techniques is key. this is a great opportunity for someone who is excited about using their statistics and data science expertise to design and build the algorithms and models used at the core of launching veeva s projected data products. you ll collaborate closely with the product management and engineering team to productize the methodologies and get to see enterprise life science customers leverage your work every day. what you ll do apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologies own responsibilities related to project and people leadership, including leading data scientists and analysts collaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale explore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions execute data querying, data cleansing, and experiment design rapidly build prototype product solutions, communicate findings, and iterate draw from prior experience and technical expertise to identify product improvements and inform testing plans break overall objectives down into underlying problems that can be prioritized and solved work with product and engineering teams to improve and implement methods and features master core parts of the crossix technology platform. technologies include spark, sql, python, r, aws, and proprietary data mining software what you ll do apply statistical, machine learning, and data mining techniques to large health data sets to build new products and methodologies collaborate closely with a team of data scientists, product managers, software engineers and data engineers to discover and deliver product offerings from prototype to scale, then iterate and enhance explore and find meaning in high volumes of data, identify signals and patterns to identify relationships to infer the universe from imperfect data. important skills include querying, data cleansing, experiment design, solution assessment, identifying scaling challenges. rapidly build prototype product solutions, communicate findings, and iterate draw from prior experience and technical expertise to identify product improvements and inform testing plans break overall objectives down into underlying problems that can be prioritized and solved requirements 7 years of hands on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects m.s. or ph.d. in applied statistics, mathematics, computer science, machine learning or other quantitative discipline highly proficient in python and sql experience working with aws preferred experience working with large quantities of data to develop models that work in a stable, production approach with live data advanced knowledge of statistical analysis and data mining techniques experience working with engineering to productionalize models including scaling, monitoring, and documentation comfortable about ambiguity and breaking goals down into tangible and actionable workplans strong communication skills and ability to work across internal teams perks benefits flexible pto allocations for continuous learning development health wellness programs veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['cleansing', 'big data', 'documentation', 'statistical analysis', 'sql', 'python', 'statistics', 'software', 'data science', 'product management', 'anomaly detection', 'aws', 'data mining', 'machine learning', 'data products', 'testing', 'toolkit', 'data quality', 'algorithms', 'computer science', 'mathematics', 'r']","['sql', 'python', 'san', 'documentation', 'big data', 'aws', 'data quality', 'r']","['data mining', 'machine learning', 'statistics', 'applied', 'software', 'data products', 'testing', 'data science', 'computer science', 'product management', 'anomaly detection', 'cleansing', 'mathematics', 'toolkit', 'statistical analysis', 'algorithms']","['customer success', 'environment', 'healthcare', 'regulations', 'design', 'life sciences', 'assessment', 'projection']"
320,413,Développeur de données / Data Developer,"your privacy zenimax understands the importance of privacy. please review the applicant privacy notice section below, which explains how we process the personal information we collect about you when you apply for a job or submit information to us through this job portal. by applying for this job, sharing this job or otherwise providing us with your personal information through this job portal, you acknowledge that you have read and understood the applicant privacy notice , which is set forth in the applicant privacy notice section below. overview bethesda game studios est la recherche d un d veloppeur de donn es talentueux et autonome avec de solides comp tences techniques pour rejoindre l quipe qui d passe les standards et repousse les limites du d veloppement de jeux aaa sur les plateformes mobiles. le d veloppeur de donn es travaillera avec notre sp cialiste des donn es et nos programmeurs pour mettre en place et maintenir des solutions de donn es afin de soutenir les initiatives analytiques visant am liorer l exp rience et la performance des joueurs ainsi qu augmenter la r tention et la mon tisation des joueurs. bethesda game studios is looking for talented and self driven data developer with strong technical skills to join the team that is pushing the bleeding edge aaa game development for mobile platforms. the data developer will work with our data scientist and programmers in building and maintaining data solutions to support analytics initiatives to improve player experience and game performance as well as increase player retention and monetization. responsibilities construire de nouvelles structures de donn es et tendre les structures existantes pour prendre en charge l analyse des jeux maintenir de grandes bases de donn es apache spark de plusieurs t raoctets qui incluent l optimisation des performances et les processus de r tention et de purge des donn es rechercher et r gler les probl mes de qualit des donn es, fournir des corrections et proposer des solutions court et long terme pr parer la conception des syst mes de base de donn es et recommander des am liorations en mati re de performance maintenir et d velopper divers scripts et outils de base de donn es python or scala pour faciliter les processus d automatisation fournir un soutien li toutes les initiatives de suivi des donn es valuer la mise en place du suivi des donn es dans le jeu pour toutes les demandes de propositions et aider am liorer la structure et le sch ma des rapports pour optimiser la vitesse des requ tes aider les sp cialistes de la science des donn es rassembler les donn es et construire des tables de travail pour acc l rer l analyse optimiser les requ tes sql pour am liorer la vitesse de traitement des clusters spark. build new and extend existing data structures to support game analytics maintain large, multi terabyte apache spark databases which includes performance tuning and data retention or purge processes research and troubleshoot data quality issues, providing fixes and proposing both short and long term solutions prepare designs for database systems and recommend improvements for performance maintain and develop various python or scala database scripts and tools to facilitate automation processes provide support related to all data tracking initiatives evaluate the implementation of data tracking in the game all proposals requests and assist to improve the logs structure and schema to optimize for querying speed assist data scientists to wrangle data and build working tables to speed analysis optimize sql queries to improve processing speeds on spark clusters. qualifications passion pour les jeux vid o minimum 3 ans d exp rience dans un r le similaire dans le d veloppement, la gestion, la maintenance et l optimisation d environnements de donn es de plusieurs t raoctets, y compris les pipelines de donn es et les processus etl qui leur sont associ s tr s forte exp rience avec apache spark ou une technologie similaire excellentes comp tences en sql solide exp rience dans les langages de script et de programmation tels que python, scala, linux shell, c scripting exp rience en mod lisation de donn es pour les environnements transactionnels et d entreposage de donn es, y compris la familiarit avec les normes de mod lisation dimensionnelle de kimball et 3nf exp rience de travail avec une vari t de sources de donn es telles que mysql, oracle, sql server, postgresql, s3, hdfs, et dynamo db exp rience avec les syst mes de contr le des sources solides comp tences interpersonnelles et capacit de r solution de probl mes. passion for video games minimum 3 years of experience in a similar role in developing, managing, maintaining and optimizing large, multi terabyte data environments including the pipelines of data and etl processes feeding into it very strong experience with apache spark or a similar technology expert level sql skills solid experience in scripting and programming languages such as python, scala, linux shell, c scripting data modeling experience for both transactional and data warehousing environments including familiarity with kimball dimensional and 3nf modeling standards experience working with a variety of data sources such as mysql, oracle, sql server, postgresql, s3, hdfs, and dynamo db experience using source control systems strong interpersonal skills and problem solving ability. preferred skills baccalaur at en informatique, en g nie, ou en intelligence d affaires avec une exp rience suppl mentaire appropri e exp rience dans l industrie du jeu vid o serait un grand plus exp rience de travail avec d autres technologies de donn es aws comme s3, redshift spectrum, athena, data pipeline, glue, emr, rds, et kinesis bs degree in computer science, engineering, or bi with appropriate additional experience experience in the video game industry would be a big plus experience working with other aws data technologies such as s3, redshift spectrum, athena, data pipeline, glue, emr, rds, and kinesis experience working with big data solutions such as apache spark, prestodb, impala or similar. applicant privacy notice applicant privacy notice","['databases', 'linux', 'emr', 'c', 'game development', 'apache', 'mysql', 'performance tuning', 'glue', 'sql', 'python', 'dynamo', 'data retention', 'postgresql', 'scala', 'mobile', 'scripting', 'database systems', 'informati', 'analytics', 'data', 'aws', 'pipelines', 'data warehousing', 'big data solutions', 'apache spark', 'data quality', 'athena', 'automation', 'data structures', 'programming languages', 'bi', 'data solutions', 'computer science', 'modeling', 'etl', 'r']","['databases', 'linux', 'emr', 'big', 'c', 'rds', 'apache', 'mysql', 'control systems', 'glue', 'sql', 'python', 'dynamo', 'postgresql', 'scala', 'aws', 'pipelines', 'apache spark', 'data quality', 'athena', 'programming languages', 'bi', 'r']","['data tracking', 'data retention', 'data structures', 'scripting', 'data solutions', 'mobile platforms', 'database systems', 'computer science', 'analytics', 'data', 'game development', 'modeling', 'data warehousing', 'automation', 'performance tuning', 'etl']",[]
321,414,Data Science Engineer,"about us designed for unlimited discovery and unmatched safety, epic is the leading digital library for kids. with tens of thousands of high quality books, audiobooks, and videos from the world s best publishers, every year millions of kids read, learn and explore on epic. to learn more about our vision to unlock the potential of every child, visit us at . about the job we are looking for a data engineer to join our data engineering team that delivers on key data initiatives. you will be working on developing data infrastructure and pipelines for a variety of heterogeneous data sources, including user content interaction, natural language content, impressions and click logs, for product features that use artificial intelligence and machine learning as well as for key business reports and analytics. you will be part of the core engineering team whose contributions help create a better world through learning and unlock the potential of every child on the planet. what you will be doing develop scalable real time streaming and batch infrastructure for various data streams and pipelines develop data observability systems to monitor data quality and data downtime develop data feeds for reporting and analytic needs develop automated ai and ml feature and model training pipelines for models developed by data scientists what you should have experience in one of the following programming languages python, java, or scala experience working on distributed computing and stream processing involving technologies such as kafka streams, spark streaming, pub or sub, and google cloud dataflow experience with at least one relational database system such as postgresql or mysql bachelor s degree in cs, ee or ece or a related field with at least 3 years relevant industry experience or m.s. or phd degree in cs, ee or ece or a related field with at least 1 years of relevant industry experience in data engineering curious, collaborative, and always willing to learn new things good communication skills passionate about data nice to have experience with a nosql database like cassandra or mongodb experience with docker, kubernetes, and jenkins for ci or cd pipelines benefits full medical, dental and vision coverage 401 plan take as you need vacation home office stipend lifestyle allowance in office perks unlimited access to our product job type full time","['computing', 'jenkins', 'data infrastructure', 'ci', 'mongodb', 'mysql', 'java', 'kubernetes', 'python', 'cd', 'postgresql', 'scala', 'reporting', 'data feeds', 'analytics', 'data', 'pipelines', 'data engineering', 'nosql', 'machine learning', 'stream processing', 'artificial intelligence', 'streams', 'cassandra', 'programming languages', 'ai']","['kubernetes', 'python', 'programming languages', 'scala', 'postgresql', 'jenkins', 'mysql', 'streams', 'pipelines', 'java', 'nosql', 'cassandra']","['distributed', 'computing', 'machine learning', 'cd', 'reporting', 'data infrastructure', 'data feeds', 'stream processing', 'ci', 'analytics', 'artificial intelligence', 'data', 'mongodb', 'data engineering', 'ai']",[]
322,415,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","company description eurofins scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. from the food you eat, to the water you drink, to the medicines you rely on, eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience cro services. it is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, cdmo, advanced material sciences and in the support of clinical studies. in over just 30 years, eurofins has grown from one laboratory in nantes, france to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing. in 2020, eurofins generated total revenues of eur 5.4 billion, and has been among the best performing stocks in europe over the past 20 years. eurofins cdmo alphora inc. provides a fully integrated suite of services to support drug substance and drug product development from the ind enabling development stage, through to phase ii iii supply, and commercial validation and manufacturing for niche apis. in addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, eurofins cdmo alphora inc. is committed to growing its state of the art organization, with continued investments in its people, modern facilities, equipment, and instrumentation. job description we are currently sourcing for 3 upcoming roles research scientist senior research scientist group leader the successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients . responsibilities will include but are not limited to research scientist, senior research scientist planning and execution of experiments in r d laboratories data analysis, interpretation, and documentation in development reports development of inherently safe processes based on thermal hazard assessment maintaining a safe and well organized laboratory work area technology transfer to both internal and external manufacturing facilities group leader in addition to above leading api technology programs and scientists associated provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project related issues, generating interim and final reports, preparing executive summaries for clients and executive management team qualifications experience and education requirements b.sc. or m.sc. in chemistry with 10 years experience or ph.d in chemistry with 5 years experience in the pharmaceutical or biotechnology industry the group leader position will require a ph.d in chemistry with 10 years experience in the pharmaceutical or biotechnology industry must have a strong knowledge of organic chemistry and hands on experience in the synthesis of complex organic molecules experience in process scale up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset must be highly motivated and have a proven record of success in multiple projects must be well organized and able to meet project timeline commitments must work well in a multi disciplinary team environment and have excellent written and verbal communication skills. additional information what we offer excellent full time benefits including comprehensive and medical coverage, dental, and vision options life and disability insurance rrsp or dpsp eligibility with company match paid vacation and holidays employee assistance plan, tuition program and much more working conditions this position will be working in a laboratory or manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. intermediate lifting requirements of no more than 50 lbs. hazardous materials are handled using established safety procedures and appropriate ppe. shift work and overtime may be required, as well as working periodic weekends and or or evenings. eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply if accommodations are required in the application or interview process, please contact us via only shortlisted candidates will be contacted no phonecalls or emails please. selected candidates can expect to be contacted in 3 6 weeks. no agencies, phonecalls or emails please","['hazard assessment', 'testing', 'sourcing', 'api', 'chemistry', 'specifications', 'documentation', 'data analysis', 'summaries', 'analytical']","['documentation', 'api']","['testing', 'sourcing', 'chemistry', 'specifications', 'data analysis', 'summaries', 'planning']","['pharmacology', 'validation', 'environment', 'raw materials', 'education', 'biotechnology', 'genomics', 'material', 'art', 'life sciences', 'hazard', 'materials', 'cro', 'product development', 'investments', 'manufacturing', 'environmental', 'insurance']"
323,416,Data Engineer,"about paytm labs at paytm labs, we re on a mission to provide useful technological solutions that enrich and empower millions of people in their daily lives. we apply big data, artificial intelligence and machine learning to bring the next generation of financial products and services to the indian, japanese and canadian markets. as a company, we re committed to offering the most transparent, secure, and personalized consumer experience to over 500 million users and over 20 million merchants. since our journey began 6 years ago, we ve launched the paytm canada app , and paypay , all while powering the paytm india app. job description if working with billions of events, petabytes of data and optimizing for last millisecond is something that excites you then read on we are looking for data engineers who have seen their fair share of messy data sets and have been able to structure them for building useful ai products. you will be working on writing frameworks building for real time and batch pipelines to ingest and transform events from 100 s of applications every day. our ml and software engineers consume these for building data products like personalization and fraud detection. you will also help optimize the feature pipelines for fast execution and work with software engineers to build event driven microservices. you will get to put cutting edge tech in production and freedom to experiment with new frameworks, try new ways to optimize and resources to build next big thing in fintech using data responsibilities work directly with machine learning engineers and platform engineering team to create reusable experimental and production data pipelines. understand, tune, and master the processing engines used day to day. keep the data whole, safe, and flowing with expertise on high volume data ingest and streaming platforms . sheppard and shape the data by developing efficient structures and schema for the data in storage and transit. explore as many new technology options for data processing, storage, and share them with the team. develop tools and contribute to open source wherever possible. adopt problem solving as a way of life always go to root cause qualifications degree in computer science, engineering or a related field you have previously worked on building serious data pipelines ingesting and transforming 10 6 events per minute and terabytes of data per day. you are passionate about producing clean, maintainable and testable code part of real time data pipeline. you understand how microservices work and are familiar with concepts of data modelling. you can connect different services and processes together even if you have not worked with them before and follow the flow of data through various pipelines to debug data issues. you have worked with spark and kafka before and have experimented or heard about flink or druid or ignite or presto or athena and understand when to use one over the other. on a bad day maintaining zookeeper and bringing up cluster doesn t bother you. you may not be a networking expert but you understand issues with ingesting data from applications in multiple data centres across geographies, on premise and cloud and will find a way to solve them. proficient in java or scala or python or spark what we offer due to the pandemic, we have been and will continue to wfh until it is safe to open our office. our company culture and values remain at the core of everything we do. for the third year in a row, we are proud to announce that we have been certified as a great place to work we were also certified as one of the best workplaces for mental wellness in 2020 we are an open work environment that fosters collaboration, ownership, creativity, and urgency we ensure flexible hours outside of our core working hours enrolment in the group health benefits plan right from day 1, no waiting period to keep things fun and stress free during covid 19 we started virtual daily, virtual weekly and monthly team bonding activities including trivia, games nights, movies nights, arts crafts , lunch learns , virtual wellness sessions , virtual team ubereats lunches, and so much more when we are able to open our office, our in office experience consists of team building events fuel for the day weekly delivery of groceries, and all types of snacks catered lunches and desserts on a monthly basis flexibility with wfh daily fun in the office with our competitive games of ping pong, pool, smash bros competitions, or fifa and of course, an unlimited amount of freshly made coffee we re pretty serious about our coffee beans notice for job applicants following the advice of canadian health authorities, to mitigate the risk of the potential spread of covid 19 and support social distancing, all recruiting activities including interviews and new hire onboarding will be conducted remotely. while we are doing our best to ensure reasonable response times, please expect potential delays during the recruiting process due to the current situation. we are an equal opportunity employer and value diversity and uniqueness at our company. we thank all applicants, however, only those selected for an interview will be contacted. paytm labs is committed to meeting the accessibility needs of all individuals in accordance with the accessibility for ontarians with disabilities act and the ontario human rights code . should you require accommodations during the recruitment and selection process, please let us know. don t have paytm canada app yet check us out in the google play or app store.","['personalization', 'go', 'root cause', 'big data', 'java', 'python', 'data processing', 'software', 'scala', 'app', 'pipelines', 'microservices', 'machine learning', 'data pipelines', 'data products', 'fraud detection', 'artificial intelligence', 'athena', 'computer science', 'networking', 'cluster', 'ai']","['go', 'python', 'scala', 'athena', 'app store', 'big data', 'google', 'pipelines', 'java']","['personalization', 'machine learning', 'data pipelines', 'data processing', 'software', 'data products', 'data ingest', 'root cause', 'fraud detection', 'artificial intelligence', 'computer science', 'networking', 'microservices', 'cluster', 'ai']","['environment', 'events', 'fintech', 'onboarding', 'team building', 'recruiting']"
324,417,Data Science II,"the onedrive and sharepoint data science team s charter is to foster a data driven culture to encourage and enable the entire organization to make more informed decisions through data. our data and analytics team works closely with engineering, marketing, finance, and business leaders to identify opportunities for improving the customer experience and accelerate our business s growth in support of this mission. we analyze historical data to understand salient trends, deliver standardized views of business performance, develop models to predict performance, recommend actions to be taken, and run experiments to prove that desired outcomes are being achieved. we are looking for a data scientist to join a new team focused on unlocking value for microsoft customers by understanding product usage patterns across the entirety of microsoft 365 . this is a unique opportunity to bring your knowledge of consumer and commercial offerings, as well as your deep understanding of data science methods and best practices, to help microsoft deliver the best experience possible for our customers and partners. you will be joining a group of experts on the front lines of synthesizing vast customer purchase and engagement behavior data sets into targeted recommendations for addressing real world business challenges at scale. we arelooking for you to bring a fresh perspective andyour unique voice to our team. about our culture we are a modern product and services organization, one of the largest business consumer services on the planet, and the second biggest workload in office 365. data scientists on this team will be part of the broader data science team, and specific product teams focused on tangible and immediate business impact. we have a tremendous responsibility to our customers to help transform their content needs with microsoft 365. we use data to organize our business priorities. we empower our industry leading data science, design, and user research teams to own our product s user experience. we take a direct role in framing our business value directly to our customers and vibrant community of fans. responsibilities work cross functionally to translate business problems into ones that can be solved and informed by data analysis have curiosity and apply analytical skills to dive deep into data to find key insights that impact the business. develop models of usage, user behavior business behavior to make recommendations and influence the product road map. work with other teams across microsoft to develop key metrics to achieve business outcomes. be a champion of ab testing. design, execute and analyze experiments to prove product change attribution. utilize tools like data bricks, r, python, sql to execute analyses qualifications one plus year exhibiting a strong passion understanding for the need to deliver the right business impact by working with stakeholders to turn business problems into data analysis questions and unearthing deep insights from data. have a track record of innovative thinking and problem solving skills using big data. be self driven and show the ability to deliver on ambiguous projects with incomplete data. understanding of the practical uses of statistics professional experience with large scale computing systems like hadoop, mapreduce, and or or similar systems. strong skills in sql, r, python, databricks, or related tools for large scale analysis. excellent communications interpersonal skills. ability to convince other strong personalities of their ideas and communicate complex analysis insights to a non technical audience. microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. if you need assistance and or or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the accommodation request form. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['attribution', 'sql', 'analytical skills', 'python', 'sharepoint', 'statistics', 'computing', 'complex', 'user experience', 'testing', 'hadoop', 'data science', 'analytics', 'big data', 'data analysis', 'map', 'r']","['sql', 'python', 'sharepoint', 'hadoop', 'big data', 'map', 'r']","['attribution', 'computing', 'analytical skills', 'statistics', 'complex', 'user experience', 'testing', 'data science', 'analytics', 'data analysis']","['office 365', 'user', 'metrics', 'marketing', 'business value', 'design', 'finance', 'microsoft 365', 'customer experience', 'recruiting', 'regulations']"
325,419,Data Engineer,"stackadapt is the no. 1 performing programmatic advertising platform helping brands accelerate customer engagement and acquisition. this state of the art platform is where some of the most progressive work in machine learning meets cutting edge user experience. ranking the highest in performance by g2 crowd for the fourth time, we re one of the fastest growing companies in canada and ranks 6th in deloitte s technology fast 50 ranking and 23rd in fast 500 in north america. we re looking to add data engineers to our data team this team works on solving complex problems for stackadapt s digital advertising platform. you ll be working directly with our data scientists, data engineers, engineering team, and cto on building pipelines and ad optimization models. with databases that process millions of requests per second, there s no shortage of data and problems to tackle. watch our talk at amazon tech talks https or or or watch v lrqu a4gpuu what you ll be doing design modular and scalable data pipelines to handle huge datasets understand and implement custom ml algorithms work on a micro service architecture that simultaneously implements and monitors thousands of ml models concurrently we ll be reaching out to candidates that have a high gpa from a well respected computer science program have confidence in algorithm design and concurrency preferably have at least 1 year of job experience interest in designing distributed scalable systems implementation of probabilistic and machine learning algorithms algorithms design ability stackadapters enjoy highly competitive salary with rrsp matching 3 weeks vacation 3 personal care days 1 volunteer day birthdays off full benefits from league on day one of employment work from home reimbursements coverage and support of personal development initiatives an awesome parental leave policy a weekly 15 lunch credit via ritual a friendly, welcoming, and supportive culture our social and team events about stackadapt stackadapt is a self serve programmatic advertising platform used by the most exceptional digital marketers. this state of the art platform is where some of the most progressive work in machine learning meets cutting edge user experience. ad buyers plan, execute, and manage data driven digital advertising campaigns across all devices, inventory, and publisher partners. stackadapt is a top 100 software product on g2, being the only dsp on the best software products and highest satisfaction lists. we ve been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including great place to work named stackadapt as one of canada s best workplaces for start ups in 2021 a leader in the dsp, video and cross channel advertising categories on g2 a top growing company in canada based on the globe and mail s 2020 business report named 23rd in deloitte canada s technology fast 50 program named in deloitte technology s fast 500 in north america stackadapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. we are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. we welcome and encourage anyone and everyone to apply.","['https', 'machine learning', 'databases', 'data pipelines', 'software', 'user experience', 'datasets', 'computer science', 'optimization', 'pipelines', 'algorithms', 'algorithm design']","['https', 'pipelines', 'databases']","['machine learning', 'data pipelines', 'software', 'user experience', 'datasets', 'algorithms design', 'computer science', 'optimization', 'algorithms', 'algorithm design', 'conversion rates']","['customer engagement', 'events', 'advertising', 'personal care', 'design', 'art', 'customer service', 'digital', 'hiring', 'growing companies', 'campaigns', 'architecture']"
326,420,Business Data Analyst (Investment banking),"job description trigyn is seeking business data analyst for contract position with our direct financial services client in montreal, qc. description the ideal candidate should have the skills listed below but in addition should be a self driven, dedicated individual who works well in a team and thinks and acts strategically. in addition, the candidate should respond well to change and quickly pick up new concepts in an ever moving regulatory landscape. when faced with a problem, the candidate should be able to ask questions and leverage the skill set of those around him or her. the group is responsible for the prevention and investigation of abusive, manipulative or illegal trading practices by financial advisors and the monitoring overall client suitability. this group identifies patterns behavior across multiple asset classes that may be an indication of sales practice issues or suitability concerns before these can compromise the firm s reputation or client s holdings. responsibilities maintain current state architecture, while being an active participant in discussions relating to data strategy across the organization collaborates with internal or external team members to architect solutions and implement enhancements to the platform responsible for data analysis, data profiling and data sourcing create and communicate an analytics strategy that sets the direction and describes the related activities necessary to create meaningful business and customer value support the global team of business analysts, data sme s, data providers and developers with data subject expertise, query building and optimization develop a thorough understanding of the data definitions, domain values, data relationships, business rules, sources and data integration translate business requirements into data models and etl design specifications define data quality rules, identify data issues partner with data providers to ensure upstream data requirements are met coordinate and conduct impact analysis because of upstream data changes and or or issues write detailed data requirements and use cases ensure that data requirements are met by participating in testing and data reconciliation work with management to prioritize business and information needs identify and define new process improvement opportunities follow through with data sources on issues and resolution effectively troubleshoot data quality issues implement and refine data quality controls qualifications the candidate should be capable of understanding and solving highly complex problems, have excellent communication skills and have financial services experience, preferably in the areas of investment banking and trading. proven working experience as a data analyst or business data analyst strong analytical skills with the ability to collect, organize, analyze, and disseminate large amounts of information with attention to detail and accuracy performs thorough root cause and impact analysis solid analytical, profiling and troubleshooting skills has strong understanding of data concepts good knowledge of relational databases must possess sound knowledge in rdbms, sql queries, indexes, keys and tables considering platforms, such as apache hadoop, oracle, mysql, hiveql, and microsoft sql. knowledge in programming languages, such as r, python, matlab and sas. advanced analytics or data scientist experience a plus. experience in data integration, conversion and migration excellent verbal and written communication skills, ability to work with cross cultural teams located globally knowledge of microsoft office applications experience with etl tools with the ability to develop etl design specifications and understand from the code what existing etls do knowledge of domain specific data and enterprise data knowledge of autosys, unix commands and scripting knowledge of data quality controls implementation of dq rules or checks preferably using an industry standard tool knowledge and experience in agile development methodology preferred. extensive experience documenting processes, workflows and technical specifications. quick learner with excellent attention to detail. highly motivated, flexible, proactive, and adaptable to change. education level bachelor s degree please respond only if you are currently eligible to work in canada. for immediate response call 732 876 7624, or send your resume to trigyn 8181 trigyn technologies, inc. is an equal opportunity employer and has been in business for 30 years. trigyn is an iso 9001 2015, iso 27001 2013 and cmmi level 5 certified company.","['analytical skills', 'rdbms', 'microsoft sql', 'troubleshooting', 'data profiling', 'root cause', 'new concepts', 'working experience', 'apache', 'business', 'mysql', 'investigation', 'sql', 'python', 'autosys', 'scripting', 'enterprise', 'unix', 'data', 'analytics', 'integration', 'data models', 'sas', 'relational databases', 'testing', 'design', 'sourcing', 'specifications', 'data analysis', 'data quality', 'matlab', 'programming languages', 'hadoop', 'optimization', 'etl', 'r']","['sql', 'python', 'autosys', 'programming languages', 'hiveql', 'rdbms', 'hadoop', 'microsoft sql', 'unix', 'apache', 'data models', 'data quality', 'sas', 'mysql', 'matlab', 'r']","['analytical skills', 'troubleshooting', 'data profiling', 'root cause', 'new concepts', 'working experience', 'business', 'investigation', 'scripting', 'data', 'analytics', 'integration', 'relational databases', 'testing', 'design', 'sourcing', 'specifications', 'agile development', 'data analysis', 'etls', 'enterprise data', 'use cases', 'optimization', 'methodology', 'etl']","['education', 'iso 9001', 'trading', 'customer value', 'sales', 'process improvement', 'sme', 'microsoft office', 'design', 'iso 27001', 'financial services', 'investment banking', 'architecture']"
327,422,Business Intelligence (BI) Developer/Data Analyst,"company description at jane, we re working to find the best ways to help small businesses succeed, and we re using the latest technology to build a better online marketplace. we have some pretty big goals and are always looking for talented people who want to be a part of something new. we not only work hard at our jobs but also to maintain a culture of authenticity and collaboration. join us and enjoy the janelife to its fullest. jane s values lead with empathy pull together just say it make it count make your mark about the team the data team was recently formed under a single executive to combine resources throughout the organization to optimize and enhance the data driven capabilities at jane. the main pillars of our data team are analysis and insights bi development data engineering data governance data science performance management you will have the opportunity to work with others across our team collaborating to deliver services to enhance the execution of our business. while supporting all business functions at jane, you will also have the chance to develop other data skills within the data team to apply to your development as a data professional. what you ll be doing reporting into our manager of data analytics, you will build reports and dashboards on our bi platform to support various stakeholders design and build data models on our bi platform to enable self service bi and data exploration resolve ad hoc data requests and changes to our bi platform build complex sql queries and explore data in support of business initiatives engage with business consumers of data, gather requirements, and deliver end to end data driven insight and solutions maintain and update our data wiki and data dictionary as required provide training and guidance to end users of our bi platform and in the analysis and understanding of data prepare technical and non technical documentation and presentations qualifications university or college degree with focus on either computer science, business, mathematics or statistics preferred at least 2 years experience in similar data related positions. for example, as a data analyst, data scientist, data engineer, bi developer. compensation will be commensurate with experience solid understanding of data warehousing concepts, dimensional and relational database design strong experience and skills in sql is a must experience with business intelligence platforms l.e. cognos, tableau, looker, and power bi etc. ability to build interactive dashboards and reports strong written and verbal communication skills are a must ability to communicate and present to technical and non technical audiences ability to write accurate, concise technical documentation a self starter who can work well independently with minimal direction ability to think outside the box and infuse creativity into problem solving","['tableau', 'dashboards', 'data analytics', 'sql', 'looker', 'statistics', 'reporting', 'data science', 'database design', 'data', 'data models', 'data engineering', 'data warehousing', 'business intelligence', 'bi', 'computer science', 'mathematics', 'technical documentation', 'performance management']","['sql', 'looker', 'tableau', 'bi', 'business intelligence', 'data models']","['data analytics', 'statistics', 'reporting', 'dashboards', 'data science', 'database design', 'computer science', 'data', 'mathematics', 'technical documentation', 'data engineering', 'data warehousing', 'performance management']","['business initiatives', 'presentations', 'design', 'governance', 'compensation']"
328,423,"Data Engineer, ClearAngel","clearangel is building yc for the 99 of founders. those who traditionally don t have access to advice, capital or network we want to support that long tail. most founders don t live in silicon valley or have the pristine pedigree to get in front of the right people. for far too long, startups have played on a scarcity model. this is limiting the potential of founders. we fundamentally believe that great founders and companies are everywhere. where there are problems, opportunities exist. we want to empower those founders. we are building clearangel to democratize access to advice, network and capital. we do this by scaling access to the rest of the world access to advice access to network access to capital the role of the data engineer is to collaborate on backend architecture and minimalistic data pipelines that enable features for the clear angels product and supporting processes. your responsibilities will be a superset of a typical data engineer, as there are often experiments and uncertainty that require creative solutioning at the earliest stages. application deadline ongoing what your day to day will look like you will own technical products end to end, from design and architecture to deployment and maintenance working closely with every member of the team, you will produce significant components of the clearangel code work closely with all functions of clearbanc, ranging from core engineering team to data science team to the marketing team you be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary you will scope out business needs for clearangel, and action them with speed and accuracy and then execute on it yourself you will run and participate in founder townhalls, communicating closely with early stage entrepreneurs when it comes to product and engineering on clearangel, buck stops with you. coordinate, roll up your sleeves, do what s necessary to get the ball moving forward you will thrive if you have a desire to help founders. we take a strong founder first stance on this team are self sufficient when it comes to execution. figure out how to solve problems and make things happen, not waiting for help or permission on this team, we maximize learning. you will fail if you re not learning fast enough are comfortable working in a high growth, constantly changing environment you are heavy bias towards action. ability to solve problems end to end on their own. you will implement ideas and experiments on your own with minimal support have experience working in a senior software engineering role, you are an expert when it comes to coding and you re ready to roll up your sleeves to get the job done have a strong business sense, you can foresee potential issues and solve them quickly demonstrated ability to collaborate effectively across multiple teams strong interest in building businesses, ecommerce, fintech technical requirements 3 years of experience working on a variety of different projects or stacks would be ideal experience working on remote teams able to architect and scale data integrations from third party api docs independently without much support interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes comfortable working in server and database environments that are changing constantly demonstrated experience with using third party solutions and external apis to supercharge existing features comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff comfortable with relational databases and schemas involving time series skills and interest in python, sql, snowflake, kubernetes clearco is an equal opportunity employer. we celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. at clearco, we re committed to developing and upholding an inclusive, transparent, and comfortable environment for all. we create a space where every voice, perspective, and idea is heard and acknowledged. we embrace differences, and know that our diverse team is our strength and what drives our innovation. clearco is committed to developing a barrier free recruitment process and work environment. if you require any accommodation, please let us know and we ll work with you to meet your accessibility needs.","['kubernetes', 'sql', 'python', 'schemas', 'data pipelines', 'relational databases', 'software', 'data science', 'api', 'technical requirements', 'uncertainty', 'rest', 'snowflake']","['kubernetes', 'sql', 'python', 'api', 'clearco', 'snowflake']","['schemas', 'data pipelines', 'relational databases', 'software', 'data science', 'technical requirements', 'uncertainty', 'rest']","['environment', 'fintech', 'capital', 'marketing', 'design', 'team building', 'startups', 'architecture']"
329,424,Architecte de données / Data Architect - 312699,"architecte de donn es dans le cadre de ses ententes avec ses diff rents clients, procom est actuellement la recherche d un architecte de donn es pour une entreprise dans le domaine manufacturier. notre client est situ montr al. description des t ches et responsabilit s architecte de donn es les responsabilit s du poste incluent participer l tablissement et au maintien du mod le de donn es global de l entreprise, en collaboration troite avec les lignes d affaire, l quipe de gouvernance des donn es et les ing nieurs de donn es de l organisation capturer les requis d affaire afin d tablir les mod les de donn es de type relationnel, dimensionnel ou data vault afin de supporter diff rents cas d utilisation de la donn e revoir les mod les de donn es propos s par les ing nieurs de donn es, les analystes et les scientifiques afin de les optimiser, de les aligner avec le mod le global, et de les op rationnaliser, tout en assurant une adh sion aux standards de l industrie et aux lois en lien avec gdpr et sox d finir et mettre en place les l ments d architecture qui assureront la disponibilit , la qualit , la s curit et la mise disposition des donn es voir la conformit de la plateforme bi, depuis la capture des donn es brutes jusqu la couche de pr sentation tre un or une leader dans la d finition des meilleures pratiques et de la pens e cr ative. exigences du poste architecte de donn es ma trise en informatique, intelligence d affaire ou exp rience quivalente exp rience solide et d montr e en diff rents types de mod lisation de donn es mod les relationnels mod les dimensionnels data vault 2.0. travail en quipe, tre ouvert d esprit et toujours tre pr t discuter du mod le propos ou de l approche prendre tr s organis , capable de b tir un plan de match , et de prioriser ses propres t ches avec des dates de livraison conflictuelles propose sans cesse des id es d am lioration cr atives, et adore mettre les mains dans des technologies nouvelles excellent communicateur oral et crit, en fran ais et en anglais, capable de pr parer et de faire des pr sentations ex cutives a d j travaill dans un mod le de livraison agile une exp rience avec sap ecc et s4, azure, snowflake est un plus. type de poste contractuel 12 mois avec de fortes possibilit s de renouvellement. date de d but imm diatement num ro de r f rence bh312699 english version data architect as a part of its agreements with its various clients, procom is currently seeking a data architect for a company in the manufacturing sector. our client is located in montr al. job details data architect key responsibilities for this position include participate in the establishment and maintenance of the overall enterprise data model, working closely with business lines, the data governance team and the organization s data engineers capture business requirements to establish relational, dimensional or data vault data models to support different data use cases review data models proposed by data engineers, analysts and data scientists to optimize them, align them with the overall model, and operationalize them, while ensuring adherence to industry standards and laws related to gdpr and sox define and implement the architecture elements that will ensure data availability, quality, security and delivery ensure compliance of the bi platform, from raw data capture to the presentation layer be a leader in defining best practices and creative thinking. mandatory skills data architect master s degree in computer science, business intelligence or equivalent experience strong and demonstrated experience in various types of data modeling relational models dimensional models data vault 2.0. team player, open minded and always willing to discuss the proposed model or approach to be taken highly organized, able to build a game plan , and prioritize own tasks with conflicting delivery dates constantly comes up with creative ideas for improvement, and loves to get his hands into new technologies excellent oral and written communication skills, in french and english, with the ability to prepare and deliver executive presentations previously worked in an agile delivery model experience with sap ecc and s4, azure, snowflake is a plus. assignment length 12 month contract renewable start date immediately reference number bh312699","['bi', 'security', 'enterprise', 'computer science', 'data', 'modeling', 'business intelligence', 'data models', 'vault', 'snowflake']","['bi', 'snowflake', 'business intelligence', 'data models']","['use cases', 'security', 'gdpr', 'data', 'computer science', 'modeling', 'data vault', 'vault', 'enterprise data']","['ec', 'sap', 'presentations', 'governance', 'manufacturing', 'business', 'architecture']"
330,425,Data Engineer - TW 30,"the role is going to be data engineer with our client thoughtworks. please find below the job description for the position. please send the following documents to if that interests you and matches your profile. without mandatory documents, we cannot submit a candidate. 1. updated resume in word format 2. expected hourly rate duration 6 months contract with a possibility of extension. job description you ll spend time on the following you will use continuous delivery practices to deliver high quality software as well as value to end customers as early as possible. you will work in collaborative, value driven teams to build innovative customer experiences for our clients create large scale distributed systems out of microservices you will apply the latest technology thinking from our tech radar to solve client problems efficiently utilize devops tools and practices to build and deploy software you will lead or take part in the entire cycle of software consulting and delivery from ideation to deployment and everything in between you will act as a mentor for less experienced peers through both your technical knowledge and leadership skills here s what we re looking for you have at least 6 years of experience with two or more development languages such as java, c , or ruby you can skillfully write high quality, well tested code and you are comfortable with object oriented programming presence in the external tech community you proactively share your expertise with others via speaking engagements, contributions to open source, blogs and more comfortability with agile methods, such as extreme programming , scrum and or or kanban you enjoy influencing others and always advocate for technical excellence while being open to change when needed you re willing and able to commit to travel to client sites in order to solve their business problems you re resilient in ambiguous situations and can approach challenges from multiple perspectives bonus points if you have working knowledge of cloud technology such as aws, azure, kubernetes and docker 4sik1xxuv5","['kubernetes', 'ruby', 'radar', 'kanban', 'continuous delivery', 'software', 'devops', 'scrum', 'c', 'programming', 'aws', 'less', 'distributed systems', 'microservices', 'java']","['ruby oriented', 'kubernetes', 'c', 'programming', 'aws', 'less', 'java']","['radar', 'kanban', 'continuous delivery', 'software', 'devops', 'scrum', 'distributed systems', 'microservices']","['consulting', 'engagements']"
331,426,CPXE-Data & AI Growth Analytics Analyst,"who we are cisco s customer experience organization is one of cisco s fastest growing teams, and the customer and partner experience engineering group is redefining how cisco delivers value to our customers partners via our product portfolio. the cxpe product growth team leads analytics and growth initiatives for the cisco product po rtfolio . our mission is to measure, understand and optimize the cisco experience for customers and partners across enterprise, mid market and growth segments . we are a small data driven team passionate about customer value acceleration, delivering delightful experiences and accelerating lifecycle growth through rapid experimentation. we spend our time determining the highest impact variables and l evers to unlock growth and optimize the path to product value. we use data to drive product led growth. what you ll do as part of the product growth team, you will wo rk across a multi functional team to identify, prioritiz e and execut e data driven growth activities. you will focus on using experimentation to drive growth and enhance the cisco value experienc e for customers and partners. you will build analytica l narratives t hat help solve business, marketing , and growth problems such as conversion and adoption optimization, ltv forecasting, churn analysis, causal inference, and more. who you ll work with you will be part of a fun , loving, diverse team, with an inclusive culture. duties collaboratively span strategy to execution across the cx organization to promote business growth and customer lifecycle acceleration . in addition to customers and partners , you ll partner with engineering, product management, it, digital transformation, data scientists, ux researchers our executive team. specifically, y ou will identify and investigate numerical and qualitative data sets , assemble disparate sources of data to provide insight into how customers using cisco products. collaborate with product and engineering teams to establish hypothesis, set up experiments , and interpret results convert numerical results into concrete, meaningful recommendations for business or product improvement s uccinctly communicate s olutions to cross functional partners and leadership across engineering, data science, ux research, marketing and more. must have s bs in computer science, engineering, statistics or related work experience. p roven track record of setting up and optimizing metrics tracking systems and a or b testing methodologies , multivariate testing , power analysis and regressions. proven experience working with extremely large datasets, etl processing and machine learning pipelines. proficiency with decision modeling techniques and software sql, python, r nice to haves 4 years of experience in business data analysis. you can easily give us an example of a data project you ve work on and what impact it had on driving business outcomes. knowledge of customer experience, product growth functions, understanding of customer lifecycles, familiarity with bookings and pipeline reporting. proficiency with decision modeling techniques and software sql, python, r highly collaborative and communicative, with ability to effectively manage business expectations and regularly work with both business and technical stakeholders. why cisco wearecisco, where each person is unique, but we bring our talents to work as a team and make a difference. here s how we do it. we embrace digital, and help our customers implement change in their digital businesses. some may think we re old and only about hardware, but we re also a software company. and a security company. an ai or machine learning company. we even invented an intuitive network that adapts, predicts, learns and protects. no other company can do what we do you can t put us in a box but digital transformation is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure day to day, we focus on the give and take. we give our best, we give our egos a break, and we give of ourselves we take accountability, we take bold steps, and we take difference to heart. because without diversity of thought and a commitment to equality for all, there is no moving forward. so, you have colorful hair don t care. tattoos show off your ink. like polka dots that s cool. cpxe","['business', 'sql', 'python', 'statistics', 'software', 'decision', 'reporting', 'data science', 'product management', 'analytics', 'pipelines', 'machine learning', 'ai', 'testing', 'data analysis', 'causal inference', 'qualitative data', 'hardware', 'forecasting', 'ux', 'datasets', 'security', 'computer science', 'optimization', 'modeling', 'digital transformation', 'etl', 'r']","['sql', 'python', 'hardware', 'pipelines', 'r']","['multivariate', 'business', 'power', 'statistics', 'software', 'decision', 'reporting', 'data science', 'product management', 'analytics', 'machine learning', 'testing', 'data analysis', 'causal inference', 'qualitative data', 'forecasting', 'ux', 'datasets', 'security', 'computer science', 'optimization', 'modeling', 'digital transformation', 'etl', 'ai']","['metrics', 'marketing', 'customer value', 'customer experience', 'bookings', 'product value', 'adoption', 'business growth']"
332,427,Senior Data Scientist,"parkland is an independent supplier and marketer of fuel and petroleum products and a leading convenience store operator. we power a growing family of locally known brands and our team members serve retail, commercial, and wholesale customers across canada, the united states, the caribbean region and the americas. our purpose as parklanders is to energize people and businesses to get them where they want to go. we re a passionate team of down to earth achievers, committed to getting our customers, colleagues and communities further, faster. job title senior data scientist location calgary, ab position summary parkland corporation is deeply invested in building next generation enterprise data, digital analytics capability, with an aspiration to improve our value to customers, our customers experiences, and drive profitable growth and industry leadership for parkland. parkland is seeking a senior data scientist to be part of our newly forming enterprise digital team consisting of skillsets spanning machine learning, ai, statistics, data engineering and full stack development. you will work as part of a high caliber team that works on solutions across parkland s business areas including supply, pricing and loyalty, retail, commercial, trading and refining to drive high value solutions. as canada and caribbean s largest and one of america s fastest growing independent suppliers of fuel and marketing products and a leading convenience store operator, parkland s operations provide a rich and varied set of analytics opportunities, including over 1 mm retail transactions per day. key responsibilities develop a close working relationship with a subset of business segments. translate ambiguous business needs or questions into analytical approaches using available data . able to assemble and guide small technical teams appropriate to the problem at hand. provide strategic technical direction. be able to take on accountability for business value. scope out and operationally deliver outcomes while making critical decisions regarding priorities, technologies and leadership guidance. oversee and guide the building, testing and deploy pipelines for machine learning including, but not limited to, feature engineering, model train or test or validate, and repeatable analysis or measurement of results. be able to present internally and externally on technical matters and benchmark with peers in the technology space. keep the business and leadership abreast of next generation technology needs and help them develop and maintain a multi year roadmap consistent with parkland s growth. work with and support other team members, management, and partners. qualifications and skills advanced degree in a relevant technical field . a minimum 10 years experience in data science, analytics, and model building roles in a business context. track record of working with, mentoring and leading technical teams towards measurable business output. fluency in statistical, machine learning methods from a mathematical and computational perspective. strong practical knowledge of applying analytical techniques and methodologies to business objectives, including machine learning or supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques. experience working with large complex data sets, real time or near real time analytics, and distributed big data platforms . strong knowledge of analysis tools such as python, r, spark, pyspark or r or spark on hadoop or cassandra preferred. strong background in applying statistical machine learning techniques to predictive modeling and experience with machine learning libraries . proficiency in programming in python, r, sql, javascript, java or scala or ruby and shell scripting. natural curiosity and a strong passion for empirical research and problem solving. strong written and verbal communications skills comfortable communicating with senior levels of both business and technology leadership. the following are considered as asset capability in data ingest and connector rools particularly talend proficiency in workflow and ci or cd tools e.g., airflow, circleci, jenkins proficiency in consuming rest based api capability in big data platforms including hadoop, mapreduce, hive, spark, pig familiarity with cloud based haas or paas solutions such as aws emr we offer participation in parkland pledge, an employee driven charitable giving program. our performance based annual incentive plan, an annual bonus awarding your performance. a share in our success through the employee share purchase plan and 100 company matching. flexible medical and dental packages, a health care spending account, along with a supportive employee and family assistance program. in house learning and development opportunities, leadership training, international opportunities. an employee referral program earn up to 2000 for your referral. a focus on healthy living through wellness initiatives and an annual fitness reimbursement program. discount programs and educational scholarship programs for family members. candidates must be legally able to work in canada or the united states at this time. parkland regrets that it is unable to sponsor employment visas or consider individuals on time limited visa status for this position. we thank all candidates in advance for their interest, however only those being considered will be contacted. parkland fuel corporation is committed to the principles of employment equity. we strive to provide accessibility in employment to ensure equal access to employment opportunities for candidates, including persons with disabilities. parkland fuel corporation will endeavour to provide accommodation to persons with disabilities in the recruitment process upon request. if you are selected for an interview and you require accommodation due to a disability, please notify us upon scheduling your interview.","['go', 'model building', 'pyspark', 'jenkins', 'technical direction', 'emr', 'ci', 'big data', 'empirical research', 'paas', 'javascript', 'hive', 'java', 'sql', 'python', 'ruby', 'statistics', 'cd', 'scala', 'data science', 'analytics', 'programming', 'aws', 'technology', 'pipelines', 'data engineering', 'r', 'data mining', 'analytical techniques', 'machine learning', 'testing', 'rest', 'shell scripting', 'cassandra', 'enterprise data', 'airflow', 'experimental', 'hadoop', 'neural networks', 'api', 'optimization', 'modeling', 'ai']","['go', 'pyspark', 'jenkins', 'emr', 'big data', 'paas', 'javascript', 'hive', 'java', 'mapred', 'sql', 'python', 'ruby', 'scala', 'programming', 'aws', 'pipelines', 'circleci', 'shell script', 'cassandra', 'airflow', 'hadoop', 'api', 'r']","['model building', 'technical direction', 'ci', 'data ingest', 'empirical research', 'statistics', 'cd', 'data science', 'analytics', 'data engineering', 'data mining', 'analytical techniques', 'machine learning', 'testing', 'predictive', 'rest', 'enterprise data', 'experimental', 'time series', 'neural networks', 'optimization', 'modeling', 'feature', 'ai']","['marketing', 'retail', 'business value', 'trading', 'design', 'tale', 'mentoring']"
333,428,"Data Engineer, Omnia AI (Montreal)","job type permanent primary location montreal, quebec, canada all available locations montreal learn from deep subject matter experts through mentoring and on the job coaching partner with clients to solve their most complex problems enjoy flexible, proactive, and practical benefits that foster a culture of well being and connectedness. you have a passion for analytics and advanced data management you want to build solutions that will allow customers to go further with the best of the existing data solutions are you ready to uncover the possibilities of ai in your career and set the foundation for success tomorrow then we have an opportunity waiting for you what will your typical day look like as a data engineer within our omnia ai practice, you will be a team player to a portfolio of deloitte s omnia ai engagements . you will have the opportunity to be involved in the full life cycle over ai projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. you will be able to work on the largest and most advanced analytics projects on the market 2019, 2020, 2021 gartner data analytics service provider leader. specifically, you will bring your expertise to customers who want to transform their company into a data driven organization. you will be able to leverage all the existing assets created by deloitte around ai applications, and combine them with your knowledge to build perfectly tailored applications for each customer. work with high profile clients on a variety of canadian and international engagements, including opportunity to travel across canada and internationally . about the team deloitte omnia, deloitte s artificial intelligence practice is comprised of specialized experts with hands on experience, and cutting edge information assets that facilitate successful artificial intelligence transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. our data analytics modernization team helps clients design and implement the data platform architectures be it in the cloud or on premise required to enable cutting edge ai solutions. we work closely with the omnia ai strategy, ai data science and ai factory teams to drive successful business outcomes. you will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on big data, bi or dw, data integration, data governance, master data and analytics applications. each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. to support our continued growth, we are looking to add many team players with hands on work experience ideally in the data, analytics and or or ai domains. enough about us, let s talk about you you are someone with strong interest to bring artificial intelligence and advanced analytics to enterprise applications 2 years of experience in data modeling and etl processes within enterprise systems modern analytic platforms data lake, data warehouse, datamart, dimensional models, etl processes an experience writing sql queries or python scripts, extracting and importing disparate data from source systems to analytics platforms team player attitude superior communication skills, intellectual curiosity, and strong analytical skills undergraduate studies in business or engineering or mathematics or computer science postgraduate studies in computer science related specializations advantageous differentiators but not required projects experiences with the following azure data lakes, snowflake, databricks and agile development methods in data oriented projects bilingual if you believe you have what it takes to be a successful member of our team, please apply now. we know your career is important to you and it s important to us, too. this role is just the first step of a highly successful career we can help you build. the time is right for you to join deloitte. get your career off to great start. what impact will you make why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities deloitte encourages applications from all qualified candidates that represents the full diversity of communities across canada. this includes candidates from indigenous communities in support of living our values and our commitments to our reconciliation action plan . we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally. deloitte canada has 30 offices with representation across most of the country. we acknowledge our offices reside on traditional, treaty and unceded territories as part of turtle island and is still home to many first nations, m tis, and inuit peoples. we are all treaty people.","['go', 'analytical skills', 'big', 'master', 'data analytics', 'sql', 'python', 'data science', 'enterprise', 'analytics', 'data', 'integration', 'modernization', 'enterprise systems', 'artificial intelligence', 'bi', 'data solutions', 'computer science', 'mathematics', 'modeling', 'data management', 'snowflake', 'etl', 'ai']","['go', 'sql', 'python', 'azure', 'bi', 'data lakes', 'big data', 'master data', 'snowflake']","['modernization', 'data analytics', 'analytical skills', 'data solutions', 'data science', 'enterprise systems', 'enterprise', 'computer science', 'analytics', 'artificial intelligence', 'data', 'integration', 'modeling', 'mathematics', 'agile development', 'data management', 'etl', 'ai']","['subject matter experts', 'project delivery', 'design', 'governance', 'engagements', 'proposal', 'mentoring']"
334,429,Data Engineer,"be authentic . be influential . be the expert . be all that and more at colliers. at colliers, we help leaders succeed by helping them build amazing workplaces, businesses and communities around the world. we do this by thinking differently, sharing innovative ideas and offering a unique and collaborative workplace where you can succeed. who you are you will work directly with global finance management and north america accounting on strategic projects to support and enhance our systems. various reporting and data analysis tools will be used to design solutions that best meet business needs, both current and long term. this role will work closely with other it, finance, payroll and accounting teams around the world to effectively deliver projects. what you bring 5 years of relevant experience in a similar role. 3 years of experience with microsoft sql server tools . 5 years of overall progressive financial reports development and 2 years experience with sql server programming. 3 years of experience with design and development of etl processes. experience with best practices of information visualization, user interface design, and iterative customer driven design processes. experience with financial and reporting applications. experience with developing test plans, test cases and training materials. knowledge of oriented object programming . a customer service orientation and demonstrate a can do attitude. ability to think critically and analytically. ability to multi task in a fast paced environment. an eye for automation and process improvements. bonus skills and experience experience in the following applications or systems would be considered an asset ibm cognos tm1 ibm cognos bi microsoft dynamics ax azure devops office 365 what success looks like you develop and maintain etl processes between third party systems and the north america erp and global finance data store you successfully develop and maintain microsoft sql databases including creating and maintaining databases, tables, views, stored procedures, and database triggers. you successfully work with managers, technical staff, and users to implement new reporting and integration solutions . this includes involvement in requirement analysis, test plans, individual and group training, meetings and documentation as well as ensuring that proper processes are followed in the systems life cycle to maintain responsive, reliable, and functional systems. you analyze, design, develop, test and maintain complex business intelligence reports and dashboard using various front end tools . li on1 be who you are and what you want to be with colliers. we d love to meet you. apply today to join our team. direct applicants only please, no agencies. colliers is an equal opportunity employer and values diversity in its workforce. colliers encourages applications from all qualified individuals and will accommodate applicants disability related needs, up to the point of undue hardship, throughout all stages of the recruitment and selection process. if you require a disability related accommodation in order to participate in the recruitment process, please contact the recruitment team by email at","['databases', 'microsoft sql', 'erp', 'documentation', 'functional systems', 'reporting', 'dynamics', 'programming', 'integration', 'microsoft sql server', 'stored procedures', 'sql server', 'business intelligence', 'data analysis', 'automation', 'dashboard', 'test cases', 'bi', 'devops', 'information visualization', 'user interface design', 'etl']","['dashboard', 'microsoft sql server', 'azure', 'databases', 'stored procedures', 'bi', 'sql server', 'object', 'microsoft sql', 'microsoft', 'erp', 'programming', 'documentation', 'business intelligence']","['user', 'test cases', 'interface', 'reporting', 'devops', 'information visualization', 'dynamics', 'integration', 'data analysis', 'functional systems', 'automation', 'etl']","['office 365', 'environment', 'accounting', 'design', 'finance', 'materials', 'customer service', 'finance management']"
335,430,Architecte Solutions Infonuagiques - Data (Cloud Solution Architect- Data),"microsoft a comme mission de permettre chaque personne et chaque organisation de la plan te d en accomplir davantage. pouss s vers le haut par notre culture, nous adoptons une mentalit de croissance, inspirons l excellence et encourageons les quipes et les dirigeants donner le meilleur d eux m mes chaque jour. ce faisant, nous cr ons des innovations qui changent les vies de milliards de personnes dans le monde entier. vous pouvez nous aider accomplir notre mission. microsoft souhaite aider ses clients r aliser leur propre transformation num rique gr ce la puissance de ses solutions et services microsoft cloud. c est dans cette optique que microsoft investit dans une quipe consacr e la r ussite de ses clients, qui aidera ces derniers atteindre leurs r sultats commerciaux. azure est l heure actuelle la plateforme infonuagique la plus compl te, la plus novatrice et la plus souple qui soit. par cons quent, microsoft embauche des professionnels qui favoriseront l adoption du nuage par les clients au sein des entreprises les plus importantes du march . nous ne cessons jamais d apprendre. nous sommes anim s d une insatiable curiosit . nous faisons face l incertitude, prenons des risques et apprenons rapidement de nos erreurs. nous nous d veloppons gr ce aux id es des autres, car nous sommes meilleurs tous ensemble. nous sommes merveill s par ce que l humain peut accomplir, et cela nous motive encourager les autres en faire plus gr ce nos technologies et nos innovations. ensemble, nous changeons les choses. pour en savoir plus sur la mission de microsoft, visitez le site https or or careers.microsoft.com or mission culture d couvrez tous nos produits au http or or or fr ca nous recherchons un architecte de solutions infonuagiques pour plateforme de donn es sp cialis en analyses avanc es et en intelligence artificielle. cette personne, qui devra tre fortement motiv e et passionn e, sera amen e conduire des initiatives clients hautement prioritaires sur la plateforme microsoft azure en collaboration avec les clients et les secteurs d activit de nos comptes entreprise. il s agit d un poste en lien direct avec les clients, ayant pour responsabilit d assurer la relation technique globale entre les clients et la plateforme de donn es, d analyses avanc es et d intelligence artificielle de microsoft. vous serez charg des engagements techniques li s la plateforme de donn es et aux analyses avanc es envers les clients, y compris des s ances de conception architecturale, des projets de mise en uvre particuliers et des pppv. le candidat id al aura de l exp rience dans des fonctions en lien direct avec les clients et aura r ussi mener, avec son quipe dirigeante, les architectes d entreprise, l quipe de gestion des ti et les d veloppeurs, des discussions ax es sur une architecture technique approfondie dans le but de mettre en uvre les solutions de plateforme de donn es et d analyses avanc es. microsoft is on a mission to empower every person and every organization on the planet to achieve more. our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. in doing so, we create life changing innovations that impact billions of lives around the world. you can help us to achieve our mission. microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of microsoft cloud solutions and support offerings. to this end, microsoft invests in a dedicated customer success team that will help microsoft customers successfully realize their business outcomes. azure is the most comprehensive, innovative and flexible cloud platform today and microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market. we are always learning. insatiably curious. we lean into uncertainty, take risks, and learn quickly from our mistakes. we build on each other s ideas because we are better together. we stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. together we make a difference. to learn more about microsoft s mission, please visit https or or careers.microsoft.com or mission culture check out all of our products at http or or or en us we are looking for a highly motivated and passionate data platform advanced analytics or artificial intelligence cloud solution architect to drive high priority customer initiatives on the microsoft azure platform in collaboration with customers and the microsoft field in enterprise accounts segment of our business. this is a customer facing role, owning overall technical relationship between customer and microsoft data, advanced analytics and artificial intelligence platform. you will own the data platform advanced analytics technical customer engagements including architectural design sessions, specific implementation projects and or or mvps. the ideal candidate will have experience in customer facing roles and success leading deep technical architecture discussions with senior customer executives, enterprise architects, it management and developers to drive data platform and advanced analytics solutions to productions. responsibilities parmi les principales responsabilit s comprendre l ensemble des donn es des clients, leurs priorit s informatiques et d affaires et les mesures de r ussite afin de concevoir des solutions et des architectures de mise en uvre. appliquer des connaissances techniques pour laborer l architecture de solutions qui r pond aux besoins commerciaux et informatiques, cr er des feuilles de route pour la plateforme de donn es, les analyses et l ia, et assurer la viabilit technique long terme des nouveaux d ploiements en int grant des technologies d analyses cl s au besoin . s assurer que les solutions pr sentent de hauts niveaux de performance, de s curit , d volutivit et de maintenabilit , ainsi qu une r utilisabilit et une fiabilit ad quates au moment du d ploiement. tablir des liens troits avec les principaux d cideurs des ti et d entreprise pertinents , qui ont la capacit d encourager l adoption de l infonuagique au sein de leur entreprise pour faire d eux des d fenseurs du nuage. tre la voix du client pour partager des renseignements et des pratiques exemplaires et pour interagir avec l quipe d ing nierie dans le but de supprimer les obstacles principaux. valuer les connaissances des clients de la plateforme azure et de la pr paration globale l infonuagique de mani re soutenir les clients au moyen d un plan d apprentissage structur et assurer sa mise en uvre gr ce aux partenaires. collaborer avec d autres architectes de solutions infonuagiques et intervenants ms pour d velopper des solutions d entreprise complexes de bout en bout sur les plateformes infonuagiques microsoft. maintenir les connaissances et les comp tences techniques, suivre les tendances du march et recueillir des renseignements concurrentiels, et collaborer et partager ses d couvertes avec la communaut technique tout en renseignant les clients sur la plateforme azure. tre un vang liste de la plateforme azure aupr s des clients, des partenaires et des communaut s externes. key responsibilities include understand customers overall data estate, it and business priorities and success measures to design implementation architectures and solutions. apply technical knowledge to architect solutions that meet business and it needs, create data platform, analytics and ai roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment develop deep relationships with key customer it decision makers and relevant business decision makers , who drive long term cloud adoption within their company to enable them to be cloud advocates be a voice of customer to share insights and best practices, connect with engineering team to remove key blockers assess the customers knowledge of azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners. collaborate with other cloud solution architects and ms stakeholders in developing complex end to end enterprise solutions on microsoft cloud platforms. maintain technical skills and knowledge, keeping up to date with market trends and competitive insights collaborate and share with the technical community while educate customers on azure platform be an azure platform evangelist with customers, partners and external communities. qualifications exp rience requise en mati re de formation, d exp riences cl s, de connaissances et de comp tences exp rience professionnelle. au moins 5 ans de succ s dans le domaine des ventes techniques consultatives ou complexes et du d ploiement de projets de plateforme de donn es et d analyses, ainsi que d exp rience en architecture, conception, mise en uvre ou soutien d applications distribu es grande chelle obligatoire. d veloppement de relations. exp rience reconnue en ce qui concerne l tablissement de relations techniques approfondies avec des dirigeants des ti de clients importants ou hautement strat giques. exp rience de gestion des relations avec divers intervenants afin d obtenir un consensus au sujet d une solution ou de projets obligatoire. bon sens des affaires pour comprendre rapidement le secteur et les affaires du client de mani re avoir des discussions pertinentes avec les d cideurs commerciaux. r solution de probl mes. aptitude r soudre les probl mes des clients au moyen de technologies infonuagiques collaboration et communication. reconnaissance pour son expertise en mati re de prise de d cisions collaborative, de r solution de conflits et de suivi des mesures et d cisions prises, en plus de comp tences exceptionnelles en mati re de communication verbale et crite aptitude organiser et mener avec influence des quipes virtuelles pour assurer le succ s de la mise en uvre des projets clients. comp tences de pr sentation avec tr s grande aisance face des publics vastes ou plus restreints obligatoires. profil technique exp rience technique en milieu d entreprise avec conceptions architecturales infonuagiques et hybrides de donn es et d analyses, migrations de base de donn es et gestion de la technologie obligatoire exp rience et aptitude technique apprendre de nouvelles technologies et comprendre les tendances infonuagiques pertinentes, en particulier dans les plateformes de donn es et l analyse concurrence connaissance des plateformes de d veloppement infonuagique partenaires compr hension des cosyst mes des partenaires et capacit mettre profit les solutions partenaires pour r pondre aux besoins des clients souhaitables vastes connaissances et exp rience technique avec expertise approfondie en la mati re dans au moins deux des solutions de plateforme infonuagique pour les analyses de donn es et l ia obligatoires sql, y compris les logiciels code source libre , azure sql bases de donn es nosql, y compris les logiciels code source libre , cosmos db donn es massives, y compris sql dw, snowflake, big query, redshift analyses avanc es, y compris azure data bricks, outils de visualisation comme powerbi, tableau gouvernance des donn es ing nierie des donn es science des donn es apprentissage automatique, y compris azure ml, ml server intelligence artificielle, y compris bot framework, cognitive services, cognitive search expertise dans les charges de travail de l environnement de donn es comme hdinsight, hadoop, cloudera, spark, python formation baccalaur at en informatique, en technologies de l information, en ing nierie ou dans un domaine connexe souhaitable certification souhaitable dans au moins une des technologies suivantes infonuagique, mobile, base de donn es, donn es massives, veille strat gique, science des donn es, apprentissage automatique, intelligence artificielle exp rience exp rience de travail dans un poste de consultation ou d architecture au sein d une entreprise de logiciels ou de services comme amazon, vmware, google, ibm ou oracle souhaitable exp rience ant rieure de livraison de solutions chez des fournisseurs sp cialis es en analyse et en ia microsoft souscrit au principe de l galit d acc s l emploi. tous les candidats admissibles seront consid r s pour le poste, peu importe l ge, l ascendance, la couleur, la n cessit d un cong familial ou d un cong de maladie, l identit ou l expression sexuelle, l information g n tique, l tat civil, l tat de sant , l origine nationale, le handicap physique ou mental, l all geance politique, le statut d ancien combattant, la race, la religion, le genre, l tat de grossesse, l orientation sexuelle ou toute autre caract ristique prot g e par les lois applicables, les r glementations ou les ordonnances. les avantages num r s ci dessous peuvent varier en fonction de la nature de votre emploi chez microsoft et du pays o vous travaillez. knowledge and skills professional experience 5 years of success in consultative or complex technical sales and deployment data platform and analytics projects, architecture, design, implementation, and or or support of highly distributed applications required relationship building. proven track record of building deep technical relationships with senior it executives in large or highly strategic accounts. experience in managing various stakeholder relationships to get consensus on solution or projects. required good business acumen to quickly understand the customer s industry and business to have relevant discussions with business decision makers. problem solving. ability to solve customer problems through cloud technologies required collaboration and communication. acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. presentation skills with a high degree of comfort with both large and small audiences required technical enterprise scale technical experience with cloud and hybrid data and analytics architecture designs, database migrations, and technology management. required the technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in data platforms and analytics competitive landscape knowledge of cloud development platforms partners understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred breadth of technical experience and knowledge, with depth or subject matter expertise in two or more of the following data analytics and ai platform cloud solutions required sql including oss , azure sql nosql databases including oss , cosmos db big data including sql dw, snowflake, big query, redshift advanced analytics including azure data bricks, visualization tools as powerbi, tableau data governance data engineering data science machine learning including azure ml, ml server artificial intelligence including bot framework, cognitive services, cognitive search expertise in data estate workloads like hdinsight, hadoop, cloudera, spark, python education bachelor s degree in computer science, information technology, engineer, or related field preferred certification in one or more of the following technologies preferred cloud, mobile, database, big data, bi, data science, machine learning, artificial intelligence experience prior work experience in a consulting or architecture position within a software and or or services company such as amazon, vmware, google, ibm, oracle desired prior solution delivery experience in analytic and ai specialized solution providers microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['https', 'databases', 'visualization', 'architectural design', 'tableau', 'big', 'it management', 'c', 'big data', 'information technology', 'microsoft azure', 'sql', 'python', 'vmware', 'data analytics', 'software', 'data science', 'analytics', 'data', 'data engineering', 'r', 'nosql', 'machine learning', 'artificial intelligence', 'sqll', 'azure', 'technology management', 'bi', 'maintainability', 'hadoop', 'technical', 'security', 'scalability', 'digital transformation', 'computer science', 'uncertainty', 'cloud development', 'snowflake', 'ai']","['https', 'microsoft data', 'sql', 'azure', 'python', 'vmware', 'tableau', 'databases', 'bi', 'hadoop', 'c', 'microsoft', 'big data', 'azure sql', 'snowflake', 'nosql', 'microsoft azure', 'r']","['visualization', 'architectural design', 'ci', 'it management', 'information technology', 'data analytics', 'hybrid data', 'software', 'data science', 'analytics', 'data', 'data engineering', 'machine learning', 'aibility', 'artificial intelligence', 'http', 'technology management', 'maintainability', 'technical', 'security', 'scalability', 'computer science', 'uncertainty', 'cloud development', 'solution', 'digital transformation', 'ai']","['customer success', 'education', 'design', 'governance', 'consulting', 'engagements', 'adoption', 'technical sales', 'regulations', 'hiring', 'architecture']"
336,431,Senior Data Engineer | Ingénieur de Données Senior,"with thousands of beautiful spaces built for travel and living, sonder is transforming the future of hospitality. each sonder is purposefully selected, designed and maintained customized to reflect the vibe of its neighborhood. whether your stay is two days, two months or two years, in a studio or a six bedroom, sonder ensures a unique, yet consistent experience. and with 24 or 7 contactless service, professional cleanings that exceed phac recommendations, and over 200 other quality standards, we re taking stay further for guests all around the world. sonder started in 2014, and now has thousands of spaces in cities across the globe. the data engineering team is mainly focused on building and operating our data infrastructure, data warehouse, data and etl pipelines, ml platform, and performing data modeling for analytics purposes. the team also partners with product engineering and data science teams to deliver data products to the business. at sonder you will build and operate our data infrastructure by building and maintaining the data platform, data pipelines, and the tools that ingest, process, transform and serve data build software libraries that standardize the acquisition, ingestion and integration of external data sources critical for real time competitive intelligence and pricing use your expert sql and data modeling skills to build the data warehouse base layer data models that will power sonder s reporting dashboards establish and maintain the company s data lake or data warehousing strategy, define the appropriate data architecture, implement the best technical solution, and continue to meet the growing needs of the business work with product and business analytics teams to ensure availability and accessibility of relevant business data and business metrics for product analytics and business performance reporting. understand sonder s business intimately and model data that will be the source of truth for sonder s business kpis and metrics design and develop scalable platforms and processes for feature extraction, model training, and simulation own tools, processes and controls to help the team grow at scale. what we look for 5 years of experience working as a data engineer at a progressive company expert python coding skills expert sql and data modeling skills knowledge of data warehouse principles and methodologies experience in writing etl jobs, performance tuning and query optimization strong communication skills and ability to gather requirements and translate them to specs and design experience with aws cloud services and data warehouse stores like redshift or snowflake background in real estate or hotel industry is desirable self driven, highly motivated and able to learn quickly we offer great benefits to make your life easier so you can focus on what you re best at competitive salary generous stock option plan medical, dental and vision insurance discretionary vacation or paid vacation and sick time annual free credits and discounts to stay in sonders monthly culture budget join your fellow colleagues for a monthly get together a company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work with colleagues we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. avec des milliers de beaux espaces construits pour le voyage et la vie, sonder transforme l avenir de l hospitalit . chaque sonder est s lectionn , con u et entretenu de mani re cibl e, et personnalis pour refl ter l ambiance de son quartier. que votre s jour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, sonder vous garantit une exp rience unique, mais coh rente. et gr ce un service sans contact 24 heures sur 24, 7 jours sur 7, des nettoyages professionnels qui d passent les recommandations de l aspc et plus de 200 autres normes de qualit , nous allons encore plus loin pour nos clients du monde entier. sonder a d but en 2014, et compte aujourd hui des milliers de chambres dans des villes du monde entier. l quipe d ing nierie des donn es se concentre principalement sur la construction et l exploitation de notre infrastructure de donn es, de notre entrep t de donn es, de nos pipelines de donn es et d etl, de notre plateforme ml et sur la mod lisation des donn es des fins d analyse. l quipe s associe galement des quipes d ing nierie de produits et de science des donn es pour fournir des produits de donn es l entreprise. sonder vous le ferez construire et exploiter notre infrastructure de donn es en construisant et en entretenant la plate forme de donn es, les pipelines de donn es et les outils qui ing rent, traitent, transforment et servent les donn es cr er des biblioth ques de logiciels qui normalisent l acquisition, l ingestion et l int gration de sources de donn es externes essentielles pour la veille concurrentielle et la tarification en temps r el utilisez vos comp tences en mati re de sql et de mod lisation des donn es pour construire les mod les de donn es de la couche de base de l entrep t de donn es qui alimenteront les tableaux de bord de sonder tablir et maintenir la strat gie de l entreprise en mati re de lac de donn es or entreposage de donn es, d finir l architecture de donn es appropri e, mettre en uvre la meilleure solution technique et continuer r pondre aux besoins croissants de l entreprise travailler avec les quipes d analyse des produits et des activit s pour garantir la disponibilit et l accessibilit des donn es commerciales pertinentes et des mesures commerciales pour l analyse des produits et les rapports sur les performances commerciales. comprendre intimement l activit de sonder et mod liser les donn es qui seront la source de v rit pour les kpi et les m triques de l activit de sonder concevoir et d velopper des plates formes et des processus volutifs pour l extraction de caract ristiques, la formation de mod les et la simulation des outils, des processus et des contr les propres pour aider l quipe se d velopper l chelle. ce que nous recherchons 5 ans d exp rience en tant qu ing nieur de donn es dans une entreprise progressiste comp tences d expert en codage python comp tences d expert en sql et en mod lisation de donn es connaissance des principes et des m thodologies de l entrep t de donn es exp rience dans la r daction de travaux etl, l optimisation des performances et des requ tes solides comp tences en mati re de communication et capacit rassembler les exigences et les traduire en sp cifications et en conception exp rience avec les services de cloud computing aws et les entrep ts de donn es comme redshift ou snowflake une formation dans l immobilier ou l h tellerie est souhaitable autonome, tr s motiv et capable d apprendre rapidement nous vous offrons de grands avantages pour vous faciliter la vie afin que vous puissiez vous concentrer sur ce que vous faites de mieux un salaire comp titif un plan d options d achat d actions g n reux assurance m dicale, dentaire et visuelle vacances discr tionnaires or vacances pay es et cong s de maladie cr dits annuels gratuits et r ductions pour s journer sonders budget mensuel de la culture rejoignez vos coll gues pour une r union mensuelle une entreprise qui a une grande vision, un environnement de travail dynamique et une quipe de coll gues intelligents, ambitieux et agr ables travailler nous sommes un employeur souscrivant au principe de l galit des chances et valorisons la diversit au sein de notre entreprise. nous ne faisons aucune discrimination fond e sur la race, la religion, la couleur, l origine nationale, le sexe, l orientation sexuelle, l ge, l tat civil, le statut d ancien combattant ou le handicap.","['data infrastructure', 'dashboards', 'business', 'performance tuning', 'sql', 'python', 'software', 'reporting', 'data science', 'data', 'analytics', 'integration', 'product', 'data models', 'aws', 'pipelines', 'data engineering', 'data warehousing', 'specs', 'cloud computing', 'data pipelines', 'data products', 'performance', 'product engineering', 'cloud services', 'model', 'optimization', 'modeling', 'snowflake', 'etl', 'r']","['sql', 'competitive', 'python', 'aws', 'data models', 'pipelines', 'snowflake', 'r']","['data infrastructure', 'dashboards', 'business', 'performance tuning', 'software', 'reporting', 'data science', 'data', 'analytics', 'integration', 'product', 'data engineering', 'data warehousing', 'specs', 'cloud computing', 'data pipelines', 'data products', 'performance', 'product engineering', 'cloud services', 'optimization', 'modeling', 'feature', 'etl']","['environment', 'metrics', 'design', 'real estate', 'insurance', 'hospitality', 'construction', 'architecture']"
337,432,Lead Data Scientist,"we re building a brand new team to deliver the next generation new product suites. this is a golden opportunity to join the team on the ground floor and you ll have opportunity to not only to define and execute on the architecture, but also to build and shape the culture of the team. who we are to succeed in the modern world you must exploit digital resources and empower human capital. often companies struggle to identify underlying opportunities and miss exploiting exponential technologies. integrityco helps companies make the right investment with the best result. we help them beat the competition and reach their fullest potential. we make legendary products. this role is dedicated to help a client located in washington a human performance company, existing at the intersection of well being and performance. together we are unlocking human potential in the workplace by providing expert coaching, interactive content, meaningful incentives, and personalized insights in a fun, inspiring way. this helps to ignite cultures, create inclusivity, and build social connections that promote growth and flourishing of people in life and work. responsibilities position description responsibilities the role responsibilities include but are not limited to design, prototype, and implement new machine learning system architectures and predictive models with a focus on classification and inference from time series data. use statistical methods and machine learning techniques to create scalable prediction systems. conduct exploratory analysis go deep into the data to develop hypotheses and to answer complex metric driven questions. make recommendations for new metrics, techniques, and strategies to improve methods to prioritize the performance of the platform. establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation. play the role of tech lead on the data science team, mentor fellow or junior data scientists. qualifications phd or msc in mathematics, statistics, computer science, physics, machine learning, micro economics or other quantitative field or equivalent years of experience 5 years working as a data scientist, applied researcher, or machine learning scientist 5 years of professional experience with a scripting language with fluency in python and sql. knowledgeable in two or more of the following machine learning, information retrieval, statistical inference, and time series analysis. solid understanding of statistical analysis and experimentation, and capacity to drive conclusions from the analysis in a scientific way. experience working with large scale data platforms such as spark, hadoop and cloud based computing . linux skills is a plus. exemplary communication skills, both verbal and written, ability to work with large cross functional teams of technical and non technical members. ability to work across disparate data sources to obtain sensible results ability to draw conclusions from data and provide recommendations experience leading and managing a technical team a strong passion for data, charts, analysis, trends, and evangelizing data usage with experience in data visualization software such as tableau, and power bi. proven track in leading, mentoring and growing teams of data scientists experience with defining organizational research and development practices in an industry setting experience in managing stakeholders and distilling complex requirements into analytical solutions community we are avid zoom collaborators until we can be together again in our office space. our community fosters collaboration, so be ready to converse and let ideas percolate we believe diversity is a necessary element to our success as a business. we are committed to building a community that represents and celebrates a variety of backgrounds, perspectives and skills we want you to bring your verve location we are currently fully remote. job types full time, permanent salary 140,000.00 200,000.00 per year benefits casual dress dental care extended health care life insurance vision care schedule monday to friday education master s degree experience python 4 years statistical analysis 2 years machine learning 4 years","['prediction', 'go', 'computing', 'linux', 'tableau', 'data visualization', 'machine', 'statistical analysis', 'sql', 'python', 'statistics', 'statistical inference', 'time series analysis', 'software', 'physics', 'scripting', 'data science', 'machine learning', 'model', 'information retrieval', 'bi', 'economics', 'hadoop', 'zoom', 'computer science', 'mathematics']","['go', 'sql', 'python', 'linux', 'tableau', 'bi', 'hadoop', 'zoom']","['prediction', 'computing', 'data visualization', 'machine', 'statistical analysis', 'statistics', 'statistical inference', 'time series analysis', 'software', 'physics', 'scripting', 'data science', 'exploratory analysis', 'machine learning', 'model', 'information retrieval', 'economics', 'computer science', 'mathematics']","['human capital', 'validation', 'exploit', 'education', 'metrics', 'incentives', 'design', 'insurance', 'architecture', 'mentoring']"
338,433,Senior Data Engineer // Ingénieur·e des données,"mistplay is the first loyalty program for mobile gamers. players use our platform to play games, connect with friends, and earn awesome rewards such as amazon gift cards and prepaid visas. we leverage a wealth of in game data and machine learning to recommend the best games to our users and coach developers of all sizes to help them build games. we use our marketing expertise and platforms to make sure our studio partners games reach millions of players around the world. with a growth of over 10 million users in under 3 years, mistplay is one of the fastest growing companies in north america. join us as we continue to level up mistplay is seeking a data engineer to join our engineering infrastructure team. we are a fast growing start up, which means you can jump into action and make significant contributions right away join our skilled, diverse and multidisciplinary team to build the data, analytics, and machine learning platform that we depend on. you ll have a unique opportunity to wear different hats so don t be afraid to roll up your sleeves and think of creative solutions to develop and improve our existing ai, database and pipeline solutions. we re looking for self starters who are focused on detail and quality while being passionate about making meaningful impacts within the company. technical skills are important, but so is being a positive addition to our culture. a can do attitude will take you a long way with mistplay mistplay recherche un e ing nieur e des donn es pour rejoindre notre quipe d ing nieurie et d infrastructure. nous sommes une start up croissance rapide, ce qui signifie que vous pourrez passer l action et apporter des contributions significatives imm diatement rejoignez notre quipe d experts, diversifi e et multidisciplinaire, pour d velopper les donn es, l analyse et la plateforme d apprentissage automatique dont nous d pendons. vous aurez l occasion unique de prendre diff rentes casquettes, alors n ayez pas peur de retrousser vos manches et de r fl chir des solutions cr atives pour d velopper et am liorer nos solutions d ia, de base de donn es et de pipeline de donn es actuelles. nous recherchons des personnes capables de prendre des initiatives, qui ont le souci du d tail et de la qualit , et qui ont c ur d avoir un impact significatif sur l entreprise. les comp tences techniques sont importantes, mais il est tout aussi important de contribuer de mani re positive notre culture. une attitude positive vous m nera loin chez mistplay what you ll be doing write and test code that is performant, scalable, maintainable and meets functional requirements build scalable data warehouses and etl processes for consumption by various machine learning and analytics products in collaboration with the analysts and data scientists develop and maintain our current data architectures develop tools to automate and handle data lifecycle and metadata management collaborate with other departments to improve the quality and reliability of data vos responsabilit s seront les suivantes crire et tester du code performant, volutif, facile maintenir et qui r ponde aux exigences fonctionnelles. cr er des data warehouses et des processus etl volutifs qui seront utilis s par divers produits d apprentissage automatique et d analyse en collaboration avec les analystes et scientifiques des donn es. d velopper et maintenir nos solutions d architecture de donn es actuelles d velopper des outils pour l automatisation et la gestion du cycle de vie des donn es, ainsi que la gestion des m tadonn es. collaborer avec les autres services pour am liorer la qualit et la fiabilit des donn es. what we re looking for bachelors degree in computer science or equivalent strong experience working with python 3 5 years experience in working with big data tools 3 5 years with aws or equivalent cloud provider knowledge of data persistence paradigms curiosity and a willingness to learn ce que nous recherchons baccalaur at en informatique ou quivalent. solide exp rience professionnelle avec python 3 5 ans d exp rience dans l utilisation d outils big data . 3 5 ans d exp rience avec aws ou un fournisseur de cloud computing quivalent. connaissance des paradigmes de persistance des donn es . curiosit et envie d apprendre. we work hard to make our work atmosphere as inviting and fun as possible working at mistplay is coupled with a whole array of perks that we ve adopted virtually and in person team lunches, game nights, company wide events, and so much more. our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. we utilize data to constantly learn, improve, and adapt. we foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life. think you have what it takes we d love to meet you","['metadata management', 'python', 'machine learning', 'informati', 'c', 'computer science', 'analytics', 'big data', 'aws', 'cloud computing', 'etl', 'ai']","['python', 'c', 'aws', 'big data', 'r']","['metadata management', 'machine learning', 'computer science', 'analytics', 'cloud computing', 'etl', 'ai']","['environment', 'events', 'marketing', 'growing companies', 'architecture']"
339,434,"Data Analyst, Embedded Systems","who we are geotab is a global leader in iot and connected transportation and certified great place to work. we are a company of diverse and talented individuals who work together to help businesses grow and succeed, and increase the safety and sustainability of our communities. geotab is advancing security, connecting commercial vehicles to the internet and providing web based analytics to help customers better manage their fleets. geotab s open platform and marketplace, offering hundreds of third party solution options, allows both small and large businesses to automate operations by integrating vehicle data with their other data assets. processing billions of data points a day, geotab leverages data analytics and machine learning to improve productivity, optimize fleets through the reduction of fuel consumption, enhance driver safety and achieve strong compliance to regulatory changes. our team is growing and we re looking for people who follow their passion, think differently and want to make an impact. ours is a fast paced, ever changing environment. geotabbers accept that challenge and are willing to take on new tasks and activities ones that may not always be described in the initial job description. join us for a fulfilling career with opportunities to innovate, great benefits, and our fun and inclusive work culture. reach your full potential with geotab. to see what it s like to be a geotabber, check out our blog and follow us insidegeotab on instagram, twitter or facebook. who you are we are always looking for amazing talent who can contribute to our growth and deliver results geotab is seeking a data analyst, embedded systems who will join our automotive engineering department, and will work with data analysts and firmware engineers to drive insights and values from massive amounts of vehicle data. if you love technology, and are keen to join an industry leader we would love to hear from you what you ll do you will be interacting with our data, including clean data, analyze data, visualize data, and provide insights and reports on a daily basis. this role will work closely with the firmware team and gain domain specific knowledge of go telematics system and firmware development. the ultimate goal for this role will be helping firmware engineers to monitor various product related issues, detect anomalies, send notifications, and keep improving the quality of the firmware in the long run. also, you will partner with other departments such as data and analytics, support and solution engineering to achieve these objectives. to be successful in this role you will be a self starter with strong written and verbal communication skills, and have the ability to quickly understand complex, technical concepts. geotab data scientists and analysts share the common passion for utilizing big data to find simple solutions for complex problems and to drive business decisions. we leverage the google cloud platform as our big data environment, and most of our development work happens in python and sql. how you ll make an impact interact with geotab s bigdata infrastructure on google bigquery using sql and develop jupyter notebooks using python. work with our firmware engineers and other stakeholders to identify the firmware issues and implement visualizations and reports using the data in various formats. process, clean and verify the integrity of the data that was collected by our product, and set up necessary monitors and alerts. leverage big data tools and assist firmware engineers with troubleshooting and providing meaningful insights. mine messy data from vehicles and build accurate and useful datasets in bigquery to meet different requirements. develop sql queries to detect anomaly behaviours from our go devices and vehicles. make recommendations for new metrics, techniques, and strategies to improve the reliability and quality of geotab device and firmware. what you ll bring to this role post secondary degree specialization in computer science, math, engineering, science or any other related field. solid technical background with understanding and or or hands on experience in large data environments and data analytics. familiar with and have experience in data warehousing and data etl processes. 2 years experience using jupyter notebook, python and data analytics packages, such as pandas, numpy, matplotlib etc. 2 years experience using sql and being able to manipulate large amounts of data in dbms or data warehouse . 2 years experience with data visualization in python and being able to draw some insights by given unknown data. experience with developing containerized app using docker, and writing bash script on linux systems is a plus. experience working with cloud products such as google cloud platform is nice to have. familiar with version control system such as git and agile project management platform such as jira. being inquisitive, results oriented, problem solving, and paying attention to details is crucial. highly organized and able to manage multiple tasks and projects simultaneously. a keen interest to learn new technologies and utilize them into our big data environment. a strong team player with the ability to engage with people within the department or outside the department. entrepreneurial mindset and comfortable in a flat organization. why job seekers choose geotab work from home and flex work arrangements baby bonus home office reimbursement program online learning and networking opportunities electric vehicle purchase incentive program competitive medical and dental benefits retirement savings program how we work at geotab, we understand that the world is always changing and that we need to change with it. geotab has adopted a hybrid model for working, including a flexible work from home program, with the opportunity to work in our safe, clean offices. when working from home, you are required to have a reliable internet connection with at least 50mb dl or 10mb ul. virtual work is supported with cloud based applications, collaboration tools and asynchronous working. the health and safety of employees are a top priority. we encourage work life balance and keep the geotab culture going strong with online social events, chat rooms and gatherings. join us and help reshape the future of technology we believe that ensuring diversity is fundamental to our future growth and progress and is an integral part of our business. we believe that success happens where new ideas can flourish in an environment that is rich in diversity and a place where people from various backgrounds can work together. geotab encourages applications from all qualified individuals. we are committed to accommodating people with disabilities during the recruitment and assessment processes and when people are hired. we will ensure the accessibility needs of employees with disabilities are taken into account as part of performance management, career development, training and redeployment processes. if you require accommodation at any stage of the application process or want more information about our diversity and inclusion as well as accommodation policies and practices, please contact us at click here to learn more about what happens with your personal data.","['go', 'bash', 'linux', 'data visualization', 'troubleshooting', 'telema', 'big data', 'sustainability', 'automotive', 'data analytics', 'python', 'sql', 'matplotlib', 'pandas', 'analytics', 'data warehousing', 'jupyter', 'machine learning', 'iot', 'embedded systems', 'numpy', 'google cloud platform', 'agile project management', 'jira', 'datasets', 'security', 'firmware', 'git', 'computer science', 'networking', 'performance management', 'version control', 'etl']","['go', 'jupyter', 'sql', 'python', 'linux', 'jira', 'iot', 'numpy', 'google cloud platform', 'git', 'pandas', 'big data', 'sql big']","['telematics', 'bash', 'data visualization', 'troubleshooting', 'sustainability', 'automotive', 'data analytics', 'matplotlib', 'analytics', 'data warehousing', 'machine learning', 'dbms', 'embedded systems', 'agile project management', 'datasets', 'security', 'firmware', 'computer science', 'networking', 'performance management', 'personal data', 'version control', 'etl']","['and safety', 'environment', 'events', 'metrics', 'development work', 'retirement', 'assessment']"
340,435,Python Data Engineer,"python data engineer id 7gb0204pde location ottawa, ontario canada term full time we are looking for a data engineer, with python fluency and dedication to code quality. as for python, we are after proficiency in object oriented and test driven development, as well as hands on experience with scientific computing packages in python . bachelor s degree in computer science or equivalent 3 years of experience in building large scale, high performance, high availability software systems in a distributed linux environment strong computer science fundamentals such as algorithms, data structures, etc. fluency and facility with one or more of the following programming languages python, scala, r, julia, go experience with big data technologies, particularly apache spark, elasticsearch, cassandra, kafka, and hadoop ecosystem working experience with microservices, container and streaming technologies comfort manipulating and analyzing complex, high volume, high dimensionality data from varying sources excellent written and oral communication skills, able to communicate with all levels of internal technology teams and business teams is dedicated to quality we re seeking someone who achieves a high standard of sw quality desired skills experience solving analytical problems using quantitative approaches, operations research and optimization algorithms exposure to machine learning, deep learning and neural networks passion for answering hard questions with data note 1 you must be legally entitled to work in canada note 2 high tech genesis inc. is an equal opportunity employer. note 3 accommodations are available upon request for all aspects of the hiring process. note 4 please submit a ms word version of your resume when applying for this position.","['go', 'computing', 'high availability', 'linux', 'test driven development', 'big data', 'working experience', 'python', 'scala', 'elasticsearch', 'microservices', 'machine learning', 'apache spark', 'algorithms', 'cassandra', 'deep learning', 'data structures', 'programming languages', 'hadoop', 'neural networks', 'software systems', 'computer science', 'optimization', 'r']","['go', 'high availability', 'python', 'linux', 'programming languages', 'scala', 'apache spark', 'hadoop', 'elasticsearch', 'big data', 'cassandra', 'r']","['high dimensionality', 'deep learning', 'computing', 'machine learning', 'data structures', 'microservices', 'test driven development', 'neural networks', 'software systems', 'computer science', 'optimization', 'scientific', 'working experience', 'algorithms']","['environment', 'hiring', 'operations']"
341,436,"Sr. Data Scientist, Architectural Services / Scientifique de données sénior, Services d'architecture","the opportunity the architectural services group provides unity s developers with crucial opportunities for technical collaboration across the company that meaningfully improves how we build our products. this is accomplished by integrating with, storing, and analyzing large data sets that are enablers to make value based business decisions that directly influence the way that we work as a company. as a sr. data engineer working with the vp of architectural services, you will make an impact by navigating globally distributed data, provide insight on significant correlation and causality events, and improve our overall understanding of a given problem space. we do this in service to support the creation of sophisticated and engaging digital content. what you ll be doing data integration, maintenance, and analysis using your problem solving skills to reach data informed conclusions develop, optimize, data models to improve our technology and development practices identify, define, and lead data engineering projects end to end research and collaborate on solutions that achieve specific measurable goals collaborate on your analysis, code, and approach with leadership to align with unity s overall direction and needs what we re looking for applied experience identifying, integrating, extracting, shaping data from various sources in production via on prem or cloud environments applied experience publishing and communicating data in a production environment by setting up dashboards, websites, and building presentations extensive experience developing applications with various programming or scripting languages utilizing light weight front end frameworks and microservices professional experience leading data centric projects from problem identification to production with excellent analysis and interpersonal skills. a bachelor s degree in one of the following areas or equivalent experience computer science, mathematics, data analysis, or data engineering you might also have prior experience with the unity engine worked on large projects in a globally distributed, collaborative, and diverse environment life at unity unity is the world s leading platform for creating and operating real time 3d content. creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use unity to make their imaginations come to life. unity s platform provides a comprehensive set of software solutions to create, run and monetize interactive, real time 2d and 3d content for mobile phones, tablets, pcs, consoles, and augmented and virtual reality devices. the company s 1,400 person research and development team keeps unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. apps developed by unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. for more information, please visit . unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. if there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know. headhunters and recruitment agencies may not submit resumes or cvs through this website or directly to managers. unity does not accept unsolicited headhunter and agency resumes. unity will not pay fees to any third party agency or company that does not have a signed agreement with unity. l opportunit le groupe architectural services offre aux d veloppeurs de unity des possibilit s cruciales de collaboration technique l chelle de l entreprise, qui am liorent de mani re significative la fa on dont nous concevons nos produits. pour ce faire, nous int grons, stockons et analysons de grands ensembles de donn es qui permettent de prendre des d cisions commerciales bas es sur la valeur qui influencent directement la fa on dont nous travaillons en tant qu entreprise. en tant que d veloppeur de donn es principal travaillant avec le vice pr sident des architectural services, vous apporterez votre contribution en parcourant les donn es distribu es l chelle mondiale, en fournissant des informations sur les v nements de corr lation et de causalit significatifs et en am liorant notre compr hension globale d un espace probl me donn . nous agissons ainsi pour soutenir la cr ation d un contenu num rique sophistiqu et attrayant. ce que vous allez faire tirer parti de vos comp tences en r solution de probl mes pour l int gration, la maintenance et l analyse des donn es afin de parvenir des conclusions fond es sur les donn es d velopper et optimiser les mod les de donn es pour am liorer notre technologie et nos pratiques en mati re de d veloppement identifier, d finir et diriger des projets de d veloppement des donn es de bout en bout rechercher et collaborer la mise en place de solutions qui permettent de r aliser des objectifs sp cifiques et mesurables collaborer sur votre analyse, votre code et votre approche avec la direction pour s aligner sur la direction g n rale et les besoins de unity ce que nous recherchons exp rience appliqu e d identification, d int gration, d extraction et de mise en forme de donn es partir de diverses sources en production au moyen d environnements sur site ou infonuagiques exp rience appliqu e de publication et de communication de donn es dans un environnement de production par la configuration de tableaux de bord, de sites web et la cr ation de pr sentations grande exp rience de d veloppement d applications avec divers langages de programmation or script utilisant des environnements de d veloppement frontaux l gers et des micro services exp rience professionnelle dans la direction de projets li s aux donn es, de l identification des probl mes la production, avec d excellentes comp tences d analyse et interpersonnelles baccalaur at dans l un des domaines suivants ou exp rience quivalente informatique, math matiques, analyse des donn es ou d veloppement des donn es vous avez peut tre galement exp rience avec le moteur unity exp rience de travail sur de grands projets dans un environnement mondialement distribu , collaboratif et diversifi la vie chez unity unity est la plateforme la plus utilis e au monde pour la cr ation et l ex cution interactive de contenu 3d en temps r el . des cr ateurs, notamment des d veloppeurs de jeux vid o, des artistes, architectes, concepteurs automobiles et cin astes, utilisent unity pour donner vie ce qu ils ont imagin . la plateforme de unity offre un ensemble complet de solutions logicielles pour cr er, ex cuter et mon tiser du contenu interactif 2d et 3d en temps r el pour les t l phones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de r alit augment e et de r alit virtuelle. notre quipe de plus de 1400 personnes assign es la recherche et au d veloppement fait en sorte que unity soit l avant garde du d veloppement et assure un soutien optimal pour les plus r centes technologies et plateformes. les applications d velopp es par les cr ateurs au sein de unity ont t t l charg es plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d appareils uniques. pour en savoir davantage, visitez le site . unity est un employeur ax sur l galit qui s engage cr er un environnement inclusif, innovateur et ce avec les meilleurs talents. nous offrons des opportunit s d emploi qui ne tiennent pas compte de l ge, de l ethnicit , de la religion, des limitations fonctionnelles, du sexe, de l identit sexuelle ou d un tout autre statut prot g conform ment la loi. s il y a des pre paratifs que nous pouvons faire pour vous aider a avoir une expe rience d entrevue confortable et positive, n h sitez pas nous en faire part. les chasseurs de t te et les agences de recrutement ne peuvent pas soumettre un r sum or cv directement sur notre site web ou un de nos gestionnaires. nous n acceptons pas d tre spontan ment sollicit s par un chasseur de t te et ou une agence une entente devra tre sign entre les deux partis. li ll2 sen","['virtual reality', 'dashboards', 'software solutions', 'automotive', 'forefront', 'scripting', 'informati', 'data', 'programming', 'digital', 'integration', 'data models', 'microservices', 'data engineering', 'unity', 'data analysis', 'tablets', 'computer science', 'mathematics', 'r']","['forefront', 'virtual reality', 'programming', 'unity', 'data models', 'r']","['automotive', 'tablets', 'microservices', 'digital content', 'scripting', 'dashboards', 'computer science', 'data', 'mathematics', 'integration', 'data analysis', 'data engineering', 'software solutions']","['environment', 'large projects', 'events', 'presentations', 'law']"
342,437,Principal Data Scientist - AWS Professional Services,"a bachelor or masters degree in a highly quantitative field or equivalent experience 10 years of industry experience in predictive modeling, science and analysis previous experience in a ml or scientist role and a track record of building ml or dl models experience using and or or r knowledge of sparkml excited by using massive amounts of to machine learning and deep learning models help the largest global enterprises derive business value through the adoption of artificial intelligence . are you eager to learn from many different enterprise use cases of aws ml and dl come be a key part of amazon, who has been investing in machine learning for decades, pioneering and shaping the world s ai technology at amazon web services , we are helping large enterprises build ml and dl models on the aws cloud. we are applying predictive technology to large volumes of and against a wide spectrum of problems. our professional services organization works together with our aws customers to address their business needs using ai. aws professional services is a unique consulting team. we pride ourselves on being customer obsessed and highly focused on the ai enablement of our customers. if you have experience with ai, including building ml or dl models, we d like to have you join our team. you will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers. you enjoy diving deep into , doing analysis, discovering root causes, and designing long term solutions. you like to have fun, love to learn, and want to innovate in the world of ai. you will understand the customer s business need and guide them to a solution using our aws ai services, aws ai platforms, aws ai frameworks, and aws ai ec2 instances . assist customers by being able to deliver a ml or dl project from beginning to end, including understanding the business need, aggregating , exploring , building validating predictive models, and deploying completed models to deliver business impact to the organization. use deep learning frameworks like mxnet, caffe 2, tensorflow, theano, cntk, and keras to help our customers build dl models. use sparkml and amazon machine learning to help our customers build ml models. work with our professional services big consultants to analyze, extract, normalize, and label relevant . work with our professional services devops consultants to help our customers operationalize models after they are . assist customers with identifying model drift and retraining models. research and novel ml and dl approaches, including using fpga. be able to write production level code, which is well written and explainable have experience using ml libraries, such as scikit learn, caret, mlr, mllib have experience working with gpus to models have experience handling terabyte size datasets be able to track record of diving into data to discover hidden patterns have familiarity with using data visualization tools have knowledge and experience of writing and tuning sql past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format this role is for toronto or vancouver or calgary or montreal. inclusive team culture here at aws, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team puts a value on work live balance. it isn t about how many hours you spend at home or at work it s about the flow you establish that brings energy to both parts of your life. we believe striking the right balance between your personal and professional life is critical to life long happiness and fulfillment. we offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. mentorship career growth our team is dedicated to supporting new members. we have a broad mix of experience levels and tenures, and we re building an environment that celebrates knowledge sharing and mentorship. our senior members enjoy one on one mentoring and thorough, but kind, code reviews. we care about your career growth and strive to assign projects based on what will help each team member and enable them to take on more complex tasks in the future. phd in a highly quantitative field 12 years of industry experience in predictive modeling and analysis good skills with programming languages, such as or c or c ability to experimental and analytic plans for modeling processes, use of strong baselines, ability to accurately determine cause and effect relations consulting experience and track record of helping customers with their ai needs publications or presentation in recognized machine learning, deep learning and mining journals or conferences experience with aws technologies like redshift, s3, ec2, pipeline, emr combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer s organization demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. if contacted for an employment opportunity, advise human resources if you require accommodation, including in order to apply for a position.","['emr', 'tensorflow', 'data visualization', 'c', 'sql', 'keras', 'aws', 'r', 'amazon web services', 'machine learning', 'fpga', 'artificial intelligence', 'deep learning', 'programming languages', 'devops', 'datasets', 'modeling', 'enablement', 'ai']","['sql', 'amazon web services', 'keras', 'programming languages', 'emr', 'scikit', 'cntk', 'predict', 'fpga', 'c', 'aws', 'amazon machine', 'r']","['mllib', 'deep learning', 'use cases', 'machine learning', 'devops', 'tensorflow', 'datasets', 'data visualization', 'artificial intelligence', 'modeling', 'enablement', 'ai']","['environment', 'investing', 'professional services', 'affinity', 'business value', 'human resources', 'large enterprises', 'consulting', 'adoption', 'team culture', 'legislation', 'mentoring']"
343,438,Research Scientist – Protein Engineering & Lead Optimization,"abcellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a highly motivated scientist with experience engineering antibody sequences. our ideal candidate is a self directed scientist, a team player who thrives in a fast paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. this is an exciting opportunity to join one of canada s fastest growing biotechs and to contribute to our cutting edge research on next generation antibody derived therapies. how you might spend your days engineering antibody sequences, including bispecifics and single chain antibodies to improve therapeutically relevant molecular properties performing data analysis of biophysical datasets from uplc and spr based methods. implementation and evaluation of novel protein engineering techniques developing and iterating workflows to streamline common protein engineering tasks collaborating with teams across the company to understand protein engineering challenges and propose solutions organizing, supporting, and collaborating with team members to meet project deliverables and timelines we d love to hear from you if you are a creative problem solver and fast learner who believes in team work to tackle the most challenging scientific problems you are self motivated and have the initiative and drive to meet goals under tight project timelines you think critically, and are passionate about the integration of computational and experimental protein engineering methods required qualifications and experience a phd in biochemistry or computational biology or msc with 5 years in an academic or industry lab environment great interpersonal skills with the ability to work collaboratively as a member of cross functional team strong data analysis skills and the ability to interpret, communicate, and document large data sets. familiarity with python data analysis is preferred. experience with common antibody engineering tasks, including humanization, reformatting, and bispecific antibody generation excellent verbal and written communication skills, including public presentation of complex data offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please submit your application through our website and refer to job id 21154 in your cover letter. we apologize in advance, but we receive a large volume of applications and are only able to contact those who are selected for an interview.","['python', 'machine learning', 'datasets', 'high throughput', 'integration', 'data analysis', 'solver', 'automation', 'computational biology']","['python', 'solver']","['machine learning', 'datasets', 'high throughput', 'micro', 'integration', 'data analysis', 'automation', 'computational biology']","['environment', 'antibodies', 'immune', 'genomics', 'biochemistry', 'molecular', 'protein', 'compensation', 'protein engineering']"
344,439,Data Engineer,"mogo finance technology inc. a financial technology company offers a finance app that empowers consumers with simple solutions to help them get in control of their financial health and be more mindful of the impact they have on society and the planet. we all know it s time to do things differently. it s time for a new way to manage our money, one that s inclusive and sustainable. one that takes into account our financial health, the planet s health and the health of our society. at mogo, users can sign up for a free account in only three minutes and begin to learn the 4 habits of financial health and get convenient access to products that can help them achieve their financial goals and have a positive impact on the planet including a digital spending account with mogo visa platinum prepaid card featuring automatic carbon offsetting, free monthly credit score monitoring, id fraud protection and personal loans. the mogo platform has been purpose built to deliver a best in class digital experience, with best in class products all through one account. with more than one million members and a marketing partnership with canada s largest news media company, mogo continues to execute on its vision of becoming the go to financial app for the next generation of canadians. to learn more, please visit mogo.ca or download the mobile app . mogo is looking for a data engineer to be a key member of mogo s team. based in vancouver, this role will be responsible for the architecture, integration and analysis of both traditional and non traditional data sources used for model building. check out the list of qualifications below and if this sounds like you, send us your resume we want to hear from you what you ll do create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws big data technologies. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. work with stakeholders including the executive, product, data and design teams to assist with data related technical issues and support their data infrastructure needs. keep our data separated and secure across national boundaries through multiple data centers and aws regions. create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. work with data and analytics experts to strive for greater functionality in our data systems. what you ll need 3 5 years experience in a similar role with an emphasis on translating quantitative data into meaningful insights. experience working in the financial services industry and or or with digital products. degree in computer science, statistics, mathematics or other related discipline advanced working sql knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases. experience building and optimizing big data data pipelines, architectures and data sets. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. strong analytic skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. working knowledge of message queuing, stream processing, and highly scalable big data data stores. proficient with the the following software or tools big data tools hadoop, spark, kafka, etc. relational sql and nosql databases, including postgres and mongodb. aws cloud services ec2, emr, rds, redshift object oriented or object function scripting languages python, javascript. salary range for this role is 80,000 90,000 per annum based on experience. interested applicants can submit an application online or through email at klww6hss46","['go', 'model building', 'databases', 'quantitative data', 'emr', 'operational efficiency', 'data infrastructure', 'financial technology', 'root cause', 'big data', 'mongodb', 'javascript', 'sql', 'python', 'statistics', 'software', 'scripting', 'queuing', 'analytics', 'integration', 'aws', 'data systems', 'nosql', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'data centers', 'metadata', 'cloud services', 'data structures', 'datasets', 'hadoop', 'scalability', 'computer science', 'mathematics']","['go', 'sql', 'python', 'databases', 'emr', 'object', 'hadoop', 'data centers', 'aws', 'big data', 'rds', 'javascript', 'nosql']","['model building', 'quantitative data', 'operational efficiency', 'data infrastructure', 'financial technology', 'root cause', 'mongodb', 'statistics', 'software', 'scripting', 'queuing', 'analytics', 'integration', 'data systems', 'unstructured', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'metadata', 'cloud services', 'data structures', 'datasets', 'scalability', 'computer science', 'mathematics']","['loans', 'customer acquisition', 'metrics', 'marketing', 'design', 'finance', 'financial services', 'functionality', 'business performance', 'architecture']"
345,440,SENIOR DATA SCIENTIST,"we are looking for a senior data scientist who is enthusiastically driven to generate actionable insights and create new growth opportunities. you must have proven leadership skills to grow and foster a highly effective team capable of rapid learning and application. you will lead a team conducting research experiments, advanced statistical modelling and develop data driven products across several domains including infrastructure optimization, logistics efficiency, and data visualization. this is a unique opportunity to apply your leadership skills in a growing company and lead our next generation products. requirements m.sc. or ph.d. in a quantitative field . significant experience solving problems with the required the use of advanced statistical modelling techniques. proven programming skills including experience conducting modelling and statistical analysis , object oriented software development , and massive parallel processing . excellent communication skills and ability to describe and present complex technical concepts in clear language. ability to lead teams and create an environment of continuous learning and open communication. ability to structure and lead a project from idea to experimentation to prototype to delivery. what we expect self starter that is focused and driven with amazing follow through. enthusiastically tackling problems with a love for teaching and celebrating the successes of others. ability to synthesize information, evoke good conversation and consider problems from new perspectives. desire to share information with others and contribute to our top notch learning environment. driven to delivery quality solutions.","['data visualization', 'parallel processing', 'software development', 'programming', 'optimization', 'statistical analysis']",['programming'],"['data visualization', 'parallel processing', 'software development', 'optimization', 'statistical analysis']","['environment', 'new growth']"
346,441,Ingénieur de données - Data & Analytic / Data engineer - Data & Analytic - 313669,"ing nieur de donn es data analytic dans le cadre de ses ententes avec ses diff rents clients, procom est actuellement la recherche d un ing nieur de donn es data analytic pour une entreprise dans le domaine du transport. notre client est situ montr al. description des t ches et responsabilit s ing nieur de donn es data analytic les responsabilit s du poste incluent construire et concevoir des applications grande chelle architecture de base de donn es et entreposage de donn es mod lisation et extraction de donn es mod lisation statistique et analyse de r gression calcul distribu et algorithmes de fractionnement pour une pr cision pr dictive. exigences du poste ing nieur de donn es data analytic d veloppement spark or python azure databricks et or ou snowflake exp rience etl or data compr hension et exp rience de travail avec le processus et le pipeline devops . type de poste contractuel 5 mois avec de fortes possibilit s de renouvellement. date de d but imm diatement num ro de r f rence bh313669 english version data engineer data analytic as a part of its agreements with its various clients, procom is currently seeking a data engineer data analytic for a company in the transport sector. our client is located in montr al. job details data engineer data analytic key responsibilities for this position include building and designing large scale applications database architecture and data warehousing data modeling and mining statistical modeling and regression analysis distributed computing and splitting algorithms to yield predictive accuracy. mandatory skills data engineer data analytic spark or python development azure databricks and or or snowflake etl or data experience understands and experience working with devops process pipeline . assignment length 5 month contract renewable start date immediately reference number bh313669","['computing', 'python', 'algorithms', 'regression analysis', 'devops', 'database', 'data', 'statistical', 'modeling', 'data warehousing', 'snowflake', 'etl']","['python databricks', 'python', 'snowflake', 'r']","['distributed', 'computing', 'algorithms', 'regression analysis', 'devops', 'database', 'data', 'statistical', 'modeling', 'data warehousing', 'etl']",['architecture']
347,443,"Specialist, Information Management (Open Data)","who are we credit valley conservation is one of ontario s 36 conservation authorities dedicated to protecting, restoring and enhancing our local natural environment. we care for the credit river, its streams and tributaries from the headwaters in orangeville to the shores of lake ontario in mississauga. we are scientists, engineers, researchers, educators, environmentalists, stewards, planners, foresters, recreation experts and much more. we create connections between people and nature, knowledge and action. we inspire appreciation for the role of nature in keeping people connected, healthy and happy. we re leaders and explorers. we are professional and we re inspired. we know our stuff, and we work every day to make a difference. who are you you want to be part of an organization with an environmental goal. you get up every day and go to work with purpose. you accept that you may not change the world, but you ll try to make an impact in your corner. you like to partner with skilled people across many professions. it s as natural for you think about the outdoors as it is to think out of the box. you re passionate, responsible and approachable. you do what s right, not just what s easy. you care, and it shows. why work for us we offer competitive public sector pay. we have a good employee benefits program. we re members of the ontario municipal employees retirement system pension fund. we have flexible work hours for many positions. we find time to have fun and celebrate successes. you ll have free access to our parks and discounts on recreational equipment rentals. you ll know your co workers by name and will make fast friends. you ll like being at work. summary of functions reporting to the manager, information management at credit valley conservation , this position will be responsible for cvc s open data policy creation, working with stakeholders to ensure data quality and currency, deployment of open data platform and assist the information management team with various other arcgis online related projects, gis analysis and data management. this is a 12 month contract position. the primary role will be to focus on cvc s status on various datasets, research and create open data policy with as per guidelines set out by the information management framework and in consultation with various stakeholders, deployment of the open data platforms and related arcgis online projects. the position also will support with meta data and data quality projects. the position will support the im team for various gis projects while assisting team members with an occasional database related work, particularly around integration with various systems. this position will work closely with records and information management system team, gis team, mobile application or solutions team, and database team members on various tasks. work will be performed according to guidelines, standards and recommendations provided by cvc. the specialist will work with developers to develop or enhance the front end applications, primarily related to data, data management and visualization. the other role of the position involves integration or interlinking of various data and databases, including gis and other information management systems. eligibility requirements education university degree or advanced diploma in geography, environmental science or studies, gis, computer science. required experience 3 years of relevant progressive experience with gis, data management, databases, mapping, access databases, data quality review, analytics, databases, gis, and visualization. very solid proven background and experience with various open data policies, platforms, implementation paths. strong expertise in gis, esri based suites, particularly a background in publishing and coordinating with arcgis online related projects. experience or a strong understanding of various geohubs, open data solutions, story maps. understanding of a high level integration of sql server and gis systems. experience with analytical and modeling software related to gis. hands on experience in process automation, best practice approach, technology efficiency, and effectiveness. experience in various database related tasks. experience in troubleshooting and coming up with solutions. desirable skills certification or accreditation in gis or sql server an asset. experience query building using access and an understanding of sql server system an asset. experience with project conception to implementation. knowledge of various databases, including geodatabase to access. experience with sql query development as it relates to spatial and non spatial databases an asset. knowledge, skills, and ability pro active with service first attitude, positive attitude with a great customer services as it requires interacting with clients for business requirement gathering. knowledge of, or experience with esri based enterprise gis systems. demonstrated advanced problem solving abilities. excels at the highest technical level of all phases of applications systems analysis and programming activities. ability to exercise considerable independent judgment, tact, and sensitivity in dealing with internal and external contacts. able to present ideas and clearly articulate the concepts to management. excellent problem solving or analytical skills and knowledge of analytical tools. display and execute logical and complex troubleshooting methods. report writing and presentation skills as needed. excellent time management skills and the ability to prioritize and complete projects with conflicting deadlines and urgency. ability to work in a team environment as well as independently. proven ability to be innovative and flexible, doing what is needed to get the job done. ability to work independently and self manage tasks to completion. ability to provide outstanding customer service, be a good listener and work well with others. outstanding attention to detail with superior time and project management skills. ability to learn new concepts and skills quickly. a valid driver s license and or or access to a vehicle an asset. summary of major tasks gis, open data, arcgis online related projects open data related research, summary creation, policy drafting and coordinate platform deployment. review cvc s current data holding, data licensing, intellectual properties on data, to prepare them for the public release. assist im team in the existing data sharing processes and help streamline the process. gis, data management, and project implementation as a part of arcgis online or enterprise gis systems. utilize all available tools in gis, with a particular focus on arcmap, arcgis pro, arcgis online, mobile solutions to help meet users requirements. come up with various ways to deploy various spatial and non spatial data to public. maintain documentation such as systems design and build documents. recommend data, data quality, and related software products to the im manager as needed. gather user needs requirements create scoping, provide relevant solutions to the users. research and stay up to date with innovative solutions and plan for a smooth transition from legacy tools and platforms. use a data driven philosophy to help bring an objective, measurable and smart decision to cvc. as a member of the im team, work on all open data related projects to address cvc s needs. test, configure, debug, and manage gis related solutions as assigned. stay current to technological changes and evaluate various platforms to implement at cvc. other duties as assigned. operational tasks coordinate open data related projects and products. assist with various data, metadata, data sharing and other requests. work on arcgis online related project such as story maps as needed. work on gis related ongoing projects on a day to day basis that includes mapping, analyzing, qa or qc of various datasets. work on data and mapping maintenance such as conservation action plan studies that are ongoing. assist cvc s staff on arcgis base solutions. track, coordinate, and inventory cvc s spatial data and maintain a guideline, and quality and currency of the data. stay current to technological changes and evaluate new data management, mobile data collection platforms, and help to implement them to meet user needs. transfer knowledge to staff via lunch and learns, newsletter, etc. as needed. assists the department with other day to day tasks as needed. other duties as assigned. anticipated start dates as soon as possible annual salary starting at 68,196 forward resume and cover letter by june 28th, 2021 please quote 21.2 information management specialist on resume or letter. resumes or letters submitted electronically must be submitted in word or pdf. format as one document. we thank all applicants for their interest. however only those selected for an interview will be contacted. no phone calls please. cvc is an equal opportunity employer. in accordance with aoda , cvc will provide accommodations throughout the recruitment, selection and or or assessment process to applicants with disabilities. if you require disability related accommodations, please inform the human resources staff. all personal information is collected under the authority of the municipal freedom of information and protection of privacy act. reference id 21.2 contract length 12 months application deadline 2021 06 28 job types full time, contract salary from 68,196.00 per year","['go', 'project', 'analytical skills', 'visualization', 'databases', 'gis', 'troubleshooting', 'documentation', 'new concepts', 'sql', 'software', 'reporting', 'analytics', 'programming', 'integration', 'data', 'technology', 'esri', 'systems analysis', 'systems design', 'process', 'data collection', 'metadata', 'streams', 'data quality', 'information management', 'automation', 'datasets', 'data solutions', 'open', 'computer science', 'geo', 'modeling', 'data management']","['go', 'sql', 'freedom of information', 'databases', 'open data', 'open', 'programming', 'documentation', 'data quality', 'esri']","['interlinking', 'visualization', 'gis', 'project implementation', 'troubleshooting', 'new', 'software', 'reporting', 'management systems', 'systems', 'analytics', 'integration', 'systems analysis', 'analytical skills tools', 'process', 'data collection', 'metadata', 'information', 'information management', 'automation', 'datasets', 'data solutions', 'computer science', 'report', 'modeling', 'data management']","['protection', 'assessment', 'environment', 'public sector', 'education', 'customer services', 'currency', 'design', 'environmental science', 'retirement', 'customer service', 'project management', 'licensing', 'streams', 'employee benefits', 'environmental', 'geography']"
348,445,"Applied Scientist, Alexa AI","phd or equivalent master s degree plus 4 years of experience in cs, ce, ml or related field 2 years of experience of building machine learning models for business application experience programming in java, c , python or related language are you excited about developing state of the art machine learning, computer vision, deep learning and natural language processing algorithms, and designs using large data sets to solve real world problems do you have proven analytical capabilities and can multi task and thrive in a fast paced environment as an applied scientist with the alexa ai team, you will bring statistical modeling and machine learning advancements to data analytics for customer facing solutions in complex industrial settings. you will be working in a fast paced, cross disciplinary team of researchers who are leaders in the field. you will take on challenging problems, distill real requirements, and then deliver solutions that either leverage existing academic and industrial research, or utilize your own out of the box pragmatic thinking. in addition to coming up with novel solutions and prototypes, you may even need to deliver these to production in customer facing products expertise on a broad set of ml approaches and techniques, ranging from supervised to unsupervised learning including svm, rdf dnn. a track record of thoughtful leadership and contributions that have advanced the field expertise in deep learning framework . experience in deploying deep learning algorithms on edge devices. experience working effectively with science, data processing, and software engineering teams. amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status. if you would like to request an accommodation, please notify your recruiter.","['deep learning', 'data analytics', 'python', 'machine learning', 'language processing', 'data processing', 'software', 'computer vision', 'c', 'statistical', 'programming', 'modeling', 'algorithms', 'java', 'ai']","['c', 'java', 'python', 'programming']","['deep learning', 'data analytics', 'language processing', 'machine learning', 'data processing', 'software', 'computer vision', 'rd', 'natural', 'statistical', 'modeling', 'algorithms', 'ai']","['environment', 'art', 'industrial research']"
349,446,Data Engineer,"function data science or data engineering reports to interim to svp, analytics and optimization location toronto type full time, permanent role description the data engineer is responsible for the deployment and maintenance of machine learning systems and supporting data streaming pipelines in production. the role reports to the director, data science machine learning. as data engineer, you ll work closely with data scientists deploying and managing machine learning solutions and build data streaming pipelines that support these solutions. you will work with internal product and technology project teams involving large scale data sets, building machine learning pipelines for machine learning model training, and serving up the personalized offers that power exchange solutions products. this role is a unique opportunity to join a dynamic team of analytical professionals that partners up with business and technology to design innovative, value adding customer engagement solutions for our clients. the role is a great fit for motivated individuals seeking to further develop their expertise in the area of machine learning in the area of e commerce and customer loyalty personalized offers. primary responsibilities be a part of a cross functional organization that includes business product management, technical product management, technical solution architects, data scientists, data management, data analysts, software and machine learning engineers, etc. work closely with product managers, architects, and data scientists to design, build, maintain and optimize our data streams and machine learning applications. work with data scientists and engineers to deploy machine learning models in production. build and manage kinesis streams, feature stores used in machine learning model training, and real time prediction implement and automate continuous integration , continuous delivery , and continuous training for machine learning systems. apply devops best practices and automated deployments, model and data versioning, model validation, data validation, and monitoring machine learning production systems closely collaborate with data scientists and machine learning engineers on the implementation, scaling, and maintenance of data science solutions within personalized offers products ensuring all relevant operational data sources ingest appropriately into standardized data warehouse schemas, working collaboratively with the data management team implement and maintain model management and a or b testing framework for evaluating test and trial of model and rule optimizations. participate in esi innovation labs as needed to support rapid product prototyping and product development contribute to the overall operations and culture of the company, fostering our values and policies. capability requirements education, skills experience post secondary education with a graduate degree in computer science, machine learning, or related fields minimum 3 5 years experience with 1 2 years of data streaming experience proficiency with sql and python proficiency with sql and nosql database technologies proven experience in implementation and maintenance of machine learning solutions using aws tooling such as kinesis streams, feature stores, sagemaker, lambdas understanding of open source streaming processing systems will be a plus exposure to automated testing and ci or cd in the machine learning context understanding of fundamental machine learning concepts critical thinking, attention to detail and accuracy, high aptitude for problem solving. excellent communication skills, both verbal and written. driven self starter looking to learn, teach and contribute significantly to the energy of a high performing team. job types full time, permanent","['prediction', 'schemas', 'ci', 'data streaming', 'sql', 'python', 'cd', 'software', 'data science', 'analytics', 'product management', 'data', 'integration', 'aws', 'pipelines', 'data engineering', 'nosql', 'machine learning', 'continuous delivery', 'testing', 'production systems', 'streams', 'model', 'prototyping', 'devops', 'computer science', 'optimization', 'data management']","['sql', 'python', 'production systems', 'aws', 'streams', 'pipelines', 'nosql']","['prediction', 'schemas', 'model management', 'ci', 'data streaming', 'cd', 'software', 'data science', 'analytics', 'product management', 'integration', 'data', 'product', 'data engineering', 'machine learning', 'continuous', 'continuous delivery', 'testing', 'model', 'prototyping', 'devops', 'computer science', 'optimization', 'data management']","['customer engagement', 'validation', 'e commerce', 'education', 'design', 'power exchange', 'product development']"
350,447,Senior Data Scientist - AWS Professional Services,"a bachelor or masters degree in a highly quantitative field or equivalent experience 10 years of industry experience in predictive modeling, science and analysis previous experience in a ml or scientist role and a track record of building ml or dl models experience using and or or r knowledge of sparkml excited by using massive amounts of to machine learning and deep learning models want to help the largest global enterprises derive business value through the adoption of artificial intelligence you will be eager to learn from many different enterprise s use cases of aws ml and dl. you are thrilled to be a key part of amazon, who has been investing in machine learning for decades, pioneering and shaping the world s ai technology at amazon web services , we are helping large enterprises build ml and dl models on the aws cloud. we are applying predictive technology to large volumes of and against a wide spectrum of problems. our professional services organization works together with our aws customers to address their business needs using ai. aws professional services is a unique consulting team. we pride ourselves on being customer obsessed and highly focused on the ai enablement of our customers. if you have experience with ai, including building ml or dl models, we d like to have you join our team. you will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers. you enjoy diving deep into , doing analysis, discovering root causes, and designing long term solutions. you like to have fun, love to learn, and want to innovate in the world of ai. you will understand the customer s business need and guide them to a solution using our aws ai services, aws ai platforms, aws ai frameworks, and aws ai ec2 instances . assist customers by being able to deliver a ml or dl project from beginning to end, including understanding the business need, aggregating , exploring , building validating predictive models, and deploying completed models to deliver business impact to the organization. use deep learning frameworks like mxnet, caffe 2, tensorflow, theano, cntk, and keras to help our customers build dl models. use sparkml and amazon machine learning to help our customers build ml models. work with our professional services big consultants to analyze, extract, normalize, and label relevant . work with our professional services devops consultants to help our customers operationalize models after they are . assist customers with identifying model drift and retraining models. research and novel ml and dl approaches, including using fpga. be able to write production level code, which is well written and explainable have experience using ml libraries, such as scikit learn, caret, mlr, mllib have experience working with gpus to models have experience handling terabyte size datasets be able to track record of diving into data to discover hidden patterns have familiarity with using data visualization tools have knowledge and experience of writing and tuning sql past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format this role is for toronto or vancouver or calgary or montreal. inclusive team culture here at aws, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team puts a value on work live balance. it isn t about how many hours you spend at home or at work it s about the flow you establish that brings energy to both parts of your life. we believe striking the right balance between your personal and professional life is critical to life long happiness and fulfillment. we offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. mentorship career growth our team is dedicated to supporting new members. we have a broad mix of experience levels and tenures, and we re building an environment that celebrates knowledge sharing and mentorship. our senior members enjoy one on one mentoring and thorough, but kind, code reviews. we care about your career growth and strive to assign projects based on what will help each team member and enable them to take on more complex tasks in the future. phd in a highly quantitative field 12 years of industry experience in predictive modeling and analysis good skills with programming languages, such as or c or c ability to experimental and analytic plans for modeling processes, use of strong baselines, ability to accurately determine cause and effect relations consulting experience and track record of helping customers with their ai needs publications or presentation in recognized machine learning, deep learning and mining journals or conferences experience with aws technologies like redshift, s3, ec2, pipeline, emr combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer s organization demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. if contacted for an employment opportunity, advise human resources if you require accommodation, including in order to apply for a position.","['emr', 'tensorflow', 'data visualization', 'c', 'sql', 'keras', 'aws', 'r', 'amazon web services', 'machine learning', 'fpga', 'artificial intelligence', 'deep learning', 'amazon', 'programming languages', 'devops', 'datasets', 'modeling', 'enablement', 'ai']","['sql', 'amazon web services', 'keras', 'amazon', 'programming languages', 'emr', 'scikit', 'predict', 'fpga', 'c', 'aws', 'r']","['deep learning', 'use cases', 'machine learning', 'devops', 'tensorflow', 'datasets', 'data visualization', 'ml', 'artificial intelligence', 'predictive', 'modeling', 'enablement', 'ai']","['environment', 'investing', 'professional services', 'affinity', 'business value', 'human resources', 'consulting', 'adoption', 'team culture', 'legislation', 'mentoring']"
351,448,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","mississauga, on, canada full time company description eurofins scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. from the food you eat, to the water you drink, to the medicines you rely on, eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience cro services. it is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, cdmo, advanced material sciences and in the support of clinical studies. in over just 30 years, eurofins has grown from one laboratory in nantes, france to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing. in 2020, eurofins generated total revenues of eur 5.4 billion, and has been among the best performing stocks in europe over the past 20 years. eurofins cdmo alphora inc. provides a fully integrated suite of services to support drug substance and drug product development from the ind enabling development stage, through to phase ii iii supply, and commercial validation and manufacturing for niche apis. in addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, eurofins cdmo alphora inc. is committed to growing its state of the art organization, with continued investments in its people, modern facilities, equipment, and instrumentation. job description we are currently sourcing for 3 upcoming roles research scientist senior research scientist group leader the successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients . responsibilities will include but are not limited to research scientist, senior research scientist planning and execution of experiments in r d laboratories data analysis, interpretation, and documentation in development reports development of inherently safe processes based on thermal hazard assessment maintaining a safe and well organized laboratory work area technology transfer to both internal and external manufacturing facilities group leader in addition to above leading api technology programs and scientists associated provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project related issues, generating interim and final reports, preparing executive summaries for clients and executive management team qualifications experience and education requirements b.sc. or m.sc. in chemistry with 10 years experience or ph.d in chemistry with 5 years experience in the pharmaceutical or biotechnology industry the group leader position will require a ph.d in chemistry with 10 years experience in the pharmaceutical or biotechnology industry must have a strong knowledge of organic chemistry and hands on experience in the synthesis of complex organic molecules experience in process scale up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset must be highly motivated and have a proven record of success in multiple projects must be well organized and able to meet project timeline commitments must work well in a multi disciplinary team environment and have excellent written and verbal communication skills. additional information what we offer excellent full time benefits including comprehensive and medical coverage, dental, and vision options life and disability insurance rrsp or dpsp eligibility with company match paid vacation and holidays employee assistance plan, tuition program and much more working conditions this position will be working in a laboratory or manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. intermediate lifting requirements of no more than 50 lbs. hazardous materials are handled using established safety procedures and appropriate ppe. shift work and overtime may be required, as well as working periodic weekends and or or evenings. eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply if accommodations are required in the application or interview process, please contact us via only shortlisted candidates will be contacted no phonecalls or emails please. selected candidates can expect to be contacted in 3 6 weeks. no agencies, phonecalls or emails please","['hazard assessment', 'testing', 'sourcing', 'api', 'chemistry', 'specifications', 'documentation', 'data analysis', 'summaries', 'analytical']","['documentation', 'api']","['hazard assessment', 'testing', 'sourcing', 'chemistry', 'specifications', 'data analysis', 'summaries', 'planning']","['pharmacology', 'validation', 'environment', 'raw materials', 'education', 'biotechnology', 'genomics', 'material', 'art', 'life sciences', 'materials', 'cro', 'product development', 'investments', 'manufacturing', 'environmental', 'insurance']"
352,449,Data Engineer,"summary the data engineer will be responsible for supporting, defining, and executing plans to create reporting solutions for our business and support teams. primarily, the data engineer will be accountable for the movement of data from our enterprise systems and landing it into a structured dataset for reporting solutions to utilize. these solutions include, but are not limited to, business intelligence and data visualization tools . this position will work with business leads and it to gather the reporting requirements and will help develop the solution. sap bw, sap business object, power bi, excel, sql, ssis, azure data factory, and other tools will be used as necessary to provide the best solution possible. this position will create and or or support data models of varying complexity from concept to completion including documenting the solution. this position will be a part of the global business intelligence team and must be able to work in a team environment and share knowledge. essential job duties data engineering responsibilities include, but are not limited to create and build robust data structures to support end user s analysis and decision making across multiple business verticals. this includes both end to end architecting and business solutioning. collaborate with end users and peers to understand requirements, formulate use cases, and then translate into an effective technical solution. participate in brainstorming sessions and contribute ideas to our technology, algorithms and products. effectively communicate and interact with business and technical personnel in solving complex data related business and technical problems. monitor data warehouse eco system and identify opportunities to make enhancements. ensure data processes run and complete on a timely basis to ensure business continuity. adhere to timelines and excel in a fast paced, high energy environment. coach and develop other data professionals. drive data best practices and contribute to development of overall data strategy and roadmap. stay informed of latest engineering methodologies and industry direction stay informed of the latest data engineering industry news and direction. other duties as assigned reporting relationships data engineering works under general supervision and may take direction from bi engineering and the data analytics management reports to data analytics manager credentials required associate s degree or two years relevant experience strong understanding of relational and dimensional data modeling . advanced experience working with data warehouses and etl applications with expert level knowledge of relational data. clear communication skills the ability to explain complex technical concepts to non technical internal clients. expertise in sql advanced experience leveraging various strategies for ingesting, modelling, processing, and persisting data as well as excellent analytical and problem solving skills. experience with cloud data warehousing and management solutions. familiarity with power bi and other visualization solutions . be a self starter, with the ability to learn new technologies and work independently an ideal candidate is curious and always willing to implement the latest and greatest technologies. demonstrated experience with azure data factory, azure sql managed instance, and azure devops, sql server integration services and other industry grade etl tools. preferred bachelor s degree or four years relevant experience as a data engineer or related specialty with demonstrable track record in developing data solutions that are correct, stable, and high performing provide business value and use resources efficiently . coding proficiency in one or more languages , expertise sap experience expertise with power bi, ssas or aas, and ssis or azure data factory cloud experience preferred . proficiency in foreign language physical requirements ability to sit at a computer terminal for long periods of time. ability to be physically in attendance at workstation at designated company office location during normal business hours designated for the position. ability to handle considerable stress at times. scansource, inc. is an equal opportunity employer eoe or m or f","['visualization', 'data visualization', 'sql', 'data analytics', 'reporting', 'data', 'integration', 'data models', 'data engineering', 'data warehousing', 'sql server', 'enterprise systems', 'business intelligence', 'algorithms', 'azure', 'data structures', 'bi', 'devops', 'data solutions', 'modeling', 'ssis', 'etl']","['sql', 'global', 'azure', 'bi', 'sql server', 'azure data factory', 'ssass', 'business intelligence', 'data models', 'azure sql', 'ssis']","['data analytics', 'use cases', 'data warehousing', 'visualization', 'data structures', 'reporting', 'devops', 'data visualization', 'enterprise systems', 'relational data', 'data solutions', 'data', 'integration', 'modeling', 'data engineering', 'algorithms', 'etl']","['business value', 'environment', 'business continuity', 'sap']"
353,450,"Sr. Data Scientist, Wish Local","company description wish is a mobile e commerce platform that flips traditional shopping on its head. we connect hundreds of millions of people with the widest selection of delightful, surprising, and most importantly affordable products delivered directly to their doors. each day on wish, millions of customers in more than 160 countries around the world discover new products. for our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market. we re fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. if you ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place. job description we are looking for a data scientist who will work cross functionally with technical and non technical teams to take on a variety of tasks including but not limited to mining data, building models, building dashboards, and conducting detailed analysis. the ideal candidate should be passionate about wish and e commerce, has a strong analytical and consultative mindset, deep understanding of databases, visualization, and modeling techniques, and the ability to thrive in a dynamic, fast paced environment delivering against tight deadlines. this role is looking for a data scientist that will drive high impact to the company through its newest function wish local. the data scientist will help shape the data strategy of this program from the ground up. what you ll be doing design, development and evaluation of highly innovative models establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation work closely with software engineering teams to drive real time model implementations and new feature creations analyze internal behavior tracking data and forecast wish demand implement the strategies and set up a or b test experiments to gauge the impact, and reiterate propose, test and implement new experimentation methodologies, causal inference approaches that can sharpen our product decision making process create own dashboards and analytical reports to track progress share learnings li mb1 li remote qualifications bachelor s or advanced degree in an analytical field 3 years of hands on experience in predictive modeling and analysis 3 years experience writing complex sql queries in a business environment 2 years in python a or b test experience experience collaborating with business eng teams preferred qualifications analytical mindset and ability to see the big picture and influence others detail oriented and must have an aptitude for solving unstructured problems ability to work effectively in a multi task, high volume environment ability to be adaptable and flexible in responding to deadlines and workflow fluctuations experience operating in a unix or linux environment strong presentation skills additional information wish values diversity and is committed to creating an inclusive work environment. we provide equal employment opportunity for all applicants and employees. we do not discriminate based on any legally protected class or characteristic. employment decisions are made based on qualifications, merit, and business needs. if you need assistance or accommodation due to a disability, please let your recruiter know. for job positions in san francisco, ca, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records. individuals applying for positions at wish, including california residents, can see our privacy policy here.","['model', 'sql', 'python', 'visualization', 'databases', 'linux', 'software', 'dashboards', 'unix', 'modeling', 'causal inference']","['sql', 'python', 'databases', 'linux', 'san', 'unix']","['model', 'visualization', 'software', 'dashboards', 'predictive', 'modeling', 'causal inference']","['validation', 'e', 'commerce', 'environment', 'design']"
354,451,Data Science Instructor,"about the position exciting things are happening at juno college we re in the midst of building out our data science career pathway and are seeking a full time instructor to join our data science team in may. we re looking for someone who is collaborative, empathetic, and passionate about teaching, with a strong background in data science. this is a flexible role that ll allow you to inspire and lead others, mould new pedagogies, research and test innovative ways of delivering content, and support the growth of our data science program offerings, while also still having the chance to practice your craft by taking on data science projects for juno, exploring our various data sets, and delivering insights that can change the trajectory of our business. we are currently offering all of our courses live online, and will only move back to in person learning when it s safe to do so. we anticipate having most, if not all, courses live online for all of 2021 and so this role is remote friendly. about us founded in 2012, juno college of technology is a well loved provider of hands on, project based training for people who want to launch new careers in tech from our 12,000 square foot office in downtown toronto to our live online classrooms, we run bootcamps and continuing education courses year round. with thousands of alumni and 1000 students a year, there s a large community of people ready to welcome you to juno responsibilities work with a team of instructors and mentors to lead data analytics and data science courses, helping students learn through lessons, code alongs and interactive exercises work directly with our students in the classroom and give project support help resolve issues, and coach through debugging and technical problem solving provide a thoughtful, stimulating, and positive classroom experience participate in supporting student events create, update and refine curriculum using student feedback and new developments in the data science field according to our curriculum roadmap collaborate with the team to create and review program improvements and innovations contribute expertise to in house data science projects using juno s data sets other tasks as required about you as a private career college, all of our instructors are required to have at least 2 years of practical, real world experience as data analysts, data scientists or similar. candidates who do not have the required experience will not be considered for this position. it would be great if you also have any experience as a teacher, instructor, or mentor, in any discipline. your qualifications hold a degree, diploma, or certification from an ontario college, university, private career college, or equivalent, and have 24 months occupational data science experience or have 36 months of teaching data science experience, and have 24 months occupational data science experience or have 48 months of occupational data science experience you could be a great fit if you are an excellent public speaker and written communicator are passionate about teaching data science and data fluency skills have demonstrable hands on industry experience in data science are collaborative, energetic, and empathetic, and a great technical problem solver have expertise in using python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization have practical knowledge of working with big data, performing customer segmentation, and using cloud services are comfortable using git, github, google docs, sheets, and drive have a positive attitude and a desire to help others. salary, perks and benefits position type full time, permanent starting salary 70,000 85,000 clear growth paths three weeks paid vacation plus extra time off in december seven paid personal days each year health spending account refreshed annually more visit our careers page at junocollege.com or careers for a full list of perks benefits. how to apply please apply through the link below and answer the provided questions. we d love to see your resume, and anything else you d like to provide us all applications are appreciated, but we will only contact successful applicants to move on to the next stage.","['data analytics', 'python', 'machine learning', 'statistics', 'github', 'project support', 'data wrangling', 'data visualization', 'data science', 'git', 'debugging', 'big data', 'data analysis', 'solver', 'cloud services']","['python', 'git', 'debugging', 'big data', 'solver', 'google docs']","['data analytics', 'machine learning', 'statistics', 'exploratory', 'project support', 'data wrangling', 'data visualization', 'data science', 'data analysis', 'github', 'cloud services']","['curriculum', 'continuing', 'events', 'private', 'education', 'developments']"
355,452,GCP Data Engineer,"procogia has doubled in size over the last two years core to procogia s culture is ensuring we maintain a balanced male to female ratio. we are proud to share our consulting teams consist of 40 50 females compared to the industry standard of 10 20 . our diversity, and differences allow us to create innovative and effective solutions for our clients. at procogia we re passionate about developing data driven solutions that provide highly informed answers to our clients most critical challenges. our projects are varied, from data warehouse builds, deploying cloud data solutions, dashboarding, building predictive models. you may be involved in all stages of the project life cycle, from data engineering or integration to building pipelines right through to advanced analytics. we work with industry leading clients from various sectors including pharmaceuticals, telecommunications, technology, financial services retail. our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal career development. the position procogia are looking to add a data engineer with gcp big query experience to our engineering team based in vancouver. the data engineer is a key member of the data engineering team. your position will be based around building enterprise data warehouse and data lake. main responsibilities work in building and architecting multiple data pipelines, end to end etl and elt process for data ingestion and transformation in google cloud platform coordinating tasks amongst the team build, maintain, and monitor batch, micro batch and real time etl pipelines in a google cloud platform architecture work closely with the data science and analytics teams to develop a clear understanding of data and data infrastructure needs assist with data related technical issue research and evaluate various approaches to data architecture and applications, including big data technologies review existing artifacts and recommend solutions and technologies to implement analyze corporate data, design and develop business intelligence and other data management solutions perform data validation and quality assurance. document requirements and business rules into appropriate technical specifications participate in work planning and estimation present technical solutions to various stakeholders provide day to day support of the edw and dl environments, with excellent customer service to internal clients, monitor new deployments and services, escalating issues where appropriate create tableau data sources and dashboards for various business stakeholders requirements 5 years experience working in a directly comparable role responsible for data warehouse and or or data lake development 2 years experience with google cloud platform 2 years experience with other cloud data technologies such as aws 5 years working directly with relational databases with strong sql programming skills significant experience with sql server , including mdx and dax 3 years experience designing, building, and optimizing big data pipelines, architectures, and data sets 3 years experience with modern programming languages 2 years experience working with nosql databases or repositories 2 years experience with big data solutions , including data stream processing experience designing a new data solution or new subject area understanding of dimensional modeling, star schemas, and associated kimball methodology excellent verbal and written skills in english exceptional attention to detail experience working on an agile development team strong analytical, troubleshooting, and problem solving skills a proven ability to effectively prioritize and execute tasks in a high pressure environment a strong work ethic without sacrificing your sense of humor or your ability to have fun on the job.","['databases', 'schemas', 'quality assurance', 'tableau', 'big', 'data infrastructure', 'dashboards', 'troubleshooting', 'sql', 'gcp', 'data science', 'enterprise', 'analytics', 'data', 'integration', 'aws', 'programming', 'pipelines', 'data engineering', 'nosql', 'data pipelines', 'relational databases', 'stream processing', 'google cloud platform', 'specifications', 'business intelligence', 'programming languages', 'dax', 'data solutions', 'modeling', 'data management', 'telecommunications', 'etl']","['sql', 'gcp', 'databases', 'repositories', 'quality assurance', 'tableau', 'programming languages', 'big', 'google cloud platform', 'programming', 'big data', 'business intelligence', 'aws', 'pipelines', 'telecommunications', 'nosql']","['schemas', 'data infrastructure', 'dashboards', 'troubleshooting', 'data science', 'analytics', 'data', 'integration', 'data engineering', 'data pipelines', 'relational databases', 'data ingestion', 'stream processing', 'specifications', 'agile development', 'planning', 'enterprise data', 'methodology', 'dax', 'data solutions', 'mdx', 'modeling', 'data management', 'etl']","['validation', 'environment', 'business rules', 'retail', 'design', 'customer service', 'consulting', 'financial services', 'internal clients', 'pharmaceuticals', 'architecture']"
356,453,Data Engineer,"at bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever stronger loyalty to their brands. that can take us in some pretty amazing directions, and as a data engineer, you ll have your hands on the wheel as we drive the future of loyalty. working on the bleeding edge of exciting technology, you re afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. every day with the data engineering team is different and each project presents its own set of new and exciting challenges. things shift very quickly in our industry and we rely on the data engineering team to keep us ahead of the curve and moving in the right direction. here s what we want problem solver you are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem collaborative you work well with other people passionate a passion for big data and an interest in the latest trends and developments constantly researching new tools and data technologies self starter you are comfortable helping your team get things done here s what you ll be doing design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services identify, design, and implement system performance improvements identify, design, and implement internal process improvements automate manual processes and optimize data delivery useful skills or background you may or may not tick off every box, and that s ok. each person brings a different background and different skills. if you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we ll see what we can do to help a degree in computer science or engineering or related field 2 4 years of experience in a software engineering environment experience with sql and nosql systems knowledge of hadoop, spark, kafka or other equivalent technologies proficiency in some of the following languages scala, java, python, bash experience with automated testing systems mentorship, collaboration, and communication skills knowledge of data modelling, data warehousing, etl processes, and business intelligence reporting tools experience working with ci or cd, containerization, and virtualization tools such as gitlab, jenkins, kubernetes, docker experience with tools like databricks, snowflake or powerbi why join us bond is proudly recognized as a great place to work and a best managed company for the third year in a row. we re 400 people working tirelessly together to make the world a more loyal place. you ll be joining a hyper talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. you ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client s biggest business challenges. if you re looking to build your career, build your skills and build bonds apply today at bond, we are proud to be a diverse organization and we are committed to building and fostering an environment where our employees feel included, valued, and heard. our belief is that a strong commitment to diversity and inclusion enables us to truly create equal opportunity and positive employment experiences for everyone. we encourage applications from indigenous peoples, racialized people, people with disabilities, people from gender and sexually diverse communities and people with intersectional identities.","['bash', 'system performance', 'jenkins', 'data services', 'ci', 'big data', 'containerization', 'java', 'kubernetes', 'sql', 'python', 'cd', 'software', 'scala', 'reporting', 'data engineering', 'data warehousing', 'solver', 'nosql', 'gitlab', 'data pipelines', 'testing', 'business intelligence', 'hadoop', 'computer science', 'virtualization', 'snowflake', 'etl']","['kubernetes', 'sql', 'python', 'gitlab', 'scala', 'jenkins', 'hadoop', 'snowflake', 'java', 'big data', 'business intelligence', 'containerization', 'solver', 'nosql', 'system performance']","['bash', 'data pipelines', 'cd', 'software', 'reporting', 'data services', 'ci', 'computer science', 'virtualization', 'data engineering', 'data warehousing', 'testing systems', 'etl']","['bonds', 'environment', 'developments', 'design']"
357,454,Chercheur scientifique - Principal - Research Scientist,"english will follow r sum en tant que chercheur principal au sein du groupe de recherche asr, le candidat effectuera des recherches algorithmiques sur des ensembles de donn es l chelle de production dans le but d optimiser la pr cision, la vitesse et l volutivit , principalement pour les syst mes asr de bout en bout qui quipent les produits nuance. ces recherches porteront notamment sur les architectures de r seaux neuronaux, les algorithmes d entra nement et d adaptation , ainsi que sur le traitement et l augmentation des donn es. principales t ches et responsabilit s fournir une analyse exp rimentale et th orique des probl mes de reconnaissance de la parole. formuler et mettre en uvre de nouveaux algorithmes et concevoir or r aliser des exp riences pour les v rifier. explorer de nouvelles architectures de mod lisation de s quence s quence pour am liorer la pr cision de la reconnaissance. optimiser la pr cision des syst mes de reconnaissance vocale de bout en bout sur des donn es r elles difficiles. suivre les d veloppements externes en mati re d algorithmes de reconnaissance vocale afin de maintenir nos recherches la pointe du progr s. discuter et pr senter les id es et les r sultats, en rendant compte r guli rement des progr s r alis s. r diger des rapports techniques internes et des articles pour une publication externe. connaissances, comp tences et qualifications formation doctorat en informatique ou quivalent nombre minimum d ann es d exp rience professionnelle 3 comp tences requises exp rience et connaissances approfondies des algorithmes d apprentissage automatique, y compris l apprentissage profond. compr hension approfondie des algorithmes de reconnaissance vocale. capacit d montr e mener des recherches in dites sur les algorithmes de reconnaissance vocale. exp rience avec les bo tes outils open source d apprentissage profond . python et script shell dans un environnement unix. bonnes comp tences en communication crite et orale. capacit prendre des initiatives, mais aussi suivre un plan et bien travailler au sein d une quipe. comp tences pr f r bonnes capacit s d analyse et de diagnostic. exp rience de l ex cution d exp riences grande chelle dans un environnement de calcul gpu en grille ou en nuage. exp rience des techniques de mod lisation de s quence s quence. summary as a principal research scientist in the asr research group, the candidate will perform algorithmic research on production scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end to end asr systems powering nuance products. this will include research into neural network architectures, training or adaptation algorithms, and data processing or augmentation. principal duties and responsibilities provide experimental and theoretical analysis of speech recognition problems. formulate and implement new algorithms and design or conduct experiments to verify them. explore new sequence to sequence modeling architectures for improving recognition accuracy optimize the accuracy of end to end speech recognition systems on challenging real world data. follow external developments in speech recognition algorithms to keep our research state of the art. discuss and present ideas and results, reporting progress on a regular basis. write internal technical reports and papers for external publication. knowledge, skills and qualifications education phd in cs or equivalent minimum years of work experience 3 years required skills strong background and knowledge of machine learning algorithms including deep learning. in depth understanding of speech recognition algorithms demonstrated ability to conduct novel research in speech recognition algorithms. experience with open source deep learning toolkits python and shell scripting in a unix environment. good written and oral communications skills. ability to take initiative, but also follow a plan and work well as part of a team. preferred skills good analytical and diagnostic skills. experience of running large scale experiments in a grid or cloud gpu computing environment. experience with sequence to sequence modeling techniques. what we offer unique environment for collaborative teamwork on cutting edge technology location is in the heart of downtown montreal flexible hours transit reimbursement and parking working with international teams to push the boundaries of technology contributing to and collaborating with international teams that drive innovation competitive benefit package 4 weeks vacation 10 paid sick days bonus plan, group rrsp, deferred profit sharing plan, employee stock purchase plan award winning top employer canada s top 100 employers 7 consecutive years montreal s top employers 6 consecutive years canada s top employers for young people 3 consecutive years","['deep learning', 'computing', 'python', 'machine learning', 'data processing', 'reporting', 'datasets', 'speech recognition', 'scalability', 'unix', 'shell scripting', 'modeling', 'algorithms', 'technical reports', 'r']","['unix', 'python', 'shell script', 'r']","['deep learning', 'algorithmic research', 'computing', 'machine learning', 'data processing', 'reporting', 'datasets', 'speech recognition', 'scalability', 'modeling recognition', 'modeling', 'sequence', 'algorithms', 'technical reports']","['environment', 'education', 'design', 'art', 'developments']"
358,456,"Compliance Manager, Data Protection & Cybersecurity","do you want to join a rocket ship that is passionate about data protection and building a compliant product the right way do you want to leverage your gdpr, hipaa or soc 2 compliance expertise to help us cure covid and cancer do you want to work with a gender balanced team of highly recognized experts in the field of cybersecurity, ai and genomics my intelligent machines is looking for a talented compliance manager, data protection cybersecurity to help build a world class augmented intelligence r d platform for life scientists working in biopharma and agriculture companies. mims is a fast growing software company, with recurring revenues, that embraces agile and privacy by design methodologies. reporting directly to the coo, you will be working closely with our cybersecurity analysts, devops engineers, system administrators, bioinformaticians, life scientists, data scientists, ai and software developers to establish best practices for the ai revolution in genomics. main responsibilities collaborate with our open minded teams to maintain compliance with these guidelines and standards european general data protection regulation us health insurance portability and accountability act of 1996 soc 2 cybersecurity framework of the us nat inst. of stand. and tech. canada personal information protection and electronic documents act california consumer privacy act iso 27001 h bergeur de donn es de sant translate legislation and regulations into policy and procedures in order to embed them smoothly in day to day activities be the company expert and champion on new regulatory developments , industry trends, and how they apply to mims assessment and review of company s service level agreements with outsourced companies and regularly review compliance of outsourced companies with these agreements provide advice, assistance and support to the business on compliance related matters assuring the design, implementation and execution of compliance framework in line with all policies setting up compliance by design especially in customer journeys or digital initiatives and while setting up playbooks for a further explanation of specific topics promoting a strong compliance culture and contributing to training and awareness on the topic of data protection and cybersecurity plan support internal and external audits regularly monitors and reviews risks as part of the compliance risk management process advise on further mitigation or on specific control testing provide guidance and feedback to the security team and compliance teams in implementing the various initiatives launched by mims guides on incident learning reports, investigates incidents. takes the lead in person oriented investigations carry out due diligence checks on new clients and suppliers or consultants qualifications minimum of 5 years of experience in a similar role a relevant certification from this list or the desire to achieve one, fully paid by mims certified ethical hacker certified information systems security professional certified compliance professional comptia security giac information security fundamentals isaca csx microsoft technology associate security fundamentals system security certified practitioner experience with identifying and resolving is technology related problems in an industrial and international company is a plus high level of professionalism, even in the midst of multiple engagements experience in working on multiple projects concurrently using agile methodologies experience with programming and or or scripting languages is a plus high level of proficiency in english high level of proficiency in french is a plus a confident approach and an ability to communicate with a wide range of people including regulators, legal advisors, outsourced partners and senior management relevant university degree who you are a flexible attitude to job roles as well as a willingness to contribute wherever needed the ideal candidate will take full ownership of their core responsibilities, and will be comfortable with those responsibilities evolving with the changing needs of the company the ideal candidate is exceptionally detail oriented and derives joy from bringing rigor, structure, and organization to complex systems ability to contribute in a multidisciplinary team as a strong team player, focused on delivering results against multiple deadlines in a fast paced growing environment submission please submit your resume or any questions you may have to we would like to hear from you even if you are not sure you have all the qualifications. by applying to this position, you are confirming you possess either a canadian citizenship, permanent resident status or work permit. we thank all those who apply but only those selected for further consideration will be contacted. about mims my intelligent machines , based in montreal, is a leader in artificial intelligence applied to life sciences. we provide biopharma and agtech companies with augmented intelligence systems enabling life scientists working in this space to model patients, cells, tissues or farm animals to develop more efficient and personalized treatments and agro products. the company is growing at a fast pace and has a strong and active research and development team. mims is a dynamic tech company with an exceptional culture which embraces diversity and gender equity. new team members consistently rate our onboarding and integration process as one of the best they have seen in their career. we are currently one of the few tech companies reaching gender balance, as half of the team is composed of women. we received the 2020 red herring s top 100 north america award, one of the most prestigious prizes granted each year to the 100 most promising private tech companies. for more information, please visit https or or","['https', 'agile methodologies', 'due diligence', 'cybersecurity', 'software', 'complex systems', 'reporting', 'devops', 'testing', 'security', 'information systems', 'system', 'scripting', 'programming', 'artificial intelligence', 'integration', 'information', 'ai']","['https', 'programming', 'soc', 'r']","['agile methodologies', 'due diligence', 'cybersecurity', 'software', 'complex systems', 'reporting', 'devops', 'testing', 'security', 'information systems', 'system', 'scripting', 'gdpr', 'artificial intelligence', 'integration', 'information', 'ai']","['environment', 'genomics', 'and compliance', 'private', 'general data', 'agro', 'assessment', 'legislation', 'developments', 'risk management', 'design', 'health insurance', 'life sciences', 'engagements', 'agriculture', 'onboarding', 'iso 27001', 'customer journeys', 'regulations', 'external audits']"
359,457,Chercheur Scientifique Senior - Senior Research Scientist,"english will follow r sum en tant que chercheur senior au sein du groupe de recherche asr, le candidat effectuera des recherches algorithmiques sur des ensembles de donn es l chelle de production dans le but d optimiser la pr cision, la vitesse et l volutivit , principalement pour les syst mes asr de bout en bout qui quipent les produits nuance. ces recherches porteront notamment sur les architectures de r seaux neuronaux, les algorithmes d entra nement et d adaptation , ainsi que sur le traitement et l augmentation des donn es. principales t ches et responsabilit s fournir une analyse exp rimentale et th orique des probl mes de reconnaissance de la parole. formuler et mettre en uvre de nouveaux algorithmes et concevoir or r aliser des exp riences pour les v rifier. explorer de nouvelles architectures de mod lisation de s quence s quence pour am liorer la pr cision de la reconnaissance. optimiser la pr cision des syst mes de reconnaissance vocale de bout en bout sur des donn es r elles difficiles. suivre les d veloppements externes en mati re d algorithmes de reconnaissance vocale afin de maintenir nos recherches la pointe du progr s. discuter et pr senter les id es et les r sultats, en rendant compte r guli rement des progr s r alis s. r diger des rapports techniques internes et des articles pour une publication externe. connaissances, comp tences et qualifications formation doctorat en informatique ou quivalent nombre minimum d ann es d exp rience professionnelle 3 comp tences requises exp rience et connaissances approfondies des algorithmes d apprentissage automatique, y compris l apprentissage profond. compr hension approfondie des algorithmes de reconnaissance vocale. capacit d montr e mener des recherches in dites sur les algorithmes de reconnaissance vocale. exp rience avec les bo tes outils open source d apprentissage profond . python et script shell dans un environnement unix. bonnes comp tences en communication crite et orale. capacit prendre des initiatives, mais aussi suivre un plan et bien travailler au sein d une quipe. comp tences souhait es bonnes capacit s d analyse et de diagnostic. exp rience de l ex cution d exp riences grande chelle dans un environnement de calcul gpu en grille ou en nuage. exp rience des techniques de mod lisation de s quence s quence. position summary as a senior research scientist in the asr research group, the candidate will perform algorithmic research on production scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end to end asr systems powering nuance products. this will include research into neural network architectures, training or adaptation algorithms, and data processing or augmentation. principal duties and responsibilities provide experimental and theoretical analysis of speech recognition problems. formulate and implement new algorithms and design or conduct experiments to verify them. explore new sequence to sequence modeling architectures for improving recognition accuracy optimize the accuracy of end to end speech recognition systems on challenging real world data. follow external developments in speech recognition algorithms to keep our research state of the art. discuss and present ideas and results, reporting progress on a regular basis. write internal technical reports and papers for external publication. knowledge, skills and qualifications education phd in cs or equivalent minimum years of work experience 3 required skills strong background and knowledge of machine learning algorithms including deep learning. in depth understanding of speech recognition algorithms demonstrated ability to conduct novel research in speech recognition algorithms. experience with open source deep learning toolkits python and shell scripting in a unix environment. good written and oral communications skills. ability to take initiative, but also follow a plan and work well as part of a team. preferred skills good analytical and diagnostic skills. experience of running large scale experiments in a grid or cloud gpu computing environment. experience with sequence to sequence modeling techniques. what we offer unique environment for collaborative teamwork on cutting edge technology location is in the heart of downtown montreal flexible hours transit reimbursement and parking working with international teams to push the boundaries of technology contributing to and collaborating with international teams that drive innovation competitive benefit package 4 weeks vacation 10 paid sick days bonus plan, group rrsp, deferred profit sharing plan, employee stock purchase plan award winning top employer canada s top 100 employers 7 consecutive years montreal s top employers 6 consecutive years canada s top employers for young people 3 consecutive years","['deep learning', 'shell', 'python', 'machine learning', 'computing', 'data processing', 'reporting', 'datasets', 'scripting', 'speech recognition', 'scalability', 'unix', 'modeling', 'algorithms', 'technical reports', 'r']","['shell', 'unix', 'python', 'r']","['deep learning', 'algorithmic research', 'computing', 'machine learning', 'data processing', 'reporting', 'datasets', 'scripting', 'speech recognition', 'scalability', 'modeling recognition', 'modeling', 'sequence', 'algorithms', 'technical reports']","['environment', 'education', 'design', 'art', 'developments']"
360,458,Senior Data Scientist - 311451,"senior data engineer on behalf of our client, procom is searching for a senior data scientist. the candidate should have excellent foundations of a seasoned data scientist. this professional is a dedicated senior data scientist with excellent knowledge of phyton, sql and data science toolkits. this professional will be responsible for maintaining fast growing datasets, developing custom data models, and extracting actionable insights to make our client s products more enjoyable and intuitive for their customers. this position works in close collaboration with cross functional teams to influence product innovation. if you want to learn the right approach to delivering the best health care experiences to our customers and are passioned about the health and wellness industry, this career path is for you. additionally, this professional must enjoy working in a fast paced environment, using cutting edge technology, and working with big data. you want to be a part of something bigger them yourself and strive to change lives for better, through digital health solutions for end users. being passioned about user experience and work well in a collaborative, knowledge sharing environment will your give the edge you need to apply for this role. job details as the senior data scientist in this team, you will build and expand machine learning models using nlp, classification, neural networks, etc. work with engineers to integrate data from multiple sources and develop predictive algorithms. extract actionable insights from complex data sets and report insights via internal dashboards and visualization to product teams for roadmap and feature decisions. review latest research papers and trends in the field of artificial intelligence and update team with new technologies. communicate findings and new trends with company leadership. conduct exploratory analysis and develop statistical models to answer key product usage and engagement questions. help product and marketing teams use experimentation and cohorting to test assumptions and launch new marketing campaigns, features and product releases. partner with product teams to define and benchmark metrics for new features launches and initiatives and help create a culture of measurement. mandatory skills as the senior data scientist in this team, you will master s degree or higher in computer science, statistics, electrical engineering, or other related fields. 5 years experience as data scientist. proficiency in using python and sql. proficiency in using data science toolkits such as keras, tensorflow, pytorch, etc. practical experience in time series analysis and sequential modeling. prior experience developing machine learning approaches for modeling and predicting user behaviors. prior experience building nlp pipelines for chatbots in a limited training data environment. prior experience building rest apis and interfacing applications with other 3rd party apis. ability to work independently and with moderate supervision. exceptional organizational skills and problem solving ability. good communication skills, both verbal and written. soft skills stable employment history passion for helping people collaborative nature if you think you could add value to a group of passionate and dedicated health and wellness professionals and be a part of a learning environment that values your contributions, let us know, please. we look forward to seeing your application","['visualization', 'user experience', 'tensorflow', 'pytorch', 'dashboards', 'big data', 'sql', 'python', 'statistics', 'keras', 'time series analysis', 'data science', 'data models', 'pipelines', 'electrical engineering', 'machine learning', 'artificial intelligence', 'rest', 'algorithms', 'datasets', 'neural networks', 'nlp', 'computer science', 'modeling']","['sql', 'python', 'keras', 'pytorch', 'nlp', 'big data', 'data models', 'pipelines']","['visualization', 'user experience', 'tensorflow', 'dashboards', 'statistics', 'time series analysis', 'data science', 'electrical engineering', 'machine learning', 'data sciencekit', 'artificial intelligence', 'exoratory analysis', 'chatbots', 'toolkit', 'rest', 'algorithms', 'datasets', 'neural networks', 'computer science', 'modeling']","['environment', 'metrics', 'marketing', 'marketing campaigns', 'research papers']"
361,459,"Data Engineer, Trust and Safety Operations","dapper labs is at an inflection point in our journey and it might be the perfect time for you to join us. less than 6 months ago we launched nba top shot on the new flow blockchain and it is already on track to be the fastest growing marketplace in history. over 200 million in sales in the past 30 days and counting we need to scale our systems to handle the demand we re looking for product minded data engineers to build out our fraud protection team. you ll join a small team that s scaling rapidly and build sustainable foundations for the future. our data pipeline currently include segment and tableau. most of our backend systems are in go, frontends in react. we use vanilla postgres as well as kafka event driven architecture in nba top shot. this is an opportunity to help define the company s data strategy, while laser focused on enabling the organization to make data driven decisions by unlocking the distribution, collection, and tooling of data. we believe in an open digital future one where people own the assets they pay for and have full transparency into the software they re using. we believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they re helping create. crypto, or blockchain, is the technology that enables this future. blockchains are public computers that anyone can access, everyone can trust, and no one can block or take down. currencies and collectibles are only scratching the surface of what s possible. titles or years of experience don t matter to us impact, authenticity, and values alignment do. we are now a remote first team and open to hiring anywhere in the world. about the role work cross functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity work with google cloud platform, bigquery, cloud composer, etc, and drive adoption of other key technologies cleaning, processing, transposing data from our data lake to endpoints like tableau create predictive models to understand user level fraud risk consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the dapper product team and our finance department bonus points if you have the following you have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made you are capable of applying your skills across a variety of use cases inflexible specialists need not apply you have a bachelor s degree in a highly quantitate field , and a master s degree preferred you have 5 years working experience in data science and or machine learning. strong knowledge of sql and python programming and graph databases you are naturally curious and passionate about fraud prevention if something seems off, you want to investigate what s going on and solve the true problem you are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions more about dapper labs dapper labs is the world s first blockchain entertainment company. we are the creators of industry leading experiences including cryptokitties and nba top shot, as well as dapper wallet, the simplest way to manage your assets and use the blockchain. we are also the original developers behind flow, a new decentralized blockchain designed from the ground up for scalability and ease of use. our mission at dapper labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. we have raised over 350m from leading vcs including fred wilson and chris dixon as well as venrock, samsung, google ventures, coatue, nba players, and global artists, among others. dapper labs partners include the nba and nbpa, the nfl pa, ubisoft, warner music, turner, dr. seuss, genies, and the ufc, as well as 100 others. visit our website to learn even more about dapper labs, including information about benefits and perks.","['go', 'databases', 'tableau', 'vanilla', 'less', 'working experience', 'laser', 'sql', 'python', 'software', 'data science', 'programming', 'machine learning', 'google cloud platform', 'fraud detection', 'graph', 'blockchain', 'crypto', 'scalability', 'blockchains']","['go', 'sql', 'python', 'databases', 'tableau', 'crypto', 'vanilla', 'programming', 'less', 'laser']","['machine learning', 'use cases', 'software', 'trans', 'data science', 'scalability', 'fraud detection', 'working experience', 'blockchains', 'blockchain']","['fraud prevention', 'finance', 'sales', 'adoption', 'hiring', 'architecture']"
362,460,"Data Engineer / Power BI Developer, Omnia AI","job type permanent primary location vancouver, british columbia, canada all available locations vancouver calgary edmonton learn from deep subject matter experts through mentoring and on the job coaching partner with clients to solve their most complex problems be empowered to lead and have impact with clients, our communities and in the officev you love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter if that is you, then omnia ai is where you want to be. what will your typical day look like as a data engineer or power bi developer within the omnia ai practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. you will play an active role throughout the entire engagement cycle, specializing in technical data solutions including etl, data integration, data warehousing, dimensional models, in memory architectures, master data or reference management, business visualization and business analytics. you are enthusiastic about all things data, have strong problem solving and analytical skills, are tech savvy and have a solid understanding of software development. specifically, in this role, you will engineer and architect etl and bi or dw solutions to enable business analytics and drive insights translate business rules and requirements into data objects, visualizations, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly plan or schedule tasks, lead small development teams, and mentor junior colleagues facilitate technical meetings with client staff and advise client with technical option analyses based on leading practices about the team our data analytics modernization team helps clients design and implement the data platform architectures be it in the cloud or on premise required to enable cutting edge bi solutions. you will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on big data, bi or dw, data integration, data governance, master data and analytics applications. each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. the integration modernization practice helps clients manage the complexity inherent in today s diverse business landscape while supporting them in consolidating or customizing multiple technologies. you will be part of a multi disciplinary team focused on delivering a breadth of solutions to solve our clients most challenging business problems, with a focus on integration platforms, api design, and micro and web services. we help our customers to reduce costs and risks by simplifying integration with existing systems and supporting them in all aspects of creating customized and innovative digital solutions. enough about us, let s talk about you you are someone with bachelor s degree in computer science, mathematics or statics master s degree desirable 5 or more years of bi data engineering related experience with high proficiency in pl or sql coding, power bi, python, cloud based data platforms , database management, and etl from job creation to performance testing and tuning ability to tackle tight deadlines and work under pressure experience working in fast paced agile environments an asset competent decision making capabilities with ability to respond and react to emergency situations effectively and communicate to stakeholders, client leadership, and individuals at several organization levels if you believe you have what it takes to be a successful member of our team, please apply now. we know your career is important to you and it s important to us, too. this role is just the first step of a highly successful career we can help you build. why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities deloitte encourages applications from all qualified candidates that represents the full diversity of communities across canada. this includes candidates from indigenous communities in support of living our values and our commitments to our reconciliation action plan . we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally. deloitte canada has 30 offices with representation across most of the country. we acknowledge our offices reside on traditional, treaty and unceded territories as part of turtle island and is still home to many first nations, m tis, and inuit peoples. we are all treaty people.","['analytical skills', 'visualization', 'big', 'business', 'master', 'data analytics', 'sql', 'python', 'software development', 'data', 'analytics', 'integration', 'data models', 'data engineering', 'data warehousing', 'modernization', 'agile environments', 'web services', 'bi', 'performance testing', 'data solutions', 'api', 'computer science', 'technology solutions', 'mathematics', 'etl', 'ai']","['sql', 'python', 'bi', 'api', 'technology solutions', 'big data', 'data models', 'master data']","['analytical skills', 'business visualization', 'business', 'data analytics', 'software development', 'data', 'analytics', 'integration', 'data engineering', 'data warehousing', 'modernization', 'web services', 'reference management', 'performance testing', 'data solutions', 'computer science', 'mathematics', 'etl', 'ai']","['subject matter experts', 'business rules', 'design', 'governance', 'mentoring']"
363,461,Data Engineer,"full timevancouver june 14, 2021 job id 21275 abcellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking an ambitious and experienced data engineer to join our data management team and contribute towards building a dynamic and scalable architecture in support of our rapidly advancing data pipeline. the ideal candidate will have experience working with ambiguity and be a creative thinker as our data landscape continues to evolve in scale, complexity, and demand. we are a fast moving and innovative company that lives on the frontier of discovery, both scientifically and technically. as such, the successful candidate will spend their days focused on the design and implementation of a sophisticated data architecture that maximizes data quality, value, and velocity based on the needs of a talented team of scientists and developers. how you might spend your days identifying, designing, and implementing internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. working with our team of developers to help improve the flow of data across the technology stack. building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws big data technologies. working with stakeholders to assist with data related technical issues and support their data infrastructure needs. performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. designing and publishing data models with supporting architecture that reflect on the prevailing needs of the organization ensuring proposed solutions are scalable and dynamic. leveraging experience with multiple aws services or equivalent to design solutions in response to the data needs of key stakeholders and teams. together with the software development teams, optimizing and ensuring data security through integration and management of identity management tools within proposed data architecture. working with the data governance office to ensure proposed solutions adhere to and align with the published data recommendations, practices, and policies. sharing your knowledge in data engineering with team members and colleagues, helping to elevate the core understanding for big data architecture and its impact on improving business processes. we d love to hear from you if you have 5 years of work experience with etl, data modeling, and data architecture. 4 years of work experience in writing advanced sql bachelor s degree in quantitative areas such as computer science, information systems, big data analytics, or related fields. experience with relational sql and nosql databases postgres, ms sql server, and cassandra, etc. experience writing complex sql queries, extracting and importing disparate data from source systems, and data manipulation based on requirement experience building and optimizing big data data pipelines, architectures and data sets. experience with data lakes, data warehousing, and the associated tools and applications for managing the flow of data across these environments. strong analytic skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. a successful history of manipulating, processing and extracting value from large disconnected datasets. strong project management and organizational skills. experience with agile development methods in data oriented projects experience supporting and working with cross functional teams in a dynamic environment. experience in tracking data lineage, ensuring data quality, and improving discoverability of data. preferred qualifications experience with native aws technologies for data and analytics such as redshift spectrum, athena, s3, lambda, glue, emr, kinesis, sns, cloudwatch, etc. or equivalent relevant technologies expertise in one or more programming languages, preferably scala, pyspark, python and or or java. experience with big data tools . offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21275 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['databases', 'emr', 'pyspark', 'big', 'data infrastructure', 'big data', 'java', 'glue', 'sql', 'data analytics', 'python', 'scala', 'software development', 'data', 'analytics', 'aws', 'integration', 'data models', 'data engineering', 'data warehousing', 'nosql', 'machine learning', 'data pipelines', 'data transformation', 'data manipulation', 'metadata', 'data quality', 'athena', 'automation', 'cassandra', 'data structures', 'programming languages', 'datasets', 'high throughput', 'security', 'information systems', 'scalability', 'computer science', 'root cause analysis', 'modeling', 'data management', 'etl']","['databases', 'emr', 'pyspark', 'big', 'sns', 'data lakes', 'big data', 'java', 'glue', 'sql', 'python', 'scala', 'data', 'aws', 'data models', 'nosql', 'data manipulation', 'data quality', 'athena', 'cassandra', 'programming languages']","['data lineage', 'data infrastructure', 'data analytics', 'microfluidics', 'software development', 'data', 'analytics', 'integration', 'data engineering', 'data warehousing', 'unstructured', 'machine learning', 'data pipelines', 'data transformation', 'metadata', 'agile development', 'automation', 'data structures', 'datasets', 'high throughput', 'security', 'information systems', 'scalability', 'computer science', 'root cause analysis', 'modeling', 'data management', 'etl']","['environment', 'antibodies', 'genomics', 'design', 'project management', 'governance', 'compensation', 'architecture']"
364,462,Cloud Data Engineer- GCP/BigQuery,"job description applied systems, inc., a worldwide leader in insurance technology, is currently searching for a knowledgeable and talented cloud data engineer gcp or bigquery to join our data engineering team. this team works to build data solutions and implement tools to help improve data accuracy and reliability so our customers can make data driven decisions with confidence. as the cloud data engineer, you will be responsible for the design and implementation of our data lake ensuring reliable data infrastructure and creating data solutions for business partners. responsibilities drive innovation within data engineering by playing a lead role in technology decisions for the future of our data science, analysis, and reporting needs work with business partners and software engineers to gather, understand, and bridge definitions and requirements lead the design and development for highly complex and critical data projects with strict timelines drive efficiency gains through improved reliability and stakeholder adoption of self serve tools leverage research and previous experience to ensure we re up to date and continuously exploring identify gaps and weaknesses in our data stack and continues to drive learning advancements for the team provide technical expertise, leadership, and mentor the data engineering team in all phases of work including analysis, design, and development of architecture design, build and work with dispersed engineering teams and business users to implement data pipelines into our centralized data platform developing in python leveraging a wide range of technologies, notably gcp, bigquery, google pub or sub, google dataflow, kubernetes, and docker develop cloud data pipelines to transform and process data between systems maintaining, improving existing continuous integration or delivery pipelines qualifications for this job 3 years of development experience building large scale data solutions experience with gcp bigquery, gcp dataflow, gcp pub or sub, apache airflow and python preferred experience with gitops in an infrastructure as code culture. experienced with git and common development workflows in github or gitlab or bitbucket experienced with ci or cd declarative pipelines experience with docker for containerizing applications and workloads experience with terraform for infrastructure provisioning experience with reporting schema designs including data modeling, denormalization, data warehousing, and data lakes experience with data quality monitoring and alerting on dynamic data sources, including anomaly detection experience with metadata management, data governance, data catalogs, and data discovery proven ability to work closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality ability to communicate technical hurdles and challenges clearly and succinctly take problems from inception to completion own the building, automated testing, deployment, and maintenance of the code that you work on who we are leading global provider of cloud based insurance software applied systems develops the top two insurance agency or broker management software products in the world. in addition, we also provide innovative mobile apps, data analytics, customer self service, insurer connectivity rating, eservicing, benefits design, and crm software products. by automating the insurance lifecycle, applied s people and products enable millions of people around the world to safeguard and protect what matters most. cloud solutions professional services we offer cloud solutions, 24x7 technical support, consulting, implementation, and education services. award winning technology we have been voted 2020 company of the year 2020 new product or service of the year 2 awards 2019 best cloud based software solutions provider in the insurance industry 2019 digital service provider of the year 2019 best broker software management house google s investment in applied google or capitalg made a minority investment in applied that will spur ai, machine learning, and digital marketing innovation in the global insurance industry. clients we provide technology to over 160k users within insurance agencies, brokerages, and carriers throughout the us, canada, the uk, and ireland. employees applied currently has 1,800 employees across the us, canada, the uk, and ireland. company culture perks join a great team we believe that success comes from a dynamic working environment that offers professionals an opportunity to grow and succeed alongside extraordinary people. we encourage idea sharing, problem solving, and teamwork in our environment. diversity matters we strive to create a positive workplace culture for those of different thinking, backgrounds, experiences, expertise, and individual qualities across our organization. we want the best and the brightest to be a part of a growing culture that embraces a sense of belonging. relaxed dress code applied allows for a relaxed dress code where jeans are permitted we call this dress for your day . fun parties perks fun perks are a staple at applied, including holiday parties with games and contests, summer celebrations employee appreciation events, art contests, employee discount programs, and more opportunities for advancement we are a growing company that offers career opportunities, and not just another job . applied believes in growing our employees and promoting from within, offering many opportunities for professional advancement along the way career stability longevity our average employee tenure is 9 years. culture of recognition applied provides a culture of employee recognition with our circle of excellence program, and our internal social network recognition program. applied cares we have a culture that embraces and promotes volunteerism. applied encourages our employees to help local charities and communities through the applied cares program benefits rewards benefits from day one applied offers medical, rx, dental, vision, virtual doctors appointments, health savings account, flexible spending accounts, critical illness, group accident, and wellness incentives to ensure employees are covered from day one. financial peace of mind in addition to wellness benefits, applied offers traditional and roth 401k options, with employer match. accidental death dismemberment, short and long term disability, and business travel accident insurance are also offered. worklife balance there is more to life than work that is why applied offers benefits to help balance your work and home life. we offer competitive paid vacation time, personal or sick time, paid holidays, summer hours, paid parental leave, volunteer time off, and a free day off for your birthday to learn more please visit appliedsystems.com applied systems is an equal employment opportunity and affirmative action employer. diversity and inclusion is a business imperative and is a part of building our brand and reputation. at applied, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law. li remote","['metadata management', 'data infrastructure', 'ci', 'bitbucket', 'software solutions', 'github', 'kubernetes', 'terraform', 'python', 'gcp', 'data analytics', 'cd', 'software', 'reporting', 'data science', 'data', 'anomaly detection', 'integration', 'crm', 'pipelines', 'data engineering', 'data warehousing', 'apache airflow', 'gitlab', 'machine learning', 'data pipelines', 'provisioning', 'testing', 'data quality', 'data solutions', 'git', 'modeling', 'ai']","['apache airflow', 'kubernetes', 'gitlab', 'python', 'gcp', 'terraform', 'provisioning', 'git', 'google dataflow', 'dataflow', 'data quality', 'bitbucket', 'data lakes', 'pipelines']","['metadata management', 'data infrastructure', 'ci', 'technical support', 'software solutions', 'github', 'data analytics', 'software management', 'cd', 'software', 'reporting', 'data science', 'data', 'anomaly detection', 'integration', 'gitops', 'esering', 'crm', 'data engineering', 'data warehousing', 'infrastructure as code', 'machine learning', 'data pipelines', 'continuous', 'testing', 'data solutions', 'modeling', 'ai']","['environment', 'art', 'law', 'education', 'incentives', 'governance', 'consulting', 'digital', 'insurance industry', 'professional services', 'business initiatives', 'marketing', 'design', 'adoption', 'dismember', 'insurance', 'architecture', 'events', 'business travel']"
365,463,"Data Engineer, Omnia AI","job type permanent primary location toronto, ontario, canada all available locations vancouver montreal ottawa toronto learn from deep subject matter experts through mentoring and on the job coaching partner with clients to solve their most complex problems be empowered to lead and have impact with clients, our communities and in the office. you love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter if that is you, then omnia ai is where you want to be. what will your typical day look like as a data engineer on our data analytics modernization team within the omnia ai practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. you will play an active role throughout the entire engagement cycle, specializing in technical data solutions including etl, data integration, data warehousing, dimensional models, in memory architectures, master data or reference management, and business analytics. you are enthusiastic about all things data, have strong problem solving and analytical skills, are tech savvy and have a solid understanding of software development. specifically, in this role, you will engineer and architect etl and bi or dw solutions to enable business analytics and drive insights translate business rules and requirements into data objects, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly plan or schedule tasks, lead small development teams, and mentor junior colleagues facilitate technical meetings with client staff, and advise client with technical option analyses based on leading practices about the team omnia ai, deloitte s artificial intelligence practice is comprised of a collaborative team of experts who use their hands on experience with cutting edge information assets to facilitate successful ai transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. our data analytics modernization team helps clients design and implement the data platform architectures be it in the cloud or on premise required to enable cutting edge ai solutions. you will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on big data, bi or dw, data integration, data governance, master data and analytics applications. each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. enough about us, let s talk about you you are someone with 3 years experience with analysis, design, development, testing and deployment of etl services in relational data warehouse environments on db2, oracle, sql server and or or sap or hana using technologies such as informatica powercenter, ibm datastage, microsoft ssis and or or talend for batch and or or real time data processing 3 years implementation experience with data warehouse architectures, data vaults, dimensional models, and or or star schema designs implemented on mpp, in memory or columnar databases, cloud based and or or rdbms platforms experience writing complex sql queries, extracting and importing disparate data from source systems, and data manipulation based on requirements experience with agile development methods in data oriented projects completed bachelor s degree in quantitative areas such as computer science, information management, big data analytics, or related field is desired if you believe you have what it takes to be a successful member of our team, please apply now. we know your career is important to you and it s important to us, too. this role is just the first step of a highly successful career we can help you build. the time is right for you to join deloitte. get your career off to great start. what impact will you make why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally.","['analytical skills', 'databases', 'rdbms', 'big', 'business', 'mpp', 'master', 'data analytics', 'sql', 'data processing', 'talend', 'software development', 'data', 'analytics', 'integration', 'data models', 'data warehousing', 'modernization', 'datastage', 'informatica', 'testing', 'ibm', 'data manipulation', 'artificial intelligence', 'information management', 'bi', 'data solutions', 'microsoft', 'technology solutions', 'computer science', 'ssis', 'etl', 'ai']","['sql', 'databases', 'bi', 'rdbms', 'big', 'talend', 'data manipulation', 'technology solutions', 'big data', 'data models', 'master data', 'ssis']","['analytical skills', 'business', 'mpp', 'data analytics', 'data processing', 'relational data', 'software development', 'data', 'analytics', 'integration', 'data warehousing', 'modernization', 'informatica', 'testing', 'artificial intelligence', 'agile development', 'reference management', 'information management', 'data solutions', 'computer science', 'etl', 'ai']","['subject matter experts', 'business rules', 'design', 'sap', 'governance', 'mentoring']"
366,464,Data Engineer,"open up to the possibilities at purolator, you ll be proud knowing you re working for a canadian company that truly values its employees. and it s community. this is an exciting and evolving industry and we re leading the change as we strive to deliver the future. here you will be empowered to help move the business forward. each and every day. are you open to the possibilities job description successful candidates will demonstrate excellent skill and maturity, be self motivated as well as team oriented, and have the ability to support the development and implementation of solutions to meet the needs of our customers. your strong experience and skills in business intelligence and data architecture will help purolator leverage its data for a variety of analytic use cases to support strategic decision making, in a way that is governed, sustainable, and scalable. you are passionate about data, and not only do you understand the mechanics of how to access, move and manipulate data, you also understand how data can be leveraged to empower reporting and analytics. while you are strong technically, you are also adept at consulting with non technical business users to understand the root of their requirements, to develop bi solutions that truly meet their needs. responsibilities serve as a subject matter expert in data engineering technology and related processes. understand business issues and decompose them into measurable data or data modelling requirements. curate data for governed reporting and self service data discovery and analytics contribute to consultations workshops with various business stakeholders to understand the root business needs for new reporting and analytics use cases build experimental data processes and bi assets for rapid prototyping of reports and dashboards from new data sources help administer the business intelligence platforms to ensure the environment is secure, up to date, and accessible skills a seasoned business intelligence professional with hands on experience developing and administering front end bi tools such as powerbi, qliksense a savvy data architect with strong understanding of datawarehouse principles and methodologies great communication skills, you can effectively convey highly technical concepts to a non technical audience excellent problem solving skills, able to systematically analyze, hypothesize, and solution problems and issues hands on experience with datawarehouse technologies, preferably with cloud based platforms such as aws redshift and azure synapse experience developing and building etl or elt pipelines using gui based tools such as glue, pyspark and ability to code custom data workflows via java and python a strong asset energized by working on a small team with the ability to make an immediate impact on the business experience working in an agile environment qualifications bachelor or master degree in a technology or analytical field such as computer science, management of information systems, mathematics, statistics, machine learning or ai, engineering, or other relevant technical fields. experience in an agile environment excellent programming knowledge in any of the languages . experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. build processes supporting data transformation, data structures, metadata, dependency and workload management. experience with relational sql and nosql databases. posting details location 530 corporate working conditions office environment reports to manager reporting and data delivery purolator is an equal opportunity employer committed to diversity and inclusion. we consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, aboriginal or indigenous status or any other factors considered discriminatory. if you require an accommodation during the recruitment process, we will work with you to meet your needs. we recognize that our employees and their families are key stakeholders. we will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. we hire for attitude and train for skills. to learn more about us and our values, go to at purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.","['go', 'databases', 'pyspark', 'dashboards', 'java', 'glue', 'sql', 'python', 'agile environment', 'statistics', 'reporting', 'analytics', 'data', 'aws', 'programming', 'pipelines', 'data engineering', 'nosql', 'machine learning', 'data transformation', 'metadata', 'business intelligence', 'prototyping', 'data structures', 'bi', 'information systems', 'computer science', 'root cause analysis', 'mathematics', 'etl', 'ai']","['go', 'glue', 'python', 'databases', 'pyspark', 'bi', 'programming', 'aws', 'business intelligence', 'pipelines', 'java', 'nosql']","['dashboards', 'etl', 'agile environment', 'statistics', 'reporting', 'analytics', 'data', 'data engineering', 'machine learning', 'data transformation', 'gui', 'metadata', 'use cases', 'prototyping', 'data structures', 'relational sql', 'information systems', 'computer science', 'mathematics', 'root cause analysis', 'ai']","['environment', 'consultations', 'consulting', 'workshops', 'architecture']"
367,465,Senior Scientist – Assay Development,"deepcell is an early stage stanford spin off company that has developed a unique platform for use in research, diagnostic testing, and therapeutics. we combine microfluidics, imaging, deep learning, and genomics to identify, isolate and analyze live, single cells. our technology addresses diverse applications in the life sciences. come join deepcell and make a difference we re a small team of passionate innovators in biomedical engineering, artificial intelligence, molecular biology, and genomics. our technology has won multiple prestigious awards and is backed by top tier venture capitalists in silicon valley. the senior scientist assay development at deepcell will report to principal scientist and be responsible on developing and optimizing methods and protocols for ngs based molecular assays. responsibilities work closely with cross functional r d team to design and execute experiments for cell isolation and bulk and single cell analysis design and optimize assays for molecular analysis of samples with small quantities of dna and rna. develop and optimize ngs based single cell analysis workflow perform sample prep, instrument operation, assay design, optimization and validation develop new sops to improve consistency and accuracy contribute to product development milestones and company goal planning process key qualifications phd in molecular biology, biochemistry, chemistry or similar fields broad background and knowledge of ngs technologies and data analysis 2 years industrial experience in ngs assay development, preferably on single cells or low input samples demonstrated record in product development and verification or validation excellent experimental design, data analysis and trouble shooting skills. sound scientific judgement. strong written and oral communication skills strong interpersonal skills with the ability to interact with individuals from a variety of levels and functions self organizer, meticulous hands on habits, keen attention to detail ability to understand and execute on the company s mission and values maintain a high degree of ethical standard and trustworthiness ability to think and adapt to a rapidly changing startup environment","['deep learning', 'experimental', 'testing', 'chemistry', 'artificial intelligence', 'optimization', 'data analysis']",['deep'],"['deep learning', 'experimental', 'testing', 'micro', 'chemistry', 'industrial', 'artificial intelligence', 'optimization', 'data analysis', 'planning']","['assay', 'validation', 'biomedical engineering', 'environment', 'biology', 'genomics', 'ass', 'biochemistry', 'design', 'life sciences', 'molecular', 'therapeutics', 'product development', 'rna', 'r']"
368,466,Data Engineer,"data engineering at eq means you re working in the hottest areas of today s technology landscape machine learning, big data, and geolocation data sets. you will be coming up with solutions to derive actionable insights about behavior, demographics, and personality out of our multi terabyte dataset of location data. examples of the type of analysis we do include understanding what university students do during the summer holidays. predicting if someone is about to buy a house based on their visiting locations understanding someone at the airport is a business or leisure traveler. and more. your role will involve working very closely with our cto, data scientists, and the extended product team. with eq leading the pack for location ad analytics in canada and a top north american player this role would let you define and shape the standards in this very vibrant and evolving industry. understand our current data sets and models and help us discover new ways to enrich the data creatively extracting real world behavior and trends out of the location data monitor and build processes for cleaning up inbound data dream up a solution, perform the r d, and deploy to production within our fluid work environment requirements ability to work with large amounts of data experience with map reduce frameworks hive, hadoop, and spark firm grasp of statistics, data modeling, and designing algorithms benefits cloud service credits public transit allowance mobile data allowance home internet allowance flex days","['algorithms', 'machine learning', 'statistics', 'hadoop', 'data', 'analytics', 'big data', 'modeling', 'data engineering', 'hive', 'map']","['hive', 'hadoop', 'big data', 'map']","['machine learning', 'statistics', 'data', 'analytics', 'modeling', 'data engineering', 'algorithms']",['environment']
369,467,"Data Analyst, Marketing Acquisition","freshbooks has an ambitious vision. we launched in 2003 but we re just getting started and there s a lot left to do. we re a high performing team working towards a common goal building an elite online accounting application to help small businesses better handle their finances. known for extraordinary product and customer service experiences and based in toronto, canada, freshbooks serves paying customers in over 120 countries. the opportunity data analyst, marketing acquisition the analyst will enable freshbooks reporting and help to derive insights from website, event, campaign and customer web and product interaction data to improve the volume and quality of acquired trailers, determine growth opportunities, understand the customer journey and major drop offs. the right person for the job will love to solve a problem and have a knack for translating data into insight and presenting that information to stakeholders. you will be collaborating with managers and a team that includes other analysts, data scientists, marketers, financial analysts, and developers all working together to drive growth at freshbooks. what you ll do complete regular ad hoc or deep dive analyses by translating raw data into useable information and insights build dashboards for core performance metrics or monitor kpi s channel level reporting on trends in acquisition performance support with a or b testing for campaign treatments content or webpage reviews and analyses work independently with engineering to ensure the integrity of data flows or transfers monitor changes in usage behaviours performance evaluations of various customer segments assist with gtm tagging, maintenance and general organization consult with internal clients to gather requirements, scope execute complex, long term analyses on visitor trends and performance impacts communicate results and recommended analyses or approaches to stakeholders what you bring intermediate to advanced knowledge of sql is required minimum 2 3 years in data analytics or business intelligence knowledge of google analytics data, and or or similar web analytics tools strong knowledge of one or more visualization tools such as looker, tableau etc. quantitative background with strong analytical skills experience working with relational databases familiarity with the marketing campaign and or or web data is preferred python knowledge is an asset google tag manager experience is an asset why join us we re a motivated bunch, with our eyes laser focused on shipping extraordinary experiences to businesses. you will be surrounded by hardworking team members who share a common vision for what an amazing software company could be, and have the opportunity to help build an elite one, right here in downtown toronto. apply now have we got your attention submit your application today and a member of our recruitment team will be in touch with you shortly freshbooks is an equal opportunity employer. we do not discriminate based on gender, religion, race, mental disability, sexual orientation, age, or any other status. all applicants are considered based on their qualifications and merits. at freshbooks, we inspire an environment of mutual respect and we believe diversity and inclusion are crucial to our success. freshbooks provides employment accommodation during the recruitment process. should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. for any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416 780 2700 and or or","['data analytics', 'sql', 'visualization', 'looker', 'analytical skills', 'tableau', 'google analytics', 'relational databases', 'python', 'reporting', 'testing', 'software', 'dashboards', 'web', 'analytics', 'business intelligence']","['sql', 'looker', 'python', 'tableau', 'business intelligence', 'google analytics data']","['data analytics', 'analytical skills', 'visualization', 'relational databases', 'software', 'reporting', 'testing', 'dashboards', 'web', 'analytics']","['environment', 'accounting', 'metrics', 'marketing', 'performance', 'customer service', 'laser']"
370,468,Machine Learning Scientist (Can be Remote Within Canada),"at bluwave ai our mission is to deliver innovative ai solutions to accelerate the transformation towards renewable energy. we apply ai software to increase the use of clean energy in smart grids and microgrids with distributed energy resources and demand response. we are also driving the transition to electrification of transportation as the grid becomes the local gas station. we are looking for talented people with entrepreneurial drive to seize on the ground floor opportunities, grow their careers, and make a positive impact for the environment. 1. who you are a machine learning engineer, with professional experience or equivalent applied research, strongly motivated by building impactful and dependable products based on pragmatic and rigorous application of ml techniques. you have the drive to learn, evaluate, and apply a range of data science and ml techniques. the applications are real time smart grid control and optimization solutions in the context of best scalability, availability, and security principles. you are a pragmatic innovator who thrives in a fast paced, disciplined, and team oriented environment where we strive individually while supporting, learning from, and building on each other s ideas and efforts to succeed as a team. you have strong verbal and written communication skills with the ability to distill complex technical concepts to the level that non specialists can comprehend. you are effective at teamwork, and you enjoy mentoring. 2. what you are responsible for analysis, design, and implementation of ml solutions to prediction and optimization tasks. develop statistical and machine learning solutions for analysis, data mining, and modeling of iot data. develop resilient testing strategies to monitor model performance. prepare documents and presentations to inform and demonstrate. 3. your knowledge, experience, and skills required experience as a ml scientist within a commercial environment, or equivalent academic research experience with pragmatic experimentation or industry collaborative projects. experience with cleaning, reshaping, exploring, and visualizing data in various formats. strong programming knowledge and skills in python. familiarity with machine learning tools and platforms such as tensorflow, keras, etc. considered an asset experience in developing ml techniques for time series prediction e.g. regression, support vector machines, and neural networks. familiarity with control and optimization of modern power and energy systems. educational requirements msc or phd in mathematics, statistics, computer science, or related data intensive fields. exceptional candidates with a bachelor s degree with strong relevant solution delivery experience are encouraged to apply. 4. what you will gain motivation to serve to the greater cause of climate change mitigation. knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains on the intersection of electrical engineering, machine learning, optimization, and software development. startup experience and ground floor opportunities for growth in an inter disciplinary team that includes phd smart grid and machine learning scientists, recent grads, and seasoned business professionals. competitive compensation. high quality of life and career in canada s national capital region or remote work. working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events. 5. general information level all experience ranges are encouraged to apply position type full time location ottawa, on department applied science position reports to vice president of technology diversity makes us stronger. bluwave ai provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, gender, national origin, disability, or any other characteristic protected by applicable laws, regulations, or ordinances. authorization to work in canada is required for this position.","['prediction', 'tensorflow', 'python', 'statistics', 'keras', 'software', 'data science', 'software development', 'programming', 'data mining', 'electrical engineering', 'machine learning', 'iot', 'testing', 'authorization', 'neural networks', 'security', 'scalability', 'computer science', 'networking', 'mathematics', 'optimization', 'modeling', 'ai']","['python', 'keras', 'authorization', 'iot', 'programming']","['prediction', 'neural', 'tensorflow', 'software development grid', 'statistics', 'data science', 'software grids', 'data mining', 'electrical engineering', 'machine learning', 'testing', 'time series', 'security', 'scalability', 'computer science', 'networking', 'mathematics', 'optimization', 'solution', 'modeling', 'ai']","['gas', 'environment', 'events', 'regulations', 'electrification', 'design', 'presentations', 'academic research', 'energy systems', 'climate change', 'demand response', 'renewable energy', 'compensation', 'mentoring']"
371,469,Intermediate Data Engineer,"bluedot continues to grow, and as a result we are looking for an intermediate data engineer to join our data systems team as an intermediate data engineer, you will create, expand, and optimize data pipelines to build upon our data platform. you thrive on writing complex queries, working with big data, and enjoy automating data pipelines and workflows. with us, you will solve problems with data integration and be working with data that has an impact on global connectivity as well as local areas of analysis. you will be working with both structured and unstructured datasets that are both spatial and non spatial in nature. who we are bluedot protects people around the world from infectious diseases using human and artificial intelligence. our software as a service solution combines medical and public health expertise with advanced data analytics to track, contextualize, and mitigate infectious disease risks. our global early warning system combines more than 100 datasets with proprietary algorithms to deliver critical insights on the spread of infectious diseases. in december 2019, we flagged an undiagnosed respiratory syndrome in wuhan, china. in january 2020, we published the world s first scientific paper on covid 19, accurately predicting its global spread. our team understands the complexity of the challenge in front of us and that the urgency to solve the problem has never been greater. our culture we are a certified b corp, have a glassdoor rating of 4.7, are diversio certified, a 2020 linkedin top start up and have been recognized as a top 50 best place to work in canada, best place to work for women, best in technology, best for youth, and best start up driven by a purpose bigger than ourselves united in a common purpose to create a healthier, safer, and more secure world, free from the impacts of dangerous infectious diseases, we understand the complexity of the challenge in front of us, and that it is so much bigger than any one of us. together, we are motivated to positively impact lives around the world, to do no harm, and to elevate each other through respect and encouragement. building careers through collaborative discovery and learning, our people tackle complex challenges with diverse expertise not assembled elsewhere. we promote personal fulfillment in the workplace by removing barriers, politics and exclusion, believing in the philosophy that by creating a positive environment we all have the opportunity do the most meaningful work of our lives. our values our values are not just words on a wall. they are our compass and they guide us in our work, in the decisions we make and in how we treat each other be the change making a meaningful difference through our work for each other, for our customers, and for the world. taking initiative, ownership, and action. think without borders freeing our minds from conventional thinking, discovering without fear of failure, and learning from our customers we make impossible challenges possible. lift others up creating space for all those inspired by our purpose, elevating each other and fostering mutual growth. our unique perspectives valued, respected and included. what you will do in more detail create and maintain optimal data pipeline architecture build and manage microservices on aws design, develop, maintain cross platform etl processes use python to automate data processes and analyses to maximize efficiency help design, develop, test, document, and data pipeline related applications, programs and systems perform spatial analyses and create information products utilizing gis and related software help design and implement data quality control procedures and policies build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources oversee and execute data migration from existing data stores assist with operationalizing data science models what you have done to get here degree in computer science, engineering, related quantitative fields, or equivalent experience knowledge and experience with python knowledge and experience with sql experience with enterprise databases experience with source code control frameworks . knowledge and experience with etl software such as fme desktop and fme server knowledge and experience using nosql databases such as mongodb or dynamodb experience with gis products nice to have collaborative attitude, with ability to excel in a team environment ability to quickly learn new tasks and systems, flexible in skills and attitude commitment to internal or external customer satisfaction through delivered excellence excellent written and verbal communication and interpersonal skills goal orientation with a drive to exceed expectations superior attention to detail and ability to produce professional deliverables documentation on time. ability to manage personal time and priorities effectively ideally, you also have a basic understanding of modern techniques and tools for data science, modeling and analytics an understanding of api architecture and integration experience with infrastructure as code experience in the health sector what we offer our team meaningful work that truly has purpose as a smaller, agile team, we offer roles with impact your contributions are integral, your voice will be heard a competitive comprehensive compensation package outstanding health, vision and dental benefits employee and family assistance plan a health and wellness spending account generous vacation and other pto a home office setup allowance we are working fully remotely due to covid 19 until at least january 2022 post pandemic we will continue with our remote first culture with the opportunity for a hybrid or flexible office space in downtown toronto accessible to our team but without the requirement to work from the office. together let s create a healthier, safer, and more prosperous world. for more information, visit us at http or or bluedot.global. bluedot recognizes that challenges remain in achieving the full participation of equity seeking groups in tech careers and is committed to identifying and eliminating barriers that may exist within its own hiring process, programs, and practices. bluedot is committed to fair and accessible employment practices. if you are contacted for a job opportunity, please let us know how we can best meet your needs and advise us of any accommodations required to ensure fair and equitable access throughout the recruitment and selection process. we thank and appreciate all applicants for their interest. only those selected for an interview will be contacted. please no agency calls.","['databases', 'gis', 'big', 'documentation', 'mongodb', 'fme', 'data analytics', 'python', 'sql', 'enterprise databases', 'software', 'software as a service', 'data science', 'data', 'analytics', 'integration', 'aws', 'data systems', 'microservices', 'nosql', 'data pipelines', 'data migration', 'artificial intelligence', 'information', 'algorithms', 'datasets', 'api', 'computer science', 'modeling', 'etl']","['fme', 'bluedot', 'python', 'sql', 'databases', 'api', 'documentation', 'big data', 'aws', 'data quality', 'nosql']","['gis', 'mongodb', 'data analytics', 'software', 'software as a service', 'data science', 'enterprise', 'data', 'analytics', 'integration', 'data systems', 'microservices', 'infrastructure as code', 'unstructured', 'data pipelines', 'data migration', 'artificial intelligence', 'information', 'algorithms', 'http', 'datasets', 'computer science', 'modeling', 'etl']","['environment', 'public health', 'design', 'customer satisfaction', 'linkedin', 'compensation', 'hiring', 'politics', 'architecture']"
372,470,Data Engineer - 96042,"what you do at amd changes everything at amd, we push the boundaries of what is possible. we believe in changing the world for the better by driving innovation in high performance computing, graphics, and visualization technologies building blocks for gaming, immersive platforms, and the data center. developing great technology takes more than talent it takes amazing people who understand collaboration, respect, and who will go the extra mile to achieve unthinkable results. it takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. if you have this type of passion, we invite you to take a look at the opportunities available to come join our team. the world s most successful companies heavily leverage data to design products and services that delight their customers. at amd, we have a culture of being customer centric, and deliver high performance devices that are a joy to use. in this data engineer position, you will be part of a select team that works on the cloud based big data analytic process and tools that will help build the analytic and data processing pipeline and to contribute to the analytic thought process that impacts amd company wide. you will be working on one of the fastest growing areas, with updated skill sets and hands on access to big data. preferred experience proficiency in one or more of the following python, r, sql, java, scala good understanding of quantitative analysis and statistical reasoning ability to learn new big data and analytic tools and technologies full stack web development, particular data dashboards machine learning and model creation and predictions examples of projects connecting data analysis with engineering or business improvements having worked on cloud based technologies academic credentials minimum of b.sc. in electrical or computer engineering or computer science location canada, ontario, markham li cc2 requisition number 96042 country canada province ontario city markham job function design amd is an inclusive employer dedicated to building a diverse workforce. we encourage applications from all qualified candidates and will accommodate applicants needs under the respective provincial human rights codes throughout all stages of the recruitment and selection process. any applicant who requires accommodation should contact amd does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services.","['go', 'computing', 'python', 'visualization', 'sql', 'data processing', 'machine learning', 'scala', 'computer engineering', 'dashboards', 'web development', 'data analysis', 'computer science', 'big data', 'graphics', 'r', 'java', 'gaming']","['go', 'sql', 'python', 'scala', 'big data', 'java', 'r']","['computing', 'visualization', 'machine learning', 'data processing', 'quantitative analysis', 'computer engineering', 'dashboards', 'web development', 'data analysis', 'computer science', 'graphics', 'gaming']","['design', 'electrical']"
373,471,"Mentor (Development, Data Science, or Cyber Security)","since 2013, lighthouse labs has been helping curious and creative people break into the tech industry with our accelerated, personalized, and outcomes obsessed education. our mission is to train the next generation of tech talent in coding, cyber security, and data science by looking at the unique needs of each student and helping them map out and achieve their career goals. a major part of this approach is our robust mentorship program, where students are guided through their learning journey by professionals who work in the industry themselves. to keep serving the ever expanding needs of our students and communities, we re growing our team of amazing mentors that are so key to student success. we re looking for intermediate to senior level full stack developers, cyber security professionals, and data scientists to join our team. are you passionate about mentoring, are creative and critical, and excited about problem solving we d love to hear from you mentoring with lighthouse labs as a mentor, your mission is to support our students through their academic journey, and prepare them for their transition into an exciting new career in tech. you ll work directly with students to coach them through any roadblocks they might be experiencing, give them tips on solving problems, and generally provide them with support and advice. based on your personal experiences, field of knowledge, and availability, you can be matched to mentor in any of the following groups web development bootcamp cohorts introductory program cohorts junior developers junior data scientists cyber security we re flexible in how we work with mentors, and your schedule is structured according to how many hours you re available for. mentors are paid an hourly rate, and are able to work from any time zone. what we need from you mentors aren t required to have formal training in their area of expertise. however, a true passion and curiosity for coding, cyber, or data, as well as learning and education in general, is a must. the following qualifications are all important assets for aspiring mentors minimum 2 years of professional experience in software development, cyber security, or data science. experience in a range of popular technologies in web development, cyber security and or or data science. html, css, javascript, ruby or rails, python, java, scala, golang, elixir, java, scala,jquery, rails, react, nodejs , django, , meteorjs, elixir phoenix, scala, angularjs, ember, r, jupyter notebooks, tableau, excel, aws, mysql, jira, flutter, firebase, typescript, apollo, graphql, postgresql, mongodb a strong understanding of open source development workflows using tools such as github any experience in teaching, mentoring, or tutoring is an asset. lighthouse labs is an equal opportunity employer. we celebrate diversity and are committed to creating an inclusive environment for all employees. all positions at this time are remote, and we welcome all applicants.","['css', 'tableau', 'angularjs', 'mongodb', 'javascript', 'java', 'mysql', 'map', 'github', 'ruby', 'python', 'elixir', 'flutter', 'scala', 'postgresql', 'data science', 'software development', 'graphql', 'aws', 'firebase', 'jupyter', 'typescript', 'apollo', 'ember', 'html', 'jira', 'security', 'web development', 'django', 'jquery', 'r']","['css', 'tableau', 'angularjs', 'javascript', 'mysql', 'java', 'map', 'ruby', 'python', 'elixir', 'flutter', 'scala', 'postgresql', 'aws', 'firebase', 'jupyter', 'typescript', 'ember', 'jira', 'django', 'jquery', 'r']","['html', 'security', 'web development', 'data science', 'software development', 'graphql', 'mongodb', 'github']","['environment', 'education', 'mentoring']"
374,472,AI-Driven Drug Discovery Scientist (Psychedelics),"about magicmed industries magicmed is a biotechnology company focused on the discovery and commercial development of novel pharmaceuticals based on known psychedelic compounds. magicmed s expanding collection of psychedelic derivatives is expected to yield the next generation of precision medicines for brain and mental health. about the opportunity there is a revolution happening in mental health treating addictions and alleviating pain. would you like to join an innovative and growing company whose goal is to make a positive impact on human health are you interested in participating in artificial intelligence and machine learning applications for cutting edge r d magicmed is seeking a full time scientist to apply machine learning techniques to the problems of drug screening and discovery. you ll be working with our research development team as they evaluate new compounds, and with our technical partners who will provide direction on the ai elements of the screening pipeline. this is an opportunity to be involved in every aspect of our computational pipeline, to contribute your ideas, and have an impact in the development of novel psychedelic compounds. ideally this position will be based at our office in calgary, alberta however, alternative options may be considered for the right candidate. about the candidate our ideal candidate is enthusiastic and has experience in the application of state of the art cheminformatics and ai tools to drug discovery projects. the candidate can work independently and is comfortable writing software, using libraries, and scripting data flows. key responsibilities filter chemical databases by using virtual screening approaches apply existing models and techniques to assess drug candidates collaborate effectively with the experimentalist team to improve biological properties of drug candidates based on feedback from assay results investigate, adapt, and train new models to improve the pipeline provide regular reports and progress updates as required education bsc in relevant field master degree or phd preferred experience experience with computational chemistry tool sets such as schr dinger, acd or labs, moe, or similar. previous experience with artificial intelligence and machine learning or deep learning frameworks core competencies an understanding of the fundamentals of drug discovery, from docking to admet. strong analytical, trouble shooting and problem solving skills, with the ability to exercise independent judgment able to work collaboratively in cross functional multidisciplinary teams excellent verbal and written communication skills strong organization, prioritization and time management skills, with high attention to detail motivated and self directed with a demonstrated ability to work with minimum supervision in a fast paced, dynamic environment proficient in the use of the microsoft office suite the successful candidate will have a strong interest and willingness to learn about psychedelics and the application of ai to drug discovery. to apply magicmed offers a competitive compensation and benefits package, a dynamic work environment and a great team please visit our web site at for more information about our company. to apply for this position, please send your resume and cover letter . magicmed is equal opportunity employer, committed to an inclusive, diverse and accessible workplace. accommodations are available on request for candidates taking part in all aspects of the selection process. to request accommodation, please contact human resources. we thank all applicants for their interest in magicmed industries however, only candidates selected for interviews will be contacted. expected start date 2021 06 28 job types full time, permanent schedule monday to friday covid 19 considerations covid 19 safety precautions and temporary remote work. work remotely temporarily due to covid 19","['deep learning', 'machine learning', 'databases', 'software', 'scripting', 'chemistry', 'screening', 'artificial intelligence', 'ai']","['databases', 'r']","['deep learning', 'machine learning', 'software', 'computational', 'scripting', 'chemistry', 'screening', 'artificial intelligence', 'ai']","['environment', 'compensation', 'education', 'biotechnology', 'human resources', 'derivatives', 'art', 'microsoft office', 'research development', 'drug discovery', 'mental health', 'pharmaceuticals']"
375,473,Data Engineer (Data Factory Experience),"1 year contract french strongly preferred but will consider english only profiles need a data engineer with data factory experience remote across canada context and mandate the client intends in the coming years through its bi modernisation program to migrate various business units from existing bi environments to its next generation enterprise data platform in the cloud. in that context, the client is looking for a knowledgeable, experienced, and motivated data integration developer. you will play a pivotal role in operationalizing the most urgent data and analytics initiatives for the client s bi, data and analytics strategy. the bulk of the work would be in the building, managing, and optimizing data pipelines and then moving these data pipelines effectively into production for key bi, data, and analytics consumers. you will need to guarantee compliance with data governance and data management requirements while creating, improving, and operationalizing these integrated and reusable data pipelines. this would enable faster data access, integrated data reuse, and vastly improved time to solution for the client s bi, data, and analytics initiatives. duration june 15th until march 31st, 2022 possibility de renew yes possibility de convert to a permanent position to be determined responsibilities or accountabilities build data pipelines and etls. provide data structure definition, validation, ingestion, processing, and visualization. collaborate with business units, architects, data modelers, data scientists, and project or product team. work with the information security team to define and implement data access. drive automation through effective data management lifecycle from governance to quality to cataloging to lineage, to ensure data compliance. requirements professional experience 3 years of experience in data integration with the required technology. experience in data profiling and data quality analysis. experience in identifying, analyzing, and interpreting trends or patterns in data sets. experience with ms data integration stack, e.g. azure data factory, ssis, etc. experience with sql for rdbmss such as azure sql, ms sql server, and mysql. experience working with powerbi for semantic layer based data discovery. strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management. knowledge of azure migration stack, e.g. azure migrate, azure database migration service, etc. experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional data integration technologies such as etl or elt, data replication or cdc, message oriented data movement, event processing, api design, and access. experience in agile methodologies and capable of applying dataops principles to data pipeline build engineering to improve integration, reuse, and automation of data. educational experience university degree or higher in computer science, business administration, business intelligence, statistics, mathematics, or equivalent. soft skills ability to linearize and bridge business needs into technical requirements. strong communication, documentation, storytelling, creativity, and presentation skills. strong interpersonal, teamwork, coordination, and consensus building skills. strong organizational skills, ability to perform under pressure, and manage multiple priorities with competing demands. language good verbal and written communication skills in french and english. other the mandate will be carried out remotely until the return to the offices once back at the office, the position will be carried out according to a hybrid model to be confirmed. contract length 12 months part time hours 40 per week job types full time, part time, contract pay 65.00 85.00 per hour language french work remotely yes","['visualization', 'schemas', 'data profiling', 'technical requirements', 'documentation', 'database migration', 'mysql', 'sql', 'statistics', 'enterprise', 'data', 'analytics', 'integration', 'data models', 'data pipelines', 'data transformation', 'replication', 'event processing', 'metadata', 'business intelligence', 'information', 'data quality', 'automation', 'agile methodologies', 'azure', 'data structures', 'bi', 'datasets', 'security', 'api', 'computer science', 'mathematics', 'azure sql', 'data management', 'ssis', 'etl']","['sql', 'bi', 'replication', 'api', 'data', 'azure data factory', 'mysql', 'business intelligence', 'data models', 'documentation', 'azure sql', 'ssis']","['visualization', 'schemas', 'data profiling', 'technical requirements', 'statistics', 'analytics', 'data', 'integration', 'data pipelines', 'data transformation', 'event processing', 'information', 'automation', 'etls', 'enterprise data', 'agile methodologies', 'data structures', 'metadataload migration', 'datasets', 'security', 'computer science', 'mathematics', 'data management', 'etl']","['validation', 'design', 'governance', 'business administration', 'business units']"
376,474,"Certified Azure Data Engineer (DP-200 & Dp-201, DP-203) 12+ yrs Exp","azure data engineer location brampton, on salary 95k full time on contract rate cad 65 or hr on inc client tech m need azure data engineer with primary skills in depth project experience in hadoop and azure cloud technologies experience in ingestion of batch and streaming data with complex transformations using apache kafka, apache spark, scala, hive sql, shell script. work directly with business users and convert use cases into solutions independently. experience in working with very large volume of log data and building analytical insights based on user requirements experience in handling semi structured data in various data formats and manipulate data in complex data types. secondary skills knowledge on devops tools and experience in building ci or cd pipelines on azure. write programs to pull data from external applications and services using rest api with different authentication methods. knowledge on nosql database types like document and graph db is a plus. knowledge on machine learning libraries for data science and analytics is a plus. has worked in agile methodologies certification azure data engineer regards, sayyad ashraf parvez email ashrafatcompestsolutions.com d 647 660 7562 ext 412 web site job types full time, temporary, permanent salary 79,138.00 95,000.00 per year additional pay bonus pay benefits dental care extended health care life insurance vision care work from home schedule 8 hour shift work remotely yes","['ci', 'authentication', 'hive', 'sql', 'shell', 'cd', 'scala', 'data science', 'analytics', 'pipelines', 'nosql', 'machine learning', 'apache spark', 'rest', 'user requirements', 'apache kafka', 'agile methodologies', 'devops', 'hadoop', 'api']","['sql', 'nosql', 'scala', 'apache spark', 'hadoop', 'shell script', 'api', 'pipelines', 'hive', 'apache kafka']","['agile methodologies', 'use cases', 'machine learning', 'cd', 'devops', 'ci', 'authentication', 'data science', 'analytics', 'rest', 'user requirements']","['hr', 'insurance']"
377,475,"Data Engineer, Data Lake","job category software opportunity awaits at altus group the next stage in proptech solutions unlocking the value of data and predictive analytics altus group is embarking on the next evolution of data, software and technology leading cloud products and services. as pioneers in the proptech and real estate analytics spaces, we are growing our offerings to enable our global clients to unlock the value of data and leverage predictive analytics for better decision making. this journey represents an expansion of our data and analytical solutions to other altus business units, including argus software, the industry standard for valuation and asset management software. we re adding world class talent to our technical team people who are interested in building the data infrastructure that will support the wide variety of global opportunities aligned to our client s needs. as we take our new and existing cloud products to the next level, this initiative is one that our leadership believes is critical to accelerating the continued and future success of altus group and our clients. the opportunity building on established market leading software and incorporating new technologies, we are creating an unrivalled platform to serve the real estate investment industry. as part of the new team spearheaded by the director, application service delivery, data solutions, we are adding two data engineers in toronto. you will collaborate with internal teams on both technical aspects of data migration and storage as well as in a consultative manner to understand unique data parameters, contributing to the design and build of a data lake. you will aggregate, organize and ingest data from various sources to ensure that the data can be accessed efficiently by our internal and external users and applications. who you are you are a data engineer with a few years of experience storing, pipelining, and transforming data using a range of technologies. you want to balance your technical deliverables with internal client interaction to gain an in depth understanding of how our platform will work and how we can meet the data needs and drive key decisions for everyone. you want to be part of building something new with great visibility across the organisation and endless possibilities ahead as we continue to grow and scale. you want to play a critical role in seeing our collaborative vision implemented. what s in it for you unparalleled exposure and impact. you will work alongside development, architecture, and product teams who are at the top of their game, solving problems that have never been looked at before. as part of a platform team specifically assembled to collaborate on new work, you will have the freedom to create from the ground up, and work unrestricted by existing tools or legacy technology. this is an opportunity to make your mark and truly accomplish something exciting as we focus on defining and driving our data and saas strategy. the latest technology, in leading edge ways. data is at the heart of everything we do. we are actively pursuing the latest iterations of modern technologies. our stack encompasses docker, microservices, snowflake, glue, spark, python, tableau, javascript, angular, node or js, rest apis, swagger wso2, and the aws ecosystem. you will be part of the team working with and continuously evolving this tech stack and our approach to data. growth and career development. altus fosters a culture of professional development and promotion from within. with retention rates double the tech industry average, and dozens of promotions within and across teams, this is a place to truly expand your skills and grow your exposure. the data solutions team offers individuals the chance to lead the scrums on a rotating basis and push the limits of what they do with dedicated time to further their individual areas of technical interest. as we move from building to scaling from platform to product and from storage to application, the opportunities to grow your skills, gain exposure, try new things, and make an impact will grow too. our new data engineer, data lake will learn. working in close collaboration with the senior data engineer, you will be given the support you need and the information you require to come up to speed and make a valuable contribution to the team. elicit, understand, and translate. you will work across business lines and newly acquired businesses to understand individualized technical and practical data storage. design. you will create and support an etl solution using aws glue to extract and import data into the new data lake. you will determine how to connect to the various data sources, bring data into our new data lake, and the appropriate method of storing the data. analyse. you will create data pipelines, reports, visualisations and extracts to support product and research needs. you will work with stakeholders to assist with data related technical issues and support their data infrastructure needs. advise. you will research data governance and security to ensure our data storage methodology adheres to any constraints and follows best practices. try new things. you will take the initiative to research, test, and solve complex data engineering problems and big data storage. our new data engineer, data lake will have an eagerness and ability to learn quickly. you have a devotion to evaluating and appropriately applying emerging and alternative technologies, languages, frameworks, and platforms. a commitment to collaboration. you thrive working across inter disciplinary groups, including architects, developers, product, and management, to build great products. you have a way of speaking, writing, and relaying information that engages people and expresses appreciation for diverse opinions and approaches. hands on experience. you have worked with a broad range of data management, analysis, and visualisation tools, including etl or data format conversion, sql, and nosql or non traditional database technologies, including newer tools such as glue and snowflake. you have worked with aws or cloud computing infrastructure. come realize your potential at altus group altus group is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. we are committed to providing reasonable accommodations, if required, and will work with you to meet your needs. if you are a person with a disability and require assistance during the application process, please contact us at or 416 641 9500.","['tableau', 'big', 'data infrastructure', 'javascript', 'glue', 'sql', 'python', 'software', 'analytics', 'saas', 'aws', 'data', 'valuation', 'microservices', 'data engineering', 'cloud computing', 'nosql', 'data pipelines', 'data migration', 'rest', 'data solutions', 'security', 'angular', 'data management', 'snowflake', 'etl']","['glue', 'sql', 'python', 'tableau', 'big', 'angular', 'aws', 'predictive', 'javascript', 'snowflake', 'nosql', 'proptech']","['data pipelines', 'software', 'data engineering', 'data infrastructure', 'data solutions', 'security', 'data migration', 'data storage', 'analytics', 'saas', 'data', 'data management', 'methodology', 'valuation', 'microservices', 'cloud computing', 'rest', 'etl']","['environment', 'asset management', 'design', 'service delivery', 'real estate', 'governance', 'business', 'business units', 'architecture']"
378,476,Data Engineer - Mississauga,"our client, located in mississauga ontario is looking for data engineers to join them on a permanent basis. join a creative organization with design, implementation, maintenance of data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services. advantages we are looking for a problem solver, someone that works collaboratively and is passionate as well as a self starter. responsibilities you will be responsible for all design, implementation, system performance. automation of manual processes and process improvements. qualifications a degree in computer science or engineering or related field 2 4 years of experience in a software engineering environment experience with sql and nosql systems knowledge of hadoop, spark, kafka or other equivalent technologies proficiency in some of the following languages scala, java, python, bash experience with automated testing systems mentorship, collaboration, and communication skills knowledge of data modelling, data warehousing, etl processes, and business intelligence reporting tools experience working with ci or cd, containerization, and virtualization tools such as gitlab, jenkins, kubernetes, docker experience with tools like databricks, snowflake or powerbi summary if you have the skills above, please apply today as we certainly would like to speak with you","['bash', 'system performance', 'jenkins', 'data services', 'ci', 'containerization', 'java', 'kubernetes', 'sql', 'python', 'cd', 'software', 'scala', 'reporting', 'data warehousing', 'solver', 'nosql', 'gitlab', 'data pipelines', 'testing', 'business intelligence', 'automation', 'hadoop', 'computer science', 'virtualization', 'snowflake', 'etl']","['kubernetes', 'sql', 'python', 'gitlab', 'scala', 'jenkins', 'hadoop', 'snowflake', 'java', 'business intelligence', 'containerization', 'solver', 'nosql', 'system performance']","['bash', 'data pipelines', 'cd', 'software', 'reporting', 'data services', 'testing systems', 'ci', 'computer science', 'virtualization', 'data warehousing', 'automation', 'etl']","['environment', 'design']"
379,477,Data Engineer Senior Consultant (Azure) / Ingénieur(e) de données (Azure),"english will follow slalom est une soci t de conseil moderne ax e sur la transformation de la strat gie, de la technologie et des activit s. dans 40 march s aux tats unis, au royaume uni, au japon, en australie et au canada, nos quipes ont l autonomie n cessaire pour agir rapidement et faire ce qui est juste, toujours. ils sont soutenus par des centres d innovation r gionaux, une culture globale d innovation et des partenariats avec les plus grands fournisseurs de technologie au monde. chez slalom, la connexion personnelle rencontre l chelle mondiale. nous tablissons des relations troites avec les clients au sein de nos march s et l chelle mondiale, en faisant circuler nos connaissances dans tous les march s afin que chaque engagement puisse b n ficier de toute l tendue de l expertise de slalom. nos sept centres r gionaux build agissent comme points centraux de l innovation pour attirer des talents de haut niveau qui collaboreront rapidement la cr ation des produits technologiques de demain. nous entretenons galement de solides partenariats avec plus de 200 fournisseurs technologiques de premier plan, notamment amazon web services, google cloud, microsoft et salesforce. avec notre mentalit ax e sur les objectifs, nous travaillons en collaboration avec des entreprises pour repousser ensemble les limites de ce qui est possible. chez slalom, chaque jour, nous sommes motiv s par les valeurs fondamentales et la vision de notre entreprise. nos valeurs fondamentales sont au c ur de toutes nos activit s et orientent notre fa on de travailler avec nos clients, nos quipes et nos communaut s. chacune de nos valeurs fondamentales nous rappelle de rester fid les nous m mes tout en produisant des r sultats incroyables pour nos clients. notre principe directeur est aimez votre avenir , ce qui inspire notre culture, notre travail et nos relations. et, plus important encore, c est ce qui nous permet d avoir le plus grand impact possible fond e en 2001, slalom a tabli son si ge social seattle et, selon un mode de d veloppement par croissance interne, compte maintenant plus de 9 000 employ s. nous figurons sur la liste des 100 meilleurs employeurs de 2021 tablie par le magazine fortune pour la sixi me ann e cons cutive, et nous sommes r guli rement reconnus par nos employ s comme offrant l un des meilleurs environnements de travail. en savoir plus https or or or fr ca or lp 1. au canada depuis 2015, slalom compte maintenant plus de 600 employ s r partis dans trois march s vancouver, toronto et montr al. titre du poste ing nieur de donn es l quipe slalom de montr al recherche un ing nieur de donn es pour notre pratique d analytiques des donn es. titre d ing nieur infonuagique de donn es de notre quipe, vous analyserez, concevrez et architecturez des solutions infonuagiques pour r pondre aux besoins de nos clients en mati re d infrastructure sous forme de service, de plateforme sous forme de service et de logiciel sous forme de service. ce poste vous fera utiliser des outils d architecture modernes, y compris l infonuagique , hadoop, spark, kafka et d autres technologies li es aux m gadonn es. en plus de b tir la prochaine g n ration de plateformes de donn es, vous travaillerez avec certaines des organisations les plus innovatrices en analytiques des donn es. nous sommes la recherche de personnes vives d esprit, disciplin es et motiv es, qui sont passionn es par l emploi de solutions infonuagiques pour r soudre des probl mes d entreprise r els. alors, quel sera mon travail travailler au sein d une quipe sur la conception et le d veloppement de solutions infonuagiques de donn es tablir les exigences techniques, valuer les capacit s des clients et analyser les r sultats afin de fournir des recommandations appropri es en mati re de solutions infonuagiques et de strat gies d adoption d finir les strat gies infonuagiques de donn es, y compris la conception de feuilles de route de mise en uvre plusieurs phases diriger l analyse, la construction, la conception et le d veloppement d entrep ts de donn es et de solutions d intelligence d affaires en savoir beaucoup sur les solutions infonuagiques, l architecture et les technologies azure, ainsi que leurs interd pendances exp rience d montr e avec des outils etl , d entrep t de donn es , d int gration de donn es , de profilage de donn es et de visualisation de donn es connaissance de l orchestration avec azure logic apps connaissance de la diffusion en continu des donn es azure avec azure event hub connaissance approfondie de sql et de d bogage de probl mes complexes rechercher, analyser, recommander et s lectionner des approches techniques pour r soudre des probl mes de d veloppement et d int gration difficiles et stimulants d couvrir et adopter de nouveaux outils et de nouvelles techniques afin d accro tre la performance, l automatisation et l volutivit aider les quipes de d veloppement des affaires ex cuter les activit s de pr vente et les demandes de proposition comprendre les objectifs et d clencheurs d affaires, et les traduire en une solution technique appropri e et qu offrirai je l organisation plus de trois ans de construction et de mise en uvre d infrastructures azure comprendre la mise en uvre de conceptions fond es sur l architecture lambda exp rience de configuration et d ajustement de nuages virtuels priv s exp rience concr te d valuation des besoins en mat riel et en stockage solides capacit s analytiques de r solution de probl mes personne autonome ayant la capacit de travailler de fa on ind pendante ou au sein d une quipe de projet b. sc. en sciences informatiques, en un domaine connexe ou une exp rience professionnelle quivalente connaissance de python et d azure devops, un atout connaissance du codage en python et .net, un atout compr hension des cosyst mes infonuagiques et des technologies infonuagiques mergentes et dernier cri bilinguisme qu est ce qui nous motive la culture notre vision est de cr er un monde dans lequel tout le monde aime son travail et sa vie. nous croyons en l importance d une communaut d employ s slalom diversifi e et inclusive, et nous les encourageons tous tre fid les eux m mes au quotidien. nous croyons qu il nous faut rester humbles et curieux, tout en inspirant passion et aventure ce n est pas parce que nous travaillons d arrache pied que nous ne nous amusons pas slalom s efforce de consolider ses quipes et s assure qu elles ont autant de plaisir qu elles sont productives. l entreprise adore rassembler ses employ s en organisant plusieurs activit s comme des v nements trimestriels, des c l brations pour les f tes, des v nements de bienfaisance et, de fa on plus d contract e, des v nements sur place ou virtuels comme des d ners conf rences, des jeux questionnaires, des soir es cin ma, des marathons de programmation et bien d autres slalom est un employeur inclusif valorisant l galit des chances et engag la cr ation d une main d uvre diversifi e. nous accueillons bras ouverts les candidatures de toutes les personnes qualifi es et travaillerons accommoder raisonnablement les candidats tout au long du processus de recrutement et de s lection. veuillez communiquer avec l quipe d attraction de talents si vous n cessitez des accommodements lors du processus d entrevue. veuillez noter que si vous tes embauch chez slalom, vous devrez remplir une v rification des ant c dents. slalom is a modern consulting firm focused on strategy, technology, and business transformation. in 40 markets across the us, uk, japan, australia, and canada, our teams have the autonomy to move fast and do what s right, always. they are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world s top technology providers. at slalom, personal connection meets global scale. we build deep relationships with our clients within our markets and across the globe, while sharing insights across markets to bring the full breadth of slalom s expertise to every engagement. our seven regional build centers are hubs for innovation, attracting top talent to rapidly co create the technology products of tomorrow. we also nurture strong partnerships with over 200 leading technology providers, including amazon web services, google cloud, microsoft, and salesforce. with our purpose driven mindset, we partner with companies to push the boundaries of what s possible together. here at slalom, we are motivated every day by our company s core values and vision. our core values are at the heart of everything we do and guide how we work with our clients, our teams, and our communities. each core value reminds us to stay true to ourselves while driving amazing outcomes for our clients. our guiding principle is to love your future which inspires our culture, work, and relationships, and most importantly it is how we make our biggest impact founded in 2001 and headquartered in seattle, slalom has organically grown to over 9,000 employees. we were named one of fortune s 100 best companies to work for in 2021 for the 6th year in a row and are regularly recognized by our employees as a best place to work. learn more at slalom.com. slalom in canada began in 2015 and has grown to over 600 employees across 3 markets vancouver, toronto, and montr al. job title data engineering senior consultant so, what will i do work as part of a team, to design and develop cloud data solutions gather technical requirements, assess client capabilities and analyze findings to provide appropriate cloud solution recommendations and adoption strategy define cloud data strategies, including designing multi phased implementation roadmaps lead analysis, architecture, design, and development of data warehouse and business intelligence solutions be versed in azure cloud solutions, architecture, related technologies, and their inter dependencies proven experience with etl , data warehousing , data ingestion , data profiling and data visualization tools knowledge of orchestration with azure logic apps knowledge of azure data streaming with azure event hub proficient in sql and debugging complex queries research, analyze, recommend, and select technical approaches for solving difficult and challenging development and integration problems learn and adopt new tools and techniques to increase performance, automation, and scalability assist business development teams with pre sales activities and rfps understand business goals and drivers and translate those into an appropriate technical solution and, what will i bring 3 years architecting and implementing azure infrastructure understanding implementing lambda architecture based data designs experience configuring and tuning virtual private clouds practical experience sizing hardware and storage needs strong analytical problem solving ability self starter with the ability to work independently or as part of a project team b.s. in computer science, related fields or commensurate work experience python, azure devops experience is a plus experience coding in python and .net is a plus understanding of cloud ecosystem and leading edge cloud emerging technologies bilingualism what keeps us here culture our vision is to enable a world in which everyone loves their work and life. we believe in having a diverse and inclusive community of slalomers, encouraging everyone to bring their authentic selves to work, every day. we believe in staying humble and curious, while still inspiring passion and adventure just because we work hard doesn t mean we don t have fun slalom strives to bring our teams together and ensure we have just as much fun as we do work. slalom loves to bring their employees together by hosting many events such as quarterly events, holiday parties, charity events and more casually, in office or virtual events like lunch learns, trivia and movie nights, hackathons and many more slalom is an inclusive, equal opportunity employer dedicated to building a diverse workforce. we encourage applications from all qualified candidates and will work to reasonably accommodate applicants needs throughout all stages of the recruitment and selection process. please advise the talent acquisition team if you require accommodations during the interview process. please note if you are hired at slalom you will be required to complete a background check. li ld1","['https', 'data visualization', 'proposition', 'technical requirements', 'data profiling', 'data streaming', 'sql', 'python', 'integration', 'valuation', 'data engineering', 'data warehousing', 'amazon web services', 'debugging', 'business intelligence', 'hardware', 'automation', 'amazon services', 'devops', 'hadoop', 'data solutions', 'scalability', 'computer science', 'etl', 'r']","['https', 'sql', 'amazon web services', 'python', 'azure', 'google cloud', 'hadoop', 'c', 'debugging', 'business intelligence', 'hardware', 'r']","['data ingestion', 'devops', 'data solutions', 'data visualization', 'scalability', 'proposition', 'technical requirements', 'data profiling', 'computer science', 'integration', 'valuation', 'data engineering', 'data warehousing', 'automation', 'etl', 'data streaming']","['business development', 'private', 'events', 'design', 'sales', 'consulting', 'construction', 'adoption', 'architecture']"
380,478,Data Management Specialist – Pharmaceutical,"at procogia we re passionate about developing data driven solutions that provide highly informed answers to our clients most critical challenges. our projects are varied, from data warehouse builds, deploying cloud data solutions, dashboarding, building predictive models. you may be involved in all stages of the project life cycle, from data engineering or integration to building pipelines right through to advanced analytics. we work with industry leading clients from various sectors including pharmaceuticals, telecommunications, technology, financial services retail. our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal career development. procogia has doubled in size over the last two years core to procogia s culture is ensuring we maintain a balanced male to female ratio. we are proud to share our consulting teams consist of 40 50 females compared to the industry standard of 10 20 . our diversity, and differences allow us to create innovative and effective solutions for our clients. position details we are seeking a data management specialist for our pharmaceutical clients development sciences department. the data management specialist will be performing data management and curation tasks to support biomarker discovery and companion diagnostic development efforts. in the process of performing this work, the candidate will communicate extensively with scientists, research associates, operations managers, clinical data managers, analysts, and vendor representatives. responsibilities working with biomarker operations managers and biometrics colleagues to draft data transfer specifications and statements of work. acquiring and qc ing digital pathology image data and associated metadata files from internal groups and external vendors. capturing data in internal file systems and databases. monitoring data processing requests and submitting data files to analysis pipelines merging different data types with clinical data to generate analysis ready data sets curating and cataloguing data sets, maintaining listings of available data, and distributing to collaborators maintaining and curating content of internal knowledge sharing repositories maintaining and developing data conformance checking scripts and requirements required skills familiarity working in a linux computing environment proficiency in scripting languages such as r or python database skills familiarity with modern informatics systems, relational and non relational databases, scripting languages, and data visualization tools. demonstrated experience with informatics best practices and developing well documented, production code in non academic environments. working knowledge of scientific research application development cycles and data management principles. working knowledge of anatomical pathology workflow and digital pathology data lifecycles experience managing and curating biological or clinical data careful, detail oriented working style outstanding communication, collaboration, and problem solving skills able to work independently and in a team setting. nice to have but not required relational databases and sql statistical software packages such as r or sas clinical trial data management working with medical images data setting up and maintaining online content management systems or wikis education bachelors or master s degree in life science, computer sciences or biomedical engineering with at least 3 years work related experience.","['computing', 'databases', 'linux', 'data visualization', 'clinical data', 'sql', 'data processing', 'software', 'scripting', 'analytics', 'python databases', 'integration', 'pipelines', 'data engineering', 'application development', 'sas', 'relational databases', 'specifications', 'metadata', 'data transfer', 'statistical', 'file systems', 'data solutions', 'data management', 'telecommunications', 'r']","['sql', 'python', 'databases', 'linux', 'repositories', 'sas', 'pipelines', 'telecommunications', 'r']","['computing', 'data visualization', 'clinical data', 'curation', 'data processing', 'scripting', 'management systems', 'analytics', 'integration', 'application development', 'data engineering', 'relational databases', 'specifications', 'metadata', 'data transfer', 'statistical', 'file systems', 'data solutions', 'software packages', 'data management']","['environment', 'biomedical engineering', 'biomarker', 'biometrics', 'education', 'statements of work', 'retail', 'life science', 'cu', 'curating', 'consulting', 'financial services', 'pathology', 'content', 'pharmaceuticals', 'scientific research']"
381,479,Data Engineer,"elements global services is an award winning hr technology and services company revolutionizing the way employers expand and manage employees internationally. global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread out teams. as elements is a truly global company, we take care of our client s employees worldwide. from chicago to manila, from johannesburg to delhi and hong kong, we provide top class benefits to all the employees we serve every day. with offices all around the world and teams spread out between multiple time zones, you too can benefit from the glocal team strategy, giving our employees the flexibility, they need to do their very best work the best way they can. a revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. we are looking to expand our team by hiring a new data engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. reporting to the vp product technology, you will be supporting our product development team by architecting and building analytics tools based on data science and machine learning capabilities that provide insights to empower businesses to be successful and reduce risks. key responsibilities key member of the product team building business intelligence and analytics saas solutions. collaborate with business stakeholders to gather and define data and reporting requirements. end to end architecture, planning, and implementation of data pipeline, web scraping, reporting, and ai or ml driven analytics develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks. drive web scraping alternate data implementation and automation. build, test, and maintain scalable and robust data and analytics stack. what we value you hold a bachelor s in electrical engineering, computer science, or related technical field advanced degree in data science, engineering, statistics, computer science, mathematics is preferred. you have 5 years of experience as a data engineer or in a similar role working on etl, data modelling, business intelligence architecture, alternative data, machine learning, reporting. you have advanced skills in data mining using sql, etl, data warehouse as well as excel. you have experience building self service reporting solutions for trends and predictions using proprietary software and business intelligence tools . you have demonstrated experience with cloud relational and nosql database technologies such as mysql, mongodb. you are expert coding experience in modern programming languages and tools such as python, ruby, c , java, sql, etc. what we offer opportunity to work in a fast growing organization with the ability to make a quick impact. allow your inspirational ideas to come to life in a highly creative and executional environment. ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core. the opportunity to challenge in a high performing organization and leave each day knowing you have made an impact. this position description may not describe all duties, responsibilities, and skills associated with this position. it is intended to portray the major aspects of the job. other duties or skills may be required. elements global services is an equal opportunity employer and prohibits discrimination and harassment of any kind elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. all employment decisions at elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex , age, physical, mental or sensory disability, hiv status, sexual orientation, gender identity and or or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. elements will not tolerate discrimination or harassment based on any of these characteristics. elements encourages applicants of all ages.","['c', 'mongodb', 'mysql', 'java', 'sql', 'python', 'ruby', 'statistics', 'software', 'reporting', 'data science', 'coding', 'analytics', 'saas', 'data', 'nosql', 'data mining', 'electrical engineering', 'machine learning', 'business intelligence', 'web scraping', 'automation', 'programming languages', 'computer science', 'mathematics', 'etl', 'ai']","['sql', 'python', 'ruby', 'programming languages', 'c', 'java', 'business intelligence', 'web scraping', 'mysql', 'nosql']","['data mining', 'electrical engineering', 'machine learning', 'statistics', 'ai', 'software', 'reporting', 'data science', 'computer science', 'analytics', 'saas', 'mathematics', 'mongodb', 'automation', 'etl', 'planning']","['environment', 'team building', 'product development', 'regulations', 'hr', 'hiring', 'architecture']"
382,488,Data Engineer,"data engineer information technology remote position canadian based candidates competitive salary our client is looking for a passionate data engineer to join their growing team for the development and deployment of etl processes, data management, data warehousing. this role will be responsible for the development and deployment of etl processes, data management, data warehousing to improve, optimize and lead further development of their data aggregation processes. you ll bring a deep understanding of big data and will help to build and enable big data analytics solutions. the ideal candidate is innovative, collaborative, determined and takes great pride in their work. the role code, test, and document new or modified data systems to create robust and scalable applications for data analytics work with stakeholders including analytics, product, and design teams to assist with data related technical issues and support their data infrastructure needs. engineer solutions for large data storage, management, and curation of training data models. explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities. act as an internal expert in each of the data sources so that you can own overall data quality. design, build and deploy new data models, etl pipelines into production and data warehouse. define and manage overall schedule and availability of all data sets. process, cleanse, verify and work with data from multiple sources work with the data science team to access and understand internal and external data sources develop algorithms and build models to solve business problems. collaborate with solution engineers to integrate pipelines into our proprietary applications bring your great ideas for new products and features to the team the ideal candidate masters or bs degree in computer science or related technical field, or equivalent practical experience. 3 years experience with data gathering, data pipelining, data standardization, data cleansing, stitching aspects some experience with cloud aws, azure, or gcp proficiency in a major programming language and or or a scripting language highly analytical and detail oriented with a dedication to analyzing data to identify deliverables, anomalies, and gaps and propose solutions to address these findings strong analytic skills related to working with unstructured datasets solid understanding and working knowledge of relational or non relational databases excellent communication , organizational, and trouble shooting skills. a preference for candidates located in calgary, winnipeg, gta, hamilton but open to canada wide applications","['data infrastructure', 'cleansing', 'big data', 'information technology', 'data analytics', 'gcp', 'reporting', 'scripting', 'data science', 'analytics', 'programming', 'aws', 'data systems', 'data models', 'pipelines', 'data warehousing', 'data aggregation', 'relational databases', 'data quality', 'algorithms', 'datasets', 'scalability', 'computer science', 'data management', 'etl']","['gcp', 'pipelines', 'big', 'programming', 'big data', 'aws', 'data models', 'data quality']","['data infrastructure', 'cleansing', 'information technology', 'curation', 'data analytics', 'reporting', 'scripting', 'data science', 'analytics', 'data systems', 'data warehousing', 'data aggregation', 'computer science gathering', 'relational databases', 'data storage', 'algorithms', 'datasets', 'scalability', 'data management', 'etl']",['design']
383,489,Data Engineer,"the green organic dutchman is a global leader in cultivating premium, certified organically grown cannabis. at the green organic dutchman , we are proud be to cultivating a great workplace from the ground up. every day we are challenging, defining, and shaping this new industry. we are growing strong with a team that is proudly committed to creating the world s best certified organic cannabis. the data engineer is a critical role for tgod as our business hits unprecedented scale. you will provide and grow in house expertise on elt or etl formulations and api interactions. our data is a critical business asset how we handle and manage that data must enable our agile business and be compliant with laws or regulations to preserve its confidentiality, availability and integrity. this role forms part of tgod s data science functions and will support the director of data science in leading and managing all data related activities including business intelligence. this role is fully remote, within canada. key responsibilities support and develop data pipelines for all core systems and 3rd party integrations into the data lake and analytics database. leverage api endpoints for operational use of centralized data assets develop broad domain and technical knowledge in aws solutions. demonstrate strong verbal or written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams. basic qualifications bachelor s degree in computer science, information systems management, it security, finance, technology or related field or 3 years relevant work experience in a data related field 2 years python, sql is a must. strong elt or etl background 1 years using apis for data extract and load 1 years with linux shell or bash for automation and server administration experience with apache airflow and docker is preferred experience with web scraping is preferred experience in the bi or analytics or data warehousing space is preferred experience with amazon web services ecosystem and general cloud architecture demonstrate critical inquiry with attention to detail ability to effectively articulate recommendations or conclusions verbally and in writing preferred qualifications tableau server and tableau desktop sap hana cloud data model, data extraction and api use cases version control best practices highly independent, organized and efficient. snowflake data warehouse data presentation skills to both business and technical teams. the green organic dutchman is an equal opportunity employer and we welcome diversity in the workplace. we encourage applications from all qualified individuals, including visible minorities, aboriginal people, and persons with disabilities. please contact human resources to request any accommodations you may require to participate in the recruitment process .","['linux', 'bash', 'tableau', 'sql', 'python', 'data science', 'analytics', 'data', 'aws', 'data warehousing', 'cloud', 'apache airflow', 'amazon web services', 'data pipelines', 'web', 'business intelligence', 'automation', 'administration', 'data presentation', 'data extraction', 'bi', 'security', 'api', 'computer science', 'version control', 'snowflake', 'etl']","['apache airflow', 'sql', 'python', 'linux', 'amazon web services', 'tableau', 'bi', 'tableau server', 'api', 'aws', 'business intelligence', 'web scraping', 'snowflake']","['information systems management', 'administration', 'bash', 'use cases', 'data pipelines', 'data extraction', 'security', 'data science', 'version control', 'computer science', 'analytics', 'data', 'data warehousing', 'cloud', 'automation', 'etl']","['human resources', 'sap', 'forms', 'finance', 'regulations', 'architecture']"
384,491,Data Science Senior Manager,"we are the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in ai or ml. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about accenture applied intelligence. you are an expert at solving real world challenges with data, analytics, ai or ml and creativity. yes, creativity you know the theory and you have hands on expertise from studies, experience and or or self taught projects. as a senior manager working at accenture you will work on a team with diverse clients and industries delivering analytics solutions and help clients turn data into actionable insights that drive tangible outcomes, improve performance and help clients lead the market. what you ll do collaborate with prospective clients to solve large complex business problems with data, analytics and ai or ml develop innovative cloud solutions for clients across functions industries educate account teams about data, analytics ai or ml and applicability to their industry or clients lead multiple teams and engagements to engineer deliver value for clients play an active role building a practice including capability development and recruitment stay abreast of technologies, academic researches hands on techniques on cloud, data, analytics and ai or ml what we re looking for extensive experience engaging with client senior leadership on complex business problems expertise developing solution offerings and communicating findings to executive audiences well versed with managing data science teams and engagements, and providing technical leadership extensive experience embracing challenges with cloud, data, analytics and ai or ml lifecycle in enterprise setting 8 years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation bonus point if graduate degree in data science or related disciplines e.g. mathematics, statistics, computer science, economics, engineering and physics ability to build, manage and foster a team oriented environment, working creatively and analytically in a problem solving environment a blend of data science capability, industry and consulting expertise high initiative and a desire or ability to persist through obstacles or ambiguity excellent written and oral communication skills with ability to clearly communicate findings, concepts and ideas","['statistics', 'economics', 'physics', 'data science', 'computer science', 'analytics', 'mathematics', 'technical leadership', 'automation', 'ai']",[],"['statistics', 'economics', 'physics', 'aimorp', 'data science', 'computer science', 'analytics', 'mathematics', 'technical leadership', 'automation', 'ai']","['environment', 'consulting', 'engagements']"
385,493,Data Engineer,"cyient is a global engineering and technology solutions company. as a design, build, and maintain partner for leading organizations worldwide, we take solution ownership across the value chain to help clients focus on their core, innovate, and stay ahead of the curve. we leverage digital technologies, advanced analytics capabilities, and our domain knowledge and technical expertise, to solve complex business problems. with over 15,000 employees globally, we partner with clients to operate as part of their extended team in ways that best suit their organization s culture and requirements. our industry focus includes aerospace and defence, healthcare, telecommunications, rail transportation, semiconductor, geospatial, industrial, and energy. job description the data engineer will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. these solutions will generate insights from the organization s connected data, enabling pratt whitney canada to advance the data driven decision making capabilities of our enterprise. this role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows in additional to basic understanding on business processes supported by the data pipeline. the ideal candidate is a skilled data or software engineer with experience creating data products supporting analytic solutions with experience in the assigned area. finally, they are an agile learner, possessing strong problem solving skills, working as part of a technical, cross functional analytics team, and desiring to solve complex data problems and deliver the insights to enable analytics strategy. bachelor s degree required computer science, mis, or engineering preferred 5 years of experience working in data engineering or architecture role, 7 preferred expertise in elt and data analysis and experience with sql and at least one programming language experience developing and maintaining data warehouses in big data solutions e.g. snowflake experience with developing solutions on cloud computing services and infrastructure in the data and analytics space database development experience using hadoop, spark or bigquery and experience with a variety of relational, nosql, and cloud database technologies worked with bi tools such as alteryx, tableau, power bi, looker conceptual knowledge of data and analytics, such as dimensional modeling, elt, reporting tools, data governance, data warehousing, structured and unstructured data. big data development experience using hive, impala, spark and familiarity with kafka familiarity with the linux operating system exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and or or applied mathematics strong understanding of agile methodologies experience as a data engineer on a cross functional agile team preferred strong communication skills with ability to communicate complex technical concepts and align organization on decisions sound problem solving skills with the ability to quickly process complex information and present it clearly and simply utilizes team collaboration to create innovative solutions efficiently passionate about technology and excited about the impact of emerging or disruptive technologies proven learning agility on both the technical and business process realms wants to unleash inner self starter and work in an environment that fosters entrepreneurial minds believes in culture of brutal transparency and trust and open to learning new ideas outside scope or knowledge skills experience apache spark, hadoop ecosystem, ibm cloud, microsoft azure, microsoft azure databricks, microsoft azure sql database, scala, spark sql, sql cyient is an equal opportunity employer. cyient recruits, employs, trains, compensates, and promotes regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, veteran status, and other protected status as required by applicable law. we are proud to be a diverse and inclusive company where our people can focus their whole self on solving problems that matter.","['linux', 'tableau', 'alteryx', 'big', 'big data', 'hive', 'microsoft azure', 'sql', 'looker', 'statistics', 'software', 'scala', 'reporting', 'computer vision', 'data science', 'analytics', 'data', 'programming', 'cloud computing', 'data engineering', 'data warehousing', 'nosql', 'unstructured', 'microsoft azure sql', 'machine learning', 'data pipelines', 'data products', 'apache spark', 'mis', 'artificial intelligence', 'data analysis', 'agile methodologies', 'bi', 'hadoop', 'computer science', 'technology solutions', 'modeling', 'applied mathematics', 'telecommunications', 'snowflake']","['linux', 'tableau', 'alteryx', 'big', 'microsoft azure', 'big data development', 'sql', 'looker', 'scala', 'ibm cloud', 'programming', 'microsoft azure sql', 'nosql', 'apache spark', 'mis', 'hiveala', 'bi', 'hadoop', 'technology solutions', 'telecommunications', 'snowflake']","['unstructured data', 'dimensional', 'applied', 'statistics', 'software', 'reporting', 'computer vision', 'data science', 'analytics', 'data', 'data engineering', 'data warehousing', 'cloud computing', 'machine learning', 'data pipelines', 'data products', 'artificial intelligence', 'data analysis', 'agile methodologies', 'functional', 'data solutions', 'computer science', 'mathematics', 'modeling']","['environment', 'healthcare', 'design', 'governance', 'business process', 'aerospace', 'law', 'architecture']"
386,494,Data Science Associate - Montreal,"company presentation world leader in gases, technologies and services for industry and health, air liquide is present in 80 countries with approximately 65,000 employees and serves more than 3 million customers and patients. oxygen, nitrogen and hydrogen have been at the core of the company s activities since its creation in 1902. air liquide s ambition is to be the leader in its industry, delivering long term performance and acting responsibly. entity and activity description founded in 1911, air liquide canada has over 2,200 employees and serves over 80,000 customers in canada s aeronautics, automobile, agri food, chemical, defence, electronics, energy, metallurgy, metal fabrication, mining and healthcare industries from our sites located in key industrial regions from coast to coast. missions and responsibilities the r d data science group at air liquide has an opening for a data scientist. the researcher will have the opportunity to work on challenging problems focusing on customers, patients and operations.the researcher will also interact with multi disciplinary teams composed of business, it and digital resources that define operating models, and build digital solutions. duties and responsibilities collaborate with the business to define needs and challenges, translate them into functional specifications, and develop solutions to address them. work with it and external organizations to obtain online or offline data. clean, and analyze the data. develop solutions relying on machine learning methods such as clustering, regression, classification, time series and deep learning. test and verify the performance of solutions with prototypes developed in r, python, or similar development environments. support the development of industrial tools and their deployment in the business units. train team members and the business, thus ensuring sustainability of the solutions for air liquide. publish research in internal reports, at conferences and peer reviewed journals competencies and profile master in computer science or related field 3 years of relevant experience is preferred a strong background and experience in statistics and machine learning strong programming skills in python or r ability to write production level, modular code demonstrates strong process and operational safety behavior at all times excellent communication and interpersonal skills ability to work in a multi disciplinary and international team preferred experience in aws, azure, and sql additional information thank you for your interest. please note that only applicants selected for an interview will be contacted for more information on our company, visit us online at job reference ca04024","['deep learning', 'sql', 'python', 'machine learning', 'statistics', 'data science', 'computer science', 'programming', 'aws', 'sustainability', 'functional specifications', 'electronics', 'r']","['sql', 'python', 'programming', 'aws', 'electronics', 'operating models', 'r']","['deep learning', 'machine learning', 'statistics', 'functional', 'data science', 'computer science', 'specifications', 'sustainability']","['healthcare', 'hydrogen', 'acting', 'agri', 'metallurgy', 'business units']"
387,495,Data Engineer - Machine Learning,"who we are creating a planet fueled by reliable, clean energy isn t what keeps us up at night it s what gets us out of bed. at opus one solutions, our software platform gridos helps us pursue solutions that will change how countries access, optimize and distribute electrical energy. from microgrids that keep things running in the event of an outage, to helping electric utilities optimize their operations and allowing homeowners to feed energy into a power grid, we re powering a more sustainable future. the opportunity as the shift to reliable, clean energy becomes an imperative, opus one solutions is at the forefront of this transition. our software reduces the complexity of systems coordination and establishes the financial base for resource deployment, allowing countries to accelerate carbon reduction, and system operators to facilitate the distribution of carbon neutral energy. the opus one solutions gridos software platform brings intelligence to every level of the electrical grid, from smart meters that can minimize the impact of power outages to the most challenging electrical utility marketplaces that can coordinate market actors to enhance system operations. our software enables optimization of energy systems from planning to operations, leveraging the data at not only the utility, but also the various entities connected to its infrastructure. we have assembled a diverse group of power systems experts and distributed software system professionals who are working to tackle these challenges together and are looking to expand the team to accelerate our shared journey to a more sustainable future. you will be working as part of the opus one solutions data science team focusing primarily on building and deploying high velocity machine learning models targeted at electrical distribution utility customers. our end users require the integration of highly accurate energy demand and generation forecasts combined with production level outcomes delivered into operational systems resulting in a need for a balanced approach of model development and deployment. energy demand and generation both depend on climate, weather, seasonality, and long term trends. the data sources may be clear and well understood or sparse and require investigation by the data science team. you will be an integral part of this process. you will work with the data science team to ensure the outcomes are repeatable, scalable, traceable, and defensible what you will work on design, build and maintain the data processing pipelines required for the opus one solutions machine learning based time series forecasting models and production deployments. create the etl or elt workflows to ingest measurement data timeseries forecasting engine support the integration with third party data sources including advanced metering infrastructure , electrical grid distribution and feeder models, meteorological services, solar and generation forecast data along with additional socio economic information as required . analyze foundational data tables and metrics supporting the power flow optimization and data science teams with clear definitions, data lineage, loading patterns, test coverage and transformations to ensure that data is reliable, intelligible, and maintainable build and extend time series forecasting engine apis for product and project services. implement systems to track data quality and consistency explaining issues or problems with data. communicate high quality software engineering practices for building data infrastructure and pipelines at scale including the documentation of etl or elt flows and systems architecture. support testing processes, troubleshoot and resolve issues. work in an agile or scrum team setting including cross functional structures and varying levels of management. requirements who are you we re looking for a data engineer to help us accelerate the adoption of distributed energy resources such as wind and solar into the day to day operations of the electrical utilities. you will have a proven track record of shipping performant data processing systems in production environments and are comfortable developing and automating complex pipelines and workflows that underpin ai or ml powered products. you are a data engineer with experience working in a machine learning or big data production environment. experience in the application of best practices for software engineering in the ai or ml and data spaces, with an emphasis on time series data experience standing up services and building scalable production data workflows. you may also have experience working within the electrical utility marketplace or an adjacent industry where experience in forecasting can be used. here s what you bring education bachelor s degree in computer science, math, statistics, engineering, or a related quantitative field, or equivalent experience technical 3 years of industry experience in software engineering or data engineering proficiency working with structured and unstructured data including experience with relational data stores such postgresql, sql, and etl or elt frameworks experience with implementing chronological, time series processes experience with service oriented architecture including designing and developing restful apis a demonstrated ability to build and maintain etl or elt processes including staging, cleansing, mapping, and loading work experience developing in python, java, or other programming languages experience building high quality end to end data solutions in an agile environment from requirements to production. some exposure to the workflow management engines along with hadoop or similar ecosystems including hive, spark, pig, or others is desired. collaboration solve problems in robust and creative ways demonstrating solid verbal, interpersonal and written communication skills. effective in working across team boundaries to establish overarching data architecture, and provide guidance to individual teams collaborate across multiple development, project delivery teams along with technical and non technical stakeholders. benefits why join opus one solutions opus one is growing after spending first four years under the radar focused on research and pilot projects we re ready to shine as one of canada s top 10 game changers named by cix cleantech, fast company s 2017 world changing idea in energy and one of top 100 global cleantech companies we are deploying exciting microgrid projects in north america and have partnerships with leading energy players such as national grid. our leadership has assembled carefully selected teams with some of the best strategic visionaries and executors in technology and the clean energy space. we are all driven by one common goal to accelerate the integration of clean and sustainable energy in north america and the world. at opus one solutions we understand that not everyone develops their talent and hones their skills in a traditional way. different paths and experiences are part of the diversity we know we need to succeed. if you feel you meet all or most of the qualifications we are seeking, take a chance and express your interest here. opus one solutions welcomes and encourages applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process.","['unstructured data', 'workflow management', 'data infrastructure', 'test coverage', 'documentation', 'big data', 'cleansing', 'hive', 'java', 'investigation', 'forefront', 'sql', 'statistics', 'data processing', 'python', 'postgresql', 'software', 'agile environment', 'data science', 'data', 'integration', 'loading', 'pipelines', 'data engineering', 'machine learning', 'testing', 'scrum', 'data quality', 'forecasting', 'model', 'radar', 'programming languages', 'hadoop', 'data solutions', 'computer science', 'optimization', 'operational systems', 'etl', 'ai']","['sql', 'forefront', 'python', 'postgresql', 'programming languages', 'hadoop', 'model development', 'data quality', 'documentation', 'big data', 'pipelines', 'hive', 'java']","['unstructured data', 'machine learning series', 'data lineage', 'workflow management', 'data infrastructure', 'cleansing', 'investigation', 'agile environment', 'statistics', 'data processing', 'test coverage series', 'software', 'data science', 'relational data', 'systems', 'data', 'integration', 'data engineering', 'feed', 'system operations', 'machine learning', 'testing', 'scrum', 'forecasting', 'planning', 'radar', 'data solutions', 'computer science', 'optimization', 'operational systems', 'etl', 'ai']","['utilities', 'environment', 'project delivery', 'education', 'power outages', 'metrics', 'carbon neutral', 'energy systems', 'design', 'electrical', 'power flow', 'sustainable', 'adoption', 'power systems', 'power grid', 'architecture']"
388,496,Sr. Medical Scientist (Cell Therapy) / Scientifique Médical (Thérapie cellulaire),"kite is continuing to hire for all open roles. our interview process may be conducted virtually and some roles will be asked to temporarily work from home. over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams. for current kite pharma employees and contractors please log onto your internal career site to apply for this job. job description kite, a gilead company, is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long term durable response and eliminating the burden of chronic care. the company is focused on chimeric antigen receptor and t cell receptor engineered cell therapies designed to empower the immune system s ability to recognize and kill tumors. the role the medical scientist is a field based medical scientific expert in the assigned therapeutic area. the ms assumes responsibility for all medical activities within the assigned territory and executes the field medical strategy. this involves gathering insights, medical education and communication, supporting clinical research, and managing projects of various scope including educational events and regional advisory boards. the role requires close national and international collaboration with colleagues from medical affairs and other departments. implements defined goals and objectives aligned with the medical affairs plan of action and other strategic initiatives within the cell therapy therapeutic area responds to clinical inquiries regarding marketed or developmental gilead or kite products. develops and presents complex scientific and clinical data related to gilead or kite products. identifies and develops regional and national opinion leaders to support gilead or kite products through personal contacts and on site visits establishes strong relationships with opinion leaders, clinical investigators and healthcare professionals at academic and non academic settings works on phase 3 or phase 4 programs that include collaboration with investigators and internal personnel provides input into site selection for both phase 4 and other clinical trials anticipates obstacles and difficulties that may arise in the field and resolves them in a collaborative manner the candidate works collaboratively with gilead or kite personnel in commercial, marketing, market access, clinical research, global safety and global medical affairs utilizes scientific resources to deliver impactful presentations in a variety of settings. the incumbent travels to appointments, meetings and conferences on a frequent and regular basis, occasionally with short notice must have the ability to work as a member of several teams that may overlap such as national ms team, regional team, national accounts, and others well developed experience in preparing and delivering presentations is required. experience in the management or investigation of clinical trials is preferred exhibits gilead or kite core values integrity, inclusion, teamwork, accountability, and excellence knowledge, experience and skills advanced health sciences degree with a minimum of 3 years of experience in healthcare or pharmaceutical industry two to four years of experience in oncology in a clinical or research or medical affairs capacity is preferred excellent oral and written communication skills and interpersonal skills bilingualism is required excellent project management ability and organizational skills, including the management of multiple priorities and resources excellent judgment and personal initiative are required advanced knowledge of microsoft office suite is required must have knowledge of and be willing to comply with all regulatory or compliance policies candidate must be based in quebec ability to travel 70 of the time domestic and international travel is required, including potential attendance at conferences which may include occasional weekend travel kite, une soci t de gilead, se consacre la mise au point d immunoth rapies novatrices contre le cancer dans le but d offrir une r ponse rapide, durable et long terme et d liminer le fardeau que repr sentent les soins de longue dur e. l entreprise concentre ses nergies sur des th rapies cellulaires, savoir les cellules t r cepteur antig nique chim rique et les r cepteurs de l antig ne des lymphocytes t . ces traitements visent renforcer la capacit du syst me immunitaire d tecter les tumeurs et les liminer. r le le scientifique m dical est un expert scientifique du domaine m dical qui travaille sur le terrain, dans le domaine th rapeutique qui lui a t attribu . le sm assume la responsabilit de toutes les activit s m dicales dans le territoire attribu et ex cute la strat gie m dicale sur le terrain. il doit par exemple recueillir des id es, soutenir la formation et les communications m dicales, appuyer la recherche clinique et g rer des projets d importances diverses, y compris des v nements ducatifs et des conseils consultatifs r gionaux. le titulaire de ce poste doit entretenir une troite collaboration nationale et internationale avec des coll gues des affaires m dicales et d autres services. mettre en uvre des objectifs d finis qui cadrent avec le plan d action des affaires m dicales et avec les autres initiatives strat giques du domaine th rapeutique de la th rapie cellulaire. r pondre aux questions cliniques portant sur les produits de gilead or kite actuellement sur le march ou en cours de d veloppement. d velopper et pr senter des donn es scientifiques et cliniques complexes li es aux produits gilead or kite. rep rer des leaders d opinion r gionaux et nationaux, et les amener appuyer les produits de gilead or kite par l interm diaire de contacts personnels et de visites sur place. tablir de solides relations avec des leaders d opinion, des investigateurs cliniques et des professionnels de la sant en milieu universitaire et non universitaire. travailler aux programmes de phase iii et iv notamment en collaborant avec les investigateurs et le personnel interne. contribuer la s lection des centres o seront r alis es des tudes cliniques de phase iv et d autres tudes cliniques. pr voir les obstacles et les difficult s pouvant survenir sur le terrain, puis les r soudre de mani re collaborative. travailler avec le personnel de gilead or kite des secteurs affaires commerciales, marketing, acc s au march , recherche clinique, innocuit mondiale et affaires m dicales mondiales. employer des ressources scientifiques pour donner des pr sentations convaincantes dans divers milieux. se rendre r guli rement et fr quemment des rendez vous, des r unions et des conf rences, parfois avec un court pr avis. pouvoir travailler en tant que membre de plusieurs quipes dont les activit s pourraient se chevaucher, notamment dans l quipe nationale des scientifiques m dicaux, l quipe r gionale et l quipe des comptes nationaux. poss der une grande exp rience en laboration et en animation de pr sentations, obligatoire. poss der une exp rience en gestion ou en investigation d tudes cliniques, un atout. incarner les valeurs de gilead or kite, soit l int grit , l inclusion, le travail d quipe, la responsabilit et l excellence. connaissances, exp riences et comp tences dipl me de haut niveau en sciences de la sant et au moins trois ans d exp rience dans le secteur pharmaceutique ou des soins de sant . de deux quatre ans d exp rience en oncologie dans un poste du domaine clinique, de la recherche ou des affaires m dicales, un atout. excellentes aptitudes en communications crites et orales, et de solides comp tences en relations interpersonnelles . bilinguisme, anglais et fran ais, obligatoire. remarquables comp tences organisationnelles et en gestion de projets, y compris la capacit de g rer plusieurs ressources et priorit s. jugement et esprit d initiative hors pair, obligatoire. connaissance avanc e de la suite microsoft office , obligatoire. connaissance des politiques r glementaires et de conformit , et volont de les respecter, obligatoires. domicile au qu bec, obligatoire. capacit voyager 70 du temps, autant l int rieur qu l ext rieur du pays, ce qui inclut d ventuelles participations des conf rences pouvant n cessiter des d placements les fins de semaine. kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long term durable response and eliminating the burden of chronic care. the company is focused on chimeric antigen receptor and t cell receptor engineered cell therapies designed to empower the immune system s ability to recognize and kill tumors. kite is based in santa monica, ca. for more information on kite, please visit . sign up to follow kitepharma on twitter at or kitepharma . for current kite pharma employees and contractors please log onto your internal career site to apply for this job.","['site visits', 'investigation', 'clinical data']",[],"['site visits', 'investigation', 'clinical data']","['and safety', 'events', 'education', 'healthcare', 'marketing', 'or', 'presentations', 'microsoft office', 'project management', 'clinical research', 'market access', 'clinical trials', 'strategic initiatives', 'health', 'oncology', 'therapy', 'international travel']"
389,497,Big Data Engineer,"company description virtuetech inc. is an amazon partner network consulting partner, focusing exclusively on amazon web services . with a strong foot in aws, cloud infrastructure and data analytics, we are a global technology solutions provider with a reputation for stringent quality standards. we are a very fast growing company and a trusted analytics partner for multiple fortune 500 companies. our business value and leadership has been recognized by various market research firms, including forrester and gartner. working with us offers you an excellent opportunity for significant career development in a fast growing and challenging entrepreneurial environment with a high degree of individual responsibility job description job description focus on scalability, performance, service robustness, and cost trade offs continuous drive to explore, improve, enhance, automate, and optimize systems and tools to best meet evolving business and market needs attention to detail, coupled with ability to think abstractly create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. create prototypes and proof of concepts for iterative development keen to learn new technologies and apply the knowledge in production systems take complete ownership of projects and their development cycle contract length 6 8 months application deadline 2021 04 24 expected start date 2021 04 26 job types full time, temporary, contract salary 62,173.00 130,000.00 per year additional pay overtime pay schedule 8 hour shift monday to friday covid 19 considerations remote job. working from home work remotely yes covid 19 precaution remote interview process","['data analytics', 'amazon web services', 'scalability', 'technology solutions', 'analytics', 'aws', 'cloud infrastructure', 'production systems']","['production systems', 'amazon web services', 'aws', 'technology solutions']","['scalability', 'data analytics', 'analytics', 'cloud infrastructure']","['environment', 'business value', 'consulting', 'market research']"
390,498,Data Engineer,"do you love making sure that information is accessible and easy to use so do we. you are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively. about you you draw on your experience in bringing data to life to aim sometimes complex problems, and you re able to use concepts around storing, transforming, and visualizing data along the way. about the job as a data engineer, you know the importance of data to business. you design and set up projects that bring together information from a variety of sources, to enable analysis and decision making. you make sure that data is accessible and easy to use, so that it can be used for routine and ad hoc analysis. day to day you use your knowledge to plan and deliver data warehouses and storage take part in crafting and running bespoke data services for individual projects stay up to date with business best practice in using and retrieving data design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining customize storage and extraction, metadata, and information repositories build and use effective metrics and monitoring processes help to develop business intelligence tools craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources your skills you have got a great experience in data and analysis, and how to source, store and share information. you re a problem solver who s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members. your skills and experience include strong knowledge of python, spark, and t sql database, storage, collection and aggregation models, techniques, and technologies and how to apply them in business experience in structured problem solving strong knowledge of python, spark, and t sql superb communication skills ability to use technology to aim business problems using one or more microsoft analytics services for building data pipelines, data streams, and system integration desirable skills knowledge of azure tools such as azure data factory, azure data lake, azure sql dw or azure sql knowledge of big data tools such as hadoop or azure hdinsight spark, azure cosmos db, azure databricks, azure stream analytics experience preparing data for data science and machine learning crafting and building data pipelines using streams of iot data knowledge of dev ops processes and infrastructure as code fundamentals you re likely to have a bachelor s degree in it, applied mathematics, statistics or another meaningful field, or an equivalent combination of education and experience. you also have several years of relevant professional experience.","['applied', 'data services', 'dashboards', 'big data', 'bespoke', 'sql', 'python', 'statistics', 'data science', 'portals', 'data', 'analytics', 'integration', 'solver', 'ops', 'data mining', 'machine learning', 'data pipelines', 'relational databases', 'iot', 'metadata', 'business intelligence', 'streams', 'azure', 'hadoop', 'system', 'microsoft', 'mathematics']","['sql', 'python', 'azure', 'repositories', 'iot', 'azure data lake', 'microsoft', 'azure sql dw', 'azure data factory', 'big data', 'business intelligence', 'azure databricks', 'streams', 'azure sql', 'solver', 'hadoop cosmos']","['applied', 'data services', 'dashboards', 'bespoke', 'statistics', 'data science', 'portals', 'data', 'analytics', 'integration', 'infrastructure as code', 'ops', 'data mining', 'machine learning', 'data pipelines', 'relational databases', 'metadata', 'system', 'mathematics', 'stream']","['generators', 'education', 'metrics', 'forms', 'design', 'business experience', 'architecture']"
391,499,Big Data Engineer (Remote Optional),"who we are centro delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands. our comprehensive ad tech platform, basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place. we are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. we invest in our culture and support our employees so they can do their best work. centro is headquartered in chicago, with beautiful offices also in toronto, dallas, denver, and new york to name a few. post covid, many of us will be returning to one of our offices . all of our employees have the flexibility to work in one of our office locations, completely remote, or a hybrid of the two. please note, we are hiring on a remote working basis only in the u.s. and canada. about the team technology is at the core of what we do. centro s innovative engineering team designs and develops new features and integrations for basis, our industry leading, comprehensive software solution. our platform processes over 300 billion events per day and uses ai and machine learning to automate and simplify the entire digital campaign process. ways you ll contribute this team is all about data and in order to create value from the massive amount of data we collect, engineering leverages their dynamic data engineering, data science, and business intelligence teams to create insights that benefit the industry as a whole. you will contribute by implementing scalable, fault tolerant and accurate etl pipelines that work in a distributed hadoop environment. developing platform services to operate the big data applications at scale. gathering and processing raw data at scale from diversified sources into hadoop. building enterprise business analytics and reporting applications on hadoop. what you bring to the table proven experience working with various components of hadoop ecosystem spark, hive, impala, kafka, oozie strong understanding of computer science fundamentals proficiency with relational databases and sql queries understanding of how to handle high velocity, high volume data events. understanding of factors affecting performance of etl processes and sql queries, ability to work on performance tuning. experience implementing data pipelines moving large volumes of data a day. experience in implementing application in scala on spark. experience coding in python bonus points skills in real time streaming applications. knowledge of scala. a development workflow using docker containers. compulsion for automating your day to day processes. our tech stack ruby, java, python, and react.js hadoop, scala, spark, hive kubernetes, docker, kafka postgresql, nosql aws anything else don t think you have all the skills required for this role that s okay, we recognize that experience can be built in many ways. if you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn t match our exact requirements. life with centro we take care of our people and believe that centro s success depends on the growth and well being of each one of our team members. we provide a thoughtful perks and benefits package including competitive 401k or rrsp matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a work from home stipend for employees in closed offices, and more. we are proud to be an equal opportunity employer are committed to building teams of centrons that are diverse in thought, perspective, and culture. we celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age. our employee led communities enrich our culture of uniqueness, inclusivity, and empowerment.","['big data', 'hive', 'business', 'performance tuning', 'java', 'kubernetes', 'sql', 'python', 'ruby', 'postgresql', 'software', 'scala', 'reporting', 'data science', 'analytics', 'aws', 'pipelines', 'data engineering', 'nosql', 'machine learning', 'data pipelines', 'relational databases', 'business intelligence', 'hadoop', 'computer science', 'etl', 'ai']","['kubernetes', 'sql', 'python', 'ruby', 'postgresql', 'scala', 'hadoop', 'big data', 'business intelligence', 'aws', 'pipelines', 'hive', 'java', 'nosql']","['machine learning', 'data pipelines', 'relational databases', 'software', 'reporting', 'data science', 'computer science', 'analytics', 'planning', 'data engineering', 'business', 'performance tuning', 'etl', 'ai']","['environment', 'events', 'digital media', 'mental health', 'hiring']"
392,501,Data Governance Analyst,"title data governance analyst freshbooks has an ambitious vision. we launched in 2003 but we re just getting started and there s a lot left to do. we re a high performing team working towards a common goal building an extraordinary online accounting application to help small businesses better handle their finances. known for extraordinary product and customer service experiences and based in toronto, canada, freshbooks serves paying customers in over 120 countries. the opportunity data governance analyst freshbooks is seeking a data governance analyst to join our team. as part of the data and analytics team, you will contribute to the creation of, and help implement, our data governance strategy across the enterprise. if you re committed to great work and are constantly looking for ways to improve the systems you re responsible for, we d love to chat with you what you ll do collaborate with data engineers, data scientists, and data analysts to design and develop data glossaries and standards and keep the metadata repositories up to date. work with business stakeholders to identify and map business critical and sensitive data elements. collaborate closely with colleagues from business and technology teams to ensure metadata requirements are well understood. focus on data management functional areas of data quality, data lineage, data cataloging and data privacy. manage, maintain and continuously update the metadata repositories or tools. interface with vendors to make sure the data governance tools are running and working as expected. be the champion for promoting data literacy within the organization. provide expertise around the data governance policy reviews, metrics, and reporting wherever needed by business and technical teams. what you bring 2 4 year s experience in a field related to information management or metadata management. experience applying metadata management and data governance principles. experience with metadata management tools is an asset the ability to write accurate sql queries. familiarity with data and analytics platforms and concepts ability to create a variety of business documents that will be positioned as enterprise artifacts. what you might bring experience implementing data solutions or rolling out new data tools or products. experience with industry etl bi tools understanding of data warehouse modeling fundamentals and application relational database concepts subject matter data expertise in saas industry. why join us we re an ambitious bunch, with our eyes laser focused on shipping extraordinary experiences to small business owners. you ll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world class one, right here in downtown toronto. apply now have we got your attention submit your application today and a member of our recruitment team will be in touch with you shortly freshbooks is an equal opportunity employer that embraces the differences in all our employees. we celebrate diversity and are committed to creating an inclusive environment for all freshbookers. all applicants are evaluated based on their experience and qualifications in relation to this position. here at freshbooks, we welcome and encourage applications from people with disabilities. should you require any accommodations during the recruitment process, please advise your recruiter on how we can meet your needs to ensure a fair and equitable selection process in a confidential manner. job type full time","['metadata management', 'sql', 'software', 'bi', 'reporting', 'etl', 'data solutions', 'data privacy', 'analytics', 'data', 'metadata', 'saas', 'modeling', 'data quality', 'data management', 'laser', 'information management', 'map']","['sql', 'repositories', 'bi', 'data quality', 'laser', 'map']","['metadata management', 'data lineage', 'software', 'reporting', 'data cataloging', 'data solutions', 'data privacy', 'analytics', 'data', 'metadata', 'saas', 'data management', 'information management', 'etl', 'modeling database']","['environment', 'accounting', 'metrics', 'design', 'customer service', 'governance']"
393,502,Data Science Instructor,"about the role journey is looking for an experienced, energetic, data scientist with an interest in teaching. as a data science instructor you will be responsible for leading lectures on various topics, assigning course work, grading, and mentoring students on a 1 1 basis. you will work closely with other instructors and members of our education team, and follow along with our pre built curriculum and teacher guide. you will work as an instructor for our concordia bootcamps program and have a direct impact on changing peoples lives through education. this is a full time contractual position which will last 14 weeks. hours will be from 9 30am to 5 30pm monday through friday. this course will be taught remotely. you can review the program and upcoming course dates here https or or concordiabootcamps.ca or courses or data science remote or responsibilities teach a class of beginners with the goal of ensuring they graduate ready for junior level roles in data science act as coach or mentor to students as they work their way through the course care profoundly about every student s success present lectures on math, stats, python, pandas, sql, data visualization, and more work with the director of education to learn and adjust to the pre established curriculum and course content follow each student independently and ensure that they develop a mastery of the subject matter qualifications you have experience teaching , coaching, managing or supporting junior staff or managing projects you have a minimum of 2 years of professional experience in the field of data science you are an outstanding presenter. you re easy to follow when you explain difficult concepts because of your ability to dissect and disseminate them into bite sized, understandable ideas you re energetic and have a strong ability to motivate others who you are you love the idea of helping people lead better lives through education you re a lifelong learner, constantly learning new things in your field you love to share your learnings and experiences with others you don t let a bad minute ruin a good day you re an active listener you re empathetic salary and benefits this is a 14 week contractual position salary range from 10,000 15,000 cad for the duration of the contract dependant on experience fully remote work work with an amazing and fun team possibility to extend your contract and teach more courses about journey education journey provides digital skills training with courses, workshops, and events all offered online. our product lineup currently includes courses in web development and data science, with new products on the way. founded in 2014 and headquartered in montreal, canada, journey works with highly experienced instructors to develop cutting edge, real world training and meaningful educational products that help people unlock their potential. at journey, we are building an environment where our employees feel included and heard. diversity and inclusion are important to us and we strongly encourage applications from minorities, people with disabilities, people from gender and sexually diverse communities and or or people with intersectional identities.","['https', 'sql', 'python', 'data visualization', 'data science', 'web development', 'pandas']","['https', 'pandas', 'python', 'sql']","['web development', 'data visualization', 'data science']","['curriculum', 'environment', 'events', 'education', 'grading', 'workshops', 'mentoring']"
394,503,"Azure Data Engineer (Certified DP-200 & Dp-201, DP-203)","title azure data engineer location brampton, on rate 60 or hr or 90k tech mahindra need azure data engineer with primary skills in depth project experience in hadoop and azure cloud technologies experience in ingestion of batch and streaming data with complex transformations using apache kafka, apache spark, scala, hive sql, shell script. work directly with business users and convert use cases into solutions independently. experience in working with very large volume of log data and building analytical insights based on user requirements experience in handling semi structured data in various data formats and manipulate data in complex data types. secondary skills knowledge on devops tools and experience in building ci or cd pipelines on azure. write programs to pull data from external applications and services using rest api with different authentication methods. knowledge on nosql database types like document and graph db is a plus. knowledge on machine learning libraries for data science and analytics is a plus. has worked in agile methodologies certification azure data engineer regards, sayyad ashraf parvez email ashrafatcompestsolutions.com d 647 660 7562 ext 412 web site job types full time, contract, permanent salary 80,078.00 90,207.00 per year additional pay bonus pay benefits dental care extended health care life insurance work from home schedule 8 hour shift","['project', 'ci', 'authentication', 'hive', 'sql', 'cd', 'scala', 'data science', 'analytics', 'pipelines', 'nosql', 'machine learning', 'apache spark', 'rest', 'user requirements', 'apache kafka', 'agile methodologies', 'devops', 'hadoop', 'api']","['sql', 'nosql', 'scala', 'apache spark', 'hadoop', 'shell script', 'api', 'pipelines', 'hive', 'apache kafka']","['agile methodologies', 'use cases', 'machine learning', 'cd', 'devops', 'ci', 'authentication', 'data science', 'analytics', 'rest', 'user requirements']","['hr', 'insurance']"
395,504,FULLSTACK DEVELOPPER & DATA ENGINEER (bank of candidates),"position description we are looking for a savvy data engineer to join our growing data analytics and business intelligence local practice team. in the role of fullstack developer, the ideal candidate will assume front end and or or back end analysis, design and development on all types of programming languages required by the client mandates to which he or she will be assigned. the date engineer will be responsible for expanding and optimizing our client s data and data pipeline architecture, as well as optimizing data flow and collection from a variety of sources for cross functional teams. the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. the data engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. they ensure that data is ready for use in digital products, data science, reporting, and analytics. they will design and maintain data warehouses and data marts, and structure volumes of data. they must be self directed and comfortable supporting the data needs of multiple teams and systems wearecgi your future duties and responsibilities create and maintain optimal data pipeline architecture assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc.. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and cloud based big data technologies. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. work with stakeholders including the executive, product, data and design teams to assist with data related technical issues and support their data infrastructure needs. keep data separated and secure across national boundaries through multiple data centers and cloud providers regions.. improve data availability, acting as a liaison between source systems and data science and bi teams collect, blend, and transform data using etl tools, database management systems, and code including sql and python perform aggregation on data across various warehousing models, such as olap cubes and star schemas for bi purposes provide training or coaching for junior members managing a team as a lead developer or scrummaster ensure the analysis, design, estimation, planning and front end and or or backend development of cloud computing, web, ecommerce or big data applications . required qualifications to be successful in this role 2 5 years of experience in a data engineer role 5 6 years experience in a backend and or or front end developer role computer science, statistics, informatics, information systems degree or equivalent education and experience. advanced working sql knowledge and experience working with relational databases. experience building and optimizing big data data pipelines. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. strong analytics skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. a successful history of manipulating, processing and extracting value from large disconnected datasets. strong proficiency in python and sql for analytics, database development, and data modelling working knowledge of message queuing, stream processing and highly scalable big data data stores. experience supporting and working with cross functional teams in a dynamic environment. should also have experience using the following software or tools o experience with big data tools python, hadoop, spark, kafka, etc. o experience with relational sql and nosql databases, including postgres and cassandra. o experience with data pipeline and workflow management tools azkaban, luigi, airflow, etc. o experience with aws, ms azure, google cloud services, databricks o experience with stream processing systems storm, spark streaming, etc. o experience with object oriented or object function scripting languages python, java, c , scala, etc. fluency in french and english, oral and written strong understanding of agile methodologies and experience on an agile team keen collaborator and clear communicator, responsive to service needs and operational demands passionate about the impact of emerging technologies and learning new skills and ideas optional experience with erp and crm environments and data sap, salesforce, peoplesoft, ms dynamics, etc. what you can expect from us build your career with us. it is an extraordinary time to be in business. as digital transformation continues to accelerate, cgi is at the center of this change supporting our clients digital journeys and offering our professionals exciting career opportunities. at cgi, our success comes from the talent and commitment of our professionals. as one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. all of our professionals benefit from the value we collectively create. be part of building one of the largest independent technology and business services firms in the world. learn more about cgi at no unsolicited agency referrals please. cgi is an equal opportunity employer.","['databases', 'schemas', 'data flow', 'workflow management', 'operational efficiency', 'data infrastructure', 'c', 'erp', 'big data', 'google', 'java', 'olap', 'data analytics', 'sql', 'python', 'statistics', 'software', 'scala', 'reporting', 'scripting', 'data science', 'database', 'queuing', 'dynamics', 'analytics', 'data marts', 'aws', 'data systems', 'crm', 'cloud computing', 'cloud', 'nosql', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'data centers', 'metadata', 'business intelligence', 'cgi', 'cassandra', 'airflow', 'cloud services', 'agile methodologies', 'programming languages', 'data structures', 'bi', 'datasets', 'hadoop', 'information systems', 'scalability', 'computer science', 'root cause analysis', 'digital transformation', 'etl']","['databases', 'c', 'erp', 'big data', 'google', 'java', 'sql', 'python', 'scala', 'azkaban', 'aws', 'nosql', 'object function', 'data centers', 'business intelligence', 'cgi', 'cassandra', 'airflow', 'big data data', 'programming languages', 'bi', 'hadoop']","['schemas', 'data flow', 'workflow management', 'operational efficiency', 'data infrastructure', 'olap', 'data analytics', 'statistics', 'software', 'reporting', 'management systems', 'scripting', 'data science', 'database', 'queuing', 'dynamics', 'analytics', 'data marts', 'data systems', 'cubes', 'crm', 'cloud computing', 'unstructured', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'metadata', 'planning', 'cloud services', 'agile methodologies', 'data structures', 'database development', 'datasets', 'information systems', 'scalability', 'computer science', 'root cause analysis', 'digital transformation', 'etl']","['environment', 'customer acquisition', 'education', 'metrics', 'design', 'sap', 'acting', 'referrals', 'business performance', 'architecture']"
396,505,Data Analyst (Research),"about hri homewood research institute invites applicants for the position of data analyst . hri is an ambitious and growing national charity dedicated to research that transforms mental health and addiction services in canada and around the world. through strategic partnerships with homewood health and a vital growing network including some of the world s most influential scientists, clinicians and researchers, we are uniquely positioned to innovate, test new discoveries, and accelerate the process that brings research into solutions for the real world. for more information, visit hriresearch.com. position overview the hri data analyst works closely with research associates, research scientists, and investigators to ensure accurate collection, organization, documentation, analysis and sharing of data. the data analyst is responsible for the statistical analysis required for knowledge translation and exchange activities and for peer reviewed publications. the data analyst is an integral member of the research and evaluation team. key responsibilities 1. data analysis and planning plans and conducts relevant analyses for internal or external collaborators involving a range of statistical methods, including multivariate analyses, structural equation modeling with cross sectional and longitudinal data using data from a rolling cohort applies methods of handling missing data, such as multiple imputations uses external data from a variety of sources , in combination with internal project data prioritizes and responds to ad hoc and routine data inquiries 2. development and maintenance of datasets leads the development and maintenance of datasets including the creation of standard operating procedures for creating, organizing, storing, documenting, extracting or exporting, converting, merging and manipulating large and small data files ensures that data are accurate, consistent, properly maintained, and shared in compliance with relevant privacy protection, confidentiality, and other ethical principles uses sas or r to process and prepare datasets for hri investigators including merging multiple data sets , deriving project specific variables in consultation with hri investigators, and applying appropriate de identification techniques tailored to each unique data request writes documentation reports to accompany the release of datasets, including relevant procedural notes and data codebooks 3. knowledge translation and communication contributes to the writing of peer reviewed scientific publications and technical reports provides data outputs and creates reports for stakeholders including visually intuitive graphs and depictions on complex study results presents findings at scientific meetings when appropriate communicates clearly with research team members, external stakeholders, and funders 4. consultation and training provides data analysis and data management consultation or support to researchers, graduate students, post doctoral fellows and to affiliated scientists as needed position requirements education master s degree in quantitative research skills and experience demonstrated ability to interact effectively and build rapport with a wide range of individuals strong organizational skills and initiative work well independently proficiency in statistical analysis software such as sas, r, mplus, stata, and or or spss advanced proficiency in microsoft excel ability to perform data management and formatting for standard statistical software strong verbal and written communication skills with statisticians and non statisticians including technical report writing and writing for peer reviewed scientific publications ability to work on multiple analytical projects concurrently with attention to detail initiative to acquire new skills and remain current with new developments as required commitment to hri values of anti oppression equity and inclusion and supports related organizational goals and research activities knowledge of mental health and addictions research would be an asset english or french bilingual capacity would be considered an asset anti oppression, diversity and inclusion focus at hri, we strive to foster anti oppression, equity, and inclusion , because we believe living these values is the most powerful platform for social change. we believe that people and organizations thrive when we embrace the richness of the human experience and invite all voices to contribute to a shared goal. we are passionate about our vision no life held back or cut short by mental illness or addiction. this vision encompasses everyone, including first nations, m tis, and inuit, people with disabilities, people of all cultural, religious, racial, and ethnic backgrounds, people of all income and education levels, people of all ages, non binary and gender nonconforming people, women, and two spirit, lesbian, gay, bisexual, trans, queer, questioning, intersex, and asexual people. as a research organization, we are working continuously to move aoei values into action through our organizational culture, policies, and research activities. job location this position offers remote work arrangements due to the ongoing pandemic, however regular in person meetings and events will be required when work returns to normal. how to apply please submit a resume and cover letter and inform us if you require accommodations during the interview process. we thank all applicants for their interest, however, only those selected to interview will be contacted. reference id hri 2021 03 application deadline 2021 06 25 job types full time, permanent pay 29.88 38.15 per hour benefits dental care disability insurance employee assistance program extended health care life insurance paid time off rrsp match vision care schedule monday to friday education master s degree work remotely temporarily due to covid 19","['mplus', 'quantitative research', 'software', 'datasets', 'data analysis', 'statistical', 'documentation', 'technical reports', 'data management', 'modeling', 'microsoft excel', 'statistical analysis', 'sas', 'translation', 'r']","['mplus', 'documentation', 'microsoft excel', 'sas', 'r']","['software', 'datasets', 'data analysis', 'statistical', 'technical reports', 'report', 'data management', 'modeling', 'statistical analysis', 'translation', 'planning']","['events', 'education', 'mental illness', 'mental health', 'developments', 'insurance']"
397,506,Data Engineer (Ingestion),"data engineer ingestion location toronto are you ready to step up and take your technology expertise to the next level there is never a typical day at accenture, but that s why we love it here this is an extraordinary chance to begin a rewarding career at accenture technology. immersed in a digitally compassionate and innovation led environment, here is where you can help top clients shift to the new using leading edge technologies on the most ground breaking projects imaginable. immerse yourself in a supportive ecosystem that values your individuality and encourages you to innovate, ideate and disrupt. we recognize that it s the diversity of our people that makes us stronger, smarter and more effective as a team. we are accenture cloud first accenture is a leader in cloud transformations working with aws, azure, google, and private clouds. the formation of accenture cloud first, with a 3 billion investment over three years, demonstrates our commitment to deliver greater value to our clients when they need it most. our cloud first multi service group of more than 70,000 cloud professionals delivers a full stack of integrated cloud capabilities across data, edge, integrated infrastructure and applications, deep ecosystem skills, culture of change along with a deep industry expertise to shape, move, build and operate our clients businesses in the cloud. to accelerate our clients transformation leveraging cloud, we combine world class learning and talent development expertise deep experience in cloud change management and cloud ready operating models with a commitment to responsible business by design with security, data privacy, responsible use of artificial intelligence, sustainability and ethics and compliance built into the fundamental changes accenture helps companies achieve. our services cover the full spectrum of client needs, from strategy to service management, device to cloud networks, workplace solutions, and more. today, more than ever, companies need to operate and compete at an unprecedented speed and scale as industries are reshaping beneath them. this means innovating faster, creating new revenue streams, deriving more insights from data and from the edge and interacting differently with their customers, partners, and employees. choose accenture and make delivering this kind of innovative work part of your extraordinary career. the work accenture s cloud first infrastructure engineering professionals partner with our clients to advise, create, and deploy end to end infrastructure transformation solutions, enabling business innovation. these solutions are the backbone of driving it enabled differentiation. ie professionals are grounded in new it with an expertise in one or more of our core practice areas digital workplace, network technology, service management, hybrid cloud, public cloud, and traditional data center. key responsibilities application design, development and support for azure data and ai data analytics platform involved in designing and developing new solutions lead the effort to design, build and configure applications, acting as the primary point of contact. lead team for azure databricks, azure data lake, adb, pyspark and synapse responsible for application support and lead the role with offshore on shore teams co ordinate with the client resolving issues, implementing enhancement, and troubleshooting issues to come up with recommendations for the client who are we looking for 3 year of experience in the following azure data factory pyspark azure sql azure data lake preferred skills certification azure data certification python","['data analytics', 'azure', 'sql', 'python', 'application support', 'pyspark', 'hybrid cloud', 'streams', 'resolving issues', 'security', 'data privacy', 'public cloud', 'troubleshooting', 'artificial intelligence', 'aws', 'sustainability', 'operating models', 'ai']","['azure', 'python', 'pyspark', 'azure data lake', 'public cloud', 'azure data factory', 'aws', 'azure sql azure data lake', 'streams', 'operating models']","['data analytics', 'infrastructure engineering transformation', 'service', 'application support', 'hybrid cloud', 'resolving issues', 'security', 'data privacy', 'troubleshooting', 'artificial intelligence', 'sustainability', 'ai']","['environment', 'change management', 'private', 'and compliance', 'offshore', 'design', 'acting', 'talent development']"
398,507,Senior Data Engineer,"senior data engineer my client, the largest e commerce investor, was founded by founders for founders. they invested 2b in over 4k business. looking for a data engineer talent to join their smart team to build the data driven app for early stage founders. contact me for details about this exciting opp 100 remote if you want but no no no outside the country applicants, thank you. responsibilities you will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development working closely with every member of the team, vendors and external partners, you will produce significant components of the code collaborate with all functions, ranging from core engineering team to data science team to the marketing team you be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary you will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself. you will run and participate in founder townhalls, communicating closely with early stage entrepreneurs coordinate, roll up your sleeves, do what s necessary to get the ball moving forward what we look for great communication skills, with a desire or experience to lead a small team of other devs in the near future desire to help founders. we take a strong founder first stance on this team be self sufficient when it comes to execution. figure out how to solve problems and make things happen, not waiting for help or permission on this team, we maximize learning. you will fail if you re not learning fast enough comfort working in a high growth, constantly changing environment heavy bias towards action. ability to solve problems end to end on their own. you will implement ideas and experiments on your own with minimal support have experience working in a senior software engineering role, you are an expert when it comes to coding and you re ready to roll up your sleeves to get the job done have a strong business sense, you can foresee potential issues and solve them quickly demonstrated ability to collaborate effectively across multiple teams strong interest in building businesses, ecommerce and fintech technical requirements ideally, you have worked on 3 or more different stacks in your career in a professional setting. bonus points for systems managing time series able to architect and scale data integrations from third party api docs independently, extracting the right business value for the vision and roadmap interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes comfortable working in server and database environments that are changing constantly comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff comfortable with relational databases and schemas involving time series skills and interest in python, sql, snowflake, kubernetes and pipeline management or orchestration tools tor123","['kubernetes', 'sql', 'python', 'schemas', 'relational databases', 'software', 'data products', 'api', 'data science', 'technical requirements', 'snowflake']","['kubernetes', 'sql', 'python', 'api', 'snowflake']","['schemas', 'relational databases', 'software', 'data products', 'data science', 'technical requirements']","['environment', 'e commerce', 'fintech', 'marketing', 'business value', 'design', 'team building', 'architecture']"
399,508,Ingénieur·e de données /Data Engineer,"qui sommes nous buspatrouille est une entreprise sp cialis e dans la technologie de s curit . titre de principal fournisseur international de dispositifs visant faire respecter le bras d arr t des autobus scolaires, notre mission principale est d am liorer la vie des l ves o qu ils se trouvent. la technologie de buspatrouille a t d ploy e sur un plus grand nombre d autobus et a t utilis e pour d livrer un plus grand nombre de contraventions relatives au bras d arr t des autobus scolaires que toute autre technologie des autres entreprises existantes l chelle mondiale. notre technologie exclusive transforme les autobus scolaires en autobus intelligents quip s de cam ras vid o, de gps, de t l m trie, de traitement de donn es et d archivage. de cette mani re, nous permettons aux comt s et aux districts scolaires d am liorer la s curit des enfants. buspatrouille est en pleine croissance. nous sommes donc la recherche d un.e ing nieur.e de donn es d exp rience pour int grer notre quipe de veille strat gique . si vous aimez travailler dans un environnement dynamique avec des coll gues talentueux, ce poste est pour vous. responsabilit s le r le de l ing nieur.e de donn es est essentiel pour construire des donn es volutives et des mod les analytiques, ainsi qu une architecture allant de la formation l ingestion d v nements, puis la production de rapports, en partant du d but. vous valuerez et soutiendrez la mise en uvre de syst mes robustes utilis s par chaque quipe et client de buspatrouille. la personne id ale poss de de solides connaissances en gestion des donn es, en d veloppement etl , en codage et en infonuagique. elle aime travailler avec une diversit d outils, de langages, de syst mes et d architectures tout en s assurant que les syst mes de donn es et la strat gie respectent les meilleures pratiques en mati re d volutivit . r diger des t ches etl et elt l aide de divers outils et langages de programmation. cr er des pipelines de donn es dans des environnements aws avec aws glue. crire des requ tes sql complexes et optimiser leur vitesse et leur pr cision. concevoir, d velopper, tester, corriger et d ployer des pipelines de donn es en soutien aux produits de base, aux d ploiements aupr s des clients et aux rapports de performance. crire des scripts pour planifier l ingestion et la synchronisation des donn es. d velopper des minientrep t de donn es partir des besoins de l entreprise pour permettre aux parties prenantes de l entreprise d tre autonomes. cr er et tenir jour une documentation claire. travailler avec des coll gues ing nieur.e.s, des chefs de projet et des utilisateurs. suivre les processus et les proc dures de l entreprise, en particulier les pratiques relatives la s curit de l information. connaissances et comp tences requises un baccalaur at ou un dipl me sup rieur en technologie, dans un domaine quantitatif ou dans un autre domaine connexe . plus de cinq ans d exp rience en ing nierie des donn es, ing nierie des bases de donn es ou analyse commerciale. plus de cinq ans d exp rience avec sql . plus de quatre ans d exp rience avec les principaux langages de script tels que python. plus de trois ans d exp rience dans la conception de sch mas, la mod lisation de donn es dimensionnelles, la conception d api et le d veloppement de services web restful. une exp rience de la visualisation de donn es est un atout. une curiosit intellectuelle, une volont constante d apprendre, un esprit d initiative. de solides comp tences en communication crite et verbale. un esprit d quipe. r mun ration et avantages un salaire concurrentiel. des avantages sociaux complets, notamment une assurance soins m dicaux, soins dentaires et soins de la vue. un poste indispensable au sein d une entreprise qui se d veloppe rapidement et qui est investie d une mission. l occasion de travailler avec une quipe tr s performante. l occasion de contribuer la cr ation d une entreprise vou e la s curit des enfants. nous sommes la recherche de membres essentiels de l quipe de buspatrouille qui nous aideront dans notre qu te pour accro tre la s curit des enfants. ce poste joue un r le important dans notre entreprise et constitue une formidable opportunit pour les personnes qui seront retenues. nous offrons un milieu de travail inclusif, diversifi , enthousiaste, int gre et profond ment engag . venez nous aider assurer la s curit des enfants. who we are our mission is to create a culture of responsibility and awareness on the road. we are devoted to making the journey to and from school safer. we develop partnerships, deploy safety tech and manage the entire program. we have equipped thousands of busses across north america with our innovative technology and we continue to educate tens of thousands of drivers a month on safety. buspatrol america cares about student safety. we educate motorists every day by helping enforce the law and work with school officials to improve safety. the role the data engineer at buspatrol will build scalable data and analytics models and architecture from event formation to ingestion to reporting, from scratch. you will evaluate and lead the implementation of robust systems used by every team within buspatrol. you will shape the vision and architecture of end to end pipeline while following industry best practices. the right candidate will have strong data architecture, etl, sql, and a proven track record working with enterprise metrics to build automated data pipelines. the candidate will also have strong operational skills to drive efficiency and speed, expertise in building repeatable data engineering processes, strong project management skills, and a vision for how to deliver data products. responsibilities create data pipelines in state of the art aws environment ec2, s3, lambda, etc. with aws glue. manage all aspects of the data and analytics system from stream configuration to etl to aggregate tables and cubes for reporting needs. identify, design, and implement internal data pipeline jobs or processes improvements using machine learning automating manual processes, optimizing data delivery, re designing infrastructure for scalability, etc. write scripts to schedule data ingestion and syncing. evaluate, lead and form backend logic to create data marts from requirements for the purposes of self serving stakeholders. assist data architects to build the working framework for data search and retrieval. troubleshoot data jobs or processes in production to fix data quality bugs or pipeline performance issues. build and assemble large, complex data sets with multi dimensional relationships that meet both functional and non functional requirements from business stakeholders. build appropriate ml data models and data schemas for business use cases. requirements bachelor s degree or higher in a quantitative or technical field 5 years of relevant experience in one of the following areas data engineering, database engineering, business intelligence or business analytics 5 years of sql knowledge for various reporting and transformation needs 4 years of experience in core languages such as python 3 years of experience with schema design and dimensional data modeling experience with data lake architectures, and with combining structured and unstructured data into unified representations. experience with api design and development of restful web services hands on experience building large scale machine learning infrastructure that have been successfully delivered to customers. analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions. data visualization experience with tools like tableau a plus must be an intellectually curious self starter and motivated to continually learn. what we will offer you the opportunity to join a mission driven company, dedicated to developing and deploying safety technology in support of children s safety the opportunity to build an it infrastructure group in support of our mission dedicated, accessible and committed colleagues and leadership team the chance to join an innovative and dedicated team, focused on leading edge technology competitive salary and benefits package we re looking for critical members of the buspatrol team to assist us in our quest to improve children s safety. this is an important role for us and a great opportunity for the right candidates. our environment is inclusive, diverse, ignited, built on integrity and deeply committed. come and help us keep our children safe. type d emploi temps plein","['unstructured data', 'schemas', 'tableau', 'data visualization', 'documentation', 'business', 'glue', 'sql', 'python', 'reporting', 'analytics', 'data', 'aws', 'data marts', 'data models', 'pipelines', 'data engineering', 'machine learning', 'data pipelines', 'data products', 'web services', 'business intelligence', 'data quality', 'qualitative data', 'pipeliness', 'api', 'scalability', 'schema', 'modeling', 'etl']","['glue', 'sql', 'python', 'tableau', 'pipeliness', 'api', 'data quality', 'documentation', 'aws', 'business intelligence', 'data models', 'pipelines', 'r']","['unstructured data', 'schemas', 'data visualization', 'business', 'reporting', 'enterprise', 'data', 'analytics', 'data marts', 'data engineering', 'database engineering', 'machine learning', 'data pipelines', 'data products', 'data ingestion', 'web services', 'qualitative data', 'use cases', 'scalability', 'schema', 'modeling', 'etl']","['environment', 'metrics', 'art', 'design', 'project management', 'law', 'architecture']"
400,509,Data Engineer (contract),"at bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever stronger loyalty to their brands. that can take us in some pretty amazing directions, and as a data engineer, you ll have your hands on the wheel as we drive the future of loyalty. working on the bleeding edge of exciting technology, you re afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. every day with the data engineering team is different and each project presents its own set of new and exciting challenges. things shift very quickly in our industry and we rely on the data engineering team to keep us ahead of the curve and moving in the right direction. here s what we want problem solver you are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem collaborative you work well with other people passionate a passion for big data and an interest in the latest trends and developments constantly researching new tools and data technologies self starter you are comfortable helping your team get things done here s what you ll be doing design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services identify, design, and implement system performance improvements identify, design, and implement internal process improvements automate manual processes and optimize data delivery useful skills or background you may or may not tick off every box, and that s ok. each person brings a different background and different skills. if you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we ll see what we can do to help a degree in computer science or engineering or related field 2 4 years of experience in a software engineering environment experience with sql and nosql systems knowledge of hadoop, spark, kafka or other equivalent technologies proficiency in some of the following languages scala, java, python, bash experience with automated testing systems mentorship, collaboration, and communication skills knowledge of data modelling, data warehousing, etl processes, and business intelligence reporting tools experience working with ci or cd, containerization, and virtualization tools such as gitlab, jenkins, kubernetes, docker experience with tools like databricks, snowflake or powerbi why join us you can see the code getting to production faster than you used to you will try your big data skills, where precise and robust code really matters you will work with the 3.5 billion record tables you will learn how difference between european and australian privacy laws can affect your design decisions. bond brand loyalty is proud to be recognized as one of canada s best managed companies. we re 400 people working tirelessly together to make the world a more loyal place. you ll be joining a hyper talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. you ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client s biggest business challenges. if you re looking to build your career, build your skills and build bonds apply today bond brand loyalty welcomes and encourages applications from people with disabilities. accommodations are available on request for candidates taking part in all aspects of the selection process.","['bash', 'system performance', 'jenkins', 'data services', 'ci', 'big data', 'containerization', 'java', 'kubernetes', 'sql', 'python', 'cd', 'software', 'scala', 'reporting', 'data engineering', 'data warehousing', 'solver', 'nosql', 'gitlab', 'data pipelines', 'testing', 'business intelligence', 'hadoop', 'computer science', 'virtualization', 'snowflake', 'etl']","['kubernetes', 'sql', 'python', 'gitlab', 'scala', 'jenkins', 'hadoop', 'snowflake', 'java', 'big data', 'business intelligence', 'containerization', 'solver', 'nosql', 'system performance']","['bash', 'data pipelines', 'cd', 'software', 'reporting', 'data services', 'ci', 'computer science', 'virtualization', 'data engineering', 'data warehousing', 'testing systems', 'etl']","['bonds', 'environment', 'developments', 'design']"
401,510,"Senior Actuarial Analyst, Actuarial Consultant or Data Scientist (level 2-3)","from coast to coast, our inspiring colleagues are at the heart of what we do best helping people, businesses and society prosper in good times and be resilient in bad times. with our team, you ll bring this purpose to life every day by living our values, being open to change, and pursuing your goals. at intact, we ll give you countless opportunities to learn and grow, alongside a diverse and passionate community of experts the best the industry has to offer. you ll be empowered to be your best self, do your best work, and make a meaningful impact. here, you can shape the future of insurance, win as a team, and grow with us. about the role attention to all analytical superstars who are ready to take on a new challenge we are looking for several actuaries or data scientists to join our brand new team within the data lab. its mandate is to support the profitability and growth objectives of a whole new market for ifc the united kingdom. we need you and your expertise to find solutions to complex problems that only critical minds can solve. we do everything we can to create an inspiring work environment that offers great opportunities to develop your skills, pursue a rewarding career and bring your innovative ideas to life. hiring manager catherine tremblay your mission from canada, you will work closely with our uk personal lines pricing team. you ll be called upon to play a key role in the collaboration between the two countries and the knowledge transfer between the canadian and english markets. support the various pricing teams already in place in the uk in their ongoing initiatives to improve pricing sophistication. identify opportunities for involvement in order to implement the best pricing strategy in a changing market environment. integrate a new team with high visibility and which will offer a range of varied and stimulating challenges. what does the collaboration with the united kingdom consist of since june 1, 2021, icf has an insurance product distribution network outside of north america. with the largest market being the uk, it is with the aim of creating a close relationship with canada that we are setting up the uk i team within the data lab. the team has a broad mandate and you will be involved in contributing and supporting a variety of uk personal lines pricing projects. in this role, team members should have an openness to travel to the uk if the need arises. the market context is currently in a period of change with a major legislative reform that will change the face of insurance in the country starting january 2022. canadian knowledge and experience will be a great asset to help put in place the best strategy for this new reality. qualifications your qualities you are autonomous and resourceful. you understand the needs and are able to translate a business problem into a concrete solution within a set time frame. you have great communication skills and you know how to adapt to many different audiences. you are a driver of change and you strive for excellence. you are comfortable working in complex and constantly changing environments. you are always ready to help your colleagues and put team success at the forefront. you demonstrate leadership, have influence capabilities and networking skills. your qualifications bachelor s degree in actuarial science or post secondary training in data science . at least 2 years of experience as an actuary or data scientist. knowledge of pricing and portfolio optimization concepts and related practical experience. ability to focus on loosely defined issues requiring a creative and effective approach. understanding of machine learning and artificial intelligence . knowledge of earnix, emblem and radar software . fcas . personal lines insurance experience in a regulated environment . here are a few reasons why others have joined our team an award winning, inspiring workplace that supports its people and recognizes great work stimulating, challenging projects and development opportunities to help you grow your skills and career a comprehensive financial rewards program that recognizes your success an extensive, flexible benefits package an industry leading employee share purchase plan where we match 50 of net shares purchased a 350 annual wellness account that promotes an active lifestyle closing statement we are an equal opportunity employer at intact, our value of respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. we value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard. if we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the talent acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs. background checks as an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. we want intact to be a great place to work this means that internal and external candidates will be asked to consent to background checks so we can learn more about you. please note that for positions with access to financial data or funds, your credit must be in good standing. internal candidates for internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. please note we may have identified other internal candidates through our employee development program, and that the selection process may also be opened to external applicants. eligibility to work in canada it s important that you are legally eligible to work in canada at the time an offer of employment is made. you may be requested to provide proof of eligibility at that time. linkedin sponsored li quebecit","['forefront', 'machine learning', 'radar', 'financial data', 'software', 'data science', 'networking', 'artificial intelligence', 'optimization']",['forefront'],"['machine learning', 'radar', 'financial data', 'software', 'data science', 'networking', 'artificial intelligence', 'optimization']","['actuaries', 'environment', 'actuarial', 'background checks', 'financial services', 'linkedin', 'ifc', 'hiring', 'insurance']"
402,511,Intermediate Project Scientist / Intermediate Project Technician,"intermediate project scientist or intermediate project technician why join us this position is based out of our environment geoscience office in fort st. and reports to a project manager. you will be responsible for supporting our local environment team on a variety of projects in the site assessment and remediation and environmental monitoring sectors. as a result of growth and internal opportunities, snc lavalin is seeking an experienced and career oriented intermediate project scientist or intermediate project technician with technical and project management capabilities. e g offers consulting services in the following areas land reclamation, environmental studies, environmental impact assessments and social impact assessments, habitat assessments and compensation, aquatic life assessments, air quality assessments and greenhouse gas emissions, carbon credits, sustainability, environmental management and planning, geographic information systems, contaminated sites, waste management, mining, water distribution and treatment, pollution control and rural development. our offices are located in attractive regions of bc, with quick access to arts culture and a variety of outdoor activities including mountain biking, skiing, hiking, hunting, and water sports. snc lavalin offers a flexible work schedule and a relaxed office environment. how will you contribute to the team setting and maintaining project schedules, health and safety plans and program budgets making decisions with respect to overall technical execution of the project liaising with technical specialists, field personnel or other project managers to ensure the technical integrity of the project. provide management and technical expertise for contaminated site investigation and remediation programs. interpret findings and preparation and or or review of technical reports. supervision or mentorship of junior professional staff involved in carrying out field programs, ensuring project requirements are communicated and health and safety protocols are adhered to. responsible for conducting or participating in yearly performance evaluations of assigned staff. actively promote health and safety programs and culture. active in business development activities and maintaining client relationships. participate in the preparation of proposals and cost estimates. work as a team in all areas of the environment and in other regions as opportunities arise. reviewing and ensuring billing memos or invoices are accurate and issued monthly participate in short and long range planning within assigned clients group or offices. what will you contribute diploma, bachelor s or advanced degree in engineering, sciences or environmental with eligibility for professional designation . intermediate positions minimum of 8 years of progressive experience encompassing project coordination and or or management, staff training and supervision, and contractor supervision with emphasis in the areas of contaminated site investigation and remediation. experience should include preparation and review of phase i esas, phase ii esas including design and execution of soil, groundwater and vapour phase investigation programs, interpretation of hydrogeological and geochemical data, monitoring studies, phase iii remedial plan design and implementation and execution, report writing and review, and interpretation of provincial and federal environmental regulations. experience should demonstrate leadership and managerial experience as well as a commitment to excellent health safety practices. demonstrate excellent verbal and written communication skills, proven technical report writing skills, and an ability to multi task as well as being organized and detail oriented. valid class 5 bc driver s license.","['site', 'technical', 'information systems', 'project managers', 'remediation', 'sustainability', 'technical reports', 'investigation']",[],"['technical', 'information systems', 'project managers', 'report', 'remediation', 'sustainability', 'technical reports', 'investigation', 'planning']","['and safety', 'gas', 'environment', 'business development', 'land', 'compensation', 'project coordination', 'health safety', 'waste management', 'regulations', 'design', 'project management', 'consulting', 'assessment', 'environmental', 'staff training']"
403,512,Data Engineer - Big Data - $70.00 p/h REMOTE Contract,"role data engineer big data projects structure contract 6 months location toronto, on pay 70.00 p or h inc. hours monday friday we currently have an opportunity for a data engineer working on big data projects contract working in banking environments. the required skills for this role will be 6 years in data engineering or analysis good experience with sql and nosql databases general etl experience previous experience with 1 project on public cloud either azure or aws or gcp good communication skills please apply with an updated resume and ensure the required skills you are able to speak to for this position are included. for more roles like this please go to or find a job or job types full time, permanent salary 65.00 70.00 per hour schedule 8 hour shift work remotely temporarily due to covid 19","['go', 'sql', 'databases', 'gcp', 'banking', 'public cloud', 'big data', 'aws', 'data engineering', 'nosql', 'etl']","['go', 'big data projects', 'sql', 'databases', 'gcp', 'public cloud', 'big data', 'aws', 'nosql']","['data engineering', 'etl', 'banking']",[]
404,515,Senior Data System Analyst - Big Data,"at cn, we work together to move our company and north america forward. be part of our information technology team, a critical piece of the engine that keeps us in motion. from enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value added tasks. you will be able to develop your skills and career in our close knit, safety focused culture working together as one team. the careers we offer are meaningful because the work we do matters. join us job summary the role of the data designer is to work with leading edge technologies such as sensors and control electronics, sophisticated planning and decision support systems, big data infrastructures, advanced analytics, deep learning. this role is responsible for delivering of data services in support data goverance, engineering and machine learning practices. the role requires a deep understanding of the data analysis techniques and data model design. the data designer brings technical expertise to ensure the quality and accuracy of that data, then process, design and present it in ways to help people, businesses, and organizations make better decisions. the role ensures data integrity and normalization, and provides designs to support the development of data pipelines. the roles requires an individual that is able to develop a specification to support the data pipelines for both batch and real time data streaming. main responsibilities definition delivery of data assets design, develop data assets to be consumable from a data lake, and data warehouse, to support operational reporting, data science and self serve analytics data design must be ensure the integrity of all data accuracy participate in simplification initiatives to allow for more effective data management to change the conversation from tactical to strategic which is insight and action orientated focused obtains the requirements from the business using user stories, for the data pipelines design that will enable faster, better, data informed decision making within the business leads innovation through exploration, benchmarking, making recommendations, and implementing data technologies and data design models analyzing proposed application or system changes and making recommendations for approval identify sources systems, develops knowledge of business context, becomes sme of data source, works with data engineers or scientists to provide expertize on the data sources being analyzed performs ad hoc analyses of data stored in the business s databases or data warehouse and writes sql scripts, to analyze data troubleshoots data issues within the business and across the business and presents solutions to these issues must be able to test and apply test processes for data management practice. illustrate and support a variety of optimized analytics delivery capabilities working conditions this role may require occasional business travel in accordance with cn policy for meetings requirements general experience minimum 7 10 years overall work experience between 5 and 7 years of experience in support the development of data warehouse, and data lakes must have experience in building data models, for data warehouse and data lake storage ideal if the person has design experience in supporting real time streaming, modeling for non sql database has developed requirements into user stories, worked with developers for grooming the requirements has provided conceptual, logical and physical data models has capture business transformation rules must be able to do data wrangling, cleans the data, develop insights from data assets expert ability to identify data requirements, gaps and assess end to end data requirements excellent communication skills to build alliances and gain consensus with key stakeholders to promote test data management best practices education or certification or designation bachelor s degree specializing in mathematics and statistics or computer science or business analytics or or other quantitative field, related degree or equivalent experience technical skills or knowledge has worked in a data warehouse or data lake organization experience in data design, data analytics or data science exposure to data modeling experience, and data architecture best practices experience with relational database modeling techniques experience with dimensional modeling techniquesexperience with coding, using data bricks, spark streaming, python, data factory, snowflake expert in sql development further providing support to the database design, data flow and analysis activities advising staff and users on database design practices nice to have experience with unstructured data, withe background with using data from of social media, video feeds or audio. excellent verbal and written communication skills and the ability to interact professionally with a diverse group experience in doing design for real time data streaming and loading data profiling, data extraction and breaking down data to a domain driven model strong test strategies, using advance sql skills to support the performance tuning of the extraction process, ability to create strategies for loading, purging and retaining data assets tools used ideally kafka, spark, mulesoft, postgress, graphql, snowflake, databricks and spark experience working across both business and technology written presentation experience presenting insights in plain language and images experience in understanding complex businesses questions and framing the right analytical question to solve a business problem excellent verbal and written communication skills and the ability to interact professionally with a diverse group the ability to learn quickly, problem solve or troubleshoot, work independently and in a team exposure to principles of change management, and scrum agile experience in leading and participating in business workshops ability to promote business intelligence, analytics, and reporting vision exposure to delivering commercially beneficial insights and analytics strategies exposure to hands on support to orientate analytics around delivering value back to the business willingness to work on multiple projects at one time exposure to building analytical and quantitative analysis models about cn as a leading north american transportation and logistics company, cn is a true backbone of the economy. with a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. we transport us 200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000 mile network spanning canada and mid america. cn is the only canadian company listed in the transportation and transportation infrastructure sector of the dow jones sustainability world index . launched in 1999, the djsi world represents the gold standard for corporate sustainability. at cn, we work as one team, focused on safety, sustainability and our customers, providing operational and supply chain excellence to deliver results. cn is an employment equity employer and we encourage all qualified candidates to apply. we thank all applicants for their interest, however, only candidates under consideration will be contacted. please monitor your email on a regular basis, as communication is primarily made through email.","['unstructured data', 'databases', 'data flow', 'data services', 'data integrity', 'data profiling', 'information technology', 'sustainability', 'electronics', 'business', 'performance tuning', 'data streaming', 'sql', 'data analytics', 'python', 'statistics', 'reporting', 'support systems data', 'data science', 'database', 'enterprise', 'database design', 'analytics', 'data', 'graphql', 'data models', 'machine learning', 'data pipelines', 'scrum', 'business intelligence', 'data analysis', 'model', 'deep learning', 'sensors', 'data extraction', 'data wrangling', 'computer science', 'mathematics', 'modeling', 'data management', 'snowflake']","['sql', 'databases', 'python factory', 'data lakes', 'big data', 'business intelligence', 'data models', 'electronics', 'snowflake', 'control']","['unstructured data', 'dimensional', 'data flow', 'data services', 'data integrity', 'data profiling', 'database modeling', 'information technology', 'modeling', 'sustainability', 'business', 'performance tuning', 'data streaming', 'test data management', 'data analytics', 'statistics', 'reporting', 'data science', 'database design', 'enterprise', 'analytics', 'data', 'graphql', 'machine learning', 'data pipelines', 'quantitative analysis', 'scrum', 'data analysis', 'planning', 'model', 'deep learning', 'methodology', 'sensors', 'data extraction', 'data wrangling', 'computer science', 'mathematics', 'database design practices', 'support systems', 'data management']","['business transformation', 'change management', 'education', 'design', 'business travel', 'sme', 'architecture', 'workshops', 'benchmarking']"
405,516,Bio informaticien/Bioinformatics scientist,"avant le sras cov 2, un vaccin qui tait d velopp rapidement prenait environ 4 ans. en comparaison, les vaccins contre le sras cov 2 ont t d velopp s en moins de 12 mois. imaginez un monde o chaque vaccin serait d velopp la vitesse des vaccins contre le sras cov 2... aidez genaiz faire de ce r ve une r alit . rejoignez nous maintenant genaiz, une division d uni3t, est une entreprise jeune et dynamique de d veloppement de logiciels, active dans l industrie pharmaceutique et des sciences de la vie. notre mission est d accro tre le bien tre collectif en acc l rant la cr ation de meilleurs produits, processus et traitements gr ce un assistant l innovateur la pointe de la technologie. nous recherchons actuellement un bio informaticien qui apportera automatisation et innovation aux processus bio informatiques pour les clients. il s agira de mettre en uvre des techniques analytiques standard et d am liorer les techniques existantes. en tant que bio informaticien de genaiz, vous devez aimer documenter votre travail et vos recherches, partager ces connaissances et crire un excellent code, tout en suivant les processus de d veloppement agiles typiques. le g n rique masculin est utilis sans discrimination et uniquement dans le but d all ger le texte. responsabilit s traduire les besoins bio informatiques des clients en solutions innovantes et robustes pr tes pour la production, avec l aide d une quipe. cr er des connaissances et des technologies en s appropriant des projets bio informatiques. agir de mani re ind pendante, en effectuant votre travail sans supervision importante. communiquer et documenter les solutions bio informatiques pour des publics techniques et non techniques. communiquer et documenter la recherche pour des publics techniques et non techniques. rapporter et pr senter des solutions de mani re claire et efficace ses coll gues et la direction. tre un joueur d quipe en participant la r vision par les coll gues, en partageant des id es et en aidant tout le monde r ussir. qualifications une ma trise ou un doctorat en bio informatique, en informatique m dicale, en informatique ou dans un domaine li . 5 ans d exp rience dans l industrie sur des projets bio informatiques multidisciplinaires. exp rience dans la r alisation de recherches, l analyse et la communication des r sultats. quelque exp rience en mati re d exigences op rationnelles. efficacit prouv e travailler avec des donn es biom dicales . capable d crire du code propre, r utilisable et pr t pour la production sur python, r et bioconductor. connaissance des statistiques et des structures de donn es computationnelles telles que les graphes. excellente communication crite, verbale et interpersonnelle. une expertise dans l analyse des r seaux et des voies de communication et dans des analyses similaires. connaissance des donn es string, reactome, kegg et similaires. qualifications pr f r es exp rience avec mongodb, git, gcp, docker, aws, k8s et les micro services. exp rience en prot omique et g nomiques computationnelles. avantages poste permanent temps plein salaire de base comp titif prime couverture d assurance compl te culture d entreprise dynamique avec des possibilit s de d veloppement de carri re horaires de travail flexibles situ entre griffintown et le vieux montr al, dans le quartier de la cit du multim dia, qui fait maintenant partie du p le holistique de montr al pour l innovation, l ducation et l entrepreneuriat le quartier de l innovation. genaiz est un employeur offrant l galit des chances. tous les candidats seront consid r s pour un emploi sans gard l ge, la couleur, aux cong s pour soins familiaux ou m dicaux, l identit ou l expression sexuelle, l tat civil, la condition m dicale, l origine nationale, un handicap physique ou mental, l affiliation politique, la race, la religion, au sexe , l orientation sexuelle ou toute autre caract ristique prot g e par les lois, r glements et ordinogrammes applicables. nous vous remercions de votre int r t. seuls les candidats qualifi s seront contact s. until sars cov 2, the fastest vaccine ever developed took about 4 years. sars cov 2 vaccines were developed in less than 12 months. imagine a world where every vaccine was developed at the speed of sars cov 2 vaccines. help genaiz make this a reality. join us genaiz, a division of uni3t, is a young and dynamic software development company that is active in the life science and pharmaceutical industry. our mission is to increase collective well being by accelerating the creation of better products, processes and treatments, through a state of the art innovator s assistant. we are currently looking for a bioinformatics scientist that will bring automation and innovation to bioinformatics processes for clients. this will involve implementing standard analytic techniques and improving on existing techniques. as a genaiz bioinformatics scientist, you must enjoy documenting your work and research, sharing this knowledge and writing excellent code, while following typical agile development processes. responsibilities translate client bioinformatics needs into innovative robust production ready solutions, with the help of a team. create knowledge and technology by owning bioinformatics projects act independently, completing your work without significant supervision communicate and document bioinformatics solutions for technical and non technical audiences. communicate and document research for technical and non technical audiences. report and present solutions clearly and effectively to peers and management be a team player by participating in peer review, sharing ideas and helping everyone succeed qualifications a master s or phd degree in bioinformatics, medical informatics, computer science or related field 5 years of industry experience on multidisciplinary bioinformatics projects experience completing research, analyzing and communicating results some working knowledge of business requirements experience working with biomedical data able to write clean, re usable, and production ready code on python, r and bioconductor knowledge of statistics and computational data structures such as graphs proven capabilities of network and pathway analysis and similar analyses experience with string, reactome, kegg and similar data excellent written, verbal and interpersonal communication preferred qualifications experience with mongodb, git, gcp, docker, aws, k8s and micro services experience with computational proteomics genomics benefits permanent full time position competitive base salary bonus comprehensive insurance coverage dynamic company culture with career development opportunities flexible working hours located between griffintown and the old montreal, in the cit du multim dia neighborhood, now part of montreal s holistic hub for innovation, education, and entrepreneurship the quartier de l innovation genaiz group is an equal opportunity employer. all applicants will receive consideration for employment without regard to age, color, family or medical care leave, gender identity or expression, marital status, medical condition, national origin, physical or mental disability, political affiliation, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we thank you for your interest, only qualifying candidates will be contacted.","['python', 'gcp', 'statistics', 'data structures', 'bioinformatics', 'git', 'g', 'software development', 'computer science', 'aws', 'mongodb', 'less', 'automation', 'r']","['python', 'gcp', 'git', 'aws', 'less', 'r']","['statistics', 'data structures', 'bioinformatics', 'computational', 'software development', 'computer science', 'agile development', 'mongodb', 'automation']","['education', 'genomics', 'entrepreneurship', 'art', 'regulations', 'insurance']"
406,517,Azure Data Engineer with ADF,"hello, please go through below job description and let me know your interest. role azure data engineer with adf location boca raton, fl or milwaukee, wi or remote duration 12 month job details must have skills 1. adf 2. data bricks 3. hive detailed job description has to work on pipeline, data ingestion framework and data transformation framework. experience in azure platform, big data, cloud technologies developing and maintaining solutions to integrate data from various data sources testing the code using testing document as per the testing methods. deploying the code using deployment group possess knowledge on data lake, and reporting tools support uat testing during business hours, help users on the data extract needed for dashboard validation respond users on the query, issue and clarification. interact with clients for plans, specifications and effort estimates for development and support work. thanks sumit talekar sr. technical recruiter usa canada silverlink technologies llc job types full time, permanent, seasonal pay 60.00 65.00 per hour schedule 8 hour shift experience azure adf 4 years data engineer 7 years azure data bricks 5 years work remotely temporarily due to covid 19","['go', 'dashboard', 'data transformation', 'testing', 'reporting', 'specifications', 'big data', 'hive']","['go', 'hive', 'dashboard', 'big data']","['data transformation', 'data ingestion', 'testing', 'reporting', 'specifications']",['validation']
407,518,Research Scientist - Primary Cell Culture,"abcellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking an experienced scientist with a strong background in primary cell culture and media development to join our discovery team. this role offers the exciting opportunity to contribute to the development of technologies for therapeutic antibody discovery from natural immune repertoires, while working in one of canada s top biotech companies. we are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. if you re highly motivated, self directed, and a team player who thrives in a fast paced and focused environment, we d love to hear from you. the candidate should have exceptional organizational and collaborative skills, be able to multitask, problem solve, think critically, and demonstrate scientific rigor. how you might spend your days developing and optimizing culture and media conditions for diverse species and tissues for therapeutic antibody discovery innovating and refining the tools and approaches for measuring successful implementation of new media and cell culture protocols working with project leads and specialized teams to support, optimize and troubleshoot the development of protocols for high throughput antibody discovery coordination and support of a multidisciplinary r d group focused on multiple parallel goals, including tracking progress of individual projects and managing group priorities performing literature reviews and reviewing project data to identify areas of improvement or innovation that will ultimately improve antibody discovery and other parallel technologies liaising and coordinating joint projects and technologies with other r d groups including enrichment, immunization, assay development, immune repertoire sequencing, and data sciences hands on execution of experiments, including training and supporting developing talent creating and maintaining systems for tracking reagent inventories and resources solving problems at a high level training, mentoring and supervising members of a dynamic team we d love to hear from you if you are experienced in the development and assessment of primary cell culture strategies for culture and in vitro differentiation you think outside the box and excel at identifying and prioritizing key activities you have strong leadership skills and you enjoy mentoring and bringing out the best in your teammates you have exceptional organizational skills you enjoy planning and managing multiple lab based projects you are proficient in the analysis and interpretation of data you thrive in a collaborative environment you take pride in being a self motivated person, fast learner, team player, and creative problem solver required qualifications and experience phd in relevant field or msc plus at least 5 years work experience in primary cell culture or the development of culture protocols and media or associated reagents demonstrated experience and broad expertise across areas of cell biology, cell purification or enrichment, microscopy, molecular biology and data analysis hands on cell culture experience is a requirement excellent documentation and organizational skills proven interpersonal skills with the ability to work collaboratively strong leadership skills, including demonstrated mentorship training experience in immunology is highly desired, but not required offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21123 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['machine learning', 'high throughput', 'documentation', 'data analysis', 'solver', 'automation']","['solver', 'documentation']","['machine learning', 'high throughput', 'micro', 'data analysis', 'automation', 'planning']","['purification', 'environment', 'sequencing', 'reagents', 'antibodies', 'genomics', 'reagent', 'drug discovery', 'biology', 'cell culture', 'literature', 'assessment', 'r', 'cell', 'compensation', 'microscopy', 'assay', 'immunology', 'in vitro', 'molecular', 'immunization', 'mentoring']"
408,519,Research Scientist - Cell Biology & Assay Development,"abcellera is a vibrant, rapidly growing company nestled in the heart of vancouver. we are seeking an experienced scientist with a strong background in mammalian cell biology and assay development to join our dynamic cell screening team. this role offers the exciting opportunity to contribute to therapeutic antibody discovery from natural immune repertoires using cutting edge technologies, while working in one of canada s top biotech companies. we are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. if you re highly motivated, self directed, and a team player who thrives in a fast paced and focused environment, we d love to hear from you. how you might spend your days working with our highly motivated team on projects related to the identification of high quality antibodies. the scope of the work may include the development of in vitro assays that include various mammalian cell lines and primary cells, design of in vivo experiments, development of media conditions and or or enrichment strategies for primary cells, and design of complex functional assays optimizing and troubleshooting the development of screening assays for high throughput antibody discovery and antibody validation developing assays and cutting edge technologies for antibody discovery against challenging targets designing, planning, and executing experiments, either independently or in collaboration with your teammates analyzing and presenting data to colleagues and partners solving problems at a high level liaising with partners and communicating project updates and deliverables training, mentoring and supervising members of a dynamic team maintaining and implementing standard operating procedures while recognizing opportunities for improvements and innovation organizing, supporting and collaborating with other team members to meet project deliverables and timelines we d love to hear from you if you thrive in a collaborative environment you enjoy mentoring and bringing out the best in your teammates you enjoy working in a fast paced work environment and coordinating with your team to juggle multiple competing priorities you take pride in being a self motivated person, fast learner, team player, and creative problem solver required qualifications and experience post doc or phd in relevant field, or msc plus at least 5 years work experience in relevant field demonstrated experience in cell biology and data analysis experience with mammalian cell culture and cell based assay development excellent communication and presentation skills excellent documentation and organizational skills impeccable attention to detail proven interpersonal skills with the ability to work collaboratively strong leadership skills experience in immunology, infectious disease, development of antibody based assays, flow cytometry or microscopy offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please submit your application through our website and refer to job id 2015 in your cover letter. only applicants selected for an interview will be contacted.","['machine learning', 'high throughput', 'screening', 'troubleshooting', 'documentation', 'data analysis', 'solver', 'automation']","['solver', 'documentation']","['machine learning', 'high throughput', 'micro', 'screening', 'troubleshooting', 'data analysis', 'automation', 'planning']","['cell', 'validation', 'environment', 'immunology', 'cytometry', 'biology', 'antibodies', 'in vitro', 'microscopy', 'genomics', 'design', 'cell culture', 'compensation', 'drug discovery', 'mentoring']"
409,520,Research Scientist - Cell Enrichment & Flow Cytometry,"abcellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking an experienced scientist with a strong background in mammalian cell biology, immunology and cell enrichment strategies to join our dynamic discovery team. this role offers the exciting opportunity to contribute to therapeutic antibody discovery from natural immune repertoires using cutting edge technologies, while working in one of canada s top biotech companies. we are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. if you re highly motivated, self directed, and a team player who thrives in a fast paced and focused environment, we d love to hear from you. how you might spend your days working with our dynamic team on developing and optimizing innovative cell enrichment strategies using flow cytometry, cell sorting or other cell separation technologies contributing to our antibody discovery campaigns by advising on the design of enrichment strategies and helping hands on in their implementation designing, planning, and executing experiments, either independently or as a member of various cross functional teams spanning a wide expertise range developing cutting edge molecular, cellular and functional assays to assess enrichment strategies analyzing and presenting data to key stakeholders maintaining and implementing standard operating procedures while recognizing and addressing opportunities for improvements and innovation training, mentoring and supervising members of a dynamic team organizing, supporting and collaborating with other team members to meet project deliverables and timelines we d love to hear from you if you thrive in a collaborative environment you enjoy mentoring and bringing out the best in your teammates you enjoy working in a fast paced work environment and coordinating with your team to juggle multiple competing priorities you take pride in being a self motivated person, fast learner, team player, and creative problem solver required qualifications and experience msc or phd in relevant field with at least 5 years work experience in cell biology, immunology and cell enrichment strategies strong experience in multicolor flow cytometry , cell sorting, or other cell separation technologies demonstrated experience in developing innovative cell enrichment strategies experience with mammalian tissue isolation and processing, cell culture and cell based assay development strong troubleshooting and decision making skills in a fast paced environment excellent data analysis and interpretation skills excellent communication and presentation skills excellent documentation and organizational skills impeccable attention to detail proven interpersonal skills with the ability to work collaboratively strong leadership skills background in b cell immunology, experience in imaging, microscopy and development of antibody based assays. offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 3 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21118 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['machine learning', 'high throughput', 'troubleshooting', 'documentation', 'data analysis', 'solver', 'automation']","['solver', 'documentation']","['machine learning', 'high throughput', 'troubleshooting', 'data analysis', 'automation', 'planning']","['environment', 'immunology', 'microfluidics', 'biology', 'antibodies', 'genomics', 'design', 'molecular', 'mentoring', 'campaigns', 'compensation', 'drug discovery', 'cytometry']"
410,522,"Manager, Customer Data Platform","this role requires a broad understanding of marketing technologies, crm and integrations of customer data platforms to consumer facing applications such as customer interactions hubs, emails, chat bots, web personalization, call centers, and analytics tools. this position is the subject matter expert for the cdp. you will be responsible for creating and owning a vision that aligns to business priorities and delivering that vision through providing overall direction, planning, coordination, execution, monitoring, and control of our customer data. this role requires strong partnership and interactions with senior executive management, business stakeholders , data scientists, engineering, and it organizations. the person must be able to work at a detail level, when needed, to identify issues, risks, root causes, develop mitigation strategies and solutions, and identify and track actions to closure. the candidate must be articulate, be able to effectively and openly communicate with management, raise issues and risks quickly, and help develop solutions. essential job duties and responsibilities drive customer data platform vendor assessment workshops obtain requirements from different and global business stakeholders and create a product roadmap for the cdp implement best in class cdp system work with various marketing teams in order to create ideal customer profiles based on cdp data responsibility for assisting marketing campaigns with segmentations derived from cdp ad hoc reporting and data analysis essential job qualifications 2 years experiences in cdp, analytics, data driven marketing, and digital transformation experience in data architecture and data modeling experience working with various marketing technologies , sfdc, paid media, social, and offline data proven success through partnership and collaboration with a cross functional team proven ability to set strategic direction and drive high quality execution strong track record of managing large technology initiatives and delivering capabilities that drive business growth solid understanding of segmentation for marketing purposes excellent team player with the ability to influence and negotiate highly adaptable to changing environment disclaimer the above statements are intended to describe the general nature and levels of work being performed by people assigned to this classification. they are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. quadient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.","['personalization', 'reporting', 'vendor assessment', 'analytics', 'data', 'data analysis', 'modeling', 'crm', 'customer data', 'digital transformation']",[],"['personalization', 'reporting', 'web', 'digital transformation', 'data analysis', 'analytics', 'data', 'modeling', 'crm', 'customer data', 'ad hoc', 'planning']","['global business', 'law', 'environment', 'marketing', 'executive management', 'marketing campaigns', 'assessment', 'workshops', 'architecture', 'business growth']"
411,523,Data Engineer,"type full time, permanent career level experienced category information technology about company marine thinking is a young, agile, dynamic team in the artificial intelligence and robotic technologies industry. we partner with businesses across atlantic canada and west coast marine industries, advancing and improving processing factories workflow, work efficiency and driving higher production efficiency. our technology at marine thinking aims to protect the environment and strengthen the sustainable development of the marine industry. we are looking for motivated, energetic and talented data engineer to join us to support ai team to design, build and maintain our big data platform, help to implement and scale machine learning models to solve real world problems. duties responsibilities design, care, and feeding of our big data environments built upon technologies in the hadoop ecosystem discover and solve real world problems by analyzing large amounts of ocean and sensor data collaborate with the development team to design simulations and experiments and create models investigate and characterize non trivial issues in various environ, identify problems and provide solutions on marine related projects work on data modelling, discovering insights, and identifying opportunities through the use of statistical, algorithmic, data mining, and visualization techniques customize and manage integration tools, databases, and analytical systems manage and structure data, including performance optimization, database optimization and stream processing day to day troubleshooting of problems and performance issues in our clusters validate system configurations from hardware layer to hadoop application layer prepare technical documents in clear, concise writing perform project delivery activities such as undertaking and organizing data collection and survey fieldwork, data and literature review willingness to mentor and teach people around you qualifications bachelor s degree in computer science or a closely related computer technical field and 3 years of hadoop administration experience or comparable work experience intimate and extensive knowledge of linux administration and operational practices must have experience with monitoring tools used in the hadoop ecosystem such as nagios and ambari experience in designing, implementing and administering large , highly available hadoop clusters experience with modern data pipelines, data streaming, and real time analytics using tools such as apache kafka, spark streaming, or similar tools experience with containerization is a plus in depth knowledge of capacity planning, management, and troubleshooting for hdfs, yarn or mapreduce, hbase understanding cluster capacity and bottlenecks, basics of memory, cpu, os, storage, and networks experience in data management, analysis and model modification proficiency in a scientific computing language must demonstrate practical experience of data management, data analysis, mapping and data standards and associated software ability to handle time pressures, managing own time to accomplish required results within deadlines strong technical writing abilities ability to communicate effectively, orally and in writing ability to understand and set priorities among multiple work tasks ability to work independently as well as, work well with others exceptional communication skills, both written and verbal attention to detail job types full time, permanent benefits dental care extended health care vision care schedule monday to friday","['computing', 'visualization', 'databases', 'linux', 'troubleshooting', 'data standards', 'big data', 'information technology', 'containerization', 'technical writing', 'data streaming', 'software', 'database', 'analytics', 'integration', 'nagios', 'data mining', 'machine learning', 'data pipelines', 'stream processing', 'data collection', 'artificial intelligence', 'data analysis', 'hardware', 'apache kafka', 'model', 'administration', 'hadoop', 'simulations', 'computer science', 'optimization', 'capacity planning', 'data management', 'cluster', 'ai']","['databases', 'linux', 'hadoop', 'nagios', 'data standards', 'big data', 'containerization', 'hardware', 'apache kafka']","['computing', 'visualization', 'analytical systems', 'troubleshooting', 'information technology', 'data streaming', 'software', 'analytics', 'integration', 'data mining', 'machine learning', 'data pipelines', 'performance', 'stream processing', 'data collection', 'artificial intelligence', 'data analysis', 'scientific', 'administration', 'technical', 'simulations', 'computer science', 'optimization', 'capacity planning', 'data management', 'cluster', 'ai']","['environment', 'project delivery', 'design']"
412,524,IT Expert - Backend/Java/Data,"position it expert duration permanent full time location mississauga office it expert who will innovate healthcare we are the it centre for roche a company in top 10 biggest r d spenders worldwide. we do code4life to create innovative software that helps doctors, patients and scientists around the world. we are looking for it expert who has bachelor s or master degree or equivalent work experience minimum 6 years of work experience related to custom software development in enterprise projects expert knowledge in java technologies knowledge of other jvm based programming languages and frameworks like java sdk, spring, rest, data persistence excellent knowledge of database technologies like sql, nosql and graph databases knowledge and hands on experience with warehousing solutions, etl processing and data pipelines knowledge and hands on experience with apache spark, hadoop, or equivalent big data processing technologies and tools fluency in the usage of cloud computing models , good knowledge of modern architectures , tools and practices , all connected with devops mindset excellent knowledge of modern development tools like intellij, git, jira, etc. experience in driving cross organizational initiatives related to custom software development model implementation and rising maturity in this area ability to design solutions and independently solve complex problems within the framework of own duties and assisting others in this respect knowledge of and ability to put standards and good practices in scope of designing architecture of it solutions into effect. leadership skills strategic thinking, management level communication and influencing skills within peers, partners and upwards motivation to learn and develop new skills, fast learner responsible and reliable, goal and task oriented. this position is not eligible for relocation support. all employment is conditional upon the completing and obtaining a satisfactory background check, including educational, employment, references and criminal records checks. agency notice please note that roche canada does not accept unsolicited resumes from recruiters or employment agencies. in the absence of a signed services agreement with agency or recruiter, roche canada will not consider or agree to payment of any referral compensation or recruiter fee. in the event a recruiter or agency submits a resume or candidate without a previously signed agreement, roche canada explicitly reserves the right to pursue and hire those candidate without any financial obligation to the recruiter or agency.","['databases', 'java', 'sql', 'data processing', 'software', 'software development', 'development tools', 'cloud computing', 'nosql', 'data pipelines', 'apache spark', 'graph', 'rest', 'jvm', 'jira', 'programming languages', 'devops', 'hadoop', 'git', 'etl']","['jvm', 'sql', 'databases', 'jira', 'programming languages', 'java sdk', 'apache spark', 'hadoop', 'big', 'git', 'java', 'nosql', 'r']","['it solutions', 'data pipelines', 'data processing', 'software', 'devops', 'software development', 'development tools', 'rest', 'cloud computing', 'etl']","['healthcare', 'design', 'architecture', 'compensation', 'refer']"
413,525,Scientifique Principal - Immunologie / Principal Scientist - Immunology,"sommaire le scientifique principal chez cellcarta, au sein de l unit d affaire immunecarta, est le lead scientifique pour les tudes en immune monitoring en support aux essais cliniques et aux tudes pr cliniques. le scientifique principal participe au design, au d veloppement et la validation des essais in vitro. de plus, il est le premier point de contact avec les sponsors, leurs fournissant un sommaire des donn es, des pr sentations et des rapports. il participe aussi au troubleshooting. finalement, le scientifique principal est en charge des aspects scientifiques et r glementaires des tudes en immune monitoring. principales responsabilit s supervise la planification et l avancement des tudes et des projets sous sa responsabilit r alise et pr pare des plans de travail sp cifiques aux tudes et pr pare les documents justificatifs pour les essais et les protocoles de suivi de la r ponse immunitaire discute avec la direction et obtient les approbations n cessaire, le cas ch ant participe l laboration de nouveaux tests in vitro selon les besoins des clients, y compris la phase qualification et validation des essais travaille en troite collaboration avec le personnel du laboratoire affect s ses projets veille ce que les projets soient r alis s selon les d lais tablis ce que les retards soient communiqu s de mani re proactive aux clients avec un plan d action pour r duire les retards au minimum identifie les contraintes de ressources et travaille avec la direction pour les r soudre et am liorer la productivit participe la pr paration des pr sentations et des publications en collaboration avec les clients lorsque cela est possible interagit r guli rement avec les clients, les sites cliniques et la direction de cellcarta pour r soudre sans d lai tout probl me li au projet la satisfaction du client. documente les interactions et les communications li es aux tudes participe activement la pr paration et la conduite des audits pour les clients ou les organismes r glementaires. formation requise ph.d. ou formation quivalente en sciences de la vie, de pr f rence en immunologie, virologie, microbiologie ou biologie mol culaire. exp rience et connaissances exig es un minimum de 5 ans d exp rience dans un poste quivalent en industrie connaissance en immunologie moderne et tre jour concernant la litt rature actuelle, les m thodologies de suivi de la r ponse immunitaire et de la conception et de la r glementation des essais cliniques connaissance et exp rience avec les techniques de cytom trie en flux et les applications g n riques dans le domaine du suivi de la r ponse immunitaire connaissance de la conception de tests, ainsi que la manipulation de donn es complexes d essais de cytom trie multiparam triques connaissance des analyses en milieu cellulaire pour suivre l volution des r ponses immunitaires acquises et naturelles exp rience de travail avec les logiciels d analyse de donn es en cytom trie en flux et d analyse statistiques connaissance et compr hension suffisantes des normes glp et d autres directives r glementaires pour effectuer des tudes glp excellentes aptitudes de communication avec des collaborateurs internes et les clients exp rience en gestion de projets et faire preuve de solides aptitude en planification et organisation parle couramment le fran ais et l anglais . approche de travail m thodique et syst matique capable d tablir des priorit s d montre et applique un niveau avanc de compr hension et de comp tences analytiques pour interpr ter les donn es et en tirer des conclusions dans les objectifs du projet d montre un esprit critique et cr atif communique clairement et avec confiance et poss de d excellentes comp tences interpersonnelles capacit travailler sur plusieurs t ches en m me temps dans un environnement dynamique. conditions de travail doit tre dispos exercer des fonctions ou superviser des activit s dans des installations de niveau de s curit biologique 1 ou 2 o les chantillons biologiques peuvent tre soit naturellement ou exp rimentalement infect s par des virus potentiellement dangereux tels que le vih, le vhc ou le cmv. summary the principal scientist is responsible for the overall conduct of studies in different immune therapeutic area, overseeing experimental testing design, as well as formulating conclusions and recommendations for next steps. the incumbent has the ability to present cellcarta capabilities to clients in a compelling way demonstrating value and differentiation as support function to business development activities as well as presentation of results to sponsor and scientific meetings. the incumbent is ensuring that the timelines and milestones of a study are met by proactively assessing foreseeing challenges, assessing impact of deviations and overall quality of the study conduct. main responsibilities oversees the planning and progress of studies and projects under her or his responsibility designs and prepares detailed study specific work plans and support documentation for protocols and assays discusses with management and obtains approval as appropriate participates in the development of new in vitro assays as per client needs, including the assay qualification and validation phase instructs laboratory personnel assigned to her or his projects ensures that projects are conducted as per established timelines and delays are communicated in a proactive manner to clients with action plan to minimize the delays identifies resource constraints and inefficiencies and works with management to resolve prepares preliminary and final reports ensures that all study related data is appropriately maintained and archived participates in the preparation of presentations and publications in collaboration with clients when possible interacts regularly with clients, clinical sites and cellcarta management to address project issues in a timely manner and to the satisfaction of the client. documents study related interactions and communications properly actively participates in the preparation and conduct of audits for clients or regulatory bodies. education ph.d. or equivalent training in life sciences, preferably in immunology, virology, microbiology or molecular biology. experience and skills required a minimum of 2 years experience in an equivalent position in the industry or in an academic environment knowledge and experience with multi parametric flow cytometry techniques and its generic applications in the field of im including testing design as well as handling complex data set of multi color panels knowledge of modern immunology and kept abreast with current literature, im methodologies and clinical trial design and regulations knowledge of cell based assays to monitor adaptive and innate immune responses experience working with flowjo, pestle, spice, prism and excel knowledge and understanding of glp regulations and other regulatory guidelines sufficient to carry out glp studies experience in project management experience with client management strong communication ability approaches work methodically and systematically establishes priorities from among a number of demands demonstrates and applies advanced level of understanding and analytical skills to interpret data and draw conclusions within the project goals critical and creative thinker communicates clearly and confidently and has excellent interpersonal skills skilled at working in a fast paced and multi tasking environment. eaviggh2bf","['analytical skills', 'experimental', 'spice', 'testing', 'troubleshooting', 'documentation', 'r']","['spice', 'prism', 'documentation']","['analytical skills', 'experimental', 'tests', 'testing', 'troubleshooting', 'installations', 'planning']","['business development', 'environment', 'glp', 'project management', 'microbiology', 'education', 'biology', 'cytometry', 'validation', 'regulatory guidelines', 'design', 'presentations', 'life sciences', 'immunology', 'vitro', 'in vitro', 'molecular', 'regulations', 'virology']"
414,526,Data Engineer,"role details reporting to the director of machine learning artificial intelligence, the data engineer will be responsible for the development and deployment of etl processes, data management, data warehousing and more in the automotive digital advertising industry. lotlinx is looking for a candidate that has talent with data to improve, optimize and lead further development of our data aggregation processes. required skills bs degree in computer science or related technical field, or equivalent practical experience. strong analytic skills related to working with unstructured datasets. solid understanding and working knowledge of relational or non relational databases. proficiency in a major programming language and or or a scripting language . 3 years experience with data gathering, data pipelining, data standardization, data cleansing, stitching aspects. innately curious and organized with the drive to analyze data to identify deliverables, anomalies, and gaps and propose solutions to address these findings. responsibilities work with stakeholders including analytics, product, and design teams to assist with data related technical issues and support their data infrastructure needs. engineer solutions for large data storage, management, and curation of training data models. explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities. act as an internal expert in each of the data sources so that you can own overall data quality. design, build and deploy new data models, etl pipelines into production and data warehouse. define and manage overall schedule and availability of all data sets. about lotlinx lotlinx is a leading automotive saas data company, utilizing ai powered technology to provide our clients with an end to end vehicle management and marketing system. we are experiencing tremendous growth and have an exciting opportunity for an intermediate to senior developer located in canada. our offices are currently in winnipeg, mb, and hamilton, on but given current circumstances are open to any remote location in canada. lotlinx provides employees with a dynamic work environment that is challenging, team oriented, and full of passionate people. we offer great incentives to our employees, such as competitive compensation and benefits, flex time off, and excellent career development opportunities.","['data infrastructure', 'cleansing', 'automotive', 'reporting', 'scripting', 'analytics', 'programming', 'saas', 'data models', 'pipelines', 'data aggregation', 'data warehousing', 'machine learning', 'relational databases', 'artificial intelligence', 'data quality', 'datasets', 'scalability', 'computer science', 'data management', 'etl', 'ai']","['data quality', 'programming', 'pipelines', 'data models']","['data infrastructure', 'cleansing', 'automotive', 'reporting', 'scripting', 'analytics', 'saas', 'data aggregation', 'data gathering', 'data warehousing', 'unstructured', 'machine learning', 'relational databases', 'artificial intelligence', 'data storage', 'datasets', 'scalability', 'computer science', 'data management', 'etl', 'ai']","['environment', 'advertising', 'incentives', 'marketing', 'design', 'compensation']"
415,527,Data engineer,"about q4 at q4, we hustle, we grind and we grow. as the team members that make up q4orce, we care, we compete and we support each other every day. we re on a mission to deliver a best in class client experience driven by technology, data, and of course, our people. as the leading provider of website, analytics and virtual events solutions to investor relations and the capital markets, q4 is a trusted partner to over 2,400 of the world s most successful public companies and institutions and we are growing at an incredible pace. we re on our way to becoming the largest capital markets platform company in the world. that s where you come in. we hire smart, curious, and talented people to push boundaries, reimagine what s possible and turn challenges into opportunities, all while keeping the needs of our clients at the heart of everything we do. this is your opportunity to be a part of something special. join us the gig. the data engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. the data engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. they must be self directed and comfortable supporting the data needs of multiple teams, systems and products. the right candidate will be excited by the prospect of optimizing or even re designing our company s data architecture to support our next generation of products and data initiatives. key responsibilities create and maintain optimal data pipeline architecture. assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws big data technologies. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. keep our data separated and secure through multiple data centers and aws regions. create data tools for analytics and different team members that assist them in building and optimizing our product into an innovative industry leader. requirements bachelor s degree in computer engineering or a related field required, or equivalent education advanced working sql knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. strong analytic skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. working knowledge of message queuing, stream processing, and highly scalable big data data stores. strong project management and organizational skills. experience supporting and working with cross functional teams in a dynamic environment. experience with relational sql and nosql databases, including postgres and cassandra. experience with data pipeline and workflow management tools experience with aws cloud services ec2, emr, rds, redshift experience with stream processing system analytical mind, critical thinker, problem solver understanding of the financial services industry and global capital markets why q4 we are motivated by solving complex problems in unorthodox ways. emphasis on your well being means you experience your true potential. we offer a variety of benefits to ensure you can always work hard and have fun health, wellness and lifestyle benefits to balance your heart, mind, and body. pension matching and employee equity incentives to support your financial health. unlimited paid time off so you can be really recharge and enjoy life. enough said. flexible working environment. choose your home, one of our trendy offices or mix it up. virtual team building and socials. keeping people connected is important. and an amazing culture to top it all off join q4orce a career at q4 means joining a team that thrives in a fast paced, high growth environment one that is focused on providing growth opportunities, encouraging diversity inclusion and working to inspire an entrepreneurial spirit. we re thrilled to be able say that the q4 team and culture have even won some awards along the way including being recognized as one of canada s best workplaces for women and technology. q4 values diversity and people of all backgrounds and abilities. should you require any accommodations prior to or during the interview process, please contact","['databases', 'data flow', 'workflow management', 'emr', 'operational efficiency', 'big data', 'sql', 'software', 'queuing', 'analytics', 'data', 'aws', 'data systems', 'solver', 'nosql', 'relational databases', 'data transformation', 'computer engineering', 'stream processing', 'data centers', 'metadata', 'cassandra', 'cloud services', 'data structures', 'datasets', 'scalability', 'root cause analysis']","['sql', 'big data data', 'databases', 'emr', 'data centers', 'aws', 'big data', 'rds', 'solver', 'nosql', 'cassandra']","['data flow', 'workflow management', 'operational efficiency', 'software', 'queuing', 'analytics', 'data', 'data systems', 'unstructured', 'relational databases', 'data transformation', 'computer engineering', 'stream processing', 'metadata', 'cloud services', 'data structures', 'datasets', 'scalability', 'root cause analysis', 'relational sql']","['environment', 'events', 'customer acquisition', 'education', 'metrics', 'incentives', 'design', 'project management', 'team building', 'financial services', 'capital markets', 'business performance', 'architecture']"
416,530,Data Engineer - ETL (Insights),"data engineer etl adgear , is an advanced advertising technology company located in the heart of downtown montreal. adgear or samsung ads focuses on enabling brands to connect with samsung tv audiences as they are exposed to digital media across all devices. being part of an international company such as samsung and doing business around the world means that we get to work on big complex projects with stakeholders and teams located around the globe. samsung ads is an advanced advertising platform where advertisers find and connect with audiences across over 100m samsung households around the world. samsung ads delivers high quality audience targeting powered by three key components first party audience data at scale, world class data science, and brand safe cross device ad inventory. using our data, insights, and scale, we help advertisers reach consumers across ctv, our native apps, mobile and desktop. with samsung ads, advertisers can buy the way they want, reach who they need, and prove business results. our purpose is to deliver unparalleled results for our customers. by using the industry s most comprehensive data to build the world s smartest connected audience platform, samsung ads is uniquely positioned to transform the advertising landscape. we deliver on samsung electronics 51 year commitment to excellence through smart, easy, effective advertising solutions to make advanced video advertising work. about reporting and insights our group is responsible for developing a cohesive set of powerful reporting insights features to empower our service and analytics teams, as well as inform our customers. our playground includes reporting facilities and dashboards to serve both internal and external users as well as various etl pipelines ingesting 1 terabyte of data per hour, around the clock. our tech stack includes a mixture of java or scala or akka, spark, hive, aws athena or rds, emr, vertica, kafka, airflow, concourse, docker and kubernetes. what you ll do as a data engineer, you will be designing and developing etls and data processing pipelines at scale. as a consequence, there will be opportunities to contribute to open source, conduct research and development, review code, participate in shaping our engineering practices and share knowledge. you will work with some incredibly talented and passionate developers within an engineering team with a strong technological background. you will also interact on a day to day basis with software engineers, scrum masters and product owners. in this position, the chosen candidate is expected to have a hands on, problem solving approach and a friendly human facing side to communicate and manage expectations. key responsibilities develop and maintain etl pipelines develop and maintain streaming jobs develop and maintain data extraction tools occasionally provide ad hoc data required skills and or or experience prior experience in a similar role experience in java, scala, python, bash, c, etc. solid understanding of unix or linux systems prior experience in streaming technologies like akka, kafka or spark streaming prior experience in airflow prior experience in working in a agile environment good communication skills and capacity or willingness to work in a multi teams environment. be resourceful, inventive and passionate you are eager to challenge the status quo and willing to learn new programming languages demonstrated ability to prioritize tasks and resolve problems in a timely manner ability to work autonomously, multi task and work in a fast paced and stressful environment be proactive, addressing potential problems before they occur attention to detail problem solving outlook, can do attitude is a must the candidate should thrive in a fast paced and dynamic environment and effectively handle working across different teams and priorities. the candidate should have an entrepreneurial mind set, taking ownership in creating opportunities, aligning to the yearly plan but also being flexible to take advantage of new opportunities. if you re interested in joining a rapidly growing team working to build an outstanding, world class advertising organization with a relentless focus on design and customer experience, you ve come to the right place. about our culture we are proud to have built a world class organization, grounded in an entrepreneurial and collaborative spirit. working at samsung ads offers one of the best environments in the industry to learn just how fast you can grow, how much you can achieve, and how good you can be. we thrive on problem solving, breaking new ground, and enjoying every part of the journey. 1rzubpnecf","['bash', 'linux', 'emr', 'dashboards', 'c', 'electronics', 'hive', 'java', 'kubernetes', 'python', 'agile environment', 'data processing', 'scala', 'software', 'reporting', 'data science', 'unix', 'analytics', 'aws', 'pipelines', 'scrum', 'athena', 'airflow', 'programming languages', 'data extraction', 'akka', 'vertica', 'etl']","['kubernetes', 'python', 'linux', 'emr', 'scala', 'programming languages', 'athena', 'akka', 'c', 'unix', 'aws', 'rds', 'pipelines', 'electronics', 'hive', 'java', 'vertica', 'airflow']","['agile environment', 'bash', 'data processing', 'software', 'data extraction', 'reporting', 'scrum', 'dashboards', 'data science', 'analytics', 'etls', 'etl']","['environment', 'advertisingge', 'advertising', 'digital media', 'design', 'customer experience']"
417,533,Product Manager and Data Scientist,"you will own, from a product management perspective, the successful definition and delivery of our new api services. you will work closely with our r d department and ensure project execution, profitability and customer satisfaction. you will join a team of very skilled, talented and passionate people, always bringing the software industry best practices to our workflow. the ideal candidate has a good business acumen and has previously been exposed to data analytics, data science, has evolved into a product management role and is at ease in speaking both technical and business languages. your impact gather business requirements and use cases from customers, sales and customer service. use this data in the roadmap strategy. prioritize the roadmap deliverables and secure required development resources to ensure timely delivery of those roadmap items. track roadmap execution plan accordingly and teams alignment around implementation trade offs that might be required. translate the data gathered to build a case for decisions presented in the roadmap. champion the product vision and strategy, exhibiting good product judgement, continuously setting clear and measurable objectives and monitoring the product s progression to achieve these. communicate this strategy to all the relevant participants and stakeholders. support pm leadership for pricing work with the r d teams to define functional architecture, processes, and development efforts required for the delivery of api services. here s what your day to day will look like in this role maintain an understanding and knowledge of the competition including competition analysis. research and analyse market, the users, and the roadmap for the product define product vision, road map and growth opportunities plan and prioritize product feature backlog and development for the product provide backlog management, iteration planning, and elaboration of the user stories provide commercial input into pricing and marketing strategies attend conferences and exhibitions, meeting with customers and agents. work closely with the sales team on rfis, rfps, itts and provide technical input in relation to bids, proposals etc. accompany area sales managers on prospective customer visits assist in identifying and qualifying opportunities. regular interactions with existing customers with pro active visits, educational sessions, seminars, webinars and workshops to promote the full and effective use of the software and data to assist with implementation of api services on customer vessels both remotely and hands on and the management of customer sea trials work with the marketing department to produce and maintain technical manuals, user guides, marketing material and computer based training. requirements technical expertise regarding data models, database design development, data mining and segmentation techniques knowledge of and experience with reporting packages , databases , programming knowledge of statistics and experience using statistical packages for analyzing datasets strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy adept at queries, report writing and presenting findings bs in mathematics, economics, computer science, information management or statistics or an equivalent experience. a strong technical background in product management, operations or sales and the ability to progress deals or other relevant experience. outstanding communication, presentation and leadership skills great problem solver who can think through problems and develop solutions quickly. training will be provided but the ability to quickly absorb information and understand and communicate usps and product differentiation is essential. must be willing and able to travel on a global basis fluent spoken and written english this role can be based out of our head office in enfield, uk or from our montreal office in canada. what about us we have successfully completed a large merger and have become the leader in a tight maritime market. now we want to act accordingly by reworking our product line, investing in long term technology to provide our customers the best solutions. we want to transform our field into a smarter, leaner maritime industry. we are designing our new products generation using the latest innovative technologies with web applications and apis deployed to more than 10,000 users worldwide. we are structured in autonomous and agile squads where the status quo is prohibited and in which everyone has a word in the organization, architecture, or design of the product. if building our future generation of software, making life easier for ship owners, ship managers and crews and resolving navigation challenges to revolutionize the maritime world inspires you, send us your application benefits friday innovation s afternoons, continuous learning policy, open source initiatives, publication of tech articles beautiful and well located office with secure bike room and showers extended healthcare plan rpp group rrsp group life ad d critical illness insurance paid time off benefits work from home flexible hours training development employee assistance program counseling what you need to get cosy","['analytical skills', 'databases', 'map', 'data analytics', 'navigation', 'statistics', 'product vision', 'software', 'reporting', 'data science', 'database design', 'product management', 'programming', 'product', 'data models', 'solver', 'data mining', 'web applications', 'information management', 'economics', 'datasets', 'api', 'computer science', 'mathematics']","['databases', 'product vision', 'api', 'programming', 'data models', 'solver', 'map', 'r']","['analytical skills', 'database design development', 'data analytics', 'navigation', 'statistics', 'software', 'reporting', 'data science', 'product management', 'data mining', 'web applications', 'information management', 'planning', 'use cases', 'economics', 'functional', 'datasets', 'computer science', 'report', 'mathematics']","['investing', 'manuals', 'maritime', 'healthcare', 'counseling', 'marketing', 'material', 'design', 'sales', 'customer service', 'insurance', 'customer satisfaction', 'exhibitions', 'workshops', 'architecture']"
418,535,Staff Data Engineer,"open canada or engineering data or full time textnow is based around a simple idea communication belongs to everyone. we work hard to help people stay connected by offering a solution that makes phone service free. at textnow, we work together to solve complex and interesting problems that have a positive impact on our customers lives. join us in our mission to help people stay connected with technology that is free textnow is looking for a staff data engineer with hands on experience designing and developing real time data platforms. you ll be a central figure in evolving the design, architecture and performance of textnow s data platform. you ll lead cross functional efforts with sre, product, backend engineering and data science to build a next level data platform that scales and supports all textnow s business and data product. this is a senior level position and accordingly, you re expected to be a technology thought leader throughout the org. what you ll do play a key role in building out a large scale, distributed, and event based data platform that serves as an underpinning for all textnow s business and data products. lead product requirements and advanced technical requirements gathering efforts, interfacing with data engineering, data scientists, analytics, and stakeholder teams. recommend and advise to improve data reliability, efficiency, and quality. build a scalable technology platform to support a growing business. explore available technologies and design solutions to continuously improve our data quality, workflow reliability, and scalability. perform capacity planning and cost estimates of proposed solutions. be a champion of textnow s data ecosystem by working with engineering and sre to guide data strategy for governance, security, privacy, quality and retention that will satisfy business policies and requirements. be an expert on big data technologies e.g., spark, kafka, presto, delta lake, etc. advise team on engineering best practices around ci or cd, secure coding, etc. enable real time data applications by designing machine learning based real time data services. drive data team to adopt industry best practices in data platform engineering. mentor other data engineers or interns on the data team. who you are creator of cool stuff that will be instrumental in building a modern data platform that is used for multiple internal use cases e.g., monetization, personalization, finance, data science, data engineering, user acquisition. brilliant collaborator with 10 years of experience in data engineering and or or data infrastructure. experience working with various data stores such as sql, no sql and key value stores . at least 7 years of development experience with python and or or scala. hands on experience with designing real time data streaming pipelines using spark structured streaming, kafka and or or kinesis is preferred. someone who takes action and ownership with hands on experience designing multi tb or pb scaled distributed data systems on cloud infrastructure such as aws. respectfully candid with the ability to initiate and drive projects to completion. highly organized, structured work approach, and dependable. ability to manage and communicate data platform engineering plans to internal partners. a bold risk taker and self starter who proactively sees areas of improvement and drives the change the needed to make it happen. resourceful and scrappy with a keen eye on roi knowledge of ad serving platforms and online advertising systems is a plus. li rs1 benefits strong work life blend flexible work arrangements employee stock options unlimited vacation competitive pay and benefits parental leave top up benefits for both physical and mental well being diversity and inclusion at textnow, our mission is built around inclusion and offering a service for everyone, in an industry that traditionally only caters to the few who have the means to afford it. we believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. we know that if we work together, we can do amazing things, and that our differences are what make our product and company great.","['personalization', 'technical requirements gathering', 'big', 'ci', 'data services', 'data infrastructure', 'data streaming', 'sql', 'python', 'cd', 'scala', 'data science', 'data', 'analytics', 'aws', 'data systems', 'pipelines', 'data engineering', 'machine learning', 'data products', 'data quality', 'security', 'scalability', 'cloud infrastructure', 'capacity planning']","['sql', 'python', 'pipelines', 'scala', 'textnow', 'big data', 'aws', 'data quality']","['personalization', 'technical requirements gathering', 'data services', 'ci', 'data infrastructure', 'data applications', 'data streaming', 'distributed', 'cd', 'data science', 'analytics', 'data systems', 'data engineering', 'machine learning', 'data products', 'product requirements', 'use cases', 'security', 'scalability', 'cloud infrastructure', 'capacity planning']","['user', 'advertising', 'design', 'finance', 'governance', 'architecture']"
419,540,Director- Data Strategy & Analytics,"working under minimal supervision, the director, data strategy analytics, is a business minded individual responsible for understanding the data needs across the enterprise and to develop and execute a roadmap to maximize data capabilities and business insights. the director is responsible for scaling the data function as new products and services are implemented and transforming data into insights that inform strategy and decision making to support profitable growth. job responsibilities guide the future direction of data strategy and processes, including intake, sources, database design and structure, data integrity and database tools. transform data and information into insights that inform high level strategy and tactical decision making in support of revenue and profitability objectives. be a champion for a data driven culture, lead a team of cross functional analysts and support and train staff in data systems and reporting. develop and execute a plan to maximize self service capabilities for internal users and customers. proactively communicate and collaborate with internal and external customers to ensure information needs are formalized and understood and be conversant in the functional requirements for information exchange. oversee internal and external application or tool development, integration and support. where required, supervise and evaluate external consultants. liaising with hsb us, uk and munich re as we forecast our needs, and business requirements. implementing business intelligence and analytics solutions and gaining support of multiple stakeholders. implementing formal data governance approach and increasing the maturity of the enterprise data capability and environment. influencing and effecting business process changes to support an efficient and cost effective business operations environment. driven by technology and fuelled by innovation, hsb is canada s premier specialty insurance and applied technology services provider. offering 150 years of technical and service excellence, we are focusing on emerging trends and unlocking new opportunities for clients. today, we are accelerating, changing the future of insurance and risk solutions, for a modern world. at hsb, we value the strengths and contributions of our diverse workforce. we offer continuous learning opportunities, giving you flexibility to grow in your career while enjoying a healthy work life balance and a collaborative approach in our coast to coast network of offices. become part of a rewarding and impactful workplace experience while seeing first hand technologies and risk solutions that are changing the way we live and work. hsb is much more it s engineering, insurance, technology. to learn more about us, please visit seven years as an analyst, data scientist or data engineer preferably in the property and casualty insurance industry, masters or bachelor s degree in one of the following analytics, business intelligence, data science, economics, engineering or statistics, strategic mindset with demonstrated experience in implementing data frameworks and driving continuous improvement, expert communication skills and ability to influence leadership, experienced manager with focus on coaching and mentoring cross functional team members, knowledge of insurance products, financial metrics used in insurance and industry data sources, exposure to insurance company processes and functions, strong teamwork skills in order to collaborate and build strong relationships with co workers and internal clients to support development and implementation of business solutions, project management skills plans, organizes, motivates, and controls resources to achieve specified project goals and objectives while respecting defined constraints, decision making skills solicits and objectively considers input from appropriate sources considers implications of actions on other areas, people, and processes when deciding, agility adapts approaches that are appropriate for each situation, accepts and adapts to new situations. we thank all candidates for their interest however only those selected for interview will be contacted.","['statistics', 'reporting', 'business insights', 'data integrity', 'economics', 'database design', 'data science', 'enterprise', 'analytics', 'data', 'integration', 'business intelligence', 'data systems', 'technology services']","['technology services', 'business insights', 'business intelligence']","['statistics', 'financial', 'reporting', 'information exchange', 'data integrity', 'economics', 'database design', 'data science', 'analytics', 'data', 'integration', 'data systems', 'enterprise data']","['environment', 'continuous improvement', 'insurance industry', 'metrics', 'business operations', 'project management', 'governance', 'business process', 'emerging trends', 'insurance', 'mentoring']"
420,545,Junior Project Scientist / Junior Project Technician,"junior project scientist or junior project technician why join us this position is based out of our environment geoscience office in fort st. john and reports to a project manager. you will be responsible for supporting our local environment team on a variety of projects in the site assessment and remediation and environmental monitoring sectors. the ideal candidate is a junior environmental engineering professional or recent graduate with an environmental engineering degree or diploma with some previous relevant experience which would be an asset. e g offers consulting services in the following areas land reclamation, environmental studies, environmental impact assessments and social impact assessments, habitat assessments and compensation, aquatic life assessments, air quality assessments and greenhouse gas emissions, carbon credits, sustainability, environmental management and planning, geographic information systems, contaminated sites, waste management, mining, water distribution and treatment, pollution control and rural development. our offices are located in attractive regions of bc, with quick access to arts culture and a variety of outdoor activities including mountain biking, skiing, hiking, hunting, and water sports. snc lavalin offers a flexible work schedule and a relaxed office environment. how will you contribute to the team work directly with project managers and other project team members to meet client deliverables on time and on budget. conduct local and remote field work as directed on a diverse range of sites, with a focus on health safety. execution of field programs including groundwater level monitoring, soil, sediment, groundwater, surface water and air sampling and surveying. supervision of contractors. calibration and operation of field instruments and equipment. collection of field data and detailed documentation . submission of field data and preparation of summaries for project managers what will you contribute a bachelor s degree or diploma in environmental studies science, environmental, or a related discipline. eligible for professional registration . previous environmental or consulting work experience is preferred. as the position will involve field work, the candidate must be able to lift up to 40 lbs, be willing to work in varying climatic conditions, and be willing to travel to remote locations and work away from home for extended periods. mechanical aptitude is considered an asset. excellent verbal and written communication skills. demonstrated organizational and time management skills. strong teamwork and collaboration skills. working knowledge of outlook, word and excel. valid class 5 bc driver s license.","['summaries', 'calibration', 'information systems', 'project managers', 'documentation', 'remediation', 'sustainability', 'sampling']",['documentation'],"['summaries', 'calibration', 'information systems', 'sampling', 'project managers', 'remediation', 'sustainability', 'planning']","['gas', 'environment', 'land', 'compensation', 'waste management', 'soil', 'field work', 'consulting', 'assessment', 'environmental']"
421,546,Big Data Engineer,"we are looking for a savvy big data engineer to join our growing team of enterprise data and advanced analytics platform. reporting to the head of enterprise data delivery, the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. this individual will be be self directed and comfortable supporting the data needs of multiple teams, systems , and products please note this opportunity is available in one of the following locations toronto, montreal, calgary or vancouver responsibilities build and maintain efficient data pipeline architecture. assemble large, sophisticated data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. administration and managing of all aws services, such as s3 buckets, rds databases, ec2 instances, vpc network, security groups, cloud formation stacks, cloudwatch, simple notification services sns and emr. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws big data technologies. practice established development subject areas such as good code management, branching , and merging of code in a git repository. has relevant and highly developed professional and technical skills experience level of knowledge in the field of expertise of business or context external client technical team teamwork to set up new clients on grapevine system support tmx internal or external users for application related inquiries. qualifications university degree, college diploma or relevant job experience in computer science, statistics or mathematics at minimum 5 8 years of overall it experience and 3 years in big data development or design including the following hadoop ecosystem components hdfs, hive, sqoop, flume, pig, kafka, spark or spark sql, oozie, hue, python and java programming strong knowledge of various dbms systems including nosql architectures and design principles. good understanding of aws cloud technology and hadoop implementation on aws including s3, ec2 and emr experience working with big data development tools like zaloni, talend, pentaho will be advantageous experience in scala, ranger a plus experience in performance tuning hive tables required experience in the configuration of yarn, mapreduce for performance, security is a plus experience crafting a technology stack for machine learning is a plus experience with development using agile methodologies qualities excellent interpersonal and communication skills strategic problem solver ability to multitask excellent analytical and problem solving skills strong analysis or design experience meticulous attention to detail must be a self starter with ability to follow through on projects assigned tmx is committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and one which reflects the diversity of the community in which we operate. we provide accommodations for applicants and employees who require it.","['databases', 'emr', 'big data', 'pentaho', 'hive', 'java', 'performance tuning', 'sql', 'python', 'statistics', 'scala', 'reporting', 'talend', 'development tools', 'analytics', 'programming', 'aws', 'data systems', 'design principles', 'nosql', 'solver', 'machine learning', 'enterprise data', 'administration', 'agile methodologies', 'sqoop', 'hadoop', 'security', 'git', 'scalability', 'computer science', 'mathematics']","['databases', 'emr', 'sns', 'big data', 'rds', 'pentaho', 'hive', 'java', 'big data development', 'sql', 'python', 'scala', 'talend', 'programming', 'aws', 'solver', 'nosql', 'zaloni', 'sqoop', 'hadoop', 'git']","['administration', 'agile methodologies', 'machine learning', 'statistics', 'reporting', 'security', 'scalability', 'development tools', 'computer science', 'analytics', 'mathematics', 'performance tuning', 'data systems', 'design principles', 'system support', 'enterprise data']","['environment', 'dbms', 'design', 'architecture']"
422,551,Data Engineer,"about avid avid makes technology and collaborative tools so creators can entertain, inform, educate and enlighten the world. our customers are the visionaries behind the most inspiring feature films, television programs, news broadcasts, televised sporting events, music recording and live concerts. to learn how avid powers greater creators or for more information, visit job summary the data engineer will work to design and develop data process to support avid s master data management and enterprise analytics programs. the data engineer will focus primarily on designing and implementing the data pipeline and common data models that will create the new data foundation for our enterprise analytics function. this will include building the etl or elt processes and orchestration layer that will drive the development of our enterprise data warehouse and fuel the successful implementation of 360 views of our customer and products, to aid avid in optimally nurturing our customer relationships. responsibilities and duties partner with business and it management and develop relationships to solve data problems assist in development of principles, policies, standards and guidelines for data management develop data processes and data models to ensure our enterprise data is structured for ease of use and optimized for performance design and build automated and scalable data processes to support master data management and enterprise reporting applications collaborate with integrations team to create real time and near real time data connectivity between core business applications and data management platforms assist in implementing comprehensive testing and monitoring processes to ensure data quality and timely error detection build and support etl or elt and data architectures qualifications skills bachelor s degree in computer science or related field expert proficiency with sql required, python or other scripting language preferred proficiency with data management and data warehousing, experience with snowflake or other cloud data warehouse solutions preferred 5 years of experience in data management, data engineering and etl or elt development 5 years of experience with schema design and dimensional data modeling must be able to effectively communicate both verbally and written with senior management demonstrates capacity for organization and planning of work related activities and workloads ability to analyze and solve practical business problems, demonstrates good decision making, analytical and problem solving skills, as well as a strong technical aptitude. experience with data virtualization tools a plus experience with api json a plus experience with python, r, java or c is a plus avid is an equal opportunity employer. we celebrate diversity and are committed to creating an inclusive environment for all employees. li mr1","['it management', 'c', 'java', 'master', 'sql', 'python', 'reporting', 'scripting', 'json', 'enterprise', 'analytics', 'data', 'data models', 'data engineering', 'data warehousing', 'data models data', 'testing', 'data quality', 'master data management', 'enterprise data', 'snowflake', 'api', 'computer science', 'schema', 'virtualization', 'modeling', 'data management', 'error detection', 'etl', 'r']","['sql', 'python', 'json', 'api', 'c', 'java', 'data models', 'data quality', 'snowflake', 'r']","['it management', 'reporting', 'scripting', 'enterprise', 'analytics', 'data', 'data engineering', 'data warehousing', 'sc', 'testing', 'performance', 'master data management', 'planning', 'enterprise data', 'computer science', 'virtualization', 'modeling', 'data management', 'error detection', 'etl']","['environment', 'business applications', 'events', 'design']"
423,552,Data Engineer,"at neo, we empower people to get the most out of their money and time. we re a tech company reimagining everyday banking from the ground up to create rewarding experiences and build community for all canadians. we re looking for passionate go getters who want to move fast and create a lasting impact. neo financial is looking for full time data engineers to join our team in calgary. as a data engineer at neo, you ll be building out cutting edge data transformation, transmission, and storage systems for a team of data analysts scientists. you ll be hands on working with the data lake and populating the store from a diverse and ever changing set of sources. tools like databricks, kafka and airflow are your bread and butter this is a ground level role with the opportunity to set an example for the entire financial industry. our engineering team casts a wide net of problem solvers and self starters, who are all energized by fast paced work and can adjust their footing swiftly on any given day. make your mark with transformative products and technologies, alongside some of canada s most successful developers and tech minds. what you ll be doing use spark in databricks to perform data ingestions, transformations, and augmentations on large sets of data create and orchestrate data pipelines from a variety of different sources using airflow supporting bi or analytics through building out an explorable data lake in s3 work with product management and analytics teams to take new ideas to production help integrate diverse systems into our data lake or data warehouse assist with the development of automated reports and delivery of analytics data who we re looking for 2 years of experience working in a data intensive environment, preferably using python and sql experience using apache spark experience working in aws able to create and maintain data pipelines in a production environment strong understanding of data engineering principles familiarity with bi or analytics tools such as looker applicants must be eligible to work in canada and willing to relocate to calgary what will help you succeed adaptable, high achievers energized by a startup environment team players who love being part of an agile ecosystem project owners who can engage with developers or other stakeholders makers with a drive to finish, impress users, and delight customers what it s like to work with us at neo, you ll be working with industry leading technology that changes the way we live and realize a better financial future. it s a serious deal, but that doesn t mean we don t know a thing or two about having fun. our entrepreneurial environment gets our adrenaline pumping and beats the regular 9 5 job. we re in it together, always. gain hands on experience and be part of the future. about applying with neo please apply using chrome, as applications are only supported using chrome on desktop. neo financial is an equal opportunity employer. we are excited to meet with and hire the top talent out there. we appreciate your interest in working with us however, only those applicants selected for interviews will be contacted. successful candidates for this position will be required to undergo a security screening, including a criminal records check and may require a credit check.","['go', 'neo', 'sql', 'python', 'looker', 'banking', 'data pipelines', 'data transformation', 'bi', 'apache spark', 'security', 'screening', 'analytics', 'product management', 'aws', 'data engineering', 'storage systems', 'airflow']","['go', 'neo', 'sql', 'python', 'looker', 'bi', 'apache spark', 'aws', 'airflow']","['data pipelines', 'banking', 'data transformation', 'data ingestions', 'security', 'screening', 'analytics', 'product management', 'data engineering', 'storage systems']",['environment']
424,555,Data Engineer,"our client is seeking a data governance analyst to be responsible for the design and implementation of enterprise data governance tooling i.e. collibra and related. this role will also manage the sustainment and support operations, and delivery of new project workstreams. this is a 12 month contract available to candidates in vancouver and calgary. it is remote until further notice. the role primarily responsible for configuring, monitoring, operating and supporting the primary data governance and metadata management tool, collibra. is a subject matter expert with metadata and data governance solutions, specifically collibra data governance center , and is proficient in collibra connect as well as workflow development and design. collaborates with the data governance team to define and document requirements for collibra implementations and integrations. understands and contributes to the development of collibra integration solutions using mulesoft. integrates data governance automation software and metadata source systems using mulesoft. this includes definitions, coding and implementing requirements for collibra integrations. responsible for monitoring and operating metadata management software workflows or jobs and assisting in discovering, sourcing, transforming, loading, and linking metadata in and out of the metadata repository. responsible for operating and monitoring integration components between the metadata management software and other repositories. supports and contributes to process documentations, operations design, and automation of processes. ensure the confidentiality, integrity and availability of the data and ensure that backup and recovery procedures are in accordance with the business tolerance for data loss and the time available to recover. comply with and enforce the corporate policies for change management and release management when implementing system changes. comply with and enforce the corporate procedure for controlling and granting of application access permissions. the ideal candidate diploma or degree in computer science or equivalent experience experience in a variety of technologies including collibra dgc, collibra connect, mulesoft, jdbc, msft sql and azure stack to name a few, including advance level experience working with data formats such as xml, csv and json. hands on working experience with the automation of data lineage provisioning and maintenance. strong experience in data governance of wide variety of data types and wide variety of data sources including big data technologies. 3 years hands on experience designing and implementing collibra connect custom integrations for data ingestion into collibra and collibra integration solutions with downstream applications and databases 3 years hands on experience designing and implementing api integrations using mulesoft and anypoint studio or equivalent technologies, ideally integrating collibra or similar metadata repositories with other it systems. 3 years hands on experience designing and implementing collibra workflows using eclipse. experience with azure devops software and agile practices. ability to convert or translate requirements into design specifications. a strong commitment to ensuring the privacy of information related to employees and third parties. spanish language would be considered an asset. if you are interested in this position and meet the above criteria, please click the apply button to send your resume in confidence directly to meagan tunley, consultant, aplin information technology. visit our website at to view our job opportunities, career tips, and tools. we thank all applicants however, only those selected for an interview will be contacted. we appreciate your interest in david aplin group. if this is your first introduction to us, we invite you to become one of our satisfied candidates. david aplin group has been canadian owned since 1975. our professional consultants are passionate about helping you find a fulfilling job or career and ensuring your complete satisfaction with our process. our proven track record, over four decades long, is largely due to our team of highly skilled and successful specialists. through superior service and a commitment to long term relationships, we provide deep specialization in core areas for complete recruiting and hr solutions across canada all from one source. we look forward to exceeding your expectations learn more about david aplin group and view all our current job opportunities, career tips, and tools at","['metadata management', 'databases', 'big', 'information technology', 'working experience', 'sql', 'software', 'json', 'enterprise', 'data', 'integration', 'provisioning', 'sourcing', 'sustainment', 'metadata', 'specifications', 'automation', 'devops', 'api', 'computer science', 'xml', 'eclipse']","['sql', 'azure', 'databases', 'repositories', 'provisioning', 'json', 'api', 'big data', 'jdbc', 'xml', 'eclipse']","['metadata management', 'data lineage', 'csv', 'information technology', 'release management', 'working experience', 'software', 'enterprise', 'data', 'integration', 'management', 'data ingestion', 'design', 'sourcing', 'workflow development', 'sustainment', 'metadata', 'specifications', 'automation', 'devops', 'computer science']","['change management', 'design', 'governance', 'recruiting', 'hr', 'permissions']"
425,557,Solution Architect (Customer Data Platform),"a cdp solution architect helps clients get value out of their investment into a customer data platform by strategizing a scalable architecture with a strong focus on data governance and security. you will be working with a multidisciplinary team of consultants, data engineers, data scientist, and digital marketers. this is a remote opportunity. role and responsibilities be a platform expert in leading cdp solutions like aep, treasuredata, redpoint or similar provide deep domain expertise in our client s business, technology stack, and data infrastructure assess and audit the current state of a client s marketing technology stack together with a consultant work with a consultant to strategize, architect, and document a scalable cdp implementation, tailored to the client s needs translate business requirements into technical specifications lead technical delivery and provide guidance to the data engineers help implement the proper data governance for the cdp platform preferred qualifications college degree in computer science, data science, analytics or related field 7 years of experience architecting and building data pipelines 5 years of experience working with multi channel marketing hubs by adobe, salesforce or similar strong understanding of working with apis strong understanding of customer data platforms and the modern data infrastructure experience working with cloud technologies such as aws, google cloud, azure or similar experience working with data warehouse solutions like amazon redshift, google bigquery, snowflake, or similar exposure to spark, hadoop, and other big data technologies is a plus experience with analytics tools like google analytics or adobe analytics is a plus experience with marketing automation tools is a plus experience with a or b testing tools is a plus li remote if you have passion and intelligence, and possess a technical knack , we encourage you to apply. bounteous is focused on promoting an inclusive environment and is proud to be an equal opportunity employer. we celebrate the different viewpoints and experiences our diverse group of team members bring to bounteous. bounteous does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, physical or mental disability, national origin, veteran status, or any other status protected under federal, state, or local law. bounteous is willing to sponsor eligible candidates for employment visas. for employment opportunities based in canada bounteous is an equal opportunity employer. we embrace diversity and are committed to creating an inclusive workplace. in accordance with the ontario human rights code and accessibility for ontarians with disabilities act, 2005, accommodation will be provided at any point throughout the hiring process, provided the candidate makes their accommodation needs known to bounteous. we welcome applications from all qualified candidates. must be legally eligible to work in canada.","['data infrastructure', 'google', 'big data', 'data science', 'adobe', 'data', 'analytics', 'aws', 'customer data', 'amazon redshift', 'customer', 'data pipelines', 'google analytics', 'testing', 'specifications', 'automation', 'hadoop', 'security', 'computer science', 'snowflake']","['google analytics', 'hadoop', 'redpoint', 'adobe', 'aws', 'big data', 'amazon redshift', 'google bigquery', 'snowflake']","['data pipelines', 'testing', 'data infrastructure', 'security', 'data science', 'computer science', 'specifications', 'data', 'analytics', 'customer data', 'automation']","['environment', 'marketing', 'governance', 'hiring', 'law', 'architecture']"
426,558,DATA ENGINEER,"data engineer position code 2021 063 location the globe and mail, toronto salary commensurate with qualifications and experience position overview the globe and mail is looking for a self motivated data engineer with a passion for rapidly evolving tech and the media publishing industry. the ideal candidate is an experienced data pipeline developer and data wrangler who enjoys optimizing data systems and building them from the ground up. the incumbent will support devops, database architects, data analysts and data scientists on a variety of data initiatives and will ensure development activities are compliant with industry best practices. the ideal candidate must be able to work autonomously in a fast paced setting and be comfortable with supporting the data needs of multiple teams, systems and products. the candidate will be excited by the prospect of enhancing or even re designing our company s data architecture to support our next generation of products, pipelines and analytics. responsibilities create and maintain optimal and efficient data pipeline architecture that meet various functional or non functional business requirements identify, design, and implement internal process improvements including automating manual processes, optimizing data delivery workflows, re designing infrastructure for greater scalability and cost savings, improving reporting query performance, etc. build the infrastructure required for efficient extraction, transformation, and loading of data from a wide variety of disparate data sources work with various internal stakeholders including ad operations, revenue, finance and marketing supporting their data infrastructure initiatives minimum qualifications formal training in software engineering, computer science or computer engineering strong analytical, problem solving and project management skills deep understanding of good programming practices, design patterns, functional programming, and object oriented analysis and design successfully implemented and released a large number of complex data pipelines using modern engineering frameworks in the past 3 years experience performing root cause analysis on internal and external data and processes to answer specific business questions, resolve performance bottlenecks and identify opportunities for improvement or enhancement technical capacity expert proficiency in sql and relational database structures including 3 to 5 years of experience in cloud based data warehousing technologies such as snowflake or redshift proven experience ingesting and transforming structured and non structured data established experience developing and querying various rest and soap open or public, web and internal apis established experience with big data tools including hadoop, apache spark and databricks expert proficiency with at least two object oriented or object function scripting languages including java, scala and python proven etl pipeline automation and data propagation experience including authoring, scheduling and monitoring workflows using airflow established experience with aws cloud services including ec2, ebs, s3, kms key management, landing zone experience with docker and software containerization nice to have experience with olap and oltp systems and large scale erps including salesforce crm and sap ecc experience ingesting and modelling web or app analytics, clickstream or click path data working knowledge of message queuing, micro batch and stream processing working knowledge of modern day bi and data visualization tools including tableau, powerbi or bigquery tableau server and site management deploying, configuring, maintaining and upgrading tableau server habitual in storing and maintaining source code versioning in git the globe and mail is dedicated to diversity and inclusion in the workplace the globe and mail is committed to fostering an inclusive, accessible work environment, where all employees feel valued, respected and supported. we believe this strengthens our business and our journalism. we welcome and encourage applications from individuals from all groups, regardless of race, ethnicity, culture, gender, sexual orientation, religion, socio economic status, age, and physical ability. as required by the federal contractors program, the globe also tracks the proportion of staff in the four employment equity categories to ensure we are reflecting the areas in which we work. the globe and mail offers accommodation for applicants with disabilities as part of its recruitment process. if you are contacted to arrange for an interview, please advise us if you require an accommodation.","['erps', 'tableau', 'data infrastructure', 'data visualization', 'big data', 'site management', 'containerization', 'etl', 'java', 'olap', 'sql', 'python', 'oltp', 'software', 'scala', 'reporting', 'scripting', 'queuing', 'data', 'analytics', 'programming', 'aws', 'data systems', 'crm', 'pipelines', 'data warehousing', 'soap', 'design patterns', 'data pipelines', 'apache spark', 'computer engineering', 'stream processing', 'rest', 'automation', 'airflow', 'cloud services', 'bi', 'devops', 'functional', 'hadoop', 'git', 'scalability', 'computer science', 'snowflake', 'root cause analysis']","['tableau', 'object', 'big data', 'java', 'sql', 'python', 'scala', 'programming', 'aws', 'pipelines', 'soap', 'apache spark', 'kms', 'airflow', 'bi', 'functional', 'hadoop', 'git', 'snowflake', 'erps']","['data infrastructure', 'data visualization', 'site management', 'olap', 'oltp', 'software', 'reporting', 'scripting', 'queuing', 'analytics', 'data', 'data systems', 'crm', 'data warehousing', 'design patterns', 'data pipelines', 'software container', 'computer engineering', 'stream processing', 'rest', 'automation', 'cloud services', 'devops', 'scalability', 'computer science', 'root cause analysis', 'etl']","['environment', 'journalism', 'cost savings', 'marketing', 'design', 'finance', 'project management', 'sap', 'key management', 'architecture']"
427,561,Cloud Data Engineer,"role cloud data engineer location toronto, on duration long term mandatory skills and experience working on emr, good knowledge of cdk and setting up etl and data pipeline coding python aws emr, athina, supergule, sagemaker, sagemaker studio data security encryption ml or ai pipeline redshift aws lambda nice to have skills experience oracle or sql database administration data modelling rds dms serverless architectrure devops job type contract schedule 8 hour shift experience lambda 2 years","['sql', 'python', 'emr', 'devops', 'security', 'data', 'encryption', 'aws', 'database administration', 'etl', 'ai']","['sql', 'python', 'emr', 'data', 'aws', 'rds']","['devops', 'security', 'encryption', 'dms', 'database administration', 'etl', 'ai']",[]
428,562,Staff Data Engineer,"affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest. what you ll do help shape the technical direction of a domain within the data organization. build a reliable and scalable single source of truth core model data product for internal and external analytics and enable self service. partner with product, data analyst, engineering teams and other data engineers to translate business requirements into data models with measurable transformation quality under sla. develop and automate large scale, high performance data processing systems and visualization to ensure reliability and meet critical business requirements. lead data engineering projects, and overall strategy for data governance, security, privacy, quality, and retention. mentor data engineers and continue promoting data engineering and analytics tooling standards. what we look for 7 years of experience in data modeling, data architecture, and other areas directly relevant to data engineering. technical leadership capable of handling mentorship, cross functional project execution, and solid individual contributions. advanced sql, etl pipelines, data modeling design, sql performance tuning in olap and data warehouse or data lake environments proficiency with programming languages and data warehouse technologies , big data technologies , analytics familiar with data governance frameworks and agile methodology excellent written and verbal communication and interpersonal skills able to effectively collaborate with technical and business partners. eager to learn new things and have a growth mindset. bs or ms degrees in computer science, engineering, or a related technical field. location we re excited to announce that affirm is now a remote first company this role can be located anywhere canada with the exception of quebec . remote based employees may occasionally travel to an affirm office for meetings or team building events. our offices in san francisco, new york city, pittsburgh, chicago, and salt lake city will remain operational and accessible for anyone to use on a voluntary basis. li remote check out our remote first approach to learn more about the new ways we work. if you got this far, we hope you re feeling excited about this role. even if you don t feel you meet every single requirement, we still encourage you to apply. we re eager to meet people who believe in affirm s mission and can contribute to our team in a variety of ways not just candidates who check all the boxes. at affirm, people come first is one of our core values, and that s why diversity and inclusion are vital to our priorities as an equal opportunity employer. you can read about our d i program here and our progress thus far in our 2020 dei report . we also believe it s on us to provide an inclusive interview experience for all, including people with disabilities. we are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process. we will consider for employment qualified applicants with arrest and conviction records in accordance with applicable federal, state, and local laws, including the san francisco fair chance ordinance. by clicking submit application, i acknowledge that i have read the affirm employment privacy policy , and hereby consent to the collection, processing, use, and storage of my personal information as described therein.","['sql', 'visualization', 'data processing', 'programming languages', 'technical direction', 'big', 'security', 'modeling', 'analytics', 'data', 'computer science', 'data models', 'pipelines', 'data engineering', 'technical leadership', 'performance tuning', 'etl', 'olap']","['sql', 'programming languages', 'san', 'big data', 'data models', 'pipelines']","['methodology', 'visualization', 'data processing', 'technical direction', 'security', 'computer science', 'analytics', 'data', 'modeling', 'data engineering', 'technical leadership', 'performance tuning', 'etl', 'olap']","['sla', 'events', 'design', 'team building', 'governance', 'hiring', 'architecture']"
429,563,Data Analyst Health Surveillance - BC Centre for Disease Control,"data analyst health surveillance epidemiology, bc centre for disease control, 36.41 to 38.49 per hour these roles will support various covid 19 initiatives including covid surveillance, overdose surveillance, environmental health surveillance, and data provision within public health reporting warehouse. what you ll do perform data management and preparation activities, including data extraction, transformation, and documentation. develop and maintain data collection and recording systems such as databases, spreadsheets, and web sites, including designing ad hoc reports. write computer code and data queries to capture and edit data, and or or liaises with information systems department for same. create analytic reporting tools to allow internal and external users to analyze data. receive and respond to ongoing requests to evaluate data, systems, processes and procedures. automate routine data management tasks using standard programming tools. perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. identify issues, trends, and developments. communicate findings to centre staff and external stakeholders at the local, provincial and federal level. automate routine analyses using standard programming tools. monitor data quality in the information systems like the public health information system and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. correct data errors in a timely manner. document processes for these procedures. prepare and maintain documentation and report such as user guides, procedure manuals, metadata, code documentation, data security policies and data dictionaries. support data security by assigning and deleting access for various applications and network file systems. ensure the secure transfer of patient data to stakeholders when authorized to. assist as needed with gathering data, entering data, researching historical and archival data, accessing on line databases, performing interviews, and obtaining data from national, provincial and local agencies and individuals. link data from separate sources such as the client registry and msp. what you bring bachelor s degree in health information science or computer science or equivalent. three years experience as a data analyst or scientist, preferably in community health and or or the health information field, or an equivalent combination of education and experience. you will have the ability to write data management and analysis programs using data programming tools such as sas or r. manage and query data in large relational or multidimensional databases and data warehouses an asset. create data visualizations. use standard software packages, spreadsheet, statistical, graphical, database, communication and web software. have knowledge of descriptive statistics, pc systems, and applications. communicate effectively, both verbally and in writing. operate related equipment physically carry out the duties of the position. what s in it for you every phsa employee enables the best possible patient care for our patients and their families. whether you are providing direct care, conducting research, or making it possible for others to do their work, you impact the lives of british columbians today and in the future. that s why we re focused on your care too offering health, wellness, development programs to support you at work and at home. join one of bc s largest employers with province wide programs, services and operations offering vast opportunities for growth and development. access to more than 2,000 in house training programs. enjoy a comprehensive benefits package, including municipal pension plan. 12 annual statutory holidays with generous vacation entitlement and accruement. perks include onsite fitness classes and discounts to 350 bc wide recreational programs, travel, technology, car and bike sharing, and more. temporary full time 36.41 to 38.49 per hour 655 west 12th avenue, vancouver applications will be accepted until position is filled. monday to friday 0830 1630 requisition numbers 105558, 105562, 105694, 105835 what we do bc centre for disease control bccdc.ca is dedicated to preventing and controlling communicable disease and promoting environmental health for the province. provincial health services authority plans, coordinates and evaluates specialized health services with the bc health authorities to provide equitable and cost effective health care for people throughout the province. our values reflect our commitment to excellence and include respect people be compassionate dare to innovate cultivate partnerships serve with purpose. learn more about phsa and our programs jobs.phsa.ca or programs and services phsa is committed to employment equity and hires on the basis of merit, encouraging all qualified individuals to apply. we recognize that our ability to provide the best care for our diverse patient populations relies on a rich diversity of skills, knowledge, backgrounds and experiences, and value a safe, inclusive and welcoming environment. attn phsa employees to be considered as a phsa employee for this position, you must apply online via your internal profile at http or or internaljobs.phsa.ca please note the internal job posting will no longer be accessible after the expiry date of april 1, 2021. if the internal job posting has expired, please contact the internal jobs help desk and advise that you would like to be considered as a late internal applicant for this position. please do not apply for the external job posting. if you have not registered your internal profile, a password is required to log in for the first time. to obtain your password, please contact the internal jobs help desk at 604 875 7264 or 1 855 875 7264. please note regular business hours are monday friday , 8 30am to 4 30pm. for inquiries outside of regular business hours, please email the internal jobs help desk at and a help desk representative will contact you the next business day.","['databases', 'documentation', 'statistics', 'software', 'reporting', 'data', 'programming', 'epidemiology', 'sas', 'information science', 'data collection', 'statistical', 'metadata', 'information', 'data quality', 'file systems', 'data extraction', 'information systems', 'security', 'computer science', 'summaries', 'spreadsheets', 'data management', 'r']","['spreadsheets', 'databases', 'spreadsheet', 'data', 'programming', 'documentation', 'data quality', 'sas', 'r']","['file systems', 'statistics', 'data extraction', 'software', 'reporting', 'information science', 'information systems', 'data collection', 'summaries reports', 'security', 'computer science', 'statistical', 'metadata', 'data management', 'http']","['environment', 'patient care', 'manuals', 'education', 'surveillance', 'public health', 'environmental', 'developments', 'environmental health']"
430,564,"Senior Data Scientist, Advanced Analytics, Global Risk Management","requisition id 106855 join a purpose driven winning team, committed to results, in an inclusive and high performing culture. the senior data scientist, advanced analytics will taking a leading role in business use cases delivery, in an agile rapid lab environment, aimed at accelerating benefits for customers and the bank, leveraging enterprise level data management tools and advanced analytics. she or he will work closely with peers across global risk teams, the business lines, it, and digital banking to expand the credit science practice and drive the global risk management analytics coe interaction model. the candidate will identify and prioritize opportunities to deliver innovative business banking credit solutions leveraging liquidity, risk reward predictions and strategy optimization frameworks. is this role right for you in this role you, will work in agile rapid lab environment to deploy new credit solutions in 90 day increments support forward thinking, high impact analytical use cases focused on supporting grm data, analytics and technology strategy and deliver actionable insights to capitalize on business opportunities collaborate with grm analytics coe key stakeholders and partners to define machine learning and artificial intelligence best practices for agile rapid labs support risk reward predictions delivery, strategy optimizations and machine learning playbooks to drive innovative credit solutions within risk appetite thresholds build 1 2 analytical playbooks across global retail and business banking footprint to support growth or de risking initiatives support research development work focused on the effective application of design thinking and scalable advanced techniques to drive ideation and innovation in analytics, machine learning and artificial intelligence lead and support a high performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment communicating vison or values or business strategy and managing succession and development planning for the team support grm analytics coe with thought leadership and r d activities to influence grm stakeholders on trends regarding practical applications of machine learning and artificial intelligence to banking understand how the bank s risk appetite and risk culture should be considered in decision making do you have the skills that will enable you to succeed in this role we d love to work with you if you have university or post graduate degree in relevant stem discipline ability to ingest and work with large volumes of structured and unstructured non traditional data working experience with big data tools such as sql, hive, spark working experience with open source programming languages such as python, r, scala working experience with ml or ai techniques for strategy design knowledge of strategy optimization leveraging operations research principles would be an asset working experience with cloud computing platforms such as ms azure and google cloud working experience with devops principles and or or software engineering best practices would be an asset corporate, commercial and capital markets experience is an asset working knowledge of visualization tools such as tableau and power bi would be an asset strong collaboration skills with ability to translate technical knowledge into business value effective communication skills with ability to prepare project documentation and presentations what s in it for you the opportunity to join a forward thinking company surrounded by a collaborative team of innovative thinkers. a rewarding career path with diverse opportunities for professional development. internal development to support your growth and enhance your skills. a competitive compensation and benefits package. an organization committed to making a difference in our communities for you and our customers. we have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success this position is located downtown toronto location canada ontario toronto scotiabank is a leading bank in the americas. guided by our purpose for every future , we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['project', 'visualization', 'design thinking', 'tableau', 'documentation', 'big data', 'working experience', 'hive', 'sql', 'python', 'scala', 'software', 'analytics', 'cloud computing', 'r', 'machine learning', 'artificial intelligence', 'banking', 'programming languages', 'bi', 'devops', 'optimization', 'data management', 'ai']","['sql', 'python', 'tableau', 'programming languages', 'scala', 'bi', 'grm', 'big data', 'hive', 'r']","['project documentation', 'use cases', 'machine learning', 'banking', 'design thinking', 'ai', 'software', 'visualization', 'devops', 'analytics', 'artificial intelligence', 'optimization', 'working experience', 'data management', 'cloud computing', 'planning']","['liquidity', 'environment', 'private', 'compensation', 'retail', 'risk management', 'research', 'development work', 'design', 'business value', 'business strategy', 'presentations', 'operations', 'investment banking', 'capital markets', 'risk appetite', 'business']"
431,565,Scientist 1 Immunology,"at charles river, we are passionate about improving the quality of people s lives. when you join our global family, you will help create healthier lives for millions of patients and their families. charles river employees are innovative thinkers, who are dedicated to continuous learning and improvement. we will empower you with the resources you need to grow and develop in your career. as a charles river employee, you will be part of an industry leading, customer focused company at the forefront of drug development. your skills will play a key role in bringing life saving therapies to market faster through simpler, quicker, and more digitalized processes. whether you are in lab operations, finance, it, sales, or another area, when you work at charles river, you will be the difference every day for patients across the globe. important in order to be considered for this position, a resume or cv must be uploaded and submitted during the application process. please make sure work history and education are added correctly. job summary designs and or or executes scientific testing strategies and studies. leads assay development, assay validation or study conduct, or is involved in preparation of material e.g. protein, nucleic acid, cells, etc. . reviews and interprets study data, communicates results to clients and writes final reports. serves as project scientist, principal investigator, contributing scientist, project leader or study director, as applicable. ensures compliance with protocols and all applicable sops. troubleshoots and resolves assay or technical issues in the laboratory when scientific expertise is needed. may introduce new technologies or introduce improvements in existing technologies. provides advisory functions to clients designing a program or experiment, dealing with specific dataset interpretation, or when appropriate answering questions from regulatory authorities. we are seeking a scientist 1 for our immunology department site located laval in canada. the following are responsibilities related to the scientist 1 prepare and or or review study related documentation prepare study schedules and draft study plans and amendments for immunology studies ensure that the studies are planned efficiently with regard to the experiment required, staff requirements and their qualifications, health and safety legislation, such that the study will satisfy its objectives monitor the laboratory activities during the study by conducting regular visits to the lab, by supervising critical activities and reviewing the records as appropriate coordinate immunology laboratory staff in the execution of method development or transfer, validation and sample analysis perform appropriate analysis and interpretation of study data generated and advise accordingly. the following are minimum qualifications related to the scientist 1 position master s or doctorate s degree is a definite asset minimum of 3 years of relevant experience including a minimum of 1 year in a scientific position relevant to immunology working experience in more than one of the following areas elisa or ligand binding assays, multiplex assays, flow cytometry, molecular biology, and or or cell based assays good knowledge and application of glp good practical experience in project management bilingualism , verbal and written, is required good organizational, interpersonal, leadership and communication skills good problem solving and analytical skills ability to work under time constraints and adapt to change strong customer service orientation. important a resume is required to be considered for this position. if you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume or cv. about corporate functions the corporate functions provide operational support across charles river in areas such as human resources, finance, it, legal, sales, quality assurance, marketing, and corporate development. they partner with their colleagues across the company to develop and drive strategies and to set global standards. the functions are essential to providing a bridge between strategic vision and operational readiness, to ensure ongoing functional innovation and capability improvement.","['analytical skills', 'forefront', 'quality assurance', 'testing', 'documentation', 'working experience', 'operational support']","['nucleic', 'forefront', 'documentation', 'quality assurance']","['working experience', 'operational support', 'testing', 'analytical skills']","['glp', 'multiplex', 'human resources', 'project management', 'and safety', 'education', 'biology', 'material', 'customer service', 'capability improvement', 'legislation', 'cytometry', 'validation', 'marketing', 'finance', 'drug development', 'assay', 'immunology', 'sales', 'molecular']"
432,566,Cloud Data Engineer,"summary operations research and analytics is an emerging innovative team within health informatics department at providence healthcare . the team is committed to design, develop, and deploy state of the art analytical solutions and applications. scope of the work is diverse and touches on a wide variety of challenges in the health sector, such as the patient flow management, patient scheduling, capacity planning, inventory management, and others. reporting to the manager, operations research analytics, the cloud data engineer develops and establishes scalable, efficient, automated processes for large scale data analyses, model development, validation and implementation. the position will closely collaborate with the other members of the ora team to create and deploy automated data pre processing and machine learning models through the innovative understanding and use of large data sets to improve clinical processes and patient outcomes, and support data driven decision making. the ideal candidate will have experience in data modeling, data warehousing, building etl pipelines for machine learning models, and excellent problem solving ability dealing with huge volumes of medical and clinical data. the position will also stay apprised of current trends and research on all aspects of data engineering and machine learning techniques and works in collaboration with provincial and national colleagues. skills demonstrated strength in data modeling, etl development, and data warehousing with solid knowledge of various industry standards such as dimensional modeling, and star schemas etc. knowledge of business intelligence environments good knowledge of ssis and data modeling techniques with sql server. coding proficiency in python. demonstrated proficiency working with both relational and non relational databases . demonstrated skills in ai product design and proven ability to plan, organize, and coordinate ai product activities. demonstrated understanding of data privacy, security and related tools such as anonymization and encryption. excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non technical partners and to communicate to multiple audiences using data storytelling and through graphics. demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building. physical ability to perform the duties of the job. education master s degree in computer science, mathematics, or engineering and at least five years experience as a data engineer or related specialty including at least two years experience building cloud solutions in azure or aws. an equivalent combination of education, training and experience would also be considered. job types full time, permanent benefits company pension dental care employee assistance program extended health care paid time off vision care schedule 8 hour shift monday to friday","['schemas', 'encryption', 'graphics', 'sql', 'python', 'reporting', 'analytics', 'data', 'aws', 'pipelines', 'data engineering', 'data warehousing', 'clinical', 'machine learning', 'relational databases', 'data privacy', 'business intelligence', 'model', 'security', 'computer science', 'mathematics', 'modeling', 'capacity planning', 'ssis', 'etl', 'ai']","['sql', 'python', 'aws', 'business intelligence', 'pipelines', 'ssis']","['schemas', 'encryption', 'clinical data', 'graphics', 'reporting', 'analytics', 'data', 'data engineering', 'data warehousing', 'machine learning', 'relational databases', 'data privacy', 'model', 'security', 'computer science', 'mathematics', 'modeling', 'capacity planning', 'etl', 'ai']","['validation', 'environment', 'education', 'healthcare', 'product design', 'or', 'design', 'art', 'operations', 'inventory management']"
433,567,Process Data Engineer,"the chapman group is pleased to support our client eigen with the recruitment of their next process data engineer. as a process data engineer, you will be the team member focused on digitizing our customers quality and process control data into the eigen platform. you will be responsible for managing the data and performance of ai models deployed to customer production environments. this process will require being involved in the full lifecycle of customer onboarding, helping define data dictionaries, definitions, analytics, and metrics for performance, and standardizing the model performance between eigen and the customer. you will be the primary person tasked with monitoring and managing the performance of eigen algorithms and models operating in the field. in this role, you will be part of the customer engineering and delivery team. you will be required to interact regularly on customer calls, and present findings and recommendations for optimizing eigen ai performance in the field. responsibilities as a process data engineer, you will have the following responsibilities work with customers to understand their manufacturing process and the data connected with their process. define the dictionary of data to be captured and processed for a given customer install. define the analytics and insights to be derived from the customer data. define the data labeling dictionary and lexicon for anomalies and defects in the customer s manufacturing process. work with the eigen software engineering and data science teams to optimize the inputs and outputs required to train an ai model with machine learning to be used for real time detection in a customer s production environment. use the eigen data processing pipeline and tools to execute data analytics and derive insights from customer data. monitor the performance of models deployed in customer applications. work with the eigen data processing pipeline, tools, and engineering team to tune and optimize the performance of models and algorithms deployed to customers. analyze data from customer escalations and provide recommendations to improve model performance in deployed customer applications. assist in root cause analysis where needed to respond to customer escalations. recommend opportunities for process improvement and automation within the eigen monitoring and data processing pipeline. qualifications a post secondary degree in engineering. experience in industrial manufacturing, process control, quality assurance and quality control. expertise in quality and process control methodologies such as six sigma and statistical process or quality control. exposure and understanding of information technology, artificial intelligence or machine learning, and industrial automation. exposure and understanding of industry 4.0 and internet of things technologies and solutions. exposure and understanding of industrial manufacturing technologies and processes. strong programming skills in python and or or r database skills in relational databases and nosql data stores and experience in sql and jupyter notebooks and familiarity with aws. strong communications, presentation, interpersonal, and relationship skills, and experience interacting with customers. work with us we help leading, global manufacturers realize massive savings and reduce waste from their processes through our industrial vision solution. our dedicated team has not only built a truly scalable ai enabled solution, we re actually taking industrial vision to the next level. if you are interested in working in a fast paced environment and like being on the cutting edge of technology, drop us a line at","['quality assurance', 'information technology', 'quality control', 'data analytics', 'python', 'sql', 'data processing', 'software', 'data science', 'six sigma', 'analytics', 'programming', 'aws', 'customer data', 'r', 'nosql', 'jupyter', 'machine learning', 'relational databases', 'process', 'artificial intelligence', 'process control', 'algorithms', 'automation', 'internet of things', 'root cause analysis', 'ai']","['jupyter', 'sql', 'python', 'internet of things', 'quality assurance', 'programming', 'aws', 'nosql', 'r']","['data analytics', 'machine learning', 'data processing', 'quality control', 'relational databases', 'software', 'industrial vision', 'data science', 'six sigma', 'analytics', 'artificial intelligence', 'information technology', 'customer data', 'process control', 'algorithms', 'automation', 'root cause analysis', 'ai']","['environment', 'metrics', 'onboarding', 'process improvement', 'industrial', 'waste', 'manufacturing']"
434,574,Sr. Data Analyst,"since being founded in 2011, prodigy education has grown from 3,000 local users to more than 100 million registered users worldwide. as one of the fastest growing edtech startups in north america, prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. anyone with an internet connection is welcome to create a free account for prodigy s popular math game for grades 1 to 8. prodigy education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. for more information visit our passion is our mission to help every student in the world love learning our data and marketing teams are scaling rapidly as we continue to hit our product and growth milestones the work you do here will aid the educational advancement of millions of students. you will have the chance to apply your analytics skills to not only help kids learn but also help our marketing team to make better decisions. we are looking for a marketing data analytics expert to join our growing team. as we scale our marketing efforts, the team will be looking to you for insights on the effectiveness of initiatives, and opportunities for optimization and growth. you will have the chance to apply your marketing analytics expertise to add real strategic value and ensure that we are asking and answering the right questions. your impact collaborate with data analysts, data scientists, data engineers, and team leads to create solutions which will directly affect prodigy s growth help our marketing team explore, analyze, and understand their data to help marketing make channel investment decisions improve data visibility by building dashboards and charts to inform strategy, and capture market and user insights benchmark performance across all channels and inform campaign optimization based on performance analysis work with the marketing and data teams to improve data quality to provide high quality insights and recommendations help design, execute, and evaluate experiments communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non technical backgrounds. who you are at least 2 years demonstrated analytics experience worked extensively with marketing teams expert skills and knowledge of sql. expertise in working with various bi platforms experience working with a or b testing and experimentation experience in marketing analytics ability to work simultaneously on different projects with a variety of timelines ability to translate data insights into actionable steps a team and customer centric mindset love for our mission of helping kids everywhere enjoy learning bonus points for experience in cloud ecosystems and their data tooling knowledge of python or r languages knowledge of google analytics and google tag manager experience with spark demonstrated ability to solve hard mathematical, algorithmic, and statistical problems. significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship what we offer a culture of transparency, where team members are involved in important conversations full health benefits from day one for you and your family, fully covered we are a profitable company, with eligibility to participate in stock options for all full time permanent employees learning and development budget for all full time employees to use towards career growth and development opportunities we recognize 9 5 is not for everyone we offer flexible working hours that will allow you to schedule your workday with a bit more freedom while we operate 100 remotely, for the time being, we understand the importance of togetherness. we offer frequent and fun team and company events, to stay connected and in the know. please note during the covid 19 pandemic, in order to keep all our candidates and team members safe, prodigy is operating, hiring and onboarding 100 remotely for the time being. come as you are. we believe the power of our collective potential will transform education. we are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. we welcome applications from people from all underrepresented groups, including people of any gender, age, or religion, members of the lgbtqia2 community, bipoc and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of prodigy education. if you feel like you don t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we d still love for you to apply we are an equal opportunity employer and are committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act, 2005 . prodigy education will provide accommodations to job applicants with disabilities throughout the recruitment process. if you require accommodation, please notify us and we will work with you to meet your needs.","['data analytics', 'sql', 'python', 'google analytics', 'software', 'bi', 'testing', 'performance analysis', 'dashboards', 'analytics', 'optimization', 'data quality', 'rest', 'edtech', 'r']","['sql', 'python', 'google analytics', 'bi', 'data quality', 'r']","['data analytics', 'software', 'testing', 'performance analysis', 'dashboards', 'analytics', 'optimization', 'rest', 'hit', 'edtech']","['research projects', 'events', 'education', 'entrepreneurship', 'marketing', 'onboarding', 'design', 'startups', 'hiring', 'google tag']"
435,575,Data Engineer/Analyst - Active Safety & Autonomous Data Recording and Analytics,"about gm there s never been a more exciting time to work for general motors. to achieve our vision of a world with zero crashes, zero emissions and zero congestion, we need people to join us who are passionate about creating safer, better and more sustainable ways for people to get around. this bold vision won t happen overnight, but just as we transformed how the world moved in the last century, we are committed to transforming how we move today and in the future. why work for us our culture is focused on building inclusive teams, where differences and unique perspectives are embraced so you can contribute to your fullest potential as you pursue your career. our locations feature a variety of work environments, including open work spaces and virtual connection platforms to inspire productivity and flexible collaboration. and we are proud to support our employees volunteer interests, and make it a priority to join together in efforts that give back to our communities. job description core responsibilities own and develop software and data analysis solutions as part of a larger team leading and participating in data pipeline development and maintenance collaborate with others to develop requirements and perform design reviews to create data pipeline schemas, tools, and or or guis create pipelines to acquire and compile structured and unstructured data from various data sources, and verify data quality, accuracy, and robustness conduct data pipeline verification prepare and deliver bi reports that translate analytic insights into tangible, actionable solutions for data customers to implement provide clear and complete documentation per the software development process collaborate with team members through scrum or agile take ownership of each project, make design and implementation decisions autonomously, and mentor junior members be an integral part of a new and energetic team average travel requirements of 2 3 weeks a year, including travel to the us required skills and experience 3 yrs industry experience in developing, deploying, and monitoring performance of data pipelines, data analysis and bi reporting experience utilizing scripting languages databases data visualizations proven technical ability to navigate highly complex data management projects and effectively interface with global colleagues ability to investigate issues based on limited information. demonstrated high level of ability to resolve complex problems strong leadership and interpersonal communication skills must be legally allowed to work in canada and be able to travel to the us must have a valid canadian driver s license preferred skills and experience understanding of major automotive vehicle systems such as advanced driver assistance , motion control, automotive network, and powertrain experience with automotive related data experience with vehicle data acquisition tools experience with big data using spark or scala experience with machine or deep learning algorithms experience with website, sharepoint and or or gui development exposure to embedded software minimum education required bachelor s degree in mathematics, statistics, computer science, data science or engineering advanced degrees preferred diversity information general motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. we strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. we understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities. we encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities. equal employment opportunity statement accommodation is available for applicants with disabilities. should you be contacted by general motors of canada, please advise if you require accommodation. general motors of canada values diversity and is an equal opportunity employer.","['unstructured data', 'databases', 'schemas', 'documentation', 'big data', 'automotive', 'statistics', 'data acquisition', 'software', 'scala', 'reporting', 'scripting', 'data science', 'software development', 'pipelines', 'sharepoint', 'data pipelines', 'embedded', 'scrum', 'data analysis', 'data quality', 'algorithms', 'deep learning', 'bi', 'computer science', 'mathematics', 'data management']","['databases', 'sharepoint', 'pipelines', 'scala', 'bi', 'documentation', 'big data', 'data quality']","['unstructured data', 'schemas', 'automotive', 'statistics', 'data acquisition', 'software', 'reporting', 'scripting', 'data science', 'software development', 'data pipelines', 'embedded', 'scrum', 'gui', 'data analysis', 'algorithms', 'deep learning', 'computer science', 'mathematics', 'data management']","['powertrain', 'environment', 'design', 'education']"
436,576,"Sr. Manager, Data Engineering","freshbooks has a big vision. we launched in 2003 but we re just getting started and there s a lot left to do. we re a high performing team working towards a common goal building an elite online accounting application to help small businesses better handle their finances. known for extraordinary customer service and based in toronto, canada, freshbooks serves paying customers in over 120 countries. the opportunity manager, data engineering as an engineering manager for data engineering at freshbooks, you ll be responsible for the development of our data infrastructure or operations team and will work with the team to scale data pipelines to millions of users. as a leader and manager, you ll handle a group of data engineering team members and help accelerate their execution and growth. you re already a skilled leader, able to recruit new talent and champion development teams and their leaders. your technical experience with scalable software or data platform technologies allows you to lead by example. strong communication and interpersonal skills allow you to effectively influence across the organization. in all areas, you re able to anticipate and plan for the future. what you ll do drive the execution of the technical vision of our data infrastructure. manage a group of data engineers, data modellers, and other data related roles. set, maintain and raise the level of technical excellence across your group and the entire development organization. work closely with the analysts, data scientists, and product to build a world class engineering and data organization. attract and recruit talent to help execute the freshbooks mission. anticipate and prepare for the future technology, people, culture and process. what you have enthusiasm for data engineering proven technical management experience with a team of 5 or more developers over a period of at least 2 years, in an agile or scrum environment. strong technical background with experience working with large codebases and large amounts of data. history of establishing teams by developing leaders and recruiting exceptional talent. the ability to influence through strong communication and interpersonal skills. a demonstrated ability to navigate ambiguity, develop plans and successfully execute over multiple quarters. a love of learning, a drive for self improvement and a desire to help everyone be better. experience with google cloud, or another major cloud provider such as aws. experience with git workflows, automated testing, continuous integration and automated build pipelines. strong programming skills in sql, python or a similar language. experience with big query, redshift, snowflake, or similar cloud data warehouse technology. what you may have a degree in computer science or engineering or data engineering. experience developing and or or managing real time data pipelines and fast data architectures. experience with spark, kafka, flink, gearpump, dataflow, or other streaming technologies. experience with docker, kubernetes, ansible, and terraform, and other devops and infrastructure as code technologies. experience with other modern storage technologies such as cassandra, mongodb, and others. a track record of staying at the forefront of data engineering technology. a limitless imagination for where data could go and what we can do with it to make our customers and our people awesome why join us we re an ambitious bunch, with our eyes laser focused on shipping extraordinary experiences to small business owners. you ll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world class one, right here in toronto, canada. apply now have we got your attention submit your application today and a member of our recruitment team will be in touch with you shortly freshbooks is an equal opportunity employer that embraces the differences in all of our employees. we celebrate diversity and are committed to creating an inclusive environment for all freshbookers. all applicants are evaluated based on their experience and qualifications in relation to this position. freshbooks provides employment accommodation during the recruitment process. should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. for any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416 780 2700 and or or","['go', 'data infrastructure', 'mongodb', 'laser', 'kubernetes', 'sql', 'python', 'terraform', 'forefront', 'software', 'programming', 'aws', 'integration', 'pipelines', 'data engineering', 'data pipelines', 'scrum', 'testing', 'ansible', 'cassandra', 'devops', 'technical', 'git', 'computer science', 'snowflake']","['go', 'kubernetes', 'sql', 'python', 'terraform', 'forefront', 'git', 'programming', 'aws', 'pipelines', 'snowflake', 'ansible', 'cassandra']","['technical management', 'data pipelines', 'continuous', 'software', 'scrum', 'testing', 'data infrastructure', 'devops', 'computer science', 'integration', 'mongodb', 'data engineering', 'infrastructure as code']","['customer service', 'environment', 'accounting', 'recruiting']"
437,577,"Data Engineer, Analytics, Global Risk Management","requisition id 107041 join a purpose driven winning team, committed to results, in an inclusive and high performing culture. data engineer, analytics coe, global risk management the data engineer will contribute to the definition of best practices in terms of data management and data operations, and will lead the execution of efficient data pipelines to automate data processes in a big data environment . the candidate will identify and prioritize opportunities to leverage data properly and take a leading role in project based initiatives to drive innovation and digital transformation throughout the bank and global risk management. the data engineer role requires strong technical skills on big data and cloud environments as well as flexibility, collaboration and great teamwork abilities. is this role right for you in this role you, will report to the director data engineering while operating in a team based environment, you will build data pipelines on cloud and on prem environments lead the gathering and processing of data at scale guide the processing of unstructured data into a form suitable for analysis provide technical expertise, guidance, advice and knowledge transfer on aspects of code management, automated release builds and code deployment collaborate with grm key stakeholders and partners to define data engineering and technical training best practices for data projects maintain a good understanding of the bank s business strategies, business policies, risk management and it processes and disciplines. this requires working with enterprise data management office, governance and technology teams to ensure that the data captured through other initiatives is readily available for usage within analytics teams. able to work in an agile environment if required maintain an active participation in various global risk management value added initiatives from time to time be customer focused and proactive, while maintaining a healthy partnership with business line counterparts do you have the skills that will enable you to succeed in this role we d love to work with you if you have university degree in relevant stem discipline 5 years experience in development and cloud data processing applications experience cleaning, transforming and visualizing large data sets working with various data formats capability to architect highly scalable distributed data pipelines using open source tools and big data technologies such as hadoop, hbase, spark, etc. experience in python or scala. familiar with machine learning libraries or framework . hands on experience with cloud based environments, e.g. azure and databricks experience with unix tools and shell scripting solid sql skills for querying relational databases data quality or lineage solutions strong etl experience curiosity, ability to learn and to apply newly acquired knowledge to daily tasks strong time management and organizational skills to manage multiple priorities in a fast paced environment sound oral and written communication skills to elaborate and support credit decisions before internal stakeholders what s in it for you the opportunity to join a forward thinking company surrounded by a collaborative team of innovative thinkers. exposure to different data driven business lines including retail and business banking be part of a diverse and knowledgeable risk team a rewarding career path with diverse opportunities for professional development. internal development to support your growth and enhance your skills. a competitive compensation and benefits package. an organization committed to making a difference in our communities for you and our customers. we have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success this position is located downtown toronto location canada ontario toronto scotiabank is a leading bank in the americas. guided by our purpose for every future , we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['unstructured data', 'big data', 'sql', 'agile environment', 'python', 'data processing', 'scala', 'enterprise', 'unix', 'analytics', 'data engineering', 'hbase', 'machine learning', 'data pipelines', 'relational databases', 'data quality', 'shell scripting', 'banking', 'hadoop', 'data operations', 'data management', 'digital transformation', 'etl']","['hbase', 'sql', 'python', 'scala', 'hadoop', 'shell script', 'unix', 'big data', 'data quality']","['unstructured data', 'distributed', 'agile environment', 'machine learning', 'data pipelines', 'data processing', 'relational databases', 'banking', 'data engineering', 'enterprise', 'analytics', 'data operations', 'data management', 'digital transformation', 'etl']","['environment', 'environment based', 'private', 'retail', 'gr', 'risk management', 'business banking', 'governance', 'investment banking', 'capital markets', 'compensation', 'technical training', 'business lines']"
438,578,Ingénieur de données / Data Engineer,"english will follow altitude sports est le leader de la vente en ligne au canada, et se sp cialise dans la rencontre de la mode avec le plein air. fond e en 1984, l entreprise offre des conseils de premier plan en mati re d quipement et de v tements techniques haut de gamme, en plus d un programme d avantages destin s ses membres et d une multitude de produits soigneusement s lectionn s pour les aventures urbaines et en plein air.l description de poste en tant que membre fondateur de l quipe, vous serez responsable de la conduite de la vision et de l architecture long terme de l quipe, de la conduite or mise en forme des feuilles de route et du leadership technique. vous ferez partie d une quipe d ing nieurs talentueux et passionn s, vous ferez l exp rience de nombreuses facettes du monde de la vente en ligne et participerez une pouss e toujours croissante vers une exp rience client de classe mondiale et l excellence op rationnelle. les nouvelles id es sont toujours les bienvenues dans une culture de travail ax e sur la communaut qui s efforce continuellement d tre la pointe du progr s. en tant qu ing nieur des donn es, vous avez la possibilit d aider mener une transition vers une architecture de donn es de streaming volutive et polyvalente. vous travaillerez en troite collaboration avec les d veloppeurs, les parties prenantes et les analystes bi sur les donn es op rationnelles et strat giques. essentiellement, vous serez t moin de l essentiel de ce qui fait fonctionner une op ration de commerce lectronique s rieuse. r les et responsabilit s participer l architecture, au d veloppement, aux tests, au d ploiement et la livraison de flux de donn es en continu qui communiquent entre les sources de donn es de service, le lac de donn es, l entrep t de donn es et les syst mes tiers appliquer les normes, la nomenclature et les meilleures pratiques pour le stockage et la transformation des donn es maintenir les processus etl or elt existants et en mettre en uvre de nouveaux des fins op rationnelles et de bi cr er et maintenir l edi et d autres int grations tierces collaborer troitement avec les op rations et l intelligence d affaire pour r pondre leurs besoins travailler de mani re proactive avec l quipe produit pour concevoir des solutions techniques ou fonctionnelles amener l quipe vers de nouveaux sommets en pr sentant de nouveaux concepts un comit technique assurer la r silience des produits en automatisant les tests dans le cadre du processus ci or cd exigences et comp tences requises baccalaur at ou sup rieur en informatique, en g nie ou dans un domaine connexe. ma trise ou quivalent tranger en informatique, ing nierie, math matiques, un atout 2 ann es d exp rience professionnelle dans le commerce lectronique sur des ressources de streaming distribu es telles que kafka or spark, spring, aws kinesis or sns or eventbridge, etc. 2 ann es d exp rience professionnelle avec le traitement par lots etl 4 ans d exp rience avec les bases de donn es relationnelles bas es sur les lignes et les colonnes ainsi que nosql connaissance de python, bash ou technologies similaires exp rience pratique de la cr ation et de l exploitation de syst mes volutifs et s curis s sur aws or google cloud or azure ou similaire connaissance des pratiques professionnelles d ing nierie logicielle et des meilleures pratiques pour le cycle de vie complet du d veloppement logiciel, y compris les normes de codage, les revues de code, la gestion du contr le des sources, les tests, les d ploiements et les op rations continus capacit d montr e encadrer des ing nieurs logiciels d butants dans tous les aspects de leurs comp tences en ing nierie la connaissance des pratiques de science des donn es est un atout certain pourquoi te joindre nous une assurance collective des rabais employ s sur plus de 400 marques techniques et urbaines la possibilit d effectuer ses t ches en t l travail pendant la covid 19 un environnement de travail convivial au c ur du mile ex la possibilit d voluer au sein d une entreprise de e commerce en pleine croissance joindre une quipe de talent altitude sports is canada s e commerce leader, working and playing at the intersection of fashion and the outdoors. founded in 1984, the company offers best in class advice on premium gear and technical apparel, a members only benefits program and a curated selection of products for outdoor adventures and urban pursuits retailer . job description as a foundational member of the team, you will be responsible for driving the team s long term vision and architecture, drive or shape roadmaps, and provide technical leadership. you will be part of a talented and passionate squad of engineers, you will experience many facets of the world of online retail and take part in an ever growing push towards world class customer experience and operational excellence. new ideas are always welcome in a community driven work culture that continuously strives to be on the bleeding edge. as a data engineer, you are given the opportunity to help lead a transition to a scalable and versatile streaming data architecture. you will work closely with developers, stakeholders and bi analysts on operational and strategic data. essentially, you will witness the core of what makes a serious e commerce operation tick. main responsibilities participate in the architecture, development, testing, deployment and delivery of streaming data flows that communicate between service data sources, the data lake, the data warehouse and 3rd party systems enforce standards, nomenclature and best practices for data storage and transformation maintain existing etl or elt processes and implement new ones for operational and bi purposes create and maintain edi and other 3rd party integrations collaborate closely with operations and business intelligence to meet their needs proactively work with the product team to conceive technical or functional solutions requirement and skills bs degree or higher in computer science, engineering or related field. master s degree or foreign equivalent in computer science, engineering, mathematics, is an asset 2 years of professional ecommerce experience working on distributed streaming resources such as kafka or spark, spring, aws kinesis or sns or eventbridge, etc. 2 years of professional experience with etl batch processing 4 years experience with relational row based and column based dbs as well as nosql knowledge of python, bash or similar technologies hands on experience in building and operating scalable and secure systems on aws or google cloud or azure or similar knowledge of professional software engineering practices best practices for full software development life cycle, including coding standards, code reviews, source control management, testing, continuous deployments and operations. demonstrated ability to mentor junior software engineers in all aspects of their engineering skill set knowledge of data science practices is a definite asset why work with us a complete benefits package staff discount on 400 urban and technical brands the possibility to work remotely during covid 19 a welcoming work environment in the heart of montreal s little italy be part of a fast growing company in the booming e commerce space be part of a talented team. kafka ,spark, spring, aws kinesis ,sns, eventbridge,etl batch processing,pentaho, talend, ssismysql, ms sql,snowflake, bigquery, cassandra,mongodb, dynamodb, elastic search, python, bash aws or google cloud or azure","['bash', 'coding standards', 'mongodb', 'pentaho', 'technical leadership', 'batch processing', 'sql', 'python', 'cd', 'software', 'talend', 'data science', 'software development', 'data', 'aws', 'nosql', 'testing', 'business intelligence', 'cassandra', 'bi', 'computer science', 'mathematics', 'snowflake', 'etl']","['sql', 'python', 'cassandra', 'google cloud', 'bi', 'sns', 'talend', 'aws', 'business intelligence', 'pentaho', 'snowflake', 'nosql', 'edi']","['batch processing', 'bash', 'tests', 'cd', 'software', 'testing', 'ci', 'data science', 'software development', 'computer science', 'data', 'mathematics', 'coding standards', 'mongodb', 'data storage', 'technical leadership', 'etl']","['commerce', 'e commerce', 'environment', 'retail', 'fashion', 'apparel', 'customer experience', 'operational excellence', 'architecture']"
439,579,Data Arch Consultant,"data architect consultant location toronto, on we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are a hands on solution architect who knows how to develop, design and maintain technologies that work for our clients. you are a next generation thinker when it comes to what we call data in the new. your superpower using the latest data and analytics technologies to help clients glean the most value from their data. and you know how to come up with strategies, solutions, and processes for managing enterprise wide data throughout the data life cycle. you re a digital native who s right at home when the challenge calls for teamwork and originality the work defining the policies standards for cloud native data management for structured, semi and unstructured data use defining the data architecture for cloud native data management with expert level knowledge on popular cloud platforms data layers integration design , etl , velocity data architecture design patterns defining the data architecture for cloud native data management with focus to business process flows to support data sourcing lineage data modelling methodologies tools reference architectures defining the data architecture for cloud native data management with focus to data definitions metadata reference data management master data management data lineage defining the data management vision strategies, managing the change journey and or or playing serving as the architect to design and scale end to end data management with special focus to data quality rules kpis automated data cleansing compliance rules kpis data democratisation data security compliance security policies for data access, use integration qualifications external here s what you need a minimum of 3 years of working as a data governance consultant or directly with clients leveraging popular tools like informatica, collibra, ibm, asg etc. a minimum of 3 years in a role that had taken ownership of the data assets for the organization to provide users with high quality data that is accessible in a consistent manner. a minimum of 3 years facilitating data cleansing and enrichment through data de duplication and construction a minimum of 3 years in a role that discovered captures the current state of the system, encompassing processes such as data discovery, profiling, inventories. a minimum of 3 years in a role that defined processes include data classification, business glossary creation and business rule definition. a minimum of 3 years in a role that applied processes with aim to operationalize and ensure compliance with policies and include automating rules, workflows, collaboration etc. bonus points if experience in a role that led measurement and monitoring to determine the value generated and include impact analysis, data lineage, proactive monitoring, operational dashboards and business value. experience in a role that led repeatable, iterative, and standardized processes to define how the data should be governed. at a minimum, below processes and procedures must have been practiced defining data domains change management data stewardship and ownership conflict resolution technology automation communication experience performing master data management metadata management data management and integration systems development lifecycle data modeling techniques and methodologies database management database technical design and build extract transform load tools cloud data architecture, data architecture principle online analytical processing data processes data architecture principles data architecture estimation","['metadata management', 'data classification', 'dashboards', 'technical design', 'cleansing', 'data cycle', 'reference', 'master', 'data', 'analytics', 'integration', 'unstructured', 'machine learning', 'design patterns', 'informatica', 'sourcing', 'metadata', 'data quality', 'automation', 'security', 'modeling', 'data management', 'etl', 'ai']","['data quality', 'data']","['unstructured data', 'metadata management', 'data classification', 'data lineage', 'dashboards', 'technical design', 'database management', 'cleansing', 'analytical processing', 'reference data management', 'analytics', 'data', 'integration', 'technology', 'machine learning', 'design patterns', 'informatica', 'sourcing', 'metadata', 'master data management', 'automation', 'security', 'modeling', 'data management', 'etl', 'ai']","['change management', 'business value', 'design', 'governance', 'construction', 'business process', 'architecture']"
440,580,Data Engineer,"next pathway the automated cloud migration company listed as one of canada s hottest start ups by the globe and mail, next pathway is a technology services company providing clients a pathway from existing to emerging technologies. our automation technology helps our customers accelerate the migration of complex applications and workloads to the cloud. next pathway is located in the heart of the financial district, minutes from union station and the subway. we are looking for skilled data engineers to join our team contract to december 31, 2021. the candidate needs to have extensive experience as follows minimum of 3 years of proven experience in a core competency proven hands on software development experience strong data warehouse knowledge and experience, include data modeling, data ingestion, transformation, data consumption patterns strong sql knowledge and experience, including developing and optimizing complex queries, creating efficient udfs to extend the functionalities experience in at least 3 of below rdbms teradata, netezza, sql server, greenplum, oracle, sybase, db2, mysql, redshift, sqldw. experience with cloud technologies experience with etl tools experience with major programming languages strong understanding and experience of relational database, include design and implementation develop and maintain unit tests and integration tests, and test automation. adoption of agile and scrum development methodology ba or ms or phd degree in computer science, engineering, or a related subject . other technologies you might work with include microsoft office suite basecamp project management team communication slack messaging platform zoom meetings and video conferencing confluence collaboration tool jira project management software . other skills team player with excellent interpersonal and communication skills strong work ethic with a positive attitude and a passion for data and development strong analytical and problem solving skills excellent time management skills contract length 9 months job types full time, contract schedule monday to friday experience sql 4 years etl 4 years netezza 2 years oracle 2 years work remotely yes covid 19 precaution remote interview process","['rdbms', 'confluence', 'mysql', 'cloud migration', 'sql', 'software', 'software development', 'data', 'programming', 'integration', 'technology services', 'teradata', 'scrum', 'netezza', 'automation', 'jira', 'zoom', 'computer science', 'modeling', 'etl']","['sql', 'jira', 'rdbms', 'zoom', 'udfs', 'confluence', 'programming', 'mysql', 'technology services', 'teradataezza']","['methodology', 'cloud migration', 'tests', 'test', 'software', 'data ingestion', 'scrum', 'software development', 'computer science', 'data', 'integration', 'modeling', 'automation', 'etl']","['microsoft office', 'design', 'video conferencing', 'project management', 'adoption']"
441,582,Data Engineer,"mogo finance technology inc. a financial technology company offers a finance app that empowers consumers with simple solutions to help them get in control of their financial health and be more mindful of the impact they have on society and the planet. we all know it s time to do things differently. it s time for a new way to manage our money, one that s inclusive and sustainable. one that takes into account our financial health, the planet s health and the health of our society. at mogo, users can sign up for a free account in only three minutes and begin to learn the 4 habits of financial health and get convenient access to products that can help them achieve their financial goals and have a positive impact on the planet including a digital spending account with mogo visa platinum prepaid card featuring automatic carbon offsetting, free monthly credit score monitoring, id fraud protection and personal loans. the mogo platform has been purpose built to deliver a best in class digital experience, with best in class products all through one account. with more than one million members and a marketing partnership with canada s largest news media company, mogo continues to execute on its vision of becoming the go to financial app for the next generation of canadians. to learn more, please visit mogo.ca or download the mobile app . mogo is looking for a data engineer to be a key member of mogo s team. based in vancouver, this role will be responsible for the architecture, integration and analysis of both traditional and non traditional data sources used for model building. check out the list of qualifications below and if this sounds like you, send us your resume we want to hear from you what you ll do create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws big data technologies. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. work with stakeholders including the executive, product, data and design teams to assist with data related technical issues and support their data infrastructure needs. keep our data separated and secure across national boundaries through multiple data centers and aws regions. create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. work with data and analytics experts to strive for greater functionality in our data systems. what you ll need 3 5 years experience in a similar role with an emphasis on translating quantitative data into meaningful insights. experience working in the financial services industry and or or with digital products. degree in computer science, statistics, mathematics or other related discipline advanced working sql knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases. experience building and optimizing big data data pipelines, architectures and data sets. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. strong analytic skills related to working with unstructured datasets. build processes supporting data transformation, data structures, metadata, dependency and workload management. working knowledge of message queuing, stream processing, and highly scalable big data data stores. proficient with the the following software or tools big data tools hadoop, spark, kafka, etc. relational sql and nosql databases, including postgres and mongodb. aws cloud services ec2, emr, rds, redshift object oriented or object function scripting languages python, javascript. salary range for this role is 80,000 90,000 per annum based on experience. interested applicants can submit an application online or through email at","['go', 'model building', 'databases', 'quantitative data', 'emr', 'operational efficiency', 'data infrastructure', 'financial technology', 'root cause', 'big data', 'mongodb', 'javascript', 'sql', 'python', 'statistics', 'software', 'scripting', 'queuing', 'analytics', 'integration', 'aws', 'data systems', 'nosql', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'data centers', 'metadata', 'cloud services', 'data structures', 'datasets', 'hadoop', 'scalability', 'computer science', 'mathematics']","['go', 'sql', 'python', 'databases', 'emr', 'object', 'hadoop', 'data centers', 'aws', 'big data', 'rds', 'javascript', 'nosql']","['model building', 'quantitative data', 'operational efficiency', 'data infrastructure', 'financial technology', 'root cause', 'mongodb', 'statistics', 'software', 'scripting', 'queuing', 'analytics', 'integration', 'data systems', 'unstructured', 'data pipelines', 'relational databases', 'data transformation', 'stream processing', 'metadata', 'cloud services', 'data structures', 'datasets', 'scalability', 'computer science', 'mathematics']","['loans', 'customer acquisition', 'metrics', 'marketing', 'design', 'finance', 'financial services', 'functionality', 'business performance', 'architecture']"
442,583,Cloud Data Engineer,"who is digitalonus at digitalonus, we not only provide agile and devops methodologies to our customers, but we have also adopted the same within the company as well. our nimble processes are not mired in red tape, yet robust, flexible and results oriented. we are software engineers, technical architects, cloud and devops specialists. but the most important, we are dreamers, creators, and challengers. each day, we strive to make great come alive. our lemma work smart and play hard our technology partners are hashicorp, cloudbees, chef, pagerduty, docker and sap . we are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. does ambition, success, fun, friends learning define your idea of a career join us and be part of our family we are looking for a data engineer responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow. will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. location canada qualifications we are looking for azure data engineers collaborate with business stakeholders to identify and meet data requirements. they design and implement solutions. they also manage, monitor, and ensure the security and privacy of data to satisfy business needs. the role of a data engineer is different from the role of a database administrator. 5 years of experience in data engineering familiarity with eclinical works data, hl7 or fhir experience with machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, hidden markov models and graph algorithms. data warehousing experience with sql server, oracle, redshift, teradata, etc. experience with big data technologies experience with real time data processing and api platforms. experience in using python, java and or or other data engineering languages. experience with data visualization and presentation, turning complex analysis into insight. healthcare domain and data experience ideal background healthcare data background, especially provider data , including clinical data. experience with fhir is highly desirable. experience and deep background in various methods of etl is required. programming and full stack development experience would be a great addition. key activities maintain, improve, clean, and manipulate data in the business operational and analytics databases design and deploy data platforms across multiple domains ensuring operability transform data for meaningful analyses improve data efficiency, reliability and quality create data enrichment build high performance ensure data integrity create and manage data stores at scale ensure data governance security, quality, access and compliance why you will love this job we look for people who are thoughtful, can break down problems, work individually sometimes, and in pairs or teams at other times. you are trusted to work on your own but ask for help when you are blocked we will work with you to find the balance of what you want to do, what you are good at, and how that fits in with the company goals. what you can expect from us at digitalonus, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. trust and openness lead to quality, innovation, commitment to deliverables, efficiency, and cost effectiveness for all our customers. empathy for your coworkers and our customers is an important part of success here. as an early stage startup, most people wear many hats. we are growing at a phenomenal pace we have lots of opportunities to grow and learn hear your voice, nurture your talent, and help you strengthen your footprint health, life, dental, and vision insurance flexible work hours work from home options company wide retreats if you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for digital onus, s. de rl de cv . if you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and or or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the federal law on protection of personal data held by private parties, its regulations, and other applicable regulations. if you are the owner of personal data in possession of the company and wish to obtain further information regarding the processing of your personal data or the exercise of your arco rights, please consult our integral privacy notice on the website https or or or privacy policy or","['https', 'databases', 'data flow', 'data integrity', 'data visualization', 'big data', 'clinical data', 'java', 'sql', 'python', 'data processing', 'software', 'complex analysis', 'data', 'programming', 'analytics', 'data engineering', 'data warehousing', 'teradata', 'machine learning', 'data efficiency', 'algorithms', 'language processing', 'devops', 'neural networks', 'security', 'api', 'kernel', 'etl']","['https', 'sql', 'teradata', 'python', 'databases', 'api', 'hashicorp', 'programming', 'big data', 'java']","['cost', 'dimensionality', 'data flow', 'data integrity', 'data visualization', 'natural', 'clinical data', 'data processing', 'software', 'analytics', 'data', 'data engineering', 'data warehousing', 'machine learning', 'algorithms', 'language processing', 'devops', 'neural networks', 'security', 'kernel', 'personal data', 'etl']","['environment', 'and compliance', 'private', 'healthcare', 'design', 'sap', 'insurance', 'governance', 'regulations', 'law', 'architecture']"
443,584,Scientist - Biological Sciences Platform - Regular Full-time (06082021),"scientist sunnybrook research institute the sunnybrook research institute , the research arm of sunnybrook health sciences centre a research hospital fully affiliated with the university of toronto is currently seeking candidate for a scientist position in the biological sciences platform. as the research enterprise of a premier academic health sciences centre and one of canada s largest hospitals, sri s groundbreaking research changes the way patients are treated around the world. sri is one of the fastest growing hospital based research enterprises in canada with well established programs in basic and applied research, developing innovations in care for more than 1 million patients annually. sri is located in toronto, one of the most populous cities in canada. it is located on the northwestern side of the lake ontario. toronto is an international centre of business, finance and cultures, and is known to be one of the most multicultural cities in the world. position the successful candidate will hold a phd and or or md, have demonstrable scientific leadership in their field and a proven track record in publishing high quality, peer reviewed research. the successful candidate will lead an independent academic program of research excellence in high content cellular analysis dedicated to the identification and characterization of basic cellular mechanisms and of new targets governing diseases. expertise in high content screening of cells and or or tissues and automated data analysis are assets. academic appointments in the faculty of medicine, university of toronto at the assistant or associate professor level and the sunnybrook research institute, will be commensurate with experience. the term of the appointment will be three years and is renewable in accordance with hospital and university policies. career interruptions sunnybrook research institute recognizes that scientists have varying career paths and understands the impact that career interruptions can have on a candidate s record of research achievement. candidates are encouraged to explain interruptions in order to allow for a fair assessment of their application. search committee members have been instructed to give careful consideration to, and be sensitive to the impact of, career interruptions in their assessments. environment conducting 125 million in research each year, sri is home to 1000 scientists, clinician scientists research associates and more than 400 trainees, operating in 500,000 sq.ft. of state of the art infrastructure http or or sunnybrook.ca or research or . how to apply applications should include 1 a letter of interest. the letter should describe the applicant s research accomplishments 2 a complete curriculum vitae including professional services, outreach, mentoring or training of highly qualified personnel and other contributions appropriate to the specific position and all materials should be addressed to dr. david andrews, chair of the search committee. please submit your application via email to carmen ho with subject line scientist biological sciences this post will stay active until the position is filled. we would like to thank all applicants, but only those selected for an interview will be contacted. all qualified candidates are encouraged to apply however, canadians and permanent residents will be given priority. diversity statement sunnybrook research institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to women, visible minorities or persons of colours, indigenous peoples, people from all genders, religions and ethnicities, persons with disabilities, lgbtq persons, and all others who may contribute to the further diversification of ideas. accommodation policy sunnybrook research institute is committed to providing accessible employment practices that are in compliance with the accessibility for ontarians with disabilities act . if you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter. job information company operating name sunnybrook research institute business address 2075 bayview ave. toronto, ontario, m4n 3m5 title scientist noc 2121 number of positions 1 education requirements doctoral or phd language requirements verbal english written english duration of employment permanent, full time benefits 4 weeks vacation per year with full time benefits wage 120,000 to 130,000 sunnybrook research institute is committed to providing accessible employment practices that are in compliance with the accessibility for ontarians with disabilities act . if you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter. sunnybrook research institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to visible minorities, all religions and ethnicities, persons with disabilities, lgbtq persons, and all others who may contribute to the further diversification of ideas. sunnybrook research institute is committed to providing accessible employment practices that are in compliance with the accessibility for ontarians with disabilities act . if you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter. sunnybrook research institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to visible minorities, all religions and ethnicities, persons with disabilities, lgbtq persons, and all others who may contribute to the further diversification of ideas.","['screening', 'medicine', 'data analysis']",[],"['screening', 'http', 'medicine', 'data analysis']","['curriculum', 'environment', 'education', 'characterization', 'professional services', 'art', 'finance', 'materials', 'assessment', 'mentoring']"
444,586,Data Integration and Big Data Processing( Data Engineer),"12 month contract remote within canada required skills big data engineers are responsible for developing, maintaining, evaluating and testing big data solutions. in addition, they are generally involved in the design of big data solutions. must gcp knowledge experience responsible for hadoop development. implementation including loading from disparate data sets, preprocessing using hive and pig. scope and deliver various big data solutions. ability to design solutions independently based on high level architecture. manage the technical communication between the survey vendor and internal systems. maintain the production systems . collaborate with other development and research teams. building a cloud based platform that allows easy development of new applications. proficient understanding of distributed computing principles. management of hadoop cluster, with all included services. ability to solve any ongoing issues with operating the cluster. proficiency with hadoop v2, mapreduce, hdfs. experience with building stream processing systems, using solutions such as storm or spark streaming. good knowledge of big data querying tools, such as pig, hive, and impala. experience with spark. experience with integration of data from multiple data sources. experience with nosql databases, such as hbase, cassandra, mongodb. knowledge of various etl techniques and frameworks, such as flume. experience with various messaging systems, such as kafka or rabbitmq. experience with big data ml toolkits, such as mahout, sparkml, or h2o . good understanding of lambda architecture, along with its advantages and drawbacks. experience with cloudera or mapr or hortonworks. reference id ti090421 i contract length 12 months job types full time, contract schedule monday to friday work remotely yes covid 19 precaution remote interview process","['computing', 'databases', 'technical communication', 'cluster', 'big data', 'mongodb', 'hive', 'gcp', 'integration', 'nosql', 'hbase', 'big data solutions', 'testing', 'stream processing', 'production systems', 'cassandra', 'hadoop', 'rabbitmq', 'etl']","['hbase', 'ma', 'mapr', 'gcp', 'databases', 'hadoop', 'big', 'ka', 'big data', 'rabbitmq', 'production systems', 'hive', 'nosql', 'cassandra']","['distributed', 'computing', 'testing', 'data solutions', 'stream processing', 'integration', 'mongodb', 'etl', 'cluster']","['design', 'architecture']"
445,587,Senior Data Integrator,"are you looking for unlimited opportunities to develop and succeed with work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations. job description are you a go getter who has a passion in building next gen data solutions for business problems are you a big fan of simplification and automation manulife is seeking a senior data integrator, to join our rapidly expanding it organization and assist us as we work to be a digital leader in our industries. responsibilities for this role include work closely with source system smes to produce source to target mappings, business glossaries, data lineages and data access requirements produce clear, concise business requirement documents capture acceptance criteria along with specification of test cases associated experience with sdlc and or or agile methodologies for project development, and able to contribute to all phases of project development, is required solid understanding of hadoop and complementary big data services or technologies familiarity with data modeling and diagram practices, such as er, eer, erd, and uml thrive on turning ambiguity and conflicting information into clarity in a fast changing environment solid foundation in sql and good understanding of various data source systems build relationships, communicate, and collaboratively work with both business and technical partners. ability to break down complex problems into logical, digestible steps ability to effectively manage multiple projects and priorities simultaneously designs and ensures consistent data flow through the organization collaborates with data scientists and data engineers on moving data analysis models into production assesses middleware tools for data integration, transformation and routing utilizes a variety of data interchange formats to ensure that data requirements for the business are met monitors mapping and data integrity across the organization evaluates data integration assets and capabilities across bu s and divisions for overlap, consolidation and reuse potential. supervises and reviews data dictionaries for accuracy on a periodical basis identifies emerging technologies for future use has positive impact to specific organizational entities has some understanding of the nature of the impact usually a top contributor to team s success job requirements for this role include demonstrated ability to interpret business needs and translate business cases into manageable, detailed technical requirements, identifying key features to be delivered understanding of how data strategy supports manulife s strategy understanding of drivers of data demand and how data is used attends advanced training sessions and is certified on multiple domains of expertise demonstrates all core skills, and good interpersonal skills for the role uses and combines knowledge of the field and the market to formulate the right approach strong knowledge of the business or ability to come up to speed in a short time. constantly learns from both success and failure good organizational and problem solving abilities that enable you to manage through creative abrasion. good verbal and written communication able to effectively articulate technical vision, possibilities, and outcomes. experiments with emerging technologies and understanding how they will impact what comes next. good analytical skills, copes with complex situations through deliberate analysis and planning master s and or or bachelor s degree in computer science or related field experience or exposure to data engineering, data architecture, system design, business intelligence, qa and data science programming experience in python, spark, hql, scala, and shell scripting experience or exposure to ci or cd code flow and tooling, and an understanding of the principles and pragmatics for build pipelines, artefact repositories, zero downtime deployment knowledge and understanding of cloud technologies or platform familiarity and domain expertise in data and analytics initiatives this is a full time permanent role located in toronto, on. if you are ready to unleash your potential, it s time to start your career with manulife or john hancock. about manulife manulife financial corporation is a leading international financial services group that helps people make their decisions easier and lives better. with our global headquarters in toronto, canada, we operate as manulife across our offices in canada, asia, and europe, and primarily as john hancock in the united states. we provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. at the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. as of december 31, 2020, we had 1.3 trillion in assets under management and administration, and in the previous 12 months we made 31.6 billion in payments to our customers. our principal operations are in asia, canada and the united states where we have served customers for more than 155years. we trade as mfc on the toronto, new york, and the philippine stock exchanges and under 945 in hong kong. manulife is an equal opportunity employer at manulife or john hancock , we embrace our diversity. we strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. we are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex , sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law. it is our priority to remove barriers to provide equal access to employment. a human resources representative will work with applicants who request a reasonable accommodation during the application process . all information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and manulife or john hancock policies . to request a reasonable accommodation in the application process, contact .","['analytical skills', 'data flow', 'data integrity', 'ci', 'uml', 'technical requirements', 'routing', 'sql', 'python', 'shell', 'cd', 'scala', 'scripting', 'data science', 'data', 'programming', 'integration', 'analytics', 'technical vision', 'data engineering', 'pipelines', 'business intelligence', 'data analysis', 'automation', 'erd', 'agile methodologies', 'administration', 'test cases', 'middleware', 'sdlc', 'hadoop', 'data solutions', 'computer science', 'modeling']","['go', 'sql', 'python', 'shell', 'middleware', 'repositories', 'scala', 'hadoop', 'uml', 'programming', 'big data', 'business intelligence', 'pipelines', 'erd']","['analytical skills', 'data flow', 'data integrity', 'ci', 'technical requirements', 'routing', 'cd', 'scripting', 'data science', 'data', 'analytics', 'integration', 'technical vision', 'data engineering', 'project development', 'data lineages', 'data analysis', 'automation', 'planning', 'agile methodologies', 'administration', 'test cases', 'sdlc', 'data solutions', 'computer science', 'modeling']","['environment', 'asset management', 'human resources', 'design', 'financial services', 'architecture', 'compensation', 'law', 'insurance']"
446,588,Software Engineer / Data Engineer,"xgen ai is seeking a software engineer to join our development team in vancouver, bc. the ideal candidate would have a strong desire to learn, work hard, and play an important role as part of a high performance team. as a software engineer at xgen ai, you will contribute to the design, development, and implementation of state of the art, cloud based, ai first systems powered by xgen s ai technology. responsibilities contribute to the design, development, and evolution of xgen ai s saas and machine learning platform. design, document, implement, and unit test microservices that run on aws, using the latest aws technologies. manage analytics data, datastore, and databases such as s3, rds, datalake or athena, dynamodb, redis cache...etc ensure products meet all relevant specifications and quality standards you are also playing an important role in managing data queries, importing, transforming, and storing strategies. qualifications hands on experience with python 3 experience in java is a plus. familiar with object oriented design programming familiar with agile, scrum, and devops working knowledge of databases and sql proficiency with sql complex queries and aggregation which make use of analytics excellent oral, written, and interpersonal communication skills the ability to learn quickly in a dynamic environment must be eligible to work full time experience with cloud , bigdata, and stream processing knowledge of system monitoring and dashboards must be located in vancouver job types full time, permanent pay 70,000.00 100,000.00 per year benefits casual dress company events dental care disability insurance employee stock purchase plan paid time off vision care work from home schedule 8 hour shift monday to friday education bachelor s degree experience python 3 3 years java 3 years data and analytics processing 3 years db and sql queries 3 years work remotely temporarily due to covid 19","['databases', 'dashboards', 'java', 'sql', 'python', 'software', 'redis', 'saas', 'analytics', 'aws', 'programming', 'microservices', 'machine learning', 'scrum', 'stream processing', 'specifications', 'athena', 'system monitoring', 'devops', 'ai']","['sql', 'python', 'databases', 'object oriented', 'redis', 'java', 'programming', 'aws', 'rds', 'athena']","['machine learning', 'software', 'specifications que', 'scrum', 'devops', 'stream processing', 'dashboards', 'saas', 'analytics', 'microservices', 'system monitoring', 'ai']","['environment', 'events', 'education', 'design', 'art', 'insurance']"
447,589,Junior Business Intelligence Developer - Data Science and Analytics,"our subsidiary is in proptech and real estate analytics spaces, founded by serial entrepreneurs and experienced management. a data, analytics, and technology leading cloud services specializing in the canadian real estate industry. delivering ai driven analytics data solutions that enable homeowners, investors, brokers, advertisers, industry professionals, and researchers to assess, understand, engage and transact within the real estate industry. our headquartered in toronto. the business intelligence developer will be working under the guidance of the program supervisors and working directly with other team members including data scientists, interns and our business team. duties and responsibilities junior bi developer will develop predictive models. you will apply insights and best practices to build models that increase and optimize customer experiences with our data platforms, software solutions, and service offerings. develop tools. you will build tools and processes to monitor and analyze model performance and data accuracy. advice on continuous improvements. you will provide recommendations on new data sources to enhance the current data sets, identify new data sources, and work with the data engineering and development team to automate ingestions and transformations. development works independently or as a team member to design, develop, test, and implement our solutions to support aradata s initiatives designs and develops web applications, apis, and software utilities using r , python , bash, javascript , css, html, and other web development languages, as appropriate. creates visual tool mock ups and prototypes to validate with end users. identifies and remedies problems or issues to ensure a secure and well functioning environment. optimizes system efficiency by analyzing performance indicators and changing software responsible for application deployments, minimizing avoidable downtime. assists with initiatives to upgrade application deployment infrastructure performs systems monitoring activities, utilizing expert knowledge to identify areas that required improvement, adjustment, etc., to maintain optimal operations at peak performance on servers coordinates quality assurance activities which include reviewing test plan or test cases to facilitate the optimal provision of guidance on testing and defect reporting identifies, as required and schedules or coordinates problem reviews, following up on assigned actions in a timely manner utilizing expertise to resolve and or or facilitate the resolution of problems, where appropriate. collaborates with project teams to identify and define application requirements, making recommendations and outlining technical initiatives with the goal of improving the current situation. maintains responsibility for the development and delivery of project presentations to various stakeholders, in a timely manner to gain full buy in and corporate with endeavors. knowledge and skills an undergraduate degree in, engineering, computer science and or or a related discipline minimum 2 years of full stack development experience relevant experience in mining, analyzing, and visualizing large amounts of data and programming skills relevant experience in reporting, analysis, and insights extensive experience with html, css and javascript, including javascript libraries experience in one or more of the following python, r, javascript expert level knowledge of relational databases . experience in non relational databases is an asset. experience with popular web development frameworks, such as react, django, flask, express.js, or ruby on rails comfortable working in a linux environment proficient with version control systems experience in providing supervision, guidance, leadership and feedback to project teams and junior resources ability to multi task and work effectively both individually and as part of a team proficiency with r shiny, r markdown, and or or r studio connect is an asset. experience with data science and machine learning tools and methods is an asset. experience with ui or ux design best practices is an asset strong interpersonal skills, able to build relationships, effectively interact, influence, superior communication skills with proven ability to communicate quantitative or qualitative disciplined with a proven track record of delivering results and executing with excellence demonstrated ability to work with various data sources expertise with reporting techniques and report automation using platforms such as sql, hive excellent written and verbal skills and keen attention to detail nice to have experience with real estate and or or mortgage businesses is an asset knowledge of statistical analysis techniques such as regression, clustering algorithms using programming languages such as python, pyspark, or r is an asset academic qualifications with a focus on business, finance, or statistical analysis is an asset education required an undergraduate degree in, engineering, computer science and or or a related discipline contract length 6 months expected start date 2021 07 01 job types full time, contract benefits tuition reimbursement work from home schedule monday to friday covid 19 considerations all employees are working remotely during the covid 19 application question do you have any experience with data science and modelling what is your salary expectation education bachelor s degree experience data science professional work 1 year software development professional work 1 year work remotely temporarily due to covid 19","['project', 'bash', 'css', 'linux', 'quality assurance', 'pyspark', 'javascript libraries', 'javascript', 'software solutions', 'hive', 'statistical analysis', 'sql', 'python', 'software', 'reporting', 'version control', 'data science', 'software development', 'analytics', 'programming', 'data engineering', 'system efficiency', 'servers', 'machine learning', 'ai', 'relational databases', 'testing', 'ruby on rails', 'business intelligence', 'flask', 'web applications', 'algorithms', 'automation', 'cloud services', 'ux', 'test cases', 'html', 'programming languages', 'bi', 'data solutions', 'web development', 'computer science', 'django', 'r']","['sql', 'python', 'linux', 'css', 'quality assurance', 'programming languages', 'pyspark', 'bi', 'javascript libraries', 'ruby on rails', 'hive', 'programming', 'business intelligence', 'javascript', 'django', 'r']","['bash', 'statistical analysis', 'software', 'reporting', 'software solutions tools', 'data science', 'software monitoring', 'software development', 'analytics', 'data engineering', 'system efficiency', 'servers', 'machine learning', 'relational databases', 'testing reporting', 'flask', 'web applications', 'algorithms', 'automation', 'cloud services', 'ux', 'test cases', 'html', 'data solutions', 'web development', 'computer science', 'report', 'version control', 'ai']","['utilities', 'environment', 'education', 'design', 'presentations', 'finance', 'real estate', 'real estate industry']"
448,590,Ingénieur de données senior / Sr. Data Engineer,"english version to follow mckesson touche la vie des patients en uvrant dans pratiquement tous les secteurs des soins de sant dans le but d am liorer la sant en g n ral. chez mckesson canada, nous cr ons un impact dans la vie de 12 millions de canadiens, chaque jour. nous distribuons plus de 35 000 produits partir de 17 centres de distribution 6 300 pharmacies de d tail, 1 350 h pitaux, centres de sant longue dur e, cliniques et tablissements de sant partout au canada. toutefois, nous sommes beaucoup plus qu une entreprise de distribution. nous avons automatis 2 500 pharmacies de d tail et distribuons annuellement plus de 100 millions de doses de m dicaments gr ce nos solutions d automatisation. les fabricants, les fournisseurs de soins de sant et les patients comptent sur nous pour une gamme compl te de services qui contribuent la qualit et l int grit des soins de sant pour le b n fice de tous. chez mckesson, vous participerez la cr ation de produits et de solutions qui contribuent la r alisation de la mission de l entreprise, soit am liorer la qualit de vie et faire progresser les soins de sant . travailler ici repr sente une occasion d difier une industrie qui est vitale pour nous tous. ce que vous ferez concevoir, d velopper et maintenir des solutions de plateforme de donn es. ex cuter un cycle de d veloppement complet, y compris analyser et valuer les besoins en donn es analyser les donn es, cr er des mod les et des mappages de donn es d velopper des bases de donn es et des processus d extraction, de transformation et de chargement de donn es partir de z ro mettre en uvre des pipelines de donn es, planifier, orchestrer et automatise les t ches produire des documents de d finition selon une m thodologie ou un processus pr d termin concevoir, coder et d boguer conform ment aux normes pr d termin es r viser les codes au besoin cr er des jeux de tests effectuer des tests d unit s, d int gration et de rendement effectuer des promotions dans diff rents environnements fournir du soutien la production produire de la documentation. tre proactif et indiquer l tat de l effort accompli, les estimations des efforts restants et les probl mes ayant une incidence sur les progr s. superviser occasionnellement les ressources pour les activit s de conception et de d veloppement et assurer le suivi des efforts. collaborer avec les intervenants internes ou externes, au besoin, pour r soudre les probl mes. former et encadrer les gens et leur fournir des conseils dans divers domaines de sp cialisation favoriser le travail d quipe et l innovation en faisant participer les gens la r solution de probl mes et la pens e cr ative. participer l valuation et l tablissement de nouvelles technologies. faire en sorte que les engagements envers les clients internes et externes sont respect s en temps opportun et de mani re rentable demander de la r troaction aux clients pour d terminer les occasions d am lioration des produits ou services. qui vous tes baccalaur at s sciences sp cialis en sciences informatiques ou en g nie informatique au moins sept ans d exp rience pratique en tant que d veloppeur en informatique d cisionnelle et en processus d extraction, de transformation et de chargement de donn es dans un environnement d entrep t de donn es, incluant la conception, le d veloppement, les essais et le d ploiement desdits processus au moins cinq ans d exp rience en mod lisation d entrep t de donn es dans un environnement d entreprise grande chelle exp rience d montr e et connaissance sp cialis e de microsoft sql server exp rience et connaissance de sql et d oracle pl or sql exp rience et connaissance de la plateforme de donn es snowflake solide compr hension de l ing nierie et de la conception de bases de donn es, y compris les bases de donn es relationnelles ou d normalis es et les lacs de donn es exp rience et connaissance de la plateforme azure exp rience et connaissance de la passerelle power bi capacit de travailler de fa on autonome ou au sein d un groupe sous une supervision limit e exp rience de travail avec jira et la gestion de code source exp rience des m thodes de livraison agile esprit d quipe avec la capacit de motiver les gens et d tre un mod le positif pour eux. capacit travailler efficacement sous pression et g rer plusieurs t ches. capacit participer une rotation sur appel fortes aptitudes la communication, tant l oral qu l crit, en anglais et en fran ais. mckesson is in the business of better health and we touch the lives of patients in virtually every aspect of healthcare. at mckesson canada, we touch the lives of 12 million canadians every day. we carry more than 35,000 products in 17 distribution centers and ultimately provide distribution to 6,300 retail pharmacies, 1,350 hospitals, long term care centers, clinics and institutions all over canada. but we re so much more than a distribution company. we ve automated 2,500 retail pharmacies and dispense over 100 million doses a year through our automation solutions. manufacturers, healthcare providers and patients count on us for a full range of services that contribute to the quality and safety of care for us all. at mckesson canada, you ll help us carry out our mission to improve lives and advance healthcare. working here is your opportunity to shape an industry that s vital to us all. what you will do design, develop and maintain data platform solutions perform full development lifecycle, including analyze or evaluate business data requirements, analyze data, create data models, data mappings, develops databases and etls from scratch, implements data pipelines, schedule and orchestrate jobs, automate tasks, produce design documents according pre determined methodology or process, design, code and debug according to pre determined standards code review as required, create test cases perform unit testing, integration and performance testing promotions to different environments production support documentation. be proactive and provide status of effort accomplished, estimates of remaining effort, and issues impacting progress may supervise resources for design or development activities and follow up on efforts collaborate with internal and or or external stakeholders where needed to solve problems train, coach and provide guidance to others in area of specialization foster teamwork and innovation by involving others in problem solving and creative thinking participate in the evaluation and identification of new technologies ensure that commitments toward internal and external customers are met in a timely and cost effective manner solicits feedback from customers to identify opportunities to improve products and or or services. who you are bachelor s degree in computer science or computer engineering 7 years of hands on experience as a bi or etl developer in a data warehouse environment, including etl design, development, testing, and deployment 5 years of data warehouse modeling experience in large scale enterprise data warehouse environment experience and expert knowledge of sql server experience and knowledge of sql and oracle pl or sql experience and knowledge of snowflake data platform solid understanding of database engineering and design, including relational, de normalized, and data lakes experience and knowledge of azure platform experience and knowledge of power bi gateway ability to work independently or in a group under a limited degree of supervision experience working with jira and source code control agile delivery experience team player, with an ability to motivate and be a positive role model for others ability to work efficiently under pressure and manage multiple assignments able to participate in on call rotation strong written and oral communication skills in english and french worker type regular mckesson is an equal opportunity employer. the material contained herein is provided for informational purpose only. all open jobs offered by mckesson on this recruitment system are subject to specific job skill requirements. the job skill requirements, qualifications, and preferred experience are determined by a subsidiary, office or department within the company which is offering the position, and all positions are subject to local prevailing employment laws and restrictions. this would include immigration laws pertaining to work authorization requirements and any other applicable government permissions or compliance. the materials on this site are provided without warranties of any kind, either expressed or implied, including but not limited to warranties regarding the completeness of information contained on this site or in any referenced links. while mckesson attempts to update this site on a timely basis, the information is effective only as of the time and date of posting. mckesson is an equal opportunity employer and values diversity in its workforce. we encourage applications from all qualified individuals and will accommodate applicants needs, up to the point of undue hardship, throughout all stages of the recruitment and selection process. the information on this site is for information purpose only and is not intended to be relied upon with legal consequence. current employees must apply through internal career site. join us at mckesson","['databases', 'microsoft sql', 'documentation', 'code review', 'sql', 'ji', 'integration', 'data models', 'valuation', 'pipelines', 'data pipelines', 'testing', 'computer engineering', 'automation', 'enterprise data', 'unit', 'test cases', 'jira', 'authorization', 'performance testing', 'bi', 'computer science', 'modeling', 'snowflake', 'etl', 'r']","['sql', 'databases', 'jira', 'authorization', 'bi', 'ji', 'microsoft', 'data lakes', 'documentation', 'data models', 'pipelines', 'snowflake']","['production support', 'code review', 'data mapping', 'tests', 'integration', 'valuation', 'unit testing', 'data pipelines', 'testing', 'computer engineering', 'automation', 'etls', 'enterprise data', 'methodology', 'test cases', 'performance testing', 'computer science', 'modeling', 'etl']","['and safety', 'environment', 'healthcare', 'retail', 'material', 'design documents', 'design', 'materialsies', 'immigration', 'engagements', 'government', 'permissions']"
449,591,"Research Scientist, Core ML | Chercheur/chercheuse scientifique, apprentissage automatique de base","facebook is seeking a research scientist to join our ai research team, a research organization focused on making significant progress in ai. individuals in this role are expected to be recognized experts in identified research areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. the ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. to learn more about our research, visit https or or ai.facebook.com or . facebook est en qu te d un chercheur ou d une chercheuse scientifique pour compl ter son quipe de recherche en intelligence artificielle, un organisme de recherche dont l objectif est de permettre de grandes avanc es dans le domaine. ce poste requiert une expertise dans des domaines de recherche tels que l intelligence artificielle , l apprentissage automatique, les statistiques informatiques, les math matiques appliqu es, notamment sur des sujets comme l apprentissage profond, les mod les graphiques, l apprentissage par le renforcement, la perception artificielle, le traitement automatique du langage naturel et la repr sentation de donn es. la candidate ou le candidat id al sera avide de r ussir des perc es scientifiques permettant de comprendre l intelligence et la technologie pour d velopper encore davantage l intelligence informatique. pour en savoir plus sur nos recherches, visitez le site https or or ai.facebook.com or . lead research to advance the science and technology of intelligent machines mener des recherches pour faire voluer la science et la technologie des machines intelligentes. lead research that enables learning the semantics of data mener des recherches permettant l apprentissage de la s mantique des donn es . devise better data driven models of human behavior concevoir de meilleurs mod les de comportement humain fond s sur les donn es. work towards long term ambitious research goals, while identifying intermediate milestones participer la poursuite d ambitieux objectifs de recherche long terme, tout en d finissant les tapes interm diaires n cessaires leur r ussite. influence progress of relevant research communities by producing publications influencer les avanc es de groupes de chercheurs et de chercheuses pertinents gr ce la publication d articles. contribute research that can be applied to facebook product development contribuer aux recherches pouvant tre appliqu es au d veloppement de produits de facebook. lead and collaborate on research projects within a globally based team mener des projets de recherche et y participer aux c t s de collaborateurs et de collaboratrices du monde entier. experience holding a faculty, industry, or government researcher position exp rience dans un poste de chercheur au sein d une facult , d une industrie ou d un gouvernement. ph.d. and publications in machine learning, ai, computer science, statistics, applied mathematics, data science, or related technical fields doctorat et publications dans le domaine de l apprentissage automatique, de l ia, des sciences informatiques, des statistiques, des math matiques appliqu es, de la science des donn es, ou dans d autres domaines techniques pertinents. experience leading a team in solving modeling problems using ai or ml approaches exp rience de l encadrement d une quipe charg e de r soudre des probl mes de mod lisation l aide d approches ia or ml. experience in theoretical and empirical research and for addressing research problems exp rience de la recherche th orique et empirique et de la r solution de probl mes de recherche. experience communicating research for public audiences of peers exp rience en communication des recherches pour un public de pairs. knowledge in a programming language connaissance d un langage de programmation. must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment doit obtenir un permis de travail dans le pays o se trouve l emploi la date d embauche et maintenir ce permis pendant la dur e de l emploi. 1 year of work experience in a university, industry, or government lab, in a role with primary emphasis on ai research au moins un an d exp rience dans un laboratoire d une universit , de l industrie ou du gouvernement dans un poste principalement ax sur la recherche dans le domaine de l ia. experience driving original scholarship in collaboration with a team exp rience dans la conduite de recherches originales en collaboration avec une quipe. first author publications at peer reviewed ai conferences publications titre d auteur principal ou d autrice principale pr sent es lors de congr s sur l intelligence artificielle et valu es par des pairs. . experience in developing and debugging in c or c , python, or c exp rience de d veloppement et de d bogage en c or c , python ou c . facebook s mission is to give people the power to build community and bring the world closer together. through our family of apps and services, we re building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. whether we re creating new products or helping a small business expand its reach, people at facebook are builders at heart. our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. together, we can help people build stronger communities we re just getting started.","['https', 'applied', 'c', 'empirical', 'python', 'statistics', 'data science', 'programming', 'machine learning', 'ai', 'artificial intelligence', 'debugging', 'semantics', 'deep learning', 'language processing', 'data representation', 'authorization', 'computer science', 'mathematics', 'modeling', 'applied mathematics', 'reinforcement learning', 'r']","['https', 'ussir', 'python', 'authorization', 'c', 'programming', 'debugging', 'r']","['deep learning', 'empirical research', 'machine learning', 'statistics', 'reinforcement', 'language processing', 'data representation', 'computational', 'data science', 'computer science', 'natural', 'artificial intelligence', 'modeling', 'semantics', 'applied mathematics', 'ai']","['product development', 'research projects', 'government']"
450,592,Data Science Consultant,"do you view data as an art and a science so do we. how we support you we believe in gender equity and an inclusive community. we offer a comprehensive benefits package generous vacation allowance disability coverage, retirement plans, paid maternity and paternity leave, life insurance, hotel and travel discounts, extended benefits to cover items that support your well being, health, dental, and vision insurance, professional development and paid microsoft certification opportunities. as an industry data scientist, you will help clients understand and extract insight and value from their data using machine learning and ai techniques. working as part of a team, you re involved in all phases of analytics projects including question formulation, design, research and development, implementation, and testing. this role will explore and understand data and build advanced solutions that could be predictive, prescriptive, or optimize. you are able to translate client problems into quantitative language, find or build algorithms to solve those problems and implement them in code. you will be working on full data science pipeline, bringing solutions from research to production. the work lead and run a small team of data scientists deliver data science insights using statistical, data mining, and machine and deep learning understand client needs and build solutions for them provide thought leadership for projects and about leading technologies keep up to date on ai trends here s what you need 5 years of demonstrated ability using statistics and data science proven track record developing machine learning using clustering, regression, optimization, recommendation, and neural networks, among other techniques 2 years of experience with data science tools like python, r, scala, julia, sas, spss, matlab, microstrategy, or tableau proficiency in sql. strong vision and critical thinking contribute new ideas and challenge the status quo when appropriate form and motivate the team at the different stages of growth excellent written and verbal communication skills passion for problem solving experience working with cloud services like aws, google, and azure ability to travel to client locations bonus points if you ve got a master s degree in a related field you ve worked as a consultant on big data projects you re passionate, creative, and forward thinking you know how to use big data tools like hadoop, hive, and spark","['tableau', 'big data', 'hive', 'sql', 'python', 'statistics', 'scala', 'data science', 'analytics', 'aws', 'sas', 'data mining', 'machine learning', 'ai', 'testing', 'algorithms', 'matlab', 'cloud services', 'deep learning', 'hadoop', 'neural networks', 'optimization', 'r']","['sql', 'python', 'tableau', 'scala', 'hadoop', 'hive', 'aws', 'big data', 'sas', 'matlab', 'r']","['data mining', 'deep learning', 'machine learning', 'statistics', 'testing', 'neural networks', 'data science', 'analytics', 'optimization', 'cloud services', 'algorithms', 'ai']","['design', 'art', 'retirement', 'microstrategy', 'insurance']"
451,593,Data Engineer,"a day in the life the data engineer is a critical part of our software development and delivery team. they have a deep understanding of our data model and how to capture, structure and deliver data to help us and our partners make insightful decisions and gain competitive advantage. they are a relentless problem solver who improves the overall warehouse management system product and plays a crucial role in helping our organization continue to thrive. for the right person this position is open to be remote or in any of our locations we do business. all about you the perfect fit has the ability to work under pressure, be flexible and adapt to changing priorities. can communicate in an open, helpful, and engaging manner both internally and with clients. has the ability to organize information and convey the meaning across the organization. this person owns the tasks and projects they get involved with and sees them through from front to end. is self directed, confident, and motivated. can take a user story through the research, development, testing and deployment process without micromanagement. has a deep understanding of data engineering processing, including relational and nosql databases, restful apis and data warehousing. has attention to detail and discipline to meet complex acceptance criteria. has excellent problem solving skills, including the ability to draw reasonable conclusions from incomplete information. lives in accordance to and can make decisions based on our company values and leadership principles. the must haves must have 1 years experience in high quality software development. must have 1 years experience in data engineering or a similar discipline. microsoft sql server or other database experience. comfortable in a scrum or kanban environment with emphasis on continuous delivery, automated testing, pair programming and rigorous peer review. assets exposure to a .net language . microsoft azure cloud development experience. experience in automation. experience in software architecture design or database administration. experience with power bi. experience optimizing database performance. things you will be doing demonstrates leadership and accountability at every level. embraces personal ownership of the product and commits to helping our team succeed at meeting our objectives. suggests ways to improve our process and products, both during sprint retrospective and during the sprint. steps up where needed with insight and guidance that will help build the skills and competence of the entire development organization. calls out problems in a constructive way that helps us find the path to success. takes initiative and works in a self driven way, while maintaining open lines of communication with other team members and remaining humble enough to ask for help when needed. 2. designs and develops new data pipelines to support new features and integrations. keeps up to date on new technologies and explores new ways to work with and store our data. researches or implements best practices and designs patterns to deliver scalable, maintainable data solutions. communicates effectively with end users to create actionable reports and data transformations that will enhance our understanding of the business. collaborates with other team members on challenging deliverables and pivot as needed to ensure we succeed as a team. 3. champions clean data design and helps manage our existing data sources and stores. leverages their expert knowledge of database or dataflow design to ensure our wms software and associated systems are extended in a way that maximizes value and speeds delivery. understands our existing data systems and recommends improvements that will improve performance and integrity for the future. 4. ensures quality is baked into every step of the development process. implements appropriate unit tests during the development process. verifies that we solved the right problem in a way that meets user needs and enhances the overall quality of the system and code base. works with other developers and our quality assurance or automation specialists to ensure that new code is well covered with automated integration and ui tests. 5. participates in team scrum meetings . 6. performs other duties as requested. benefits we offer attractive working conditions and benefits to our team members and their families competitive salaries vacation choice benefits plan flexible and fun work environment ability to order directly from our amazing clients autonomy in decision making profit share program development and ongoing learning opportunities ability to have a say and make an impact on the organization. fnlxjwg2n4","['databases', 'quality assurance', 'microsoft azure', 'kanban', 'software', 'software development', 'data', 'programming', 'integration', 'data systems', 'data engineering', 'data warehousing', 'solver', 'nosql', 'software architecture', 'microsoft sql server', 'data pipelines', 'continuous delivery', 'testing', 'scrum', 'automation', 'bi', 'data solutions', 'cloud development', 'database administration']","['microsoft sql server', 'databases', 'quality assurance', 'bi', 'programming', 'solver', 'nosql', 'microsoft azure']","['pair', 'retrospective', 'dataflow', 'kanban', 'tests', 'software', 'software development', 'data', 'integration', 'data systems', 'data engineering', 'data warehousing', 'software architecture', 'data pipelines', 'continuous delivery', 'testing', 'scrum', 'automation', 'data solutions', 'cloud development', 'database administration']","['environment development', 'environment', 'design']"
452,595,Air Quality Engineer or Scientist,"air quality engineer or scientist description grounded in safety, quality, and ethics, our experts lead their fields and guide our work with rigor, a creative spirit, and vision for growth. we draw from more than 20 technical specialties around the globe and are committed to fostering an inclusive community of diverse talents, backgrounds, and expertise. we re a place to apply your passion and collaborate with top environmental talents on work that s critical to our clients and the communities they support. join a team that has the environment down to a science. your opportunity we have an opening for an intermediate air quality engineer or scientist to join our team in dartmouth, ns, fredericton, nb, charlottetown, pei or st. john s, nl. stantec s atmospheric environment group is dedicated to helping our clients manage air quality and climate change issues professionally and proactively. our professional engineers and scientists provide specialized services to a wide variety of sectors including manufacturing, industry, commercial, transportation, mining, oil and gas, power and government. we offer a full suite of services including design and permitting, monitoring programs, predictive modelling, greenhouse gas emission quantification and verification, climate adaptation assessments as well as planning and policy studies. your key responsibilities conducting field monitoring collection of data and information data analysis and interpretation regulatory and literature review predictive air dispersion modelling authoring technical air quality related reports assist with the preparation of proposals qualifications your capabilities and credentials excellent communication skills . proven and verifiable leadership skills. positive can do attitude. successful track record. strong professional references. good quantitative and computer skills with microsoft office software needed. familiar with air dispersion modelling of stationary and mobile emission sources using modelling programs such as aermod, calpuff, cal3qhc, moves, etc. familiar with preparation of emission summary and dispersion modelling reports. experience conducting ambient air quality monitoring field work. experience with programming, numerical modelling, and statistical analysis would be an asset. experience in climate change adaptation and vulnerability assessments, ghg and energy evaluations would be an asset. able to work independently with minimal supervision and in a multi disciplinary team. flexibility in scheduling is required for travel necessary for site work . experience with ambient air quality monitoring and stack testing experience with greenhouse gas quantification, verification, mitigation, and reduction planning a valid drivers license is required. education and experience a bachelor s degree in engineering, meteorology, or physical sciences. a master s degree in engineering, meteorology, or physical sciences would be an asset. minimum 3 5 years related experience necessary, or an equivalent combination of education and experience. typical office environment working with computers and remaining sedentary for long periods of time. field work may include exposure to the elements including inclement weather. ability to lift and move items and equipment up to 50 lbs. this description is not a comprehensive listing of activities, duties or responsibilities that may be required of the employee and other duties, responsibilities and activities may be assigned or may be changed at any time with or without notice. stantec is a place where the best and brightest come to build on each other s talents, do exciting work, and make an impact on the world around us. join us and redefine your personal best. primary location canada nova scotia dartmouth other locations canada new brunswick fredericton, canada newfoundland and labrador st. john s, canada prince edward island charlottetown job environmental scientist organization bc 1214 environment services ca atlantic canada employee status regular job level individual contributor travel yes, 10 of the time schedule full time job posting may 25, 2021, 8 17 16 am req id 210001az stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. we prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. eeo including disability or protected veterans","['software', 'testing', 'quantification', 'programming', 'data analysis', 'statistical analysis']","['calpu', 'programming']","['software', 'testing', 'quantification', 'data analysis', 'statistical analysis', 'planning']","['gas', 'environment', 'compensation', 'education', 'regulations', 'design', 'microsoft office', 'climate change', 'meteorology', 'oil and', 'government', 'manufacturing', 'environmental', 'hiring']"
453,596,Big Data Engineer - Analytics,"help us catch bad guys with math. our team is growing and we re looking to add a big data engineer analytics that can focus on extending our existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. this will include enabling data scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer. although there is a lot of uncertainty in the market today, especially considering the covid 19 crisis, we are set up to accommodate fully remote work, and a fully virtual interview, selection, and onboarding process. we are looking for someone who is passionate about what they do, takes a creative approach to problem solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments. here s what you ll do implement model data flows to support running cutting edge machine learning techniques on massive amounts of data. work with product managers and data scientists to turn new features and algorithms into beautiful, battle tested code. work with the technologies we use to analyze and identify cyber security threats for our customers . work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics. create efficient and robust cloud based solutions, leveraging the best in cloud technologies. in order to be considered, you must have an undergraduate or master s degree in computer science or equivalent engineering experience. strong interest in software design, distributed computing, and databases. experience developing in a jvm environment . at least two years of experience developing with or using big data analytics stacks or tools such as hadoop, hbase, spark, presto, and vertica. experience implementing and using streaming platforms such as sparksql, flink, kafka, storm, etc. experience with kubernetes, docker, ansible or any other infrastructure or containerization management or automation platform. familiarity leveraging aws emr, azure, gcp cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset. we d also love it if you had the following familiarity with data science or machine learning packages . familiarity with virtualization technologies . contributions to open source software . interest in understanding and analyzing diverse types of data. interset is an equal opportunity employer. should you require accommodation in any aspect of our selection process, please contact our recruitment team at hiring interset com. about interset we use big data and advanced behavioural analytics to detect and prevent the theft of intellectual property...simply put, we catch bad guys with math. part of the micro focus group of companies, we are a fast paced, all hands on deck kind of environment where you are respected and listened to from day one. we have a startup feel within the stability and structure of a large global company. we hire people with a wide scope of knowledge and experience that want to jump into self organizing, cross functional teams. we manage our own schedules, we support our teammates, and we always make time for fun.","['computing', 'databases', 'emr', 'big data', 'containerization', 'kubernetes', 'data analytics', 'gcp', 'software', 'data science', 'analytics', 'software design', 'aws', 'hbase', 'machine learning', 'algorithms', 'ansible', 'automation', 'jvm', 'hadoop', 'security', 'computer science', 'virtualization', 'uncertainty', 'vertica']","['jvm', 'hbase', 'kubernetes', 'databases', 'ansible', 'gcp', 'emr', 'big', 'hadoop', 'big data', 'aws', 'containerization', 'vertica']","['distributed', 'computing', 'data analytics', 'machine learning', 'software', 'security', 'data science', 'computer science', 'analytics', 'uncertainty', 'software design', 'virtualization', 'algorithms', 'automation']","['hiring', 'onboarding', 'environment', 'events']"
454,598,Data Engineer,"commure enables innovators to build modern health software that improves the quality of care and its efficiency of delivery. we believe that better software for doctors, nurses and patients and ultimately for the entire healthcare system comes from connecting the top minds in technology, healthcare and design. we are seeking talented data engineers to join our growing engineering team. at commure, engineers work side by side with designers, architects, researchers, product managers, healthcare partners, as well as physicians within our company to design, implement, and maintain solutions that meet the concrete needs of providers. we are a welcoming and diverse team with a wide range of backgrounds and experiences. we pride ourselves on building robust, high quality software using a modern tech stack. if you share our commitment to improving healthcare innovation and value close partnerships between developers and doctors, come work with us as a data engineer at commure, you will architect and implement tools and cloud agnostic products to satisfy the analytics and data demand of the organization contribute to the continuous building of our dataops culture implement data management policies identify and solve issues to improve data quality improve data foundational procedures, guidelines and standards have end to end ownership of projects throughout their lifecycle join our collaborative engineering, product, and design team and provide a valued voice as we scale our team and culture we are looking for data engineers who are inspired by our mission to improve health software and reduce burnout among providers have a solid foundation in sql and in at least one programming language experience with streaming processing frameworks and messaging queues share a commitment to high quality engineering practices using modern tools and languages exhibit grit, high integrity, a team mindset, and an affinity for continuous learning enjoy wrangling real world complexity into deceivingly simple solutions thrive in a collaborative, diverse environment benefits medical, dental, and vision coverage fsa hsa accounts commuter benefits flexible time off 401k commure is committed to creating and fostering a diverse team. we are open to all backgrounds and levels of experience, and believe that great people can always find a place. we are committed to providing reasonable accommodations to all applicants throughout the application process.","['sql', 'software', 'analytics', 'programming', 'data quality']","['data quality', 'sql', 'programming']","['software', 'analytics']","['affinity', 'environment', 'design', 'healthcare']"
455,600,"Data Engineer, Alexa Speech","bachelor s degree in math, finance, engineering, statistics, or related discipline is required. computer science or equivalent experience. 5 years experience as a data engineer, business or similar roles strong verbal or written communication data presentation skills, including an ability to effectively communicate with both business and technical teams proficient in scripting languages ability to self direct, multitask, and prioritize a constantly evolving workload obsession with quality, operational excellence, and customer experience are you customer obsessed and interested in speech and language understanding do you find creating cutting edge voice control in the automotive market exciting if so, the alexa team is looking for a talented data engineer to help revolutionize our voice forward experience. alexa is the amazon service that powers the groundbreaking echo family of devices, fire tv, tablets, third party alexa providers, and soon, cars we believe voice is the most natural user interface for interacting with technology across many domains we are inventing the future. you ve found the right team if you are a passionate data engineer with experience building innovative, mission critical applications that customers love. you will help to kick start a new organization in toronto and have an enormous opportunity to make an impact on cutting edge products used every day by people you know. we re working hard, having fun, and making history come join us the ideal candidate will have excellent analytical skills and the ability to synthesize data into data stores and data pipelines for use by data scientists, business leaders, and engineers. to be successful in this role, you should have broad skills in database design, be comfortable dealing with complex, medium to large data sets, and understand how self service dashboards are built and used with your data sets. the successful candidate will have a passion for data and analytics, be a self starter comfortable with ambiguity, strong attention to detail, an ability to work in a fast paced and entrepreneurial environment, and driven by a desire to innovate. responsibilities include develop the end to end automation of data pipelines, making datasets readily consumable by visualization tools, machine learning platforms, and notification systems establish new, scalable, efficient, automated processes for ingesting data used by scientists to model and forecast alexa traffic maintain and enhance existing data pipelines work with data scientists to source data for machine learning algorithms that forecast traffic coming to alexa work with dashboard owners and business owners to understand data needed for key business cost metrics and building data stores and data pipelines to deliver the needed data master s degree in computer science, engineering, math, finance, statistics or a related discipline. familiarity with aws solutions such as ec2, dynamodb, s3, and redshift. knowledge and direct experience using business intelligence reporting tools. . experience coding with scripting languages to do basic data manipulation and mathematical computations experience in partnering with business owners to understand requirements and develop supporting analysis to solve business problems. amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. if contracted for employment opportunity, advice human resources if you require accommodation, including in order to apply for a position.","['analytical skills', 'visualization', 'dashboards', 'automotive', 'statistics', 'reporting', 'scripting', 'database design', 'data', 'analytics', 'aws', 'machine learning', 'data pipelines', 'data manipulation', 'business intelligence', 'algorithms', 'automation', 'dashboard', 'tablets', 'datasets', 'computer science']","['dashboard', 'aws', 'business intelligence', 'data manipulation']","['automotive', 'tablets', 'statistics', 'data pipelines', 'visualization', 'machine learning', 'reporting', 'scripting', 'datasets', 'dashboards', 'database design', 'computer science', 'data', 'analytics', 'analytical skillses', 'algorithms', 'automation']","['environment', 'cost', 'metrics', 'human resources', 'finance', 'customer experience', 'operational excellence', 'legislation']"
456,610,Business Intelligence Data Engineer,"at loblaw digital, we know that our customers expect the best from us. whether that means building the best, most innovative online shopping experiences, or designing an app that will impact the lives of people across the country, we re up for the challenge. loblaw digital is the team responsible for building and operating the online businesses of canada s largest and most successful retailer. based in downtown toronto, we are an entrepreneurial, fast paced, and collaborative team working towards transforming the way canadians shop by creating leading ecommerce experiences in the online grocery shopping, beauty, pharmacy, loyalty, and apparel spaces, and we re only just getting started to achieve these goals, we are looking for talented and passionate individuals who want to collaborate and solve challenging problems and make significant and lasting impact on canadians. the impact you ll make as a business intelligence data engineer, you will impact our business by fueling the best in class data analytic and reporting platform at loblaw digital that will empower our business users in making data driven decisions and strategies in their everyday work. we re growing our bi team to better serve the enterprise data strategy and want you to be a part of it. you ll work with users across the organization to understand how data helps them and translate that into solutions that will bring data from various systems into our data warehouse. we re looking to turn our enviable wealth of data into actionable insights and meaningful recommendations that drive growth and improved engagement across all of our lines of business, and a customer focused mindset is a must have. what you ll do develop and scale quality and performant data pipelines using gcp and other open source technologies work with stakeholders to develop solutions that support various data consumers work with devops on setting up environment for new deployment build and implement robust data models and semantic layer be a subject matter expert on the entire bi framework stack support reporting and analytics needs from all areas of the business. for example developers, product managers, product designers, merchandizers, marketers, and operations analysts help us in our mission to be a hypotheses driven product development organization which means data is at the center of everything we do does this sound like you ba or bs in computer science, engineering or related technical field 2 years experience as a bi developer or data engineer hands on experience with relational databases python experience coding etls using various packages or connectors to databases and endpoints working experience with git and ci or cd pipelines experience with data pipeline automation using a code focused scheduling tool exposure to kubernetes, docker, and streaming tools experience working with sourcing and feeding data from rest apis is nice to have understanding of data warehouse concept and bi architecture is a plus strong oral and written communication skills solid stakeholder management skills proven team player that will work well in a dynamic and fast paced environment experience working in an agile environment experience in retail or ecommerce is a plus strong desire to learn and to push the boundaries of what can be done to better empower our business with data how you ll succeed at loblaw digital, we seek great people to continually strengthen our culture. we believe great people model our values, are authentic, build trust and make connections. we re able to keep innovating because our colleagues are passionate about their work and excited about the future of ecommerce. you will get to work with some of the best digital minds and will have the support of world class technologies to craft products our customers will love loblaw digital recognizes canada s diversity as a source of national pride and strength. we have made it a priority to reflect our nation s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. accommodation is available upon request for applicants with disabilities in the recruitment and assessment process and when hired. in addition, we believe that compliance with laws is about doing the right thing. upholding the law is part of our code of conduct it reinforces what our customers and stakeholders expect of us.","['databases', 'ci', 'working experience', 'kubernetes', 'python', 'gcp', 'agile environment', 'cd', 'reporting', 'analytics', 'data models', 'pipelines', 'data pipelines', 'relational databases', 'sourcing', 'business intelligence', 'rest', 'automation', 'enterprise data', 'bi', 'devops', 'git', 'computer science', 'connectors']","['kubernetes', 'python', 'gcp', 'databases', 'bi', 'git', 'business intelligence', 'data models', 'pipelines']","['agile environment', 'data pipelines', 'relational databases', 'cd', 'devops', 'reporting', 'ci', 'sourcing', 'computer science', 'analytics', 'connectors', 'working experience', 'rest', 'automation', 'etls', 'enterprise data']","['environment', 'retail', 'apparel', 'product development', 'stakeholder management', 'assessment', 'law', 'architecture']"
457,613,Data Engineer,"position description data engineer this is a remote position located anywhere in canada who is a data engineer the data engineer will play an important role in driving forward goodlife s technology innovation product roadmap through helping to build data services that support wow experiences for our members and associates. in our mission to be the best combined live and digital fitness experience, data plays a significant role in empowering a more personalized and informed suite of digital services. joining the data operations team, you will help design, implement and maintain batch and real time scalable data pipelines with complex data transformations. in addition, you will support our software developers, database architects and data analysts on data initiatives to ensure an optimal data delivery architecture. you will foster a positive working culture of continuous improvement, modernized delivery and rapid go to market product innovation. we work in a highly dynamic, fast changing, and fluid environment, and are seeking an energetic addition to the team what will you be doing design, build, maintain and improve data platform infrastructure for ingesting, storing, and transforming data to enable data driven products and services design, implement, and maintain batch and real time scalable data pipelines with complex data transformations write and optimize complex queries in order to make data easily and efficiently accessible to the consumers apply industry best practices when designing and building data pipelines to ensure data integrity, quality and security design and build prototyping solutions and conduct tests in order to support rapid product development and also to explore new design alternatives for our data platform assist with day to day support for data related technical issues and data infrastructure needs maintain data governance artifacts to enable self serve information access, including data catalog, data dictionary and data lineage documentation monitor the overall performance and stability of the data pipelines infrastructure work with cross functional teams in a dynamic environment to support the development of data driven products do you have what it takes bachelor s degree in computer science, software engineering or equivalent 5 years experience in etl or data modeling, building scalable and reliable data pipelines, architecting data stores, supporting complex etl processes including sla, performance measurements, and monitoring hands on experience with leading cloud platforms, including azure cloud data solutions and aws experience with informatica iics and snowflake considered a strong asset experience with message queues, batch and stream processing excellent sql skills and experience in a devops environment experience with agile development methodologies detail oriented high standard of data quality and integrity familiarity with nosql databases like mongodb is nice to have adaptable to a fast paced environment and able to pivot quickly to align with changing priorities strong people skills team player excellent oral and written communication skills strong analytical and problem solving skills able to multi task committed to contributing to a culture that celebrates diversity, equity and inclusion and embraces social and environmental responsibility what s in it for you ongoing training and development to ensure a long and successful career path career advancement opportunities competitive total rewards package free fitness membership fun and energetic atmosphere to come to every day at goodlife fitness, we are committed to fostering an inclusive, accessible environment, where all employees and members feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. we are committed to meeting the accessibility needs of persons with disabilities in a manner that respects their dignity and that is equitable. if you require an accommodation for the recruitment or interview process , please let us know and we will work with you to meet your needs.","['go', 'databases', 'data services', 'data integrity', 'data infrastructure', 'documentation', 'mongodb', 'sql', 'software', 'iics', 'data', 'aws', 'nosql', 'informatica', 'data pipelines', 'stream processing', 'digital services', 'data quality', 'measurements', 'prototyping', 'devops', 'security', 'data solutions', 'computer science', 'data operations', 'modeling', 'snowflake', 'etl', 'data dictionary']","['go', 'sql', 'databases', 'documentation', 'aws', 'data quality', 'snowflake', 'nosql']","['data lineage', 'data services', 'data integrity', 'data infrastructure', 'mongodb', 'performance measurements', 'tests', 'software', 'data', 'data pipelines', 'stream processing', 'agile development', 'digital services', 'prototyping', 'devops', 'security', 'data solutions', 'informatica ii', 'computer science', 'data operations', 'modeling', 'etl', 'data dictionary']","['sla', 'environment', 'continuous improvement', 'design', 'governance', 'product development', 'environmental', 'architecture']"
458,618,Cloud Data Engineer,"the questrade technology group is home to a unique environment, where our culture thrives and most importantly, we get stuff done questrade is continuing with its digital transformation initiative and our infrastructure footprint is growing beyond our data centres and into the google cloud platform. we are currently working towards our exciting strategy that is driven by business value. join us and help solve some complex challenges such as handling low latency and high traffic market data, event streams and messaging, in a hybrid cloud environment within an industry that has so much room for disruption. the cloud data engineer will work with a primary focus on delivering our data platform footprint, as an expansion of our cloud presence, enabling key initiatives such as our digital banking. this role will be working with several teams in the organization in a collaborative manner, helping deliver data related components that enable productivity across qtg by leveraging automation to deliver self service components as much as possible. this key individual will be part of a team that drives the implementation of data components such as pipelines, applications, sanitation, supporting our data scientists and working with the rest of the product teams while collaborating with the architecture team, influencing the design and delivery of our data footprint and striving for greater functionality in our data systems. what s it like working as a cloud data engineer at questrade our data engineer needs to be able to gather and understand data requirements, present it to software engineers, and work in the team to achieve high quality data ingestion goals. this engineer will need a passion for complex problems, and enjoy the challenge of operating complex and mission critical systems under extreme loads. do you think you are up to the challenge would you like to learn more and stretch your skills and career in this role, you will be a technical expert with significant scope and impact. you will work closely with a group of software engineers, product managers, data scientists, and business intelligence engineers to create the data infrastructure and pipelines necessary to drive questrade s initiatives. successful candidates should come from a strong data engineering background. you need to have experience with structured and unstructured data, and being able to analyze or transform the data using various tools. often, the pace of innovation and change implies a need to move to new data sources, and our data engineers get to participate in deep diving business data in order to understand or measure sources of disparity. your analytical skills and knowledge of schema metadata will be essential. job responsibilities of the cloud data engineer include... create and maintain optimal data pipeline architecture. assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. optimally extract, transform, and load data from a wide variety of data sources using sql and google cloud data technologies. collaborate with the team to decide on which tools and strategies to use within specific data integration scenarios. work with stakeholders to assist with data related technical issues and support their data infrastructure needs. develop and maintain code and documentation for etl and other data integration projects and procedures. monitor and anticipate trends in data engineering, and propose changes in alignment with organizational goals and needs. share knowledge with other teams on various data engineering or project related topics. are you our next cloud data engineer you are if... minimum 3 years of experience working in the data engineering field. proficiency in sql language. strong knowledge of python language. experience in optimization of high volume etl processes. experience with any of the popular clouds . good knowledge in message broker systems . data modelling skills. good knowledge of popular data standards and formats experience in the financial industry is an asset. google gcp data platform knowledge and experience is an asset, or knowledge of the equivalent open source toolset behind those products. at questrade group of companies, with multiple office locations around the world, we are committed to fostering a diverse, inclusive and accessible work environment. we value the unique skills and experiences each individual brings, and believe that when our teams feel supported and motivated, their creativity becomes a source of innovation. we are also committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and also one which reflects the diversity of the communities we serve and operate in to help us revolutionize financial services for the benefit of all of our customers. candidates selected for an interview will be contacted directly. if you require accommodation during the recruitment or selection process, please let us know and we will work with you to meet your needs","['unstructured data', 'analytical skills', 'data infrastructure', 'data standards', 'documentation', 'google', 'sql', 'python', 'gcp', 'software', 'data', 'digital', 'integration', 'data systems', 'pipelines', 'data engineering', 'deep', 'hybrid cloud', 'google cloud platform', 'metadata', 'business intelligence', 'streams', 'rest', 'automation', 'banking', 'market data', 'low latency', 'scalability', 'optimization', 'critical systems', 'digital transformation', 'etl']","['sql', 'sql data', 'python', 'gcp', 'google cloud platform', 'qtg', 'documentation', 'data standards', 'business intelligence', 'google', 'streams', 'pipelines']","['unstructured data', 'analytical skills', 'data infrastructure', 'software', 'data', 'digital', 'integration', 'data systems', 'data engineering', 'hybrid cloud', 'data ingestion', 'metadata', 'rest', 'automation', 'banking', 'market data', 'low latency', 'scalability', 'optimization', 'critical systems', 'digital transformation', 'etl']","['environment', 'business value', 'design', 'financial services', 'functionality', 'architecture']"
459,620,"Data Architect, Technology Solutions","it starts here. at mnp we pride ourselves on being different it s our entrepreneurial drive that sets us apart. it s the same drive that s helped us become canada s fastest growing national firm. we foster collaboration, value your ideas, promote based on talent, live balanced lifestyles and make time for fun. we are one firm, one team, collaborating to support you wherever you want to take your career. join the momentum. we are seeking a data architect to join our technology solutions team. driving business excellence, mnp is a leading national accounting, tax and business consulting firm in canada. our consulting team works with organizations in the public, private and not for profit sectors to provide innovative strategies tailored to maximize efficiencies, enhance performance and increase profitability. specifically, our recognized technology consulting team works with clients to translate technology issues and opportunities into meaningful results that meet organizational needs. role mnp responsibilities works closely with clients and other resources to effectively communicate, design, plan, and implement capabilities that provide value to customers architect comprehensive data solutions that enable clients to appropriately capture, make sense of and action data. demonstrate value to clients through software demonstrations and prototypes software installations or evaluations assessment of business problems and identification of solutions using the microsoft data platform stack on premise and hosted on azure ensure delivered solutions fit within overall project plan and schedule provide feedback to customers and creates structured documentation, including specifications and weekly status reports advise clients on configuration and implementation options based on best practices participates in the business requirements gathering process for client customizations leads or supports solution implementation, customization, testing, and deployment, including preparation of test scenarios. acts as a subject matter expert in transferring solution critical knowledge collaborates with client team participants ensures that all implementation methodology deliverables are complete and on time generates project status, time, and expense reports as requested by management highly motivated, creative, and self sufficient with the ability to work successfully under pressure work closely with clients and firm stakeholder to develop in depth knowledge of key drivers and success factors, operational processes, information systems and data sources pertaining to a client s data domains work with decision makers, data scientists or analysts and other end users to define and document key performance indicators, analytic themes, reports and dashboards perform other tasks related to data architecture, database performance, data access and security and data quality management, as required help guide and implement data governance initiatives troubleshoot reporting, analytics and bi tools, systems and software and performance tune these applications, as necessary skills and experience 5 years of experience with azure data lake solutions 2 years experience databricks solutions 2 years experience deploying solutions using azure data factory experience designing and implementing ci or cd pipelines experienced in the devops process design and implementation deep understanding of information and data and how it can be leveraged to provide business value comprehensive database and data warehouse analysis and design experience, with full knowledge of relational databases , data warehouse methodologies and data modeling experience working with data integration tools experience with data visualization and analytics tools strong ability to gather, author and analyze business and technical requirements and build applications and integrations according to specifications strong understanding of relational database structures, theories, principles and practices full project management and development life cycle experience ability to lead projects and team members under limited supervision superior organizational and project management skills the following skills would be considered an asset knowledge of data management tools in areas of metadata, master data management, data quality and data security deep knowledge of the dmbok attained data related certifications such as cdmp, cbip, etc. attained vendor related data or analytics or reporting certifications knowledge in ai, machine learning, data mining and or or blockchain experience as a data scientist including predictive or statistical modeling experience in cloud bi experience working with google analytics or other web analytics platforms experience working with soa and esbs experienced in devops or dataops and continuous integration or delivery or deployment attained other pm and it related certifications such as cobit, itil, cissp, cgeit, crisc, cisa, cism, pmp, prince2, etc. a degree or diploma in computer science or computer programming from an accredited post secondary educational institution previous success working in a customer facing, consultative role experience working with different sdlc methods including agile, scrum, xp, rup, and kanban the ability to work as part of a close knit delivery team time management skills in a dynamic delivery environment field consulting or professional services delivery experience ability to travel to client locations my rewards mnp more than a paycheque, mnp is proud to offer customized rewards for our team members. with a focus on health and wealth, we provide an extensive list of benefits that support our unique culture and foster work life integration. our program offers benefits that allow you to thrive at work and outside of the office. be rewarded with generous paid time off including 4 personal days, firm sponsored social events, a group pension plan with 4 matching contribution, voluntary savings products, bonus program eligibility, a wellness subsidy, health and dental benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, learning opportunities through mnp university, a flexible dress for your day environment and more","['test scenarios', 'ci', 'dashboards', 'data visualization', 'cism', 'technical requirements', 'documentation', 'itil', 'master', 'kanban', 'cd', 'software', 'reporting', 'process design', 'data', 'analytics', 'integration', 'programming', 'technology', 'pipelines', 'data mining', 'machine learning', 'relational databases', 'google analytics', 'testing', 'scrum', 'web', 'specifications', 'metadata', 'statistical', 'data quality', 'blockchain', 'soa', 'cgeit', 'bi', 'devops', 'sdlc', 'data solutions', 'information systems', 'security', 'computer science', 'technology solutions', 'modeling', 'data management', 'ai']","['microsoft data', 'google analytics', 'bi', 'database performance', 'azure data lake', 'data quality', 'data', 'technology solutions', 'documentation', 'azure data factory', 'cit', 'computer', 'pipelines', 'programming']","['test scenarios', 'ci', 'dashboards', 'data visualization', 'cism', 'technical requirements', 'modeling', 'itil', 'kanban', 'cd', 'software', 'reporting', 'process design', 'database', 'data', 'analytics', 'integration', 'technology', 'data mining', 'web analytics', 'machine learning', 'relational databases', 'continuous', 'testing', 'scrum', 'specifications', 'metadata', 'statistical', 'master data management', 'installations', 'blockchain', 'soa', 'sdlc', 'devops', 'data solutions', 'information systems', 'security', 'computer science', 'methodology', 'data management', 'ai']","['environment', 'private', 'events', 'accounting', 'mental health', 'professional services', 'business value', 'design', 'project management', 'governance', 'consulting', 'prince2', 'key performance indicators', 'assessment', 'business', 'architecture']"
460,621,Big Data Engineer,"epam is committed to providing our global team of more than 41,150 epamers with inspiring careers from day one. epamers think creatively and lead with passion and honesty. our people are the source of our success. we value collaboration, work in partnership with our customers, and strive for the highest standards of excellence. in today s market conditions, we re supporting operations for hundreds of clients around the world remotely. no matter where you are located, you ll join a dedicated, diverse community that will help you discover your fullest potential. description you are curious, persistent, logical and clever a true techie at heart. you enjoy living by the code of your craft and developing elegant solutions for complex problems. if this sounds like you, this could be the perfect opportunity to join epam as a big data engineer. scroll down to learn more about the position s responsibilities and requirements. req 225448556 what you ll do we are looking for a big data engineer that will work on the collecting, storing, processing, and analyzing of large sets of data the primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them you will also be responsible for integrating them with the architecture used across the company requirements proficient understanding of distributed computing principles management of hadoop cluster , with all included services ability to solve any ongoing issues with operating the cluster proficiency with hadoop v2, mapreduce, hdfs, sqoop experience with building stream processing systems, using solutions such as storm or spark streaming good knowledge of big data querying tools, such as pig, hive, and impala experience with spark experience with integration of data from multiple data sources such as mssql server, oracle good understanding of sql queries, joins, stored procedures, relational schemas experience with nosql databases, such as hbase, cassandra, mongodb knowledge of various etl techniques and frameworks, such as flume experience with various messaging systems, such as kafka or rabbitmq experience with cloudera fs domain knowledge a big plus but not required what we offer extended healthcare with prescription drugs, dental and vision insurance life and ad d insurance employee assistance program unlimited access to linkedin learning solutions long term disability registered retirement savings plan with company match paid time off critical illness insurance employee discounts","['computing', 'sql', 'databases', 'schemas', 'sqoop', 'stored procedures', 'cassandra', 'hadoop', 'stream processing', 'rabbitmq', 'big data', 'integration', 'mongodb', 'etl', 'hive', 'nosql', 'cluster']","['sql', 'databases', 'cassandra', 'sqoop', 'stored procedures', 'hadoop', 'big data', 'rabbitmq', 'hive', 'nosql', 'map']","['distributed', 'computing', 'schemas', 'stream processing', 'integration', 'mongodb', 'etl', 'cluster']","['healthcare', 'retirement', 'architecture', 'linkedin', 'insurance']"
461,623,Data Engineer,"we d love to hear from you if you like start up energy working with a brilliant and passionate team exponential growth flat structure and access to senior leadership for continuous mentorship meritocracy we promote based on performance, not tenure rockstar teammates. you will be working with a strong team with prior work experience at amazon, microsoft, nvidia, alibaba, etc. about jerry.ai jerry.ai is an ai powered personal concierge for your car and home . our mission is to make all aspects of car home ownership hassle free and effortless. we are starting with car insurance. enabled by disruptive technologies, jerry.ai has built a one click experience for saving money on car insurance. since our product launch, we have been growing really fast for the past 15 months and our users love the product . jerry.ai is founded by serial entrepreneurs who previously built and scaled yourmechanic . we are backed by y combinator, sv angel, funders club, and many other prominent silicon valley investors. about the role we are looking for a data engineer who is passionate and motivated to make an impact in creating a robust and scalable data platform. in this role, you will have ownership of the company s core data pipeline that powers our top line metrics. you will also leverage data expertise to help evolve data models in various components of the data stack. you will be working on architecting, building, and launching highly scalable and reliable data pipelines to support the company s growing data processing and analytics needs. your efforts will allow access to business and user behavior insights, leveraging the data to fuel other functions such as analytics, data science, operations and many others. responsibilities owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth consistently evolve data model data schema based on business and engineering needs implement systems tracking data quality and consistency develop tools supporting self service data pipeline management sql and mapreduce job tuning to improve data processing performance requirements 2 years of data engineering experience within a rigorous engineering environment proficient in sql, specially with postgres dialect. expertise in python for developing and maintaining data pipeline code. experience with apache spark and pyspark library . experience with bi software . experience with hadoop ecosystem. experience with deploying and maintaining data infrastructure in the cloud . comfortable working directly with data analytics to bridge business requirements with data engineering locations toronto boston","['sql', 'python', 'data analytics', 'data pipelines', 'data processing', 'pyspark', 'software', 'bi', 'apache spark', 'hadoop', 'data infrastructure', 'data science', 'analytics', 'core', 'data models', 'data quality', 'data engineering', 'ai']","['sql', 'python', 'pyspark', 'bi', 'apache spark', 'hadoop', 'data models', 'data quality']","['job tuning', 'data analytics', 'data processing', 'data pipelines', 'ai', 'software', 'data infrastructure', 'data science', 'analytics', 'data engineering', 'core data']","['product launch', 'environment', 'insurance', 'metrics']"
462,625,Staff Data Engineer (Americas - Remote),"company description shopify is the leading omni channel commerce platform. merchants use shopify to design, set up, and manage their stores across multiple sales channels, including mobile, web, social media, marketplaces, brick and mortar locations, and pop up shops. the platform also provides merchants with a powerful back office and a single view of their business, from payments to shipping. the shopify platform was engineered for reliability and scale, making enterprise level technology available to businesses of all sizes. job description our data platform engineering group builds and maintains the platform that delivers accessible data to power decision making at shopify for over a million merchants. we re hiring high impact developers across teams the engine group organizes all merchant and shopify data into our data lake in highly optimized formats for fast query processing, and maintaining the security and quality of our datasets. the analytics group leverages the engine primitives to build and deliver simple and useful products that power scalable transformation of data at shopify in batch, streaming, or for machine learning. this group is focused on making it really simple for our users to answer three questions what happened in the past what is happening now and, what will happen in the future the data experiences group builds end user experiences for experimentation, data discovery, and business intelligence reporting. the reliability group operates the data platform in a consistent and reliable manner. they build tools for other teams on data platform to leverage and encourage consistency as they champion reliability across the platform. qualifications an experienced technical leader with a proven track record of delivering impactful results. technical engineering background in one or more areas in the next section. experience with technical mentoring, coaching, and improving the technical output of the people around you. exceptional communication skills and ability to translate technical concepts into easy to understand language for our stakeholders. excitement for working with a remote team you value collaborating on problems, asking questions, delivering feedback, and supporting others in their goals whether they are in your vicinity or entire cities apart. a staff data developer would typically have 6 10 years of experience in one or more of the following areas experience with the internals of a distributed compute engine experience in query optimization, resource allocation and management, and data lake performance experience with cloud infrastructure experience with security products and methods experience deploying and scaling ml solutions using open source frameworks experience building full stack applications background and practical experience in statistics and or or computational mathematics modern big data storage technologies additional information at shopify, we are committed to building and fostering an environment where our employees feel included, valued, and heard. our belief is that a strong commitment to diversity and inclusion enables us to truly make commerce better for everyone. we strongly encourage applications from indigenous people, racialized people, people with disabilities, people from gender and sexually diverse communities and or or people with intersectional identities. shopify is now permanently remote and working towards a future that is digital by design. learn more","['technical engineering', 'machine learning', 'statistics', 'shopify', 'reporting', 'datasets', 'security', 'computational mathematics', 'analytics', 'optimization', 'business intelligence', 'cloud infrastructure', 'big data']","['big', 'business intelligence', 'shopify']","['technical engineering', 'machine learning', 'statistics', 'reporting', 'datasets', 'security', 'query', 'computational mathematics', 'analytics', 'optimization', 'cloud infrastructure', 'data storage']","['commerce', 'environment', 'design', 'sales', 'resource allocation', 'hiring', 'mentoring']"
463,626,Manager Product Management – Data Science,"this role will start off as work from home, gradually will be required to work in the markham, ontario office location. join an exciting team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. the insurance industry is undergoing a transformation and you get to be in the driver s seat during this data driven, technology revolution. you will be part of a dynamic small team that helps drive innovation and growth across aviva. you will work directly with various business stakeholders and drive the roadmap for future products and innovative solutions. you will work closely with the data science team to build out automated solutions that create data driven solutions that affect millions of customers. this is your chance to join the insuretech revolution your responsibilities as a manager of product management, you will build a comprehensive product strategy for data science at aviva canada. this role requires close collaboration with our business stakeholders across different areas of the business in building a strategy focused on driving automation, growth and profitability. lead a team of product managers in developing and delivering on the product strategy. possess an in depth understanding of the insurance business and internal business processes across focused strategic areas. drive discussions, engage business partners and identify areas of opportunity for data science. be able to develop compelling business cases that show expected costs and benefits with a clear understanding of return on investment. focus on the customer journey, simplicity and ease of doing business throughout all phases of discovery, strategic planning and implementation. have a good technical understanding of implemented solutions, allowing you to balance technical requirements with business priorities and develop roadmaps that take into account complexity of implementation and technical debt remediation. regularly monitor and report on project outcomes, performance trends and insights in order to measure effectiveness of the implemented solutions. build a product practice within data science and collaborate across teams to build a cohesive understanding of product management best practices across aviva. what you need to succeed you will need the following skills and experience to succeed in the role 6 years of industry experience directly involved in leading product delivery. 2 years in a leadership role in which you have led other product managers and a product management practice. great leadership skills coupled with expertise in the field of product management. the ideal candidate has a strong understanding of how to turn business needs into compelling technical solutions with a keen eye for customer outcomes and user experience. a proven track record in successfully delivering end to end products in an agile environment. excellent communication skills with the ability to influence, collaborate and drive adoption. ability to work closely with technical teams to develop technical solution strategies. what sets you apart experience working in the insurance industry and developing products in the areas of underwriting, pricing, claims, fraud or data science. experience with ai or machine learning methodologies. additional information aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation. we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","['forefront', 'agile environment', 'machine learning', 'user experience', 'data science', 'technical requirements', 'product management', 'remediation', 'automation', 'ai']",['forefront'],"['agile environment', 'machine learning', 'ai', 'strategic', 'technical understanding', 'user experience', 'data science', 'technical requirements', 'product management', 'remediation', 'automation', 'planning']","['underwriting', 'actuaries', 'product delivery', 'insurance industry', 'product strategy', 'adoption', 'hiring', 'insurance', 'return on investment']"
464,630,Remote Data Engineer,"monetizemore builds industry leading ad technology that is seen by more than 300m people per month. the company has been running for 10 years achieving consistent double digit growth each year with a team of 100 team members spread across the globe. monetizemore offers location and schedule freedom to every one of its team members. that means that you would have the lifestyle autonomy to choose to work from anywhere in the world, during the time of day you prefer. this new age work lifestyle would enable you to engineer your ideal lifestyle. say goodbye to endless commutes, stuffy business attire and the arbitrary 9 5 work day. take your life back into your hands by joining the monetizemore team the product team is the fastest and most innovative team in the company. build greenfield technology that is disrupting the ad technology industry. solve problems that have never been solved before. join a company culture that replaces constant meetings and interruptions with innovation that continues to break boundaries. take your skillset to the next level with some of the best minds in the ad technology industry to make a real difference with monetizemore. responsibilities the day to day work of a monetizemore data engineer includes building and maintaining data pipelines using kubernetes, airflow and aws stack proficient in writing complex and nested sql queries. experience with aws athena is a plus. analyze data using python pandas, apache spark dataframes, elasticsearch kibana. building javascript applications capable of tracking and responding to billions of requests per month. developing apis and integrating with 3rd party apis to automate manual tasks. integration of services to maximize ad revenues and maintain strong user experience. planning and prototyping new applications. defect resolution of existing and new issues. unit testing new features to ensure they conform to monetizemore s quality standard and meet requirements. code reviews. running performance benchmarking tests. staying up to date with new trends and advancements in web development and ad tech. attending daily stand up meetings and other scrum meetings . attributes monetizemore data engineer attributes include teamwork attributes collaboration working remotely on complex projects necessitates that you work together with your team and share knowledge. communication skills you are comfortable communicating in english at all levels, have strong spoken and written communication skills and are an active listener. teamwork you value team synergy and are excited about helping your team succeed. interpersonal skills you are able to get along, work well and coordinate with others. conflict management as a team, we are proactive in dealing with conflict.you are able to find constructive ways of resolving issues with other team members. technical attributes technology a monetizemore developer is proficient in all stages of web development, from conception to deployment. you are a one person army, ready and willing to attack any technical challenge that crosses your path analytical and problem solving skills you work hard to understand technical issues and to resolve them in an effective manner. detail orientation you work on many parts of an application or system at the same time and are able to focus on each detail meticulously. initiative you work well in a team, with little supervision, making well reasoned and effective technical decisions. reliability and responsibility you demonstrate reliability at all times. you give reasonable expectations within agile scrum framework and work hard and smart to achieve and surpass those expectations. you communicate what you are going to do, then meet that commitment. thought leadership you analyze monetizemore s tech stack, systems and processes with the goal to iterate on a regular basis. you look for opportunities to improve to increase value to monetizemore and suggest them to the team. if you think you are a good fit to join the monetizemore product team, please apply below and give specific reasons what sets you apart. we hire individuals not robots so don t be afraid to show a little personality nhovengbx5","['user experience', 'javascript', 'kubernetes', 'sql', 'python', 'kibana', 'elasticsearch', 'pandas', 'aws', 'integration', 'unit testing', 'data pipelines', 'apache spark', 'scrum', 'athena', 'airflow', 'prototyping', 'resolving issues', 'web development']","['kubernetes', 'sql', 'python', 'apache spark', 'kibana', 'elasticsearch', 'pandas', 'aws', 'javascript', 'athena', 'airflow']","['prototyping', 'data pipelines', 'tests', 'resolving', 'user experience', 'scrum', 'performance', 'web development', 'integration', 'unit testing', 'planning']",['benchmarking']
465,631,Part-Time Content Creator - Data Analytics,"about the position we ve been creating exceptional, life changing courses since 2012. our web development bootcamp has helped over 1000 people become web developers, and we re ready to expand into a new topic, data analytics. we re looking for a data professional, proficient in tableau, sql, and python, to help us create our data analytics bootcamp content. this position is a part time role that requires 8 hours per week for 12 weeks, compensated at 100 an hour. this role is remote and is designed to be manageable along with a full time job. we know what makes great programs, modules, lessons, projects, exercises and breakouts, and you know what it takes to land a job and succeed as a data analyst. we ll guide you through our curriculum creation process, and together, we ll create a life changing program featuring hands on, project based lessons, exercises and projects. you ll work closely with our director of product and our talented team of instructors to craft approachable and fun lessons that will ensure our students learn the most important skills for landing a data analyst position, while having fun this role is perfect for someone who is currently working as a data analyst or data scientist and is looking for a way to share their knowledge to help the next generation of analysts. this is an opportunity to create a data analytics program that will change the lives of thousands of people in the coming years. if this sounds exciting, we want to hear from you about us founded by heather payne in 2012, juno college of technology is an innovative technology school based in toronto, canada. as a registered private career college, juno offers courses for people who want to land jobs in tech fast and serves over 1000 students a year from a 12,000 square foot campus in downtown toronto. currently all of our courses and programs are offered live online and our team is fully remote until we are able to safely return to our office. with thousands of alumni and 1000 students a year, there s a large community of people ready to welcome you to juno responsibilities work with a team of instructors to create the data analytics bootcamp, helping students learn through lessons, code alongs, projects and interactive exercises contribute expertise to student project design and create project evaluations other tasks as required about you your qualifications 5 years data analytics or data science experience working with sql and python experience using tableau or another data visualization platform excellent writing skills passionate about creating a best in class data analytics program you have opinions on how data analytics should be taught, likely from experience hiring and training for entry level data analyst roles you could be a great fit if you have demonstrable hands on industry experience in data analytics or data science are collaborative, energetic, and empathetic, and a creative problem solver have expertise in using python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization have practical knowledge of working with big data, performing customer segmentation, and using cloud services are comfortable using git, github, google docs, sheets, and drive are passionate about improving education and accessibility to great data jobs salary, perks and benefits position type part time, contract hourly 100 how to apply please apply through the link below and answer the provided questions. we d love to see your resume, and anything else you d like to provide us all applications are appreciated, but we will only contact successful applicants to move on to the next stage.","['data analytics', 'python', 'sql', 'statistics', 'machine learning', 'tableau', 'github', 'data wrangling', 'data visualization', 'web development', 'data science', 'git', 'big data', 'data analysis', 'solver', 'cloud services']","['sql', 'python', 'tableau', 'git', 'big data', 'solver']","['data analytics', 'machine learning', 'statistics', 'exploratory', 'data wrangling', 'data visualization', 'data science', 'web development', 'data analysis', 'github', 'cloud services']","['curriculum', 'land', 'private', 'education', 'project design', 'hiring']"
466,632,Senior Optical Simulation Engineer or Scientist,"senior optical simulation engineer or scientist about metamaterial inc. meta delivers previously unachievable performance, across a range of applications, by inventing, designing, developing, and manufacturing sustainable, highly functional materials. our extensive technology platform enables leading global brands to deliver breakthrough products to their customers in consumer electronics, 5g communications, health and wellness, aerospace, automotive, and clean energy. meta s achievements have been widely recognized, including being named a global cleantech 100 company. learn more at about the role we are seeking a senior optical simulation engineer or scientist for our facility in dartmouth, nova scotia. you will be a key member of the optics team that develops new technologies and products for applications in augmented reality and scientific instruments. your role will be to both design new optical systems and develop the toolset for simulating their behaviour and optimizing their performance. the ideal candidate will have extensive experience in modelling optical systems, particularly systems involving imaging waveguides, and experience developing tools in python. responsibilities lead the development of new simulation tools for predicting and optimizing the performance of complex and novel optical systems. work with internal and external stakeholders to develop product concepts and designs that address the needs of the hmd, hud and scientific instruments markets. support other engineering staff for the most challenging simulation and modelling tasks. define best practices for the development, deployment, and maintenance of a rapidly evolving codebase. characterize performance of optical products and sub systems relative to the design goals and the broader system requirements specify and design the optical evaluation systems necessary for such characterization. identify causal relationships between observed product or sub system performance and design parameters. analyze data and communicate results through technical reports and presentations tailored to the needs of the target stakeholders. supervise junior members of the engineering team. required skills and experience must have extensive experience in code development and data analysis for scientific applications using c or c and python. must have experience in em simulation techniques and packages . experience in hands on lab work is an asset. excellent written, verbal and presentation skills. qualifications an msc or phd in physics, applied physics, optics, ee, or related field, is required. minimum 5 years of experience with optical engineering and optical simulation. canadian work authorization. professional standards and performance review as an experienced professional, the senior optical simulation engineer or scientist will maintain high professional standards and act in accordance with best practice. they will support the development of the professional standards of the team and take a continuous approach to improvement and their own personal development. as a representative of the company, the senior optical simulation engineer or scientist will act in line with the company code of conduct and will participate in the performance review process.","['automotive', 'python', 'authorization', 'augmented reality', 'physics', 'system requirements', 'performance', 'c', 'data analysis', 'electronics', 'technical reports', 'system performance']","['python', 'authorization', 'augmented reality', '5g', 'c', 'electronics', 'system performance']","['automotive', 'performance review', 'physics', 'scientific instruments', 'system requirements', 'data analysis', 'technical reports']","['characterization', 'design', 'scientific instruments', 'presentations', 'materials', 'optics', 'scientific', 'manufacturing', 'aerospace']"
467,634,Data Engineer,"job description 3 6 years expertise on spark scala. ability to develop etl jobs to implement business logic using scala conversant with hive database, able to create hql scripts and work on hive tables for data analysis performance tuning of the existing hadoop jobs, able to trouble shoot and fix existing bugs. good understanding of oracle exadata rdbms, able to profile telecom data residing in exadata and derive business rules. co lace with business, have working session with business to identify and freeze business logic. understanding or experience working on scrum based agile set up. the capgemini freelancer gateway is enabled by a cutting edge software platform that leads the contingent labor world for technology innovation. the software platform leverages machine learning and artificial intelligence to make sure the right people end up in the right job. a global leader in consulting, technology services and digital transformation, capgemini is at the forefront of innovation to address the entire breadth of clients opportunities in the evolving world of cloud, digital and platforms. building on its strong 50 year heritage and deep industry specific expertise, capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. capgemini is driven by the conviction that the business value of technology comes from and through people. it is a multicultural company of over 200,000 team members in more than 40 countries. the group reported 2018 global revenues of eur 13.2 billion.","['forefront', 'machine learning', 'scala', 'software', 'rdbms', 'hadoop', 'scrum', 'exadata', 'artificial intelligence', 'technology services', 'data analysis', 'hive', 'digital transformation', 'performance tuning', 'etl']","['forefront', 'scala', 'rdbms', 'hadoop', 'exadata', 'technology services', 'hive']","['machine learning', 'software', 'scrum', 'artificial intelligence', 'data analysis', 'digital transformation', 'performance tuning', 'etl']","['business value', 'consulting']"
468,639,Applied Scientist II - ADCC-V4587,"phd in engineering, computer science, statistics or related technical field plus 2 years of work experience in the job offered or related occupation will accept master s degree in engineering, computer science, statistics, or related technical field plus 5 years of work experience in the job offered or related occupation 5 years experience with machine learning technologies and rules based systems 2 years of project management experience across multiple stakeholders 2 years of experience with the entire life cycle of a shipped product or online service 2 years of experience producing peer reviewed research reports or publications in the field of machine learning, statistics, or data mining terms of employment full time, permanent job location 595 burrard street, 12th floor, vancouver, british columbia, v7x 1l4 salary range 133,900 223,500 or commensurable with experience. language requirement english job description as an applied scientist, you will innovate and be responsible for working across backend, client, business development, and data engineering teams to coordinate deep dives, inform roadmaps, visualize metrics, and create predictive models to determine how we can best serve our customers. your key responsibilities will include participate in the design, development, evaluation, deployment and updating of data driven models and analytical solutions for machine learning and or or natural language applications develop and or or apply statistical modeling techniques , optimization methods, and other ml techniques to different applications in business and engineering routinely build and deploy ml models on available data research and implement novel ml and statistical approaches to add value to the business mentor junior engineers and scientists. all applicants must meet all qualifications listed above. benefits amazon provides a full range of benefits for our global employees and their eligible family members. this position is eligible for further pay increases and bonuses at the company s discretion. eligible employees may also receive signing bonuses and amazon restricted stock units. while they might vary from location to location, amazon benefits for canada may include health care savings plans income protection paid time off signing bonuses employee stock amazon is an equal opportunity affirmative action employer minority or female or disability or veteran or gender identity or sexual orientation","['data research', 'data mining', 'machine learning', 'statistics', 'computer science', 'statistical', 'optimization', 'modeling', 'data engineering']",[],"['data research', 'data mining', 'machine learning', 'statistics', 'computer science', 'natural', 'statistical', 'optimization', 'modeling', 'language applications', 'data engineering']","['business development', 'metrics', 'design', 'project management', 'research reports']"
469,642,Data Engineer,"about us gsts is striving to become the leading provider of global maritime risk assessment or threat intelligence solutions, using machine learning, artificial intelligence and big data, saving lives, energy and the environment. we have been in start up mode for the past 2 years and have grown steadily through the covid 19 pandemic. gsts has gained significant momentum and will be looking to increase its team over the next 12 months. we are based in dartmouth, ns within easy commute of both the dartmouth and halifax downtown core, our facility enjoys plenty of free parking and public transport is a short walk away. gsts is committed to building its presence in the maritimes at the same time supporting working from home and working remotely. gsts is seeking exceptional talent to support product recently awarded contracts, and to continue the growth of the product. we seek individuals with drive, initiative and motivation to join our team and make the world a safer, greener place for all key responsibilities as part of the team, your main task will be to work on our innovative ociana platform, developing new functionality already identified by our clients. every new team member is buddied up with an existing team member, to ensure they are up and running as quickly as possible. we utilize slack, teams and many other collaborative tools that allow us all to stay in touch and remain a close team wherever we are based in the country. your key responsibilities will be design and implement etl or data pipelines for novel data streams create and monitor alarms and watchdogs on data pipelines develop internal documentation on data assets for team use collaborate with senior engineers in data architecture design and implementation collaborate with senior engineers in management of rds postgres, athena instances experience and qualifications bachelor s degree or diploma in computer science, data science, data management, data engineering proven experience in database operations aws experience in extract transform load strong scripting competence comfortable with gb to tb scale data git backup and restore task automation strong troubleshooting skills ability to influence internal and external stakeholders, and overcoming obstacles team player and able to effectively interact with staff all levels of the company excellent written and verbal communications skills in english ability to listen and develop a deep understanding of product and client requirements strong self initiative and work ethic ability to thrive within a rapidly changing and growing environment demonstrated ability to work well in a multi disciplinary team environment additional experience and qualifications an asset aws services athena, aurora, lambda, elastic container service postgis or geospatial data docker data modeling comments or special considerations candidates must hold or be able to obtain security and controlled goods clearances. why work for us while we offer very competitive salaries and extended health benefits, including flexible working hours and growth opportunities the main reason to consider a position with us is the opportunity to work alongside great people with a shared desire to make a real difference in the world. this is not just a position, it s a chance to be part of something bigger we actively promote personal growth and training for example the company has just restructured to support the current and future growth plans and have recently promoted four internal employees to director positions come and join us and make a difference we are committed to creating a sense of belonging amongst our team. we have placed an emphasis on fostering a diverse, collaborative and inclusive working environment. we welcome applications from qualified candidates irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief. we thank all candidates that apply, but only those selected for an interview will be contacted. job types full time, permanent benefits casual dress company events dental care employee assistance program extended health care flexible schedule life insurance on site parking vision care wellness program work from home schedule monday to friday covid 19 considerations gsts is committed to providing a safe and comfortable working environment. the gsts offices have been expanded to support working and collaborating in a safe social distanced environment. work remotely yes covid 19 precaution remote interview process personal protective equipment provided or required social distancing guidelines in place virtual meetings sanitizing, disinfecting, or cleaning procedures in place","['geospatial data', 'troubleshooting', 'documentation', 'big data', 'threat intelligence', 'scripting', 'data science', 'database', 'data', 'aws', 'data engineering', 'machine learning', 'data pipelines', 'artificial intelligence', 'risk assessment', 'streams', 'athena', 'automation', 'security', 'git', 'computer science', 'modeling', 'data management', 'etl']","['git', 'documentation', 'big data', 'rds', 'aws', 'streams', 'athena']","['geospatial data', 'machine learning', 'data pipelines', 'threat intelligence', 'data engineering', 'scripting', 'security', 'data science', 'troubleshooting', 'computer science', 'data', 'artificial intelligence', 'modeling', 'database operations', 'risk assessment', 'data management', 'automation', 'etl']","['environment', 'events', 'maritime', 'design', 'insurance', 'functionality', 'architecture']"
470,643,Data Engineer,"you have the future of the planet at heart interest in smart and electrical mobility effenco is a pioneer business in electrification and advanced connectivity of heavy duty vocational vehicles. our head office is located on the outskirts of the lachine canal, in a historical building from the south west industrialization era. the work atmosphere is typical of a technological start up company, thus creative and casual. created in 2006, this innovative business is in the high growth phase and is looking to further expand its business unit on vehicle connectivity and data enhancements. in this position, you will have the opportunity to be involved in the process optimizations and to suggest new ideas. furthermore, we offer a flexible work environment that enables you to progress in your career while achieving personal development. responsibilities the data engineer will integrate the dev it team. in this role, the main responsibility will be to participate in the development and production of our new iot and data platform. more specifically, he or she will have to define business needs in data terms. plan, develop, test, and maintain enterprise data management systems. use modern software deployment techniques . create or use tools for monitoring data pipelines. identify and test new data management technologies. automate tasks such as data cleansing and validation. respond to analytical requests from various business intelligence stakeholders. promote the democratization of data within the company. any other related tasks. required profile university degree in information systems, computer science, or equivalent. experience with databases . experience with message brokers and pub sub software. experience using and developing rest apis. experience with cloud technologies. experience with software development. ability to communicate, present, and verbalize technical results or problems. knowledge of data format specifics . mastery of the git tool. bilingualism . organizational management and rigor. demonstrate autonomy, be curious, and self taught. used technologies effenco is marketing a hybrid electric system that electrifies auxiliary equipment on heavy duty vocational vehicles. the system reduces fuel consumption, pollutant emissions, and engine hours by shutting down the combustion engine when the vehicle is stationary. each electrified vehicle is equipped with a connectivity module that enables the acquisition of usage data. the data is transmitted in life and batch mode. to date, effenco has connected nearly 400 vehicles across north america and europe. effenco s software development stack consists of the following technologies aws s3, lambda, iot core, eks, glue, etc. javascript typescript, node.js, react or vue.js, nestjs java, kotlin, python numpy, pandas, airflow, flask, fastapi, pydantic go, gitlab, docker, kubernetes, terraform, rest, jwt, gitops. our offer a full time permanent position with a flexible schedule. a company that offers real career opportunities. inclusive and open minded manager and direction. a company that appears on global cleantech 100. hot coffee, nitrogen cold coffee, sparkling water, and beer available in the effenco kegerator. lunch provided on friday at noon. type d emploi permanent avantages v nements d entreprise horaires flexibles nourriture prix r duit ou gratuite stationnement sur place tenue d contract e travail distance horaire du lundi au vendredi quart de jour repos la fin de semaine exp rience consultation 1 an sql 1 an oracle 1 an d veloppement avec datastage 1 an langue fran ais t l travail temporairement en raison de la covid 19","['go', 'databases', 'cleansing', 'javascript', 'java', 'glue', 'kubernetes', 'python', 'terraform', 'sql', 'kotlin', 'software', 'enterprise', 'software development', 'data', 'pandas', 'aws', 'gitlab', 'typescript', 'data pipelines', 'iot', 'numpy', 'business intelligence', 'flask', 'rest', 'airflow', 'information systems', 'git', 'nestjs', 'computer science', 'data management']","['go', 'databases', 'javascript', 'java', 'glue', 'kubernetes', 'python', 'terraform', 'sql', 'kotlin', 'pandas', 'aws', 'gitlab', 'typescript', 'iot', 'numpy', 'fastapi', 'business intelligence', 'airflow', 'git', 'nestjs', 'r']","['data pipelines', 'software deployment', 'software', 'management systems', 'information systems', 'enterprise', 'computer science', 'data', 'cleansing', 'software development', 'gitops', 'datasta', 'flask', 'data management', 'rest']","['validation', 'environment', 'marketing', 'electrification', 'electrical']"
471,648,Data Engineer,"what you ll do responsibilities use tools and custom code to implement automated data pipelines provide data analysis develop and advocate data governance best practices design and implement api endpoints to be consumed by data end users design, document and implement data models what you ll need qualifications required bs or ms degree in computer science or relevant experience strong software development background preferably in python or java 4 years of sql experience 4 years of experience with schema design and dimensional data modeling experience designing, building, and maintaining data processing systems strong background in microsoft azure, particularly azure data analytics offerings like azure data factory, azure managed sql, azure databricks, azure blob storage experience developing analytics driven solutions in microsoft powerbi nice to have past experience with apache airflow or similar workflow management system exposure to yandex clickhouse or other column oriented databases we re looking for core skills airflow data modeling crisp dm automation java python data science data analysis databases","['databases', 'workflow management', 'java', 'microsoft azure', 'sql', 'python', 'data analytics', 'data processing', 'data science', 'software development', 'data', 'analytics', 'data models', 'apache airflow', 'data pipelines', 'data analysis', 'dm', 'automation', 'airflow', 'microsoft power', 'azure', 'api', 'computer science', 'schema', 'modeling']","['apache airflow', 'sql', 'python', 'azure', 'databases', 'clickhouse', 'api', 'azure databricks', 'azure data factory', 'data models', 'java', 'microsoft azure', 'airflow']","['data analytics', 'data pipelines', 'data processing', 'workflow management', 'data science', 'software development', 'computer science', 'data', 'schema', 'modeling', 'analytics', 'data analysis', 'automation', 'dm']","['governance', 'design']"
472,649,Data Lab Architect,"highly technical and analytical, possessing 5 or more years of database and or or analytics systems development and deployment experience, it systems and engineering experience, security and compliance experience, etc. possess significant experience of software development and or or it and implementation or consulting experience. strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams. ability to think understand complex business requirements and render them as prototype systems with quick turnaround time. implementation and tuning experience in the big data ecosystem, , database , nosql and data warehousing and data migration and integration. track record of implementing aws services in a variety of business environments such as large enterprises and start ups. knowledge of foundation infrastructure requirements such as networking, storage, and hardware optimization. bs level technical degree required computer science or mathematics background preferred. description are you a data and analytics specialist do you have deep expertise in aws services for managing data at speed and scale do you think big about how data can change the world, and love building software would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost at aws, we re hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. aws data labs are a global and online based facility where customers come to build data and analytics platforms. you will focus on real time and batch based data processing, business intelligence, analytics, and machine learning systems. these solutions are built alongside the customer and quickly put into production use in a matter of weeks. you ll work closely with aws field teams including solution architects, technical account managers, and aws service developers to partner with customers to solve hard problems with data. every day, you ll be working with aws services and data labs customers to determine the optimal implementation, build it, prove it works, extract documents and cloudformation templates to speed project delivery. if you are builder, and love data, then this could be your ideal job inclusive team culture here at aws, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team puts a high value on work life balance. it isn t about how many hours you spend at home or at work it s about the flow you establish that brings energy to both parts of your life. we believe striking the right balance between your personal and professional life is critical to life long happiness and fulfillment. we offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. mentorship career growth our team is dedicated to supporting new members. we have a broad mix of experience levels and tenures, and we re building an environment that celebrates knowledge sharing and mentorship. our senior members enjoy one on one mentoring and thorough, but kind, code reviews. we care about your career growth and strive to assign projects based on what will help each team member develop into a better rounded engineer and enable them to take on more complex tasks in the future. hands on experience leading large scale global database, data warehousing and analytics projects. demonstrated industry leadership in the fields of database and or or data warehousing, data sciences and big data processing. deep understanding of data, application, server, and network security experience with statistics, machine learning and predictive modelling. hands on experience as a database, data warehouse, big data or analytics developer or administrator, or work as a data scientist. experience working within the software development or internet industries is highly desired. technical degrees in computer science, software engineering, or mathematics working knowledge of modern software development practices and technologies such as agile methodologies and devops. aws certification, eg. aws solutions architect, developer, or sysops associate or professiona","['network', 'big data', 'statistics', 'data processing', 'software', 'software development', 'analytics', 'data', 'integration', 'aws', 'cloud computing', 'data warehousing', 'nosql', 'machine learning', 'data migration', 'business intelligence', 'hardware', 'agile methodologies', 'devops', 'security', 'networking', 'computer science', 'mathematics', 'optimization', 'data management']","['big', 'aws', 'big data', 'business intelligence', 'hardware', 'nosql']","['network', 'statistics', 'data processing', 'software', 'software development', 'analytics', 'integration', 'cloud computing', 'data warehousing', 'machine learning', 'data migration', 'agile methodologies', 'devops', 'security', 'networking', 'computer science', 'mathematics', 'optimization', 'data management']","['and compliance', 'project delivery', 'environment', 'affinity', 'templates', 'consulting', 'team culture', 'hiring', 'mentoring']"
473,650,Software Developer - Data Operations,"who we are geotab is a global leader in iot and connected transportation and certified great place to work. we are a company of diverse and talented individuals who work together to help businesses grow and succeed, and increase the safety and sustainability of our communities. geotab is advancing security, connecting commercial vehicles to the internet and providing web based analytics to help customers better manage their fleets. geotab s open platform and marketplace, offering hundreds of third party solution options, allows both small and large businesses to automate operations by integrating vehicle data with their other data assets. processing billions of data points a day, geotab leverages data analytics and machine learning to improve productivity, optimize fleets through the reduction of fuel consumption, enhance driver safety and achieve strong compliance to regulatory changes. our team is growing and we re looking for people who follow their passion, think differently and want to make an impact. ours is a fast paced, ever changing environment. geotabbers accept that challenge and are willing to take on new tasks and activities ones that may not always be described in the initial job description. join us for a fulfilling career with opportunities to innovate, great benefits, and our fun and inclusive work culture. reach your full potential with geotab. to see what it s like to be a geotabber, check out our blog and follow us insidegeotab on instagram, twitter or facebook. who you are you will have deep knowledge in developing and documenting processes for onboarding new data into geotab s production data environment. you are highly organized and are able to manage multiple tasks and projects simultaneously. also a strong team player with the ability to engage with all levels of the organization. if you love technology, and are keen to join a data driven company we would love to hear from you what you ll do the software developer, dataops is the foundation of geotab s data factory. they are responsible for the development of scalable and reusable pipelines that minimize time from insight to production. the role continuously collaborates with data analysts and data scientists to design innovative pipelines using new tools and frameworks. they also work closely with the data architect and data quality experts to ensure all data assets are delivered with the highest quality, with the right schema and into the right location. how you ll make an impact deploy and maintain etl or elt pipelines using sql, python and airflow. design and publish reusable pipeline templates through in house python package . collaborate with data analysts and data scientists to develop complex pipeline templates involving big data tools . lead optimization of pipelines based on requirements and pipeline performance. develop connectors to extract or receive data from external sources. manage pipeline releases through git and ci or cd. contribute to the development of an alerting framework for production pipelines. ensure metadata is captured and stored across the pipeline lifecycle . support remediation of issues within production pipelines. collaborate with data quality analysts and specialists to ensure all pipelines include automatic quality checks. collaborate with data architect to ensure data schemas comply with dataops guideline. support data architect in evaluation of model based pipelines through dataform. recommend features and enhancements to infrastructure and pipeline framework. contribute to the migration of data assets and pipelines from legacy data structures what you ll bring to this role post secondary degree or diploma specialization in computer science, engineering, mathematics, or a related field. 3 5 years of python development experience. 3 5 years of experience building etl or elt production pipelines. 1 2 years of experience with sql and databases. previous experience interacting with rest apis in python is an asset. hand on experience using apache airflow in a work setting is an asset. experience working in a cloud based infrastructure, especially google cloud platform, is an asset. previous experience with python package development is highly regarded. must stay relevant to technology and have the flexibility to adapt to the growing technology and market demands. strong team player with the ability to engage with all levels of the organization. why job seekers choose geotab work from home and flex work arrangements baby bonus home office reimbursement program online learning and networking opportunities electric vehicle purchase incentive program competitive medical and dental benefits retirement savings program how we work at geotab, we understand that the world is always changing and that we need to change with it. geotab has adopted a hybrid model for working, including a flexible work from home program, with the opportunity to work in our safe, clean offices. when working from home, you are required to have a reliable internet connection with at least 50mb dl or 10mb ul. virtual work is supported with cloud based applications, collaboration tools and asynchronous working. the health and safety of employees are a top priority. we encourage work life balance and keep the geotab culture going strong with online social events, chat rooms and gatherings. join us and help reshape the future of technology we believe that ensuring diversity is fundamental to our future growth and progress and is an integral part of our business. we believe that success happens where new ideas can flourish in an environment that is rich in diversity and a place where people from various backgrounds can work together. geotab encourages applications from all qualified individuals. we are committed to accommodating people with disabilities during the recruitment and assessment processes and when people are hired. we will ensure the accessibility needs of employees with disabilities are taken into account as part of performance management, career development, training and redeployment processes. if you require accommodation at any stage of the application process or want more information about our diversity and inclusion as well as accommodation policies and practices, please contact us at click here to learn more about what happens with your personal data.","['databases', 'schemas', 'ci', 'big data', 'remediation', 'sustainability', 'data analytics', 'sql', 'python', 'cd', 'software', 'analytics', 'pipelinesform', 'pipelines', 'apache airflow', 'machine learning', 'iot', 'google cloud platform', 'metadata', 'data quality', 'rest', 'airflow', 'data structures', 'security', 'git', 'computer science', 'networking', 'mathematics', 'optimization', 'connectors', 'performance management', 'etl']","['apache airflow', 'sql', 'python', 'databases', 'pipelines', 'iot', 'git', 'google cloud platform', 'big data', 'data quality', 'airflow']","['schemas', 'ci', 'remediation', 'sustainability', 'data analytics', 'cd', 'software', 'analytics', 'data', 'machine learning', 'metadata', 'rest', 'data structures', 'security', 'computer science', 'networking', 'mathematics', 'optimization', 'connectors', 'performance management', 'personal data', 'etl']","['and safety', 'environment', 'events', 'onboarding', 'design', 'templates', 'retirement', 'assessment']"
474,651,Data Engineer,"keyrus canada, a leader in data intelligence is looking for a data engineer. the toronto team is expanding rapidly our team has doubled in the last two years and is continuing to grow. if you are looking for an innovative startup style company with a good team spirit that has the support of an internationally recognized brand, we encourage you to apply and join us who we are with offices in 18 countries and more than 20 years of experience in north america, keyrus is a trusted leader in data intelligence. keyrus canada offers stimulating projects to increase companies performance, with 2 areas of expertise data strategy to help organizations identify business objectives, build a strategy, and leverage their data to achieve their goals data intelligence to enable companies to draw critical insights from their data and shape business decisions about the role we are looking for a data engineer expert to join our toronto office as a part of the keyrus team, you will combine your business acumen and statistical knowledge with strong problem solving abilities to analyze large sets of data and deliver insightful, actionable results to our clients. you will play a key role in providing our clients with business intelligence and etl solutions to manage their data assets. you will work directly with our client s business to add value to their data intelligence environment through the use of tools such as alteryx and tableau. you will be responsible for the entire end to end analytics solution, from backend data engineering, manipulation, and cleansing, to front end data visualization. our ideal candidate at least 3 years of experience as a business intelligence developer, working directly with a tool such as alteryx, talend or ssis for etl, data manipulation, etc. as well as with a data visualization tool such as tableau experience working with a relational database and data modeling experience working with business teams to translate functional requirements into technical requirements knowledge of data visualization best practices and cloud warehouses would be an asset minimum of a bachelor s degree in it or related field. what we offer a stimulating environment driving you to discover new horizons and surpass yourself a strong innovative and entrepreneurship dna a space that promotes mutual respect, where you can express your ideas and share your opinion a positive, multicultural work atmosphere and a strong team spirit lots of opportunities to celebrate your successes afterworks, team activities, birthdays, breakfasts and other special events benefits such as insurance, rrsps, almost full repayment of the transport card, etc.","['tableau', 'alteryx', 'talend', 'data visualization', 'data manipulation', 'technical requirements', 'data', 'analytics', 'cleansing', 'business intelligence', 'modeling', 'data intelligence', 'data engineering', 'ssis', 'etl']","['tableau', 'alteryx', 'talend', 'data manipulation', 'data', 'business intelligence', 'ssis']","['data visualization', 'technical requirements', 'analytics', 'cleansing', 'data', 'modeling requirements', 'data engineering', 'etl']","['entrepreneurship', 'environment', 'events', 'insurance']"
475,652,Data Engineer - 313378,"ing nieur de donn es dans le cadre de ses ententes avec ses diff rents clients, procom est actuellement la recherche d un ing nieur de donn es pour une entreprise dans le domaine des assurances. notre client est situ montr al. description des t ches et responsabilit s ing nieur de donn es les responsabilit s du poste incluent contribuer la planification et l ex cution de pipelines de donn es pour divers projets d apprentissage automatique concevoir, mettre en uvre et maintenir des pipelines de donn es avec des transformations de donn es complexes assembler des ensembles de donn es volumineux et complexes qui r pondent aux exigences commerciales fonctionnelles or non fonctionnelles collaborer avec les parties prenantes pour r soudre les probl mes techniques li s aux donn es et r pondre leurs besoins en infrastructure de donn es effectuer la collecte des exigences commerciales et fonctionnelles et fournir des estimations de projets. exigences du poste ing nieur de donn es exp rience de travail avec des quipes commerciales pour traduire les exigences fonctionnelles en exigences techniques excellente capacit de communication vous pouvez expliquer votre travail d une mani re que tous les membres de l quipe peuvent comprendre, et vous pouvez formuler les probl mes de mani re garantir que la bonne question est pos e exp rience de soutien et de travail avec des quipes interfonctionnelles dans un environnement dynamique. type de poste contractuel 6 mois avec de fortes possibilit s de renouvellement. date de d but imm diatement num ro de r f rence bh313378 english version data engineer as a part of its agreements with its various clients, procom is currently seeking a data engineer for a company in the insurance sector. our client is located in montr al. job details data engineer key responsibilities for this position include contribute to the planning and execution of data pipelines for various machine learning projects design, implement, and maintain data pipelines with complex data transformations assemble large, complex data sets that meet functional or non functional business requirements work with stakeholders to assist with data related technical issues and support their data infrastructure needs conduct business and functional requirements gathering and provide projects estimates. mandatory skills data engineer experience working with business teams to translate functional requirements into technical requirements excellent communication ability you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked experience supporting and working with cross functional teams in a dynamic environment. assignment length 6 month contract renewable start date immediately reference number bh313378","['data infrastructure gathering', 'machine learning', 'data pipelines', 'technical requirements', 'pipelines']","['pipelines', 'r']","['machine learning', 'data pipelines', 'functional requirements gathering requirements', 'data infrastructure', 'technical requirements', 'planning']","['environment', 'insurance sector', 'design']"
476,655,Data Engineer - Level 3,"company description ssense, pronounced es uhns , is a montreal based fashion platform with global reach. founded in 2003, ssense is pacing the vanguard of directional retail with a mix of luxury, streetwear, and avant garde labels. we produce industry leading original content and take pride in building our own technology solutions and systems from scratch. our field of focus has grown beyond that of a typical e commerce entity as we explore the nexus of content, commerce, and culture. currently serving 150 countries, generating an average of 88 million monthly page views, and achieving high double digit annual growth since inception, ssense is becoming a cultural protagonist in its own right. job description ssense is looking for a data engineer to join our rapidly growing technology team. the level 3 data engineer will join a squad and deepen their knowledge of software development and data pipelines. they will break down, with minimal guidance, large tasks into smaller, manageable steps to deliver complex tasks required for well defined features of the product roadmap. the ideal candidate will contribute to knowledge dissemination within the organization and participate in the recruiting and onboarding of new employees. responsibilities product delivery build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end user facing reports, data sciences and ad hoc analyses understand the high level product roadmap and immediate features to be developed, contributing to high level estimation and layout of the development sequences complete complex development tasks with minimal guidance constantly and actively contribute to pushing code to production with the objective of becoming a main contributor review pull requests write testable, efficient, and reusable code suitable for continuous integration and deployment, that respect best practices and ssense development standards review unified modeling language diagrams and technical documentation, ensuring its quality ownership and accountability be accountable for code quality and conduct adequate testing review and contribute to technical documentation knowledge sharing and coaching join ssense university sessions to ramp up on various technologies and host at least two sessions per year lead the onboarding of new data engineers architecture contribute actively to the design of the solution, challenging other members on technical decisions help more junior data engineers understand the technical design so they can write documentation for the rest of the team recruiting participate in hr recruiting events, helping to identify and recruit top tech talent qualifications bachelor s degree in computer science, engineering, or a related technical field a minimum of 3 years of object oriented programming and or or functional programming experience knowledge of apache spark for big data processing knowledge of python programming language knowledge of the data modelling concepts and ability to define the architecture with minimal guidance to develop a complex microservice familiar with various database systems and able to write complex queries independently knowledge of cloud concepts and the ability to follow instructions to use them with minimal guidance knowledge of the aws services and apache airflow, an asset proficiency in git bilingual in french and english skills fast learner and detail oriented solution oriented mindset and can do attitude to overcome challenges team player with a high sense of accountability and ownership ability to thrive in a fast paced environment and master frequently changing technologies and techniques additional information world class technology technology is at the core of everything we do at ssense. driven by an engineering mindset and a problem solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the ssense offering. world class team the ssense tech team is responsible for an international headless commerce platform. working in an agile environment, our squads are made up of experienced innovators in product management, qa, design, devops, software development, machine learning, data engineering, and security. headquartered in montreal, our technology organization has been growing at a rate of 2x year over year and is doubling once again in 2021 as we expand across canada, us, and europe. world class platform the ssense platform runs on amazon web services making use of serverless microservices across web, mobile and app. our event source architecture already achieves over 10,000 requests or second and growing at an unmatched pace, currently unseen across the industry. our data driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in machine learning techniques. our automated continuous improvement devops model results in an average of 50 production releases every day. read more about us on our ssense tech blog.","['dissemination', 'technical design', 'documentation', 'python', 'agile environment', 'data processing', 'diagrams', 'database systems', 'software development', 'product management', 'programming', 'integration', 'aws', 'data engineering', 'microservices', 'apache airflow', 'amazon web services', 'machine learning', 'data pipelines', 'testing', 'apache spark', 'rest', 'devops', 'technical', 'security', 'git', 'computer science', 'technology solutions', 'modeling']","['apache airflow', 'python', 'amazon web services', 'apache spark', 'functional', 'big', 'git', 'technology solutions', 'programming', 'documentation', 'ssense', 'aws']","['dissemination', 'technical design', 'agile environment', 'data processing', 'diagrams', 'database systems', 'software development', 'product management', 'integration', 'data engineering', 'microservices', 'machine learning', 'data pipelines', 'continuous', 'testing', 'rest', 'devops', 'security', 'computer science', 'technical documentation', 'modeling']","['e', 'commerce', 'events', 'product delivery', 'environment', 'continuous improvement', 'retail', 'fashion', 'onboarding', 'design', 'recruiting', 'hr', 'architecture']"
477,656,Intermediate Scientist/CAPA Specialist,"our client in ottawa west is currently looking for a capa specialist, r d to join their team. as a member of research and development team, the candidate will contribute to the team s success by supporting key product development programs while gaining an understanding of the business. main tasks will include, but are not limited to, data analysis, capa documentation, performing capa investigations, and root cause analysis or failure mode effects analysis of chemical or biochemical systems and mechanical or microfluidic systems. the ideal candidate for our team will bring the following education, experiences, knowledge, and skills to the position. required education and experience bachelor s degree in science, engineering or related discipline preferred. proven technical, creative, teamwork and implementation skills to contribute to active investigations for product development. demonstrated problem solving and analytical skills. experienced using statistical tools, root cause analysis and knowledge of failure mode effects analysis. strong written and oral skills are required. comprehends and conveys information accurately and concisely, excellent technical documentation skills. ensures documentation and resulting actions comply with all corporate and regulatory requirements. understands key technical issues and provides creative solutions while balancing relative risks and gains. excellent attention to detail, organization skills and proven ability to multitask. demonstrated initiative and ability to work with tight deadlines. demonstrated judgment and decision making skills, organization, coordinating and planning skills, ability to work in a multi task environment, ability to work under pressure and propensity to continuous learning. ability to work both independently and within small and large teams strong interpersonal skills and ability to work cross functionally. ability or aptitude to work on complex problems or issues. ability or aptitude to use various types of databases and other computer software. familiarity with any of the following areas would be an asset gmp, iso 13485 standard, fda quality system requirements and other applicable us code of federal regulations for devices. working knowledge of quality management systems. risk management methods. working knowledge of capa procedures. this position requires a solid knowledge of scientific principals and theories and the ability to implement these in a creative and effective manner. the individual must be flexible and be able to work in a fast paced environment with changing priorities. this position requires someone who can work monday through friday from 8 00 a.m. to 5 00 p.m. compensation to be determined based on level of experience. if you would like to be considered for this position, please click on apply now ap1956","['analytical skills', 'databases', 'software', 'technical', 'system requirements', 'documentation', 'data analysis', 'root cause analysis', 'r']","['databases', 'documentation']","['analytical skills', 'software', 'management systems', 'system requirements', 'technical documentation', 'data analysis', 'root cause analysis', 'planning']","['environment', 'regulatory requirements', 'compensation', 'education', 'risk management', 'iso 13485', 'capa', 'fda', 'product development', 'regulations', 'gmp']"
478,659,Market Conduct Data Analyst,"job description we are canada life being a part of canada life means you have a voice. this is a place where your unique background, perspectives and talents are valued, and shape our future success. you can be your best here. you re part of a diverse and inclusive workplace where your career and well being are championed. you ll have the opportunity to excel in your way, finding new and better ways to deliver exceptional customer and advisor experiences. together, as part of a great team, you ll deliver on our shared purpose to improve the well being of canadians. it s our driving force. become part of a strong and successful company that s trusted by millions of canadians to do the right thing. be your best at canada life. we are looking for a market conduct data analyst advisor monitoring is a team of data analysts in market conduct that perform descriptive analytics looking for insights into advisor behaviour and market conduct risk while performing second line oversight of advisory network. reporting into the manager advisor monitoring, the data analyst role contributes to the execution of the advisor monitoring team by combining advanced analytical skills with strong industry knowledge. the ideal candidate is able to combine these abilities to efficiently and effectively draw conclusions and make recommendations to mitigate risk in advisory network. this includes detecting anomalous data patterns, analyzing these patterns using knowledge of distribution processes and products and projecting the results across the rest of the business to recommend control changes where appropriate. what you will do provide valuable data analytics to influence effective change combine expert industry knowledge with advanced data analytics skills to enhance predictive capabilities of advisor monitoring team while detecting emerging trends. collaborate with data scientists and other it partners to continuously enhance the efficiency and effectiveness of the advisor monitoring program. this includes tying trends identified during advisor case assessments to population studies to determine the prevalence of trends and recommend next steps. assist with the execution of advisor monitoring program analyze large volumes of transactional data to identify key risks with a focus on advisor misconduct. this includes ongoing advisor case assessment work. apply industry knowledge to assess potential advisor misconduct and resolve findings. this may require contacting advisors and or or customers where appropriate. conduct root cause analysis of market conduct complaints and use findings to set business requirements and execute upgrades to existing data analytics program. provide effective oversight of advisory network leverage program findings and understand controls framework and leverage program findings to provide effective challenge for upstream controls. share analytical best practices with business partners to drive the continuous improvement of business processes across risk compliance. follow up on referred cases to ensure successful achievement of advisor outcomes. what you will bring advanced data analytics skills with ability to work effectively in microsoft excel, microsoft power bi and tableau software. creative thinker with the ability to understand the root cause of an issue and use data to establish detective controls for the issue. strong interpersonal skills and a demonstrated experience working effectively in a team environment as well as independently. well developed planning and organizational skills with the ability to prioritize and handle multiple tasks while meeting tight deadlines. excellent verbal and written communication or documentation skills. strong influencer with the ability to provide effective challenge to legacy processes. advanced knowledge of insurance and wealth products, particularly for individual customer. understanding of advisor compensation is an asset. knowledge of internal admin systems an asset post secondary education in a related field. professional designation or diploma an asset be your best at canada life apply today we are one of canada s top 100 employers canada life serves the financial security needs of more than 13 million people across canada, with additional operations in europe and the united states. as members of the power financial corporation group of companies, we re one of canada s leading insurers with interests in life insurance, health insurance, investment and retirement savings. we offer a broad portfolio of financial and benefit plan solutions for individuals, families, businesses and organizations. we are committed to providing an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of the communities in which we live, and to creating an environment where every employee has the opportunity to reach their potential. canada life would like to thank all applicants, however only those who qualify for an interview will be contacted","['microsoft power', 'data analytics', 'analytical skills', 'tableau', 'software', 'bi', 'reporting', 'security', 'root cause', 'analytics', 'documentation', 'microsoft excel', 'rest', 'root cause analysis']","['microsoft power', 'tableau', 'bi', 'documentation', 'microsoft excel']","['data analytics', 'software', 'reporting', 'security', 'root cause', 'analytics', 'analytical skills patterns', 'rest', 'root cause analysis', 'planning']","['environment', 'continuous improvement', 'compensation', 'risk compliance', 'education', 'health insurance', 'retirement', 'insurance', 'assessment', 'emerging trends']"
479,662,Development Engineer / Development Scientist (Synthetic Biology),"about precision nanosystems inc. precision nanosystems inc. is a manufacturer of instruments, kits and reagents in the global nanomedicine market providing tools for drug development and cell specific delivery to study, diagnose and treat disease. pni s nanoassemblr family of instruments allow scientists to rapidly develop novel nanomedicine drug candidates for pre clinical testing. pni s nanoassemblr scale up platform enables the translation of these drug candidates to clinical testing and eventually to commercial use. pni s nanoassemblr transfection reagents use nanomedicine technology to deliver genetic materials in primary cells vitro and in vivo, enabling disease researchers to easily study gene function in high value models of disease. pni sells its products to leading pharmaceutical and biotechnology companies, and leading academic institutions in over 20 countries worldwide. please find more information at http or or or . position summary precision nanosystems inc. has an opening for development engineer or scientist, synthetic biology to join our growing pharmaceutical development department in vancouver, bc. the successful candidate will contribute to a wide range of product development projects including the development and commercialization of novel nanoparticle reagents, microfluidics and instrumentation to enable the field of genetic medicine. the individual will have a diverse set of molecular biology and genetic engineering skills with significant experience in vector library development, recombinant dna technology including pcr based molecular cloning, pcr based recombination techniques, nucleic acid recombinant dna technologies, analytical method development, next generation sequencing techniques, site directed mutagenesis, rna or protein synthesis, genetic engineering. the individual must have worked in the yeast or bacterial cloning, manipulating primary immortalized mammalian cell lines, genetic modification of cells and a wide range of cell based assays. the successful candidate must be adaptable, work well with people from a diverse interdisciplinary background, and able to multi task with excellent critical thinking with attention to detail and a track record of successful research contribution or significant industrial r d research experience will be an asset. areas of responsibility contribute to a wide range of product development projects, including establishing a nucleic acid based platform technology for regenerative medicine and vaccine applications, that support the existing proprietary nanoassemblr technology developed by precision nanosystems inc. contribute to establishing new techniques in house, perform routine iterative testing and supporting both internal projects and external collaborations responsible for designing and conducting experiments with input from the assigned supervisor design and perform experiments pertaining to recombinant dna technology to generate vector library. collect and analyze experimental data, present data at meetings, provide conclusions and outline future work plans troubleshoot experiments and identify abnormal or unexpected trends in data support all technical documentation related to projects and product development collaborate with internal teams to ensure successful project completion including providing support to contract research, r d, product development, manufacturing, and operations when required provide technical support to staff and customers as needed provide training on laboratory or product protocols to lab personnel as needed set up, calibrate and perform routine maintenance on specialized laboratory equipment ensure that the necessary laboratory supplies are available and perform tasks related to supporting the operation of the laboratory may be required to perform other related duties as needed or assigned qualifications and experience phd graduates in biochemical engineering, molecular biology, biochemistry, genetic engineering or biotechnology with recent postdoctoral training or experience in rna biology, rna biochemistry or recombinant dna technology considered. msc in the life sciences with recent 6 8 years of academic or industrial experience. knowledge of pharmacopeial guidance considered asset recent 3 years of hands on lab based experience in molecular biology laboratory focusing on mrna biology or mrna biochemistry significant experience in pcr based cloning and cell free nucleic acid synthesis is a considered asset experience working in pharma or biotech industry would be advantageous ability to independently design, conduct, analyze and troubleshoot experiments experience in developing dna based expression vectors for mrna and protein synthesis experience in working with both prokaryotic and eukaryotic cells experience with a wide range of laboratory techniques including pcr, qpcr, rt pcr, plasmid preparation, dna, rna protein gel electrophoresis, northern blotting, western blotting, elisa, chemical transfection, electroporation, expression vector library construction etc. experience in working with nucleic acids , recombinant dna technology, and nucleic acid purification methods sound knowledge of genetic epigenetic mechanism of prokaryotic and or or eukaryotic gene expression experience with bioinformatic software tools as well as statistical analyses of experimental data is an asset an understanding and interest in the use of nanoparticle technology for non viral gene delivery would be an asset excellent communication skills both in one on one and in a group setting with the ability to organize and present technical summaries of scientific data the individual must be a team player who thrives in a dynamic environment with multiple tasks and aggressive deadlines proven ability to apply critical and analytical thinking must be a resourceful, proactive, detail oriented individual who is able to work with minimum supervision project management skills will be considered as an asset. pni provides a competitive compensation and benefits package with excellent opportunities for personal growth. only candidates selected for an interview will be contacted. posting valid until filled. no solicitors please. precision nanosystems, inc. is an equal opportunity employer.","['clinical', 'experimental', 'software', 'testing', 'technical documentation', 'summaries', 'medicine', 'routine maintenance', 'translation']",['r'],"['clinical', 'software tools', 'data support', 'testing', 'technical support', 'routine', 'technical documentation', 'summaries', 'http', 'medicine', 'translation']","['purification', 'reagents', 'sequencing', 'environment', 'biotechnology', 'contract research', 'project management', 'vectors', 'nuclei', 'mrna', 'rna', 'biochemical engineering', 'protein synthesis', 'yeast', 'commercializationparle', 'pcr', 'microfluidics', 'biology', 'research', 'materials', 'cell', 'molecularr', 'biochemistry', 'design', 'life sciences', 'product development projects', 'dna', 'construction', 'drug development', 'product development', 'genetic engineeringr', 'gene', 'genetic engineering', 'compensation', 'nucleic', 'pcrr', 'molecular', 'manufacturing', 'r']"
480,664,Principal Data Infrastructure Engineer,"recursion is a clinical stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science and engineering to radically improve the lives of patients and industrialize drug discovery. our team is working to solve some of the hardest, most meaningful problems facing human health today. come join us in our mission to decode biology to radically improve lives, while doing the most impactful work of your life. recursion recently announced its intention to launch its first major multidisciplinary expansion beyond its utah headquarters, with plans to hire up to 50 people in toronto by the end of 2021. the impact you ll make create a world class research platform. you ll work across teams and functions with software engineers, data scientists, ml engineers, biologists, and automation scientists in building a platform for generating and storing petabytes of data, iterating quickly on novel analyses, and rapidly prototyping new deep learning models. build, scale, and operate a data platform . you ll be on a team responsible for building, operating, and tuning a data platform that allows users to discover and query across the breadth of our data at recursion, which includes a chemistry library of 3 billion compounds, nearly 8 pb of cellular microscopy images taken in 10s of millions of different experimental contexts involving 1 million different reagents, sparse bioassay data across approximately 50 drug discovery programs, and more. build relatability into a heterogeneous dataset. at recursion, we generate datasets based on a wide swath of diverse biological models and treatment approaches. you ll work with data scientists to build relatability and queryability into these datasets so they can be used in five years to answer the sorts of questions we haven t even thought of asking yet. act as a mentor, coach, and sponsor. you will share your technical knowledge and experiences, delivering impact, learning, and growth across teams at recursion. the team you ll join you will lead a new team as they plan and implement a data platform that solves the problem of making our diverse data discoverable, queryable, and relatable across datasets while we continue to add new data modalities as we grow. this will require collaboration with many different groups including teams building out reports, dashboards, and applications, teams finding and generating the required data for the machine learning problems, and teams building and iterating on new data processing pipelines. as an early leader in the new toronto office you will have an important impact by shaping how new technical teams embrace the recursion values as they deliver challenging data platform problems while effectively collaborating across physical locations, business domains, and technical functions. the experience you ll need experience working on data platforms that enable the discovery, query, and processing of large datasets. be up to date on industry trends and tools. you understand the tradeoffs between different data platform architectures and technologies like a data lake, a data warehouse, a data lakehouse, or a data mesh, and can draw on this knowledge to lead the design of the data infrastructure for recursion. experience working collaboratively on projects with significant ambiguity and technical complexity, ideally spanning multiple systems and involving diverse technologies. a people first mindset. despite the deadlines, we always prioritize supporting our coworkers in their growth and experience. a drive to deliver technical solutions that are easily monitored and understood as they run in production and the effects of change can be readily quantified. excitement to learn parts of our tech stack that you might not already know. our current tech stack includes python, clojure, kafka, docker, kubernetes, postgresql, javascript, clojurescript, and go. our cloud services are provided by google cloud platform. biology or chemistry background is not necessary, but intellectual curiosity is a must the benefits or perks you ll enjoy 100 coverage of health, vision, and dental insurance premiums 401 with generous matching stock option, restricted stock unit and employee stock purchase plan programs two one week paid company closures flexible vacation or sick leave generous paid parental leave onsite daycare facility commuter benefit and vehicle parking to ease your commute complimentary chef prepared lunches and well stocked snack bars monthly fitness or wellness stipend one of a kind 100,000 square foot headquarters complete with a 70 foot climbing wall, showers, lockers, and bike parking subject to change for remote based employees during the covid 19 pandemic united states based employees more about us recursion is a clinical stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science, and engineering, with the goal of radically improving the lives of patients and industrializing drug discovery. central to our mission is the recursion operating system, or recursion os, that combines an advanced infrastructure layer to generate what we believe is one of the world s largest and fastest growing proprietary biological and chemical datasets and the recursion map, a suite of custom software, algorithms, and machine learning tools that we use to explore foundational biology unconstrained by human bias and navigate to new biological insights which may accelerate our programs. we are a biotechnology company scaling more like a technology company. recursion is proudly headquartered in salt lake city. learn more at , or connect on twitter and linkedin . recursion is an equal opportunity employer that values diversity and inclusion. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected under applicable federal, state, local, or provincial human rights legislation.","['go', 'data infrastructure', 'dashboards', 'decoding', 'map', 'kubernetes', 'python', 'data processing', 'postgresql', 'software', 'clojure', 'data science', 'javascriptoj', 'pipelines', 'machine learning', 'google cloud platform', 'algorithms', 'automation', 'cloud services', 'deep learning', 'prototyping', 'datasets', 'chemistry']","['go', 'kubernetes', 'python', 'postgresql', 'clojure', 'pipelines', 'javascriptojures', 'map']","['deep learning', 'modalities', 'prototyping', 'machine learning', 'data processing', 'software', 'datasets', 'data infrastructure', 'dashboards', 'chemistry', 'data science', 'decoding', 'algorithms', 'automation', 'cloud services']","['human rights', 'linkedin', 'biology', 'biotechnology', 'design', 'rents', 'legislation', 'drug discovery', 'insurance', 'microscopy']"
481,671,Employment Equity INVENTORY - Aquatic Biologist/Physical Scientist & Team Leader Opportunities @ DFO,"fisheries and oceans canada aquatic ecosystems dartmouth bi 03, bi 04, pc 03, pc 04 bi 03 salary range 81,359 to 104,748 bi 04 salary range 100,920 to 119,915 pc 03 salary range 88,533 to 105,353 pc 04 salary range 102,577 to 120,520 for further information on the organization, please visit fisheries and oceans canada read about fisheries and oceans canada s mandate and role, departmental priorities and commitments, and the key legislation that supports our work. learn more about the aquatic ecosystems branch understanding the job advertisement video how to navigate the application process closing date 13 october 2021 23 59, pacific time who can apply restricted to employment equity members as follows open to canadian citizens who are members of the following employment equity groups aboriginal persons, visible minorities, and persons with disabilities. apply online important messages what you need to know about applying to this inventory this inventory is open to individuals who self declare as a visible minority, a person with a disability, or an aboriginal person. therefore, only those applicants who indicate in their application that they are members of the requisite employment equity group will be considered. in order to self declare, please ensure to indicate this by checking off the appropriate box within the online application as part of the employment equity section. the term aboriginal is used within this job advertisement as it relates to the employment equity act and other legislative frameworks. the term indigenous is used, where feasible, in support of the united nations declaration on the rights of indigenous peoples. when you apply to this selection process, you are not applying for a specific job, but to an inventory for future vacancies. as positions become available, applicants who meet the qualifications may be contacted for further assessment. how to apply we are requesting that all job applications be submitted through the gc jobs system by clicking on the apply online link below. the benefit of applying online is that candidates are guided through a series of questions which helps them submit a complete application and therefore contains all of the information that hiring managers are looking for. work environment now is your chance to gain experience in the federal public service. here are some reasons to apply did you know that fisheries and oceans canada and the canadian coast guard have been recognized as top employers we ve been recognized as forbes canada s best employers and, one of canada s top employers for young people in 2017, 2018, 2019, and 2020 the workplace, the bedford institute of oceanography campus in dartmouth, offers free parking and bus accessibility . bio is next to shannon park s canada 150 trail and offers many workplace wellness initiatives. check out to learn more about our campus. additionally, we offer learning and training opportunities to support you in your current and future career competitive salaries and benefits, such as supplemental health insurance, dental care, and vacation allowances flexible work arrangements, volunteer days, and family related leave access to an employee assistance program to support you through all stages of your career an opportunity to serve canadians by helping to protect our aquatic resources come join dfo or ccg for the opportunity to be a part of something bigger have we sparked your interest apply today intent of the process please note this process has been designed to have two different job streams in one advertisement. there are merit criteria specific to each stream please review them carefully. stream 1 aquatic biologist or physical scientist salary range 81,359 to 105,353 stream 2 section head or team leader salary range 100,920 to 120,520 candidates will not be required to indicate in their application the stream for which they wish to be considered. candidates who meet the essential qualifications will automatically be considered for the streams in which they are found qualified. please note, the above two streams may be utilized for other positions with the same requirements. if no stream information is listed after a merit criterion, it will apply to both streams on this poster. two pools will be created as a result of this process the results achieved in the process will determine if the candidate is placed in the bi 03 or pc 03 pool only or both the bi 03 or pc 03 and bi 04 or pc 04 pools. candidates may be offered positions of various tenures , and will be required to meet conditions of employment depending on the position being staffed. as a result of the potential and possible use of this selection process, and subsequent pools which may be accessed by a variety of hiring managers across the region, we encourage all interested persons seeking these types of opportunities to apply. positions to be filled 1 information you must provide your r sum . a response to a text question addressing the following employment with the federal government interest in temporary opportunities in order to be considered, your application must clearly explain how you meet the following education for bi 03 or bi 04 positions graduation with a degree from a recognized post secondary institution in a natural, physical or applied science with specialization in a field relevant to the duties of the position. for pc 03 or pc 04 positions graduation with a degree from a recognized post secondary institution, with acceptable specialization in physics, geology, chemistry or some other science relevant to the position. degree equivalency required experience for all positions 1. experience working on projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species. 2. experience providing information and advice to management on topics or issues related to the management or conservation of natural resources. 3. experience assessing, synthesizing or analyzing information from a variety of sources on issues related to the management or conservation of natural resources. . additional required experience for bi 04 or pc 04 positions 1. experience collaborating with internal teams or external stakeholders, partners or clients . stakeholders, partners or clients may include federal, provincial and municipal departments and agencies, indigenous partners, private sector organizations, ngos, etc.. 2. experience leading complex projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species. complex is defined as two or more of the following characteristics high profile involving multiple stakeholders multi jurisdictional or multi disciplinary in nature involving third party interests requiring multiple consultations or having a significant impact 3. significant experience providing information and advice to senior management on topics or issues related to the management or conservation of natural resources. significant experience is understood to mean the depth and breadth of the experience normally associated with having performed a broad range of complex related activities. senior management means the director level and above. 4. experience in assigning and supervising the work of others. if you possess any of the following, your application must also clearly explain how you meet it education post graduate degree from a recognized university in a natural, physical or applied science with a specialization in a field relevant to the position. degree equivalency the following qualifications are specific to the work in one or more of our directorates or programs. note while these qualifications are not under the heading of essential qualifications, depending on the position being staffed, any of the following asset or other qualifications may be deemed as essential qualifications and only those candidates and persons with a priority or preference entitlement who possess those qualifications will be considered for that specific vacancy. asset or essential qualifications bi 03 or pc 03 experience supervising staff. experience planning and participating in public consultation process. experience in the process for listing or recovery of species under the species at risk act. experience implementing laws, regulations, policies or programs with respect to the fisheries act, oceans act, or species at risk act . experience establishing relationships, consulting, engaging, or negotiating with at least two of the following indigenous community, academic institution, government departments or organizations, public, industry or non governmental organization. experience in managing , regulating or assessing marine aquaculture. experience in the establishment, planning, or monitoring of protected areas. experience working with geographic information systems or other spatial data programs. asset qualifications bi 04 or pc 04 significant experience in human resources management . experience in evaluating the effects of human activity on the aquatic environment. experience in coordinating work teams including several representatives from various organizations. experience in collaborating with partner or stakeholder groups to carry out marine planning or conservation initiatives. experience managing financial resources . the following will be applied or assessed at a later date various language requirements information on language requirements key leadership competencies for more information about these competencies, please visit the following link or en or treasury board secretariat or services or professional development or key leadership competency profile or examples effective ineffective behaviours.html create vision and strategy mobilize people uphold integrity and respect collaborate with partners and stakeholders promote innovation and guide change achieve results abilities ability to communicate orally. ability to communicate in writing. other information the public service of canada is committed to building a skilled and diverse workforce that reflects the canadians we serve. we promote employment equity and encourage you to indicate if you belong to one of the designated groups when you apply. information on employment equity application or assessment process step 1 application when applying to this selection process, you will be asked if you have any of the experience listed above and must answer a screening questions demonstrating how you meet the qualifications . for some of the qualifications only a yes or no response is required at this time. step 2 job matching as positions become available, the hiring manager will establish the experience requirements a candidate would require for the particular role being staffed. upon identifying the requirements of the position, human resources will review your responses to the experience questions. should you indicate you have the experience factors the hiring manager is looking for, human resources will contact you to 1. confirm you are available and interested in the position 2. ask you to elaborate on how you meet the experience required . this communication will be sent to you using the gc jobs communication platform and or or as well to your e mail. please ensure that you check your e mail and gc jobs account frequently as there is often a deadline for your response. please note that we will have to consider that you are no longer interested in participating in the selection process and that you have withdrawn your candidacy should you not provide us with an up to date email address or respond to our communication. step 3 online interview you will be asked to complete a video interview using an online platform which will be recorded and made available to the hiring manager. the online interview is designed to assess your verbal communication skills and assess you against the key leadership competencies. please note you may be asked to complete an online interview before you ve been matched to a position. step 4 additional assessment depending on the position being staffed, the hiring manager may establish additional criteria that are essential qualifications which candidates must meet. these criteria may include additional abilities and or or knowledge factors for their vacancy. therefore, in addition to reference checks, a knowledge test or additional interview may be required. step 5 appointment if the hiring manager has determined that you meet the requirements for the position, you will receive an official notification from human resources. should you be selected for the position, the hiring manager will contact you directly. you will be required to meet any conditions of employment for the position, such as a valid security clearance which will be reflected in your employment letter of offer. assessment please note that your overall conduct and communications, including email correspondence, throughout the entire process may be used in the assessment of qualifications and competencies. you will be asked to provide proof of your education credentials. if you were educated outside of canada, you must have your certificates and or or diplomas assessed against canadian education standards. for more information please click on degree equivalency in the education section above. official languages persons are entitled to participate in the selection process in the official language of their choice. applicants are asked to indicate their preferred official language in their application. preference preference will be given to veterans and to canadian citizens, in that order, with the exception of a job located in nunavut, where nunavut inuit will be appointed first. information on the preference to veterans we thank all those who apply. only those selected for further consideration will be contacted.","['html', 'bi', 'physics', 'synthesizing', 'spatial data', 'information systems', 'chemistry', 'security', 'screening', 'streams', 'r']","['streams', 'bi', 'r']","['geology', 'html', 'spatial data', 'physics', 'information systems', 'chemistry', 'security', 'screening', 'planning']","['private sector', 'environment', 'education', 'regulations', 'human resources', 'human resources management', 'health insurance', 'consultations', 'consulting', 'government', 'assessment', 'legislation', 'hiring']"
482,672,Big Data Engineer,"cubert is the name and innovation is our game. as the creators behind fittrack we know what it takes to develop new consumer hardware products and mobile applications for e commerce or retail to a loyal customer base across the world. but we take no credit. cubert s success comes down to one factor good people. every person matters, so investing in hiring, developing and retaining sharp minds is our top priority. we keep our team close knit, sharp and agile, which gives us the flexibility to constantly adapt to every situation. why a smaller team means high impact, strong communication and adaptability as a unit. we are tied together by our values we strive to be the best in what we do we obsess over customer experience we challenge convention our foundation is built on trust we take ownership in everything we do we value learning and personal mastery so if you re tired of getting caught in red tape, or having the glass ceiling stop you from making magic, you ve come to the right place. welcome to cubert. role responsibilities use big data technologies to design and develop scalable and fault tolerant big data etl systems and data lakes in a non hadoop environment. providing leadership within enterprise data strategies and providing the framework of foundation big data analytics. engaging stakeholders to understand their objectives for big data and utilizing information gathered to plan the computing framework with data sources, analytical tools and data storage. evaluating and recommending new and emerging data management and storage technologies and standards. ensuring consistency between data management, enterprise storage and all other technical system components. create and maintain a corporate repository of all data architecture artifacts. adhere to agile principles and philosophies in fulfillment of the role. work as a cross functional team member in an agile setting to help complete and deliver the team commitments. what you bring to the table bachelor s degree in information technology, software engineering, computer science, or related field. 1 year of data architecture experience in big data with advanced understanding of data architecture concepts, patterns and standards. experience in designing and implementing big data lakes and etl ingestion facilities. strong understanding of relational data structures, theories, principles, and practices. experience with enterprise data management technologies, including database platforms, etl tools, and sql. experience with data modelling tools. experience on gcp data technologies, dataflow, bigquery, pubsub, google cloud storage, dataproc, cloud function. how we help you become successful flat hierarchy and co operative international working environment learning support per company policy health benefits with health spending accounts competitive compensation dog friendly office stocked kitchen with healthy snacks cubert inc. is an equal opportunity employer and encourages applications from qualified individuals. we thank all applicants for their interest however, only those selected for an interview will be contacted. if chosen to participate in the selection process, accommodations are available upon request. we will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicant s accessibility needs.","['computing', 'enterprise storage', 'big', 'google', 'information technology', 'cloud storage', 'data analytics', 'sql', 'gcp', 'software', 'enterprise', 'data', 'mobile applications', 'hardware', 'data structures', 'hadoop', 'computer science', 'data management', 'etl']","['sql', 'big data lakes', 'gcp', 'big', 'hadoop', 'data lakes', 'big data', 'hardware']","['computing', 'data analytics', 'enterprise data strategies', 'data structures', 'software', 'enterprise storage', 'information technology', 'enterprise', 'computer science', 'data', 'data management', 'mobile applications', 'data storage', 'cloud storage', 'etl']","['commerce', 'investing', 'customer base', 'environment', 'retail', 'design', 'customer experience', 'compensation', 'hiring', 'architecture']"
483,673,Cloud Solution Architect - Data,"microsoft is on a mission to empower every person and every organization on the planet to achieve more. our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. in doing so, we create life changing innovations that impact billions of lives around the world. you can help us to achieve our mission. microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of microsoft cloud solutions and support offerings. to this end, microsoft invests in a dedicated customer success team that will help microsoft customers successfully realize their business outcomes. azure is the most comprehensive, innovative and flexible cloud platform today and microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market. we are always learning. insatiably curious. we lean into uncertainty, take risks, and learn quickly from our mistakes. we build on each other s ideas because we are better together. we stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. together we make a difference. to learn more about microsoft s mission, please visit https or or careers.microsoft.com or mission culture check out all of our products at http or or or en us we are looking for a highly motivated and passionate data platform advanced analytics or artificial intelligence cloud solution architect to drive high priority customer initiatives on the microsoft azure platform in collaboration with customers and the microsoft field in enterprise accounts segment of our business. this is a customer facing role, owning overall technical relationship between customer and microsoft data, advanced analytics and artificial intelligence platform. you will own the data platform advanced analytics technical customer engagements including architectural design sessions, specific implementation projects and or or mvps. the ideal candidate will have experience in customer facing roles and success leading deep technical architecture discussions with senior customer executives, enterprise architects, it management and developers to drive data platform and advanced analytics solutions to productions. responsibilities key responsibilities include understand customers overall data estate, it and business priorities and success measures to design implementation architectures and solutions. apply technical knowledge to architect solutions that meet business and it needs, create data platform, analytics and ai roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment develop deep relationships with key customer it decision makers and relevant business decision makers , who drive long term cloud adoption within their company to enable them to be cloud advocates be a voice of customer to share insights and best practices, connect with engineering team to remove key blockers assess the customers knowledge of azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners. collaborate with other cloud solution architects and ms stakeholders in developing complex end to end enterprise solutions on microsoft cloud platforms. maintain technical skills and knowledge, keeping up to date with market trends and competitive insights collaborate and share with the technical community while educate customers on azure platform be an azure platform evangelist with customers, partners and external communities. qualifications knowledge and skills professional experience 5 years of success in consultative or complex technical sales and deployment data platform and analytics projects, architecture, design, implementation, and or or support of highly distributed applications required relationship building. proven track record of building deep technical relationships with senior it executives in large or highly strategic accounts. experience in managing various stakeholder relationships to get consensus on solution or projects. required good business acumen to quickly understand the customer s industry and business to have relevant discussions with business decision makers. problem solving. ability to solve customer problems through cloud technologies required collaboration and communication. acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. presentation skills with a high degree of comfort with both large and small audiences required technical enterprise scale technical experience with cloud and hybrid data and analytics architecture designs, database migrations, and technology management. required the technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in data platforms and analytics competitive landscape knowledge of cloud development platforms partners understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred breadth of technical experience and knowledge, with depth or subject matter expertise in two or more of the following data analytics and ai platform cloud solutions required sql including oss , azure sql nosql databases including oss , cosmos db big data including sql dw, snowflake, big query, redshift advanced analytics including azure data bricks, visualization tools as powerbi, tableau data governance data engineering data science machine learning including azure ml, ml server artificial intelligence including bot framework, cognitive services, cognitive search expertise in data estate workloads like hdinsight, hadoop, cloudera, spark, python education bachelor s degree in computer science, information technology, engineer, or related field preferred certification in one or more of the following technologies preferred cloud, mobile, database, big data, bi, data science, machine learning, artificial intelligence experience prior work experience in a consulting or architecture position within a software and or or services company such as amazon, vmware, google, ibm, oracle desired prior solution delivery experience in analytic and ai specialized solution providers microsoft is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. benefits or perks listed below may vary depending on the nature of your employment with microsoft and the country where you work.","['https', 'databases', 'visualization', 'architectural design', 'tableau', 'big', 'it management', 'information technology', 'microsoft azure', 'data analytics', 'sql', 'python', 'vmware', 'hybrid data', 'software', 'data science', 'analytics', 'data', 'data engineering', 'nosql', 'machine learning', 'artificial intelligence', 'azure', 'technology management', 'bi', 'maintainability', 'snowflake', 'technical', 'security', 'hadoop', 'scalability', 'computer science', 'uncertainty', 'cloud development', 'digital transformation', 'ai']","['https', 'microsoft data', 'sql', 'databases', 'python', 'vmware', 'tableau', 'bi', 'hadoop', 'big data', 'azure sql', 'snowflake', 'nosql', 'microsoft azure']","['visualization', 'architectural design', 'it management', 'information technology', 'data analytics', 'hybrid data', 'software', 'data science', 'analytics', 'data', 'data engineering', 'machine learning', 'artificial intelligence', 'http', 'technology management', 'maintainability', 'technical', 'security', 'scalability', 'computer science', 'uncertainty', 'cloud development', 'solution', 'digital transformation', 'ai']","['customer success', 'education', 'design', 'governance', 'consulting', 'engagements', 'adoption', 'technical sales', 'regulations', 'hiring', 'architecture']"
484,674,Data Engineer - AWS Product BI,"bachelor s degree in computer science or a related technical field, and solid years of relevant experience. strong grasp of sql and at least one scripting or programming language. 5 years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, etl or elt and reporting or analytic tools and environments, data structures and hands on sql coding. 3 years of large it project delivery for bi oriented projects. 3 years of working with very large data warehousing environment amazon is looking for an excellent data engineer to join the aws product bi team. this is your opportunity to be a core part of the team that has direct impact on the day to day decision making in the many aws product teams like ec2, s3 and iot. since early 2006, aws has provided companies of all sizes with an infrastructure platform in the cloud. aws is a high growth, fast moving division within amazon with a start up mentality where new and diverse challenges arise every day. on the aws product bi team you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class bi is critical to our success. to help build this growing team, you should be highly analytical and possess a strong passion for analytics and accountability, set high standards with a focus on superior business success. we take working hard, having fun, and making history seriously. aws sets the standard for functionality, cost, and performance for many cloud based services, but it s still early days for cloud computing, and there are boundless opportunities to continue to redefine the world of cloud computing come help us make history as a data engineer on this team, you will be a technical leader in our team, and own the technical architecture of our bi and data platforms. you will get the exciting opportunity to work on very large data sets in one of the world s largest and most complex data warehouse environments. you will work closely with the business and technical teams in analysis on many non standard and unique business problems and use creative problem solving to deliver actionable output. our team is serious about great design and redefining best practices with a cloud based approach to scalability and automation. a successful candidate will be a self starter, comfortable with ambiguity, with strong attention to detail, an ability to work in a fast paced and ever changing environment, and an ability to work effectively with cross functional teams. key responsibilities include designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions. building secure, available, scalable, stable, and cost effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices. working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs. designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions data warehousing, enterprise system data architecture, data design , data persistence technologies, data processing, data management, and data analysis. ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements reviewing and participating in testing of the data design, tool design, data extracts or transforms, networks and hardware selections about us inclusive team culture here at aws, we embrace our differences. we are committed to furthering our culture of inclusion. we have ten employee led affinity groups, reaching 40,000 employees in over 190 chapters globally. we have innovative benefit offerings, and host annual and ongoing learning experiences, including our conversations on race and ethnicity and amazecon conferences. amazon s culture of inclusion is reinforced within our 14 leadership principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. work or life balance our team puts a high value on work life balance. it isn t about how many hours you spend at home or at work it s about the flow you establish that brings energy to both parts of your life. we believe striking the right balance between your personal and professional life is critical to life long happiness and fulfillment. we offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. mentorship career growth our team is dedicated to supporting new members. we have a broad mix of experience levels and tenures, and we re building an environment that celebrates knowledge sharing and mentorship. our senior members enjoy one on one mentoring and thorough, but kind, code reviews. we care about your career growth and strive to assign projects based on what will help each team member develop into a better rounded engineer and enable them to take on more complex tasks in the future. experience in designing and delivering cross functional custom reporting solutions. experience with massively parallel processing databases redshift, teradata etc experience with distributed systems and nosql databases experience with big data technologies e.g. hadoop, hive, oozie, presto, hue, spark, scala and more excellent oral and written communication skills including the ability to communicate effectively with both technical and non technical stakeholders. proven ability to meet tight deadlines, multi task, and prioritize workload a work ethic based on a strong desire to exceed expectations. strong analytical skills amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. if contacted for an employment opportunity, please advise human resources if you require accommodation, including in order to apply for a position.","['analytical skills', 'databases', 'system performance', 'parallel processing', 'troubleshooting', 'big data', 'distributed systems', 'hive', 'sql', 'data processing', 'scala', 'reporting', 'scripting', 'data', 'programming', 'aws', 'analytics', 'cloud computing', 'data warehousing', 'nosql', 'teradata', 'iot', 'testing', 'business intelligence', 'data analysis', 'hardware', 'automation', 'data structures', 'bi', 'hadoop', 'technical', 'data solutions', 'scalability', 'system', 'computer science', 'modeling', 'data management', 'etl']","['sql', 'teradata', 'databases', 'scala', 'bi', 'iot', 'hadoop', 'programming', 'aws', 'business intelligence', 'big data', 'hardware', 'hive', 'nosql', 'system performance']","['analytical skills', 'parallel processing', 'troubleshooting', 'distributed systems', 'data processing', 'reporting', 'scripting', 'data', 'analytics', 'cloud computing', 'data warehousing', 'testing', 'data analysis', 'data storage', 'automation', 'planning', 'data structures', 'technical', 'data solutions', 'scalability', 'computer science', 'modeling', 'data management', 'etl']","['project delivery', 'environment', 'affinity', 'human resources', 'design', 'functionality', 'team culture', 'legislation', 'architecture', 'mentoring']"
485,675,Ingénieur de données / Data Engineer,"nous sommes la recherche d un ing nieur de donn es or data engineer pour rejoindre notre quipe de conseillers en analytique avanc et travailler sur des projets innovants avec nos clients. nos conseillers travaillent pour les plus grandes entreprises qu b coises sur des projets moyen ou long terme et chez nous hors de question de travailler en silo on partage nos projets, nos comp tences et notre savoir faire au quotidien. agiledss, c est quoi or qui agiledss est une entreprise de service conseil sp cialis e en analytique avanc . depuis 15 ans, nous accompagnons les grandes entreprises qu b coises tirer le meilleur parti de leurs donn es par le biais d une expertise de pointe en analytique avanc . ce poste est pour toi si tu as un minimum de 5 ann es d exp rience pertinente en big data forte exp rience de travail avec les syst mes de base de donn es dans le cloud comme google big query, snowflake, redshift ou quivalent une solide exp rience de travail de conception et d optimisation de pipelines de donn es sur de grands volumes de donn es structur es et semi structur es exp rience en mati re de d veloppement d entrep ts de donn es, de mod lisation et or ou d analyse de donn es exp rience pertinente avec les plateformes de sciences de donn es tel que azure databricks, spark, hortonworks, etc. maitrise du java, sql, scala et python bonne connaissance de la gestion des donn es, de l int gration des donn es et des techniques de d veloppement des bases de donn es exp rience des technologies de base de donn es fait preuve de rigueur et d objectivit dans son travail d analyse flexibilit dans la gestion de son quotidien et de ses relations professionnelles excellente capacit d identification et de r solution de probl mes bon communicateur, sachant travailler efficacement en quipe bonnes aptitudes au d veloppement de relations efficaces avec les fournisseurs et prestataires de services externes atout exp rience avec les langages de programmation et de gestion de base de donn es traditionnels, y compris sql, pl or sql, avec les langages de manipulation de donn es propres aux sciences des donn es tels que python et r. anglais fonctionnel demand mais les hard skills c est pas tout avant toute chose on cherche un nouveau coll gue qui va s panouir dans notre environnement si tu es une personne qui aime partager ses connaissances, qui pr ne le self management, qui est bienveillant, fun et gourmande, tu as de grandes chances de te plaire chez nous quoi tu peux t attendre dans ton r le participer, en collaboration avec les concepteurs, l laboration et la r alisation, des solutions de donn es corporatives coordonner la collecte, la formalisation et la documentation des besoins de l organisation en ce qui a trait aux solutions de donn es corporatives ou sectorielles mettre en uvre des r gles d affaires de traitement et de valorisation des donn es corporatives et sectorielles participer des activit s de nettoyage, de transformation, de conversion et de correction des donn es r aliser des tests durant la modification des applications, pour garantir l int grit op rationnelle des solutions de donn es participer la mise en production it rative des solutions, travailler avec des quipes des diff rentes unit s d affaires pour tablir et ex cuter les t ches n cessaires, selon un ordre bien tabli travailler en collaboration avec les autres professionnels ti et communiquer avec les diff rents partenaires afin de clarifier et bien comprendre leurs besoins participer la d finition des fonctions, services ou l ments techniques requis r aliser, documenter et valider les analyses demand es respecter les r gles fonctionnelles et techniques ainsi que les normes de conception et de livraison de solutions participer ou r aliser des essais diff rents niveaux de d tails, qu ils soient fonctionnels ou techniques en contexte de livraison et de mise en production, soutenir les partenaires lors des essais d acceptation participer l implantation des solutions retenues participer au plan d volution des applications et syst mes technologiques. ce qu on t offre nous sommes avant tout une quipe de collaborateurs taille humaine qui a c ur le bien tre de ses employ s, c est pourquoi nous t offrons une r mun ration annuelle fixe et une bonification annuelle selon l atteinte de ta performance des objectifs individuels accessibles et r alistes pour garantir un environnement sans pression des assurances collectives manuvie 4 semaines de vacances remboursement des abonnements de sport et du transport horaires flexibles et t l travail plan de d veloppement pour chaque employ et coaching avec un mentor environnement non hi rarchique favorisant l intrapreneuriat activit s mensuelles de team building abonnement au spa note ce poste d butera en t l travail pour s adapter au contexte de pand mie. il faut donc pr voir un retour progressif physique en fonction du d confinement. type d emploi temps plein, permanent salaire 90 000,00 115 000,00 par an horaire du lundi au vendredi repos la fin de semaine exp rience scala 3 ans databricks 1 an consultation 2 ans big data 3 ans spark 3 ans python 3 ans langue fran ais anglais","['sql', 'python', 'scala', 'snowflake', 'opt', 'c', 'documentation', 'big data', 'pipelines', 'java', 'r']","['sql', 'python', 'scala', 'snowflake', 'c', 'documentation', 'big data', 'pipelines', 'java', 'r']",['tests'],['team building']
486,677,"Research Scientist - HEOR, Evidence Synthesis","are you a self starter with a passion for projects involving innovative health economic concepts if you a natural doer who enjoys collaborating, moving the ball forward and rolling up your sleeves keep reading our culture is similar to that of a start up, but in a well funded established global portfolio organization. our team has a real passion and excitement for heor, priding ourselves on being leaders with vision in our field. we are growing and seeking those who are passionate about health economics and outcome research researchers who love the prospect of collaborating with a diverse team of scientists and who look to make a real difference. we hire throughout the year at varying levels of experience and offer these opportunities out of offices in us, vancouver bc and london. what you can expect day to day research scientists collaborate across a broad portfolio of sophisticated health economic and health policy research projects as a member of a project team and they understand how to create the data foundation needed to provide the statistical analysis framework for projects. in collaboration with the project lead, conduct statistical analysis and modeling procedures, and contribute to interpretation of the results from statistical procedures and models in order to address client s research questions. essential responsibilities include develops client ready deliverables in terms of protocols , statistical analysis plans , technical reports, and slides, identifying necessary deviations from templates to ensure content aligns with objectives develops content for components of proposals in collaboration with senior team members applies alternative methods in terms of systematic literature reviews, evidence synthesis, and or or cost effectiveness modeling according to best practices and identifies relevant limitations to project lead accountable for timely delivery and financial performance of project subcomponents estimates required hours and identifies challenges early on and communicates any changes and possible solutions to project lead if necessary drafts and reviews update slides or minutes and actions for overall study and viewed by client as independent researcher for specific study component communicates with client frequently on calls and supports project lead in responding to emails may also be involved in face to face presentations to clients breaks down complex project tasks or project subcomponents into manageable components and approaches them in logical and clear manner highlights resourcing constraints for project subcomponents to project or team lead and identifies tasks where support is needed from junior team members identifies new opportunities within existing projects or clients participates in, and occasionally leads group strategy discussions guides junior teams members leads publication independently to implement own ideas in a wide range of other project related and infrastructure activities such as recruiting experts for meetings, advisory groups, or panels contributing to or reviewing proposals assisting with problem solving researching potential solutions among others. qualifications required master s degree minimum of 1 years experience other required excellent oral and written communication skills ability to work effectively individually and as part of a diverse team proficiency with microsoft office desired master s degree with a concentration in economics, health services research, epidemiology, biostatistics, public policy, health policy, or public health or related ph.d. experience in conducting literature reviews. experience in conducting systematic reviews, scoping reviews, rapid reviews, or critical reviews experience conducting and interpreting statistical analyses experience writing scientific or review papers understanding of medical terminology and or or any disease specific expertise experience with statistical programs such as r, stata or sas any data provided as a part of this application will be stored in accordance with our privacy policy . precision medicine group is an equal opportunity employer. employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. 2020 precision medicine group, llc if you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact precision medicine group at .","['biostatistics', 'medicine', 'economics', 'sas', 'modeling', 'terminology', 'statistical analysis', 'epidemiology', 'technical reports', 'r']","['sas', 'r']","['biostatistics', 'medicine', 'cost effectiveness', 'economics', 'precision', 'modeling', 'terminology', 'statistical analysis', 'epidemiology', 'technical reports']","['health policy research projects', 'financial performance', 'public policy', 'health economics', 'literature reviews', 'public health', 'presentations', 'templates', 'microsoft office', 'health services', 'evidence', 'health policy', 'recruiting', 'precision', 'law']"
487,678,Data Engineer (Full Time Permanent Remote Work Opportunity),"your opportunity lixar, fueled by bdo canada, is looking for a dynamic and dedicated data engineer to join our remote canadian team. as a data engineer, you will be part of a team supporting and participating in the ongoing development of leading edge applications. the ideal candidate will be a senior developer who has a strong background in big data with a mix of general programming and some exposure to data visualization. as an experienced data engineer, you have post secondary education in engineering or computer science or equivalent work experience a proven track record using the apache hadoop ecosystem to tackle big data problems a master of all things sql 5 years of programming experience in python proven experience using restful web services json good experience using cloud based data solutions experience working with production systems knowledge of elt, elt, lambda and kappa data architectures preferably, you also have knowledge of continuous integration and source control systems experience with databricks some data visualization experience in power bi, tableau, or similar exposure to data science, machine learning or statistics some experience using docker how do we define success for your role you demonstrate bdo s core values through all aspect of your work integrity, respect and collaboration you understand your client s industry, challenges, and opportunities client describe you as positive, professional, and delivering high quality work you identify, recommend, and are focused on effective service delivery to your clients you share in an inclusive and engaging work environment that develops, retains attracts talent you actively participate in the adoption of digital tools and strategies to drive an innovative workplace you grow your expertise through learning and professional development. why bdo our firm is committed to providing an environment where you can be successful in the following ways we enable you to engage with the firm s strategic plan, and be a key contributor to the success and growth of the firm. we help you be the best professional you can be in our services, industries and markets. achieve your personal goals outside of the office and make an impact on your community. giving back, it adds up where company meets community. bdo is actively involved in our communities by supporting local charity initiatives. we support staff with local and national events where you will be given the opportunity to contribute to your community. total rewards that matter we pay for performance with competitive total cash compensation that recognizes and rewards your contribution. we provide flexible benefits from day one, and a market leading personal time off policy. we are committed to supporting your overall wellness beyond working hours, and provide reimbursement for wellness initiatives that fit your lifestyle. everyone counts we believe every employee should have the opportunity to participate and succeed. through leadership by our chief inclusion and diversity officer, we are committed to a workplace culture of respect, inclusion, and diversity. we recognize and celebrate the valuable differences among each of us, including race, religious beliefs, physical or mental disabilities, age, place of origin, marital status, family status, gender or gender identity and sexual orientation. if you require accommodation to complete the application process, please contact us. ready to make your mark at bdo click apply now to send your up to date resume to one of our talent acquisition specialists. to explore other opportunities at bdo, check out our careers page. li mm1","['tableau', 'data visualization', 'big data', 'apache', 'sql', 'python', 'statistics', 'json', 'data science', 'programming', 'integration', 'machine learning', 'general', 'web services', 'production systems', 'bi', 'hadoop', 'data solutions', 'computer science']","['sql', 'python', 'tableau', 'bi', 'hadoop', 'json', 'general', 'programming', 'big data', 'apache', 'control systems']","['machine learning', 'statistics', 'continuous', 'data visualization', 'production', 'data solutions', 'data science', 'computer science', 'web services', 'integration']","['environment', 'events', 'education', 'service delivery', 'adoption', 'compensation', 'talent acquisition']"
488,679,"Manager, Data Science - Research & Analytics TORONTO, ONSOFTWARE","who we are tonal is the smartest home gym and personal trainer. it has completely revolutionized the way people work out at home, with its sleek design and advanced a.i. technology. we ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging. with this in mind, we want to bring that same innovative approach to the workplace. at tonal, we continue our shift of emphasis by growing our instrumental team. we collectively weave our knowledge and creativity, as we redefine the future of fitness. we are passionate about building products that transform lives, and building teams that transform the status quo. together, we can be our strongest. what you will do lead a team of passionate data scientists focused on understanding members habits, driving new advanced features in a data driven manner, and creating member facing metrics to track their progress and motivate them. review the team s designs, algorithms, and code while also spending time developing your own lead the initiative to fully leverage the world s best and largest fitness dataset to derive insights about member s habits and motivations work closely and collaborate with a cross functional team of product manager, designers, and engineers to drive new, innovative, data driven functionality create metrics to motivate members and track their progress analyze member behavior and engagement to inform feature roadmap and marketing drive direction of tonal s architecture, data collection, analytics, infrastructure, tools, and learning systems identify innovative opportunities for new data driven features who you are advanced degree in engineering, scientific, or mathematical field 5 years data science experience 2 years leading and or or managing technical teams knowledge of machine learning, probability, and statistics strong knowledge of python and sql strong data visualization ability and desire to explain complicated concepts simply team player with high integrity open to feedback and constantly striving to learn and improve high degree of self awareness extra credit knowledge of snowflake, dbt, looker, and amplitude tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. should you have any accommodation requests, please reach out to us via our confidential email, all requests will be addressed and responded to in accordance with tonal s accessibility policy and local legislation.","['sql', 'python', 'machine learning', 'statistics', 'looker', 'data visualization', 'data science', 'data collection', 'analytics', 'probability', 'integration', 'algorithms', 'snowflake']","['sql', 'python', 'snowflake', 'looker']","['machine learning', 'statistics', 'learning systems', 'data visualization', 'data science', 'data collection', 'analytics', 'probability', 'integration', 'algorithms']","['metrics', 'marketing', 'design', 'functionality', 'dbt', 'legislation', 'architecture']"
489,680,CT Data Engineer,"ey is a global leader in assurance, tax, transaction and advisory services. technology is at the heart of what we do and deliver at ey. technology solutions are integrated in the client services we deliver and are key to our innovation as an organization. fueled by strategic investment in technology and innovation, client technology seeks to drive growth opportunities and solve complex business problems for our clients through building a robust platform for business and powerful product engine that are vital to innovation at scale. as part of client technology, you ll work with technologists and business experts, blending ey s deep industry knowledge and innovative ideas with our platforms, capabilities, and technical expertise. as a catalyst for change and growth, you ll be at the forefront of integrating emerging technologies from ai to data analytics into every corner of what we do at ey. that means more growth for you, exciting learning opportunities, career choices, and the chance to make a real impact. the project this open role is for an integrated data platform that allows different service lines to perform various data management activities including onboard data, perform data ingestion, data processing, mapping to centralized taxonomy and then consume data for their respective product offering needs to support their clients. there is also potential to collaborate on additional platforms and offerings within the client technology group. the selected candidate leads the delivery of processes to extract, transform and load data from disparate sources into a form that is consumable by analytics processes, for projects with moderate complexity, using strong technical capabilities designs, develops and produces data models of relatively high complexity, leveraging a sound understanding of data modelling standards to ensure high quality builds networks with other departments across the business to help define and deliver business value, and may interface and communicate with program teams, management and stakeholders as required to deliver small to medium sized projects applies advanced big data concepts to ingest, process and transform data and store data in variety storage technologies applies graph and ai or ml to data and data components supporting business requirements your key responsibilities include leading the production of high quality data engineering deliverables, helping to ensure project timelines are met, and providing informal mentoring or training to junior members of the team leading the delivery of data quality reviews including data cleansing where required to ensure integrity and quality leading the delivery of data models, data storage models and data migration to manage data within the organization, for a small to medium sized project resolving escalated design and implementation issues with moderate to high complexity analyzing the latest industry trends such as cloud computing and distributed processing and beginning to infer risks and benefits of their use in business providing technical expertise to maximize value from current applications, solutions, infrastructure and emerging technologies and seek to continuously improve internal processes developing working relationships with peers across other engineering teams and beginning to collaborate to develop leading data engineering solutions driving adherence to the relevant data engineering and data modelling processes, procedures and standards skills and attributes for success batch and event processing capability to design an efficient way of processing high volumes of data where a group of transactions is collected over a period of time or on an event driven method data integration capability to design and implement models, capabilities and solutions to manage data within the enterprise . this includes the data models, storage requirements and migration of data from one system to another data quality, profiling and cleansing capability to review a data set to establish its quality against a defined set of parameters and to highlight data where corrective action is required to remediate the data data services experience building data services with asynchronous calls to data sources. using functional and reactive programming features in modern java and open source libraries intermediate understanding of the following tools and technologies, and how to apply them to solve business problems essential experience with spring boot, spring cloud, kafka, eventhub good knowledge of docker or containers and event driven architectures expertise with azure functions, azure key vault integration, azure blob storage configurations hands on experience with azure databricks, delta lake, azure functions, azure data factory hands on experience in developing ai or ml algorithms to detect data anomalies and patterns using python, r and similar technologies expertise with graph databases azure cosmos or gremlin, neo4j, spark graphframes expertise in nosql databases cosmosdb, mongodb expertise in index, search and exploration using elastic hands on experience with programming languages java, node.js, python, r, sql, xml relational smp databases azure sql paas, postgresql, synapse nice to have apigee, aks azure cognitive services, databricks mlflow is a big plus elasticsearch, kibana education b.s. in actuarial, behavior economics, computer science, data analytics, data science, econometrics, engineering, it, cyber security, or related field preferred what we look for strong analytical skills and problem solving ability a self starter, independent thinker, curious and creative person with ambition and passion excellent inter personal, communication, collaboration, and presentation skills customer focused excellent time management skills positive and constructive minded takes responsibility for continuous self learning takes the lead and makes decisions in critical times and tough circumstances attention to detail high levels of integrity and honesty what working at ey offers we offer a competitive remuneration package where you ll be rewarded for your individual and team performance. our comprehensive total rewards package includes support for flexible working and career development, and with flexey you can select benefits that suit your needs, covering holidays, health and well being, insurance, savings and a wide range of discounts, offers and promotions. plus, we offer support, coaching and feedback from some of the most engaging colleagues around opportunities to develop new skills and progress your career the freedom and flexibility to handle your role in a way that s right for you ey is committed to being an inclusive employer and we are happy to consider flexible working arrangements. we strive to achieve the right balance for our people, enabling us to deliver excellent client service whilst allowing you to build your career without sacrificing your personal priorities. about ey as a global leader in assurance, tax, transaction and advisory services, we re using the finance products, expertise and systems we ve developed to build a better working world. that starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. whenever you join, however long you stay, the exceptional ey experience lasts a lifetime. if you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. make your mark. apply now.","['analytical skills', 'databases', 'data services', 'cleansing', 'big data', 'mongodb', 'paas', 'java', 'xml', 'data analytics', 'forefront', 'python', 'sql', 'data processing', 'postgresql', 'kibana', 'elasticsearch', 'data science', 'analytics', 'data', 'integration', 'programming', 'data models', 'data engineering', 'cloud computing', 'r', 'nosql', 'econometrics', 'spring cloud', 'spring boot', 'data migration', 'vault', 'data quality', 'graph', 'algorithms', 'azure', 'programming languages', 'economics', 'security', 'neo4j', 'technology solutions', 'computer science', 'data management', 'ai']","['databases', 'gremlin', 'big data', 'paas', 'java', 'sql', 'forefront', 'python', 'azure databricks lake', 'postgresql', 'kibana', 'elasticsearch', 'programming', 'data models', 'nosql', 'spring cloud', 'spring boot', 'aks', 'data quality', 'programming languages', 'neo4j', 'technology solutions', 'azure data factory', 'azure functions', 'ml', 'azure sql', 'xml', 'r']","['analytical skills', 'data services', 'cleansing', 'mongodb', 'distributed', 'data analytics', 'data processing', 'data science', 'analytics', 'data', 'integration', 'data engineering', 'cloud computing', 'econometrics', 'data ingestion', 'data migration', 'event processing', 'vault', 'graph', 'data storage', 'algorithms', 'economics', 'security', 'computer science', 'data management', 'ai']","['taxonomy', 'smp', 'education', 'team performance', 'business value', 'design', 'client services', 'finance', 'service lines', 'insurance', 'mentoring']"
490,681,2-2021DA - Data Engineer,"data engineer if you know python, perl, or tcl you ve probably heard of activestate s language distros. now we re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it this position is available to remote workers anywhere in the world, as long as you are able to work on a schedule that aligns with our north american business hours. you can also choose to work from our headquarters in beautiful vancouver, bc once the health situation makes this possible. this position is open to experienced candidates with a track record in this area. we re building up our data warehouse and analysis skills, and we re looking for someone who knows how to analyze, recommend, deploy, and use tools and techniques to help us get the most out of our data what you ll be doing as a data engineer, you ll help foster informed decision making and innovation within activestate by making our data understandable, actionable, and available in the relevant contexts. you ll be a part of our tools and infrastructure team, and will work closely with our in house data analyst and with most of our other teams from time to time, both inside and outside of engineering. your primary work will include designing, building, and managing etl and warehousing pipelines, including recommending tools, technologies, and practices for us to adopt. improving data accessibility within activestate by developing and training other developers in the use of monitoring, analysis, and visualization tools and techniques. ensuring data is managed in compliance with our in house policies. managing and designing the data and reporting environment, including data sources, tooling, security, and metadata. designing, building, deploying, and managing tools and processes to help colleagues understand data. testing and documenting your work. you ll work with others on the following tasks using code and data visualization tools to collect, validate, normalize, collate, analyze, interpret and present data. some of this work will be ad hoc, while some will be routine and automated. analyzing and optimizing data models, queries, and access patterns. building processes and systems to monitor data quality, ensuring that production data is accurate. updating our data collection and analysis policies. our team is mostly scattered around the us and canada, so we coordinate with each other and the rest of the company using slack for chat, zoom for video calls and screen sharing, asana for task management, and google drive. we like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. we embrace open sourcing both libraries and tools developed in house as long as those are not mission critical code. what s in it for you working for a stable and growing company that offers the environment and personal growth potential of a start up. the chance to work with a smart, passionate team of people. competitive salary and bonus plan. comprehensive benefits package and health or wellness credit program. requirements demonstrated experience with etl and data management technologies demonstrated ability to develop, customize, deploy, and maintain and develop business intelligence software. practical experience working with and enhancing data warehouses or data lakes. experience creating and optimizing data models. demonstrated ability to perform, validate and document both ad hoc and automated data analysis and reporting. ability to apply statistical methods to data sets is a plus. curiosity, an analytical mind, and strong problem solving skills. excellent written and spoken communication skills, both technical and non technical, including the ability to make data and analysis understandable and relevant to a diverse set of audiences. assets if you have experience with any of the following please make sure to highlight it in your cover letter data processing, messaging, and workflow technologies such as kafka, map or reduce, hadoop, hive, prestodb, luigi, airflow, storm, argo etc. analyzing marketing and sales data google data studio postgresql aws or data engineering in cloud environments kubernetes experience working with a wide variety of different data sets using one or more of the common data analysis languages , r, matlab, etc. as well as spreadsheets and visualization tools open source projects and culture agile processes, including breaking large projects up into smaller stories, estimation, working in branches , code review, and ci. go, perl, python, tcl, and ruby working at activestate activestate has a collaborative, respectful, and professional culture. we re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. there is a commitment from the ceo on down to making work at activestate a great experience for all. our company is a team of 55 and growing, with 2 or 3rds of the positions in technical roles including software development and qa. we maintain a set of core, overlapping hours, but we re flexible with specific start and end times and are understanding about appointments and life events. our vision is to have an activestate solution on every device on every planet, so we certainly don t lack for ambition but even though we re ambitious we don t expect work to become your life. we know you will do your best work in a positive environment free from death marches. for more about working at activestate and our glassdoor rating go to or careers. how to apply please submit your contact info, resume, and a cover letter below. submissions without a cover letter will not be considered. we look forward to hearing from you we are committed to creating a welcoming environment for everyone at activestate and we welcome applicants from all walks of life. even if you don t feel you meet every exact requirement, we still would love to hear from you and why you think you would be an awesome addition to our team and we encourage you to apply.","['go', 'visualization', 'ci', 'data visualization', 'google', 'hive', 'code review', 'map', 'kubernetes', 'ruby', 'python', 'data processing', 'postgresql', 'software', 'reporting', 'software development', 'perl', 'aws', 'data models', 'pipelines', 'data engineering', 'testing', 'sourcing', 'data collection', 'metadata', 'business intelligence', 'data analysis', 'data quality', 'rest', 'matlab', 'airflow', 'tcl', 'hadoop', 'security', 'zoom', 'spreadsheets', 'data management', 'etl', 'r']","['go', 'data lakes', 'hive', 'map', 'kubernetes', 'ruby', 'python', 'postgresql', 'perl', 'aws', 'data models', 'pipelines', 'google drive', 'business intelligence', 'google data studio', 'data quality', 'matlab', 'airflow', 'asana', 'hadoop', 'zoom', 'spreadsheets', 'r']","['visualization', 'data processing', 'software', 'reporting', 'testing', 'data engineering', 'security', 'data visualization', 'data collection', 'sourcing', 'ci', 'metadata', 'software development', 'data management', 'data analysis', 'rest', 'code review', 'etl']","['environment', 'events', 'task management', 'marketing', 'sales']"
491,682,Senior Optical Engineer or Optical Scientist,"senior optical engineer or optical scientist about metamaterial inc. meta delivers previously unachievable performance, across a range of applications, by inventing, designing, developing, and manufacturing sustainable, highly functional materials. our extensive technology platform enables leading global brands to deliver breakthrough products to their customers in consumer electronics, 5g communications, health and wellness, aerospace, automotive, and clean energy. meta s achievements have been widely recognized, including being named a global cleantech 100 company. learn more at about the role we are seeking a senior optical engineer or optical scientist for our facility in dartmouth, nova scotia. you will be a key member of the optics team that develops new technologies and products for applications in augmented reality and scientific instruments. your role will be to develop concepts and hardware for prototyping and manufacturing new optical devices based on holographic elements. you will be working hands on within a diverse, multi disciplinary team to develop holographic optical elements for high performance imaging systems. the ideal candidate has extensive experience developing new concepts for optical systems matched with the practical skills to bring them to life. responsibilities provide expert level optical engineering expertise towards the development of holographic optical components and sub systems for hmd, hud and scientific instrument applications. lead hands on assembly, testing and debugging of custom hardware systems for development and manufacturing. work with internal and external stakeholders to develop product concepts and designs that address market needs. characterize the performance of optical products relative to the design goals design and construct the necessary metrology systems. identify causal relationships between observed product performance and the design parameters. monitor and communicate to the team industry development and trends. communicate results through technical reports and presentations tailored to the needs of the target stakeholders. supervise junior members of the engineering team. required skills and experience hands on experience implementing and testing optical devices and systems, particularly holographic devices. extensive experience constructing and validating models of optical devices and sub systems. experience in process control, data acquisition, and data analysis in python or matlab, r or julia. proficiency with optical design tools and modelling methods . excellent written, verbal and presentation skills. qualifications an msc or phd in physics, applied physics, optics, ee, or related field, is required. minimum 5 years of experience with optical engineering and or or applied optics, with industrial experience developing products based on new technologies. professional standards and performance review as an experienced professional, the senior optical engineer or optical scientist will maintain high professional standards and act in accordance with best practice. they will support the development of the professional standards of the team and take a continuous approach to improvement and their own personal development. as a representative of the company, the chemistry laboratory manager will act in line with the company code of conduct and will participate in the performance review process.","['automotive', 'python', 'prototyping', 'augmented reality', 'data acquisition', 'testing', 'physics', 'performance', 'chemistry', 'data analysis', 'debugging', 'new concepts', 'hardware', 'process control', 'electronics', 'technical reports', 'matlab', 'r']","['python', 'augmented reality', '5g', 'debugging', 'hardware', 'electronics', 'matlab', 'r']","['automotive', 'prototyping', 'applied', 'data acquisition', 'performance review', 'testing', 'physics', 'chemistry', 'data analysis', 'design tools', 'technical reports']","['metrology', 'process control', 'design', 'presentations', 'materials', 'optics', 'optical', 'scientific', 'manufacturing', 'aerospace']"
492,685,Big Data Engineer 9+Yr Exp Canadian Citizen or PR,"position or title bigdata engineer location brampton rate or hr client cognizant bigdata specializing in software products services and technology developing features using serverless technologies like aws lambda, glue, emr developing big data pipeline using aws technologies like kinesis, sqs, sns and so on development of batch and real time processing jobs using apache spark and java or python development of complex features using bigdata technologies which includes doing impact analysis, design, and development. work effectively in a fast paced and dynamic environment communicate effectively with all stakeholders must have bigdata application or data pipeline development experience using pyspark and following aws technologies lambda, api gateway, glue, emr, ecs, kinesis, sqs, sns, rds, dynamodb, cognito, redshift experience in databricks language core java or python tools maven, git os linux good to have bigdata skills hadoop, kafka, apache spark , hive, sql, hbase or cassandra, kubernetes, redshift regards, sayyad ashraf parvez email ashrafatcompestsolutions.com d 647 660 7562 ext 412 web site reference id 210010 job types contract, permanent salary 80,031.00 100,000.00 per year schedule 8 hour shift work remotely yes","['linux', 'emr', 'pyspark', 'big data', 'maven', 'hive', 'java', 'glue', 'sql', 'python', 'kubernetes', 'software', 'aws', 'apache spark', 'cassandra', 'hadoop', 'api', 'git', 'ecs']","['linux', 'emr', 'pyspark', 'sns', 'big data', 'rds', 'maven', 'hive', 'java', 'glue', 'sql', 'python', 'kubernetes', 'aws', 'hbase', 'apache spark', 'cassandra', 'hadoop', 'api', 'git', 'ecs']",['software'],"['environment', 'hr', 'design']"
493,686,Data Analytics Consultant - Contractor,"data analytics consultant contractor customer 360 analytics the telus business marketing team is looking for a talented, driven, passionate individual with strong analytical and interpersonal skills. our team telus business solutions marketing bi has a mandate to build solutions for our stakeholders using data from various sources, building algorithms that can predict customer loyalty, churn and stickiness. we love to turn data into stories stories about money falling through the cracks, success stories about our products and services, but most importantly stories about our customers and how we can enhance their experience. we run like a start up and we have embraced lean and agile methodologies. we celebrate our failures and see them as opportunities to learn. our culture fosters collaborative learning and out of the box thinking in a relaxed environment. come help us to make something awesome candidates are able to communicate with business stakeholders, gather requirements, develop, design and implement reporting solutions in an agile type environment. they must be able to shift effortlessly between business conversations about performance analytics and technical conversations around databases, sql and domo with their stakeholders and peers. a successful candidate has strong business analysis, problem solving and critical thinking skills. candidates must be comfortable working within a dynamic, cross functional environment and be able to explain complex concepts, performance reporting methodologies, and analysis results to a diverse stakeholder community. you must be willing to roll up your sleeves and get close to the data. here s the impact you ll make and what we ll accomplish together you will be successful because you have an optimal mix of business and technical skills honed in a high performance driven business. you would be working with data scientists, engineers and analysts to help build trigger based b2b campaigns to target the right customer at the right time with the right product. you have a passion for growing our business, the courage to innovate and embrace change in our business intelligence capabilities and embody the spirited teamwork necessary to support stakeholders across a wide variety of teams. here s how you will develop new analytical solutions to provide timely insights to the business assemble multiple data sources across various databases to build foundational c360 data marts build repeatable processes and automation to create standardized datasets, reports and analysis implement business intelligence and rules, optimize data processes and perform data quality audits proactively work with business stakeholders, manage relationships and lead marketing programs from a data standpoint effectively communicate with leadership and stakeholders lead customer 360 programs, coach and mentor junior team members you are the missing piece of the puzzle if you love digging into quantitative and qualitative data you analyze it, pivot it and distill issues to their core to provide the best possible performance reports and channel insights you have expert knowledge and understanding of global best practices in business intelligence tools you have advanced working sql knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases you are recognized for your curiosity and growth mindset you see the bigger picture of the problem you are trying to solve, and will proactively out new data points from varied sources to complement your analysis you have excellent attention to detail, a structured approach to analysis and the ability to develop logical arguments you have minimum 4 7 years of experience in a similar role and or or related education with demonstrated performance great to haves prior telecommunications expertise python experience hive, spark, nifi experience b2b marketing experience with cloud experience with the salesforce tech, i.e., marketing cloud, pardot, einstein data science or modeling experience or working in a data science team contract would be until 31st dec 2021,with a high possibility of extension. other locations alberta, british columbia, quebec","['databases', 'business analysis', 'hive', 'data analytics', 'sql', 'python', 'reporting', 'data science', 'analytics', 'data marts', 'relational databases', 'business intelligence', 'qualitative data', 'data quality', 'algorithms', 'automation', 'agile methodologies', 'performance reporting', 'bi', 'datasets', 'modeling', 'telecommunications']","['sql', 'python', 'databases', 'bi', 'hive', 'pardot', 'business intelligence', 'data quality', 'domo', 'telecommunications']","['agile methodologies', 'data analytics', 'performance reporting', 'business analysis', 'relational databases', 'reporting', 'datasets', 'performance', 'data science', 'analytics', 'data marts', 'modeling', 'qualitative data', 'algorithms', 'automation']","['environment', 'education', 'marketing', 'design', 'business', 'campaigns']"
494,687,Senior Data Analyst,"what does it mean to work at esg we are east side games a pillar in beautiful vancouver s gaming community. our mission is to create games that are easy to pick up, hard to put down, and don t suck we put players at the heart of our evolution, independence, and profitability. with their help, we ve defined the narrative idle gaming space with huge brands that reach the lives of millions globally... and we re just getting started culture rules here, and that s what makes us unique. we put people at the core of what we do. we believe that you can steer the ship of your career, and we anchor through support, trust, and connection. tackle your challenges, share your learnings, then share a drink with the studio in our weekly cheers friday announcements. have we piqued your curiosity then check out our amazing culture and benefits what impact can a lead data scientist have at esg at east side games, we all band together to deliver a world class gameplay experience for our players around the globe. whether that s working on archer danger phone, or on any of our other current or upcoming titles, you re committed to making memorable player experiences. everyone has an impact here. as a senior data analyst, you create actionable insights from the data we collect that directly leads to product improvements within our idlekit team. through a deep understanding of our player s behaviour, you ll work on building dashboards, reports, and predictive models that ultimately lead to a world class game experience our players cherish. what is idlekit idlekit is east side games core technology platform that enables our internal games and external partnership games. the idlekit team operates as an independent business unit that productizes our platform and actively publishes new games under the east side games brand. we re a remote first studio and encourage all applications. what you might do in your day to day formulate hypotheses and run a variety of a or b tests to determine the best strategies to implement into our products. work with external partner studios to create balance changes and features that will improve target metrics. evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data. be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data. build partnerships with each team member, sharing the tools and insights that predict and improve retention and monetization within our products. continuously improve, maintain, and develop our analytics tools and predictive models for our games. what you bring to esg a bachelor s degree in mathematics, statistics, computer science, economics, or a related quantitative field and or or a graduate degree in data science or business analytics. at least four years prior experience as a data analyst or scientist, preferably in the f2p mobile gaming space. expert level knowledge of sql , tableau , and proficiency with at least one scripting language . ambition to own and take ownership of the reporting and analysis functions for our games. the ability to tell a convincing story with data. an innate curiosity and ability to mine large complex data sets and build predictive models that lead to meaningful conclusions. previous experience a or b testing and calculating statistical significance within a big data context . strong written and oral communication skills. prior management experience is a huge plus. you are hungry, humble, and smart and can use these three pillars to impact you and those around you. a mobile game fanatic. you are on top of the latest games, trends, and what s happening in live events. entrepreneurial, self motivated, and have the attitude to get things done. a risk taker, and gain your biggest learnings through them. empathic, compassionate, and curious. solution oriented and data driven. comfortable in an environment where priorities and plans can change rapidly. we re built on the foundations of diversity and inclusion east side games are an equitable employer that values justice, equity, diversity and inclusion. we welcome and encourage people of marginalized backgrounds, particularly qtbipoc folks, to apply, and will acknowledge and value the strengths you bring to foster yours and the studio s growth. if this sounds like something you hoped for and more, and you re enthused to build genre defining narrative idle games, click the apply here button below. if now is not the right time for you but you know someone who would be a great match for us at east side games, check out our referral bonus here let s build great games together we can t wait to hear from you okaddf8gps","['sql', 'statistics', 'tableau', 'economics', 'scripting', 'reporting', 'dashboards', 'data science', 'testing', 'computer science', 'analytics', 'mathematics', 'gameplay', 'big data', 'business', 'gaming']","['sql', 'big data', 'gameplay', 'tableau']","['esg', 'statistics', 'tests', 'economics', 'scripting', 'reporting', 'dashboards', 'data science', 'testing', 'computer science', 'analytics', 'mathematics', 'business', 'gaming']","['environment', 'game', 'events', 'metrics', 'design', 'f2p']"
495,689,ARCHITECTE DE SOLUTION BIG DATA,"ctc006039 architecte de solution big data location montreal, quebec field solutions architect position type contract starting july 5, 2021 ending july 1, 2022 resources required 1 position description duration 12 months mandate with possibility of permanence. bilingualism required . rate open remote 100 remote. an eventual presence on site will be considered. it is recommended to live in montreal or its surroundings. about the role do you have a strong background in big data and would like to leverage it by designing innovative and groundbreaking solutions do you want to influence the bank s it strategies and directions do you want to put your expertise to work building the digital bank of tomorrow the it advanced analytics ecosystem team is looking for a big data solutions architect to join a project at the heart of our data strategy. we need someone who is creative in designing analytical solutions, able to deliver real results while meeting commitments, and able to collaborate happily and efficiently in multidisciplinary teams. working on an architecture team means being at the center of the bank s transformation and playing a key role in designing secure, forward thinking solutions. more details on responsibilities in collaboration with domain architecture, development teams and operations, design and implement complex megadata solutions. define the megadata and analytics strategy using relevant technologies and analytics industry trends. lead the implementation of the defined strategy in the design and architecture of the client analytics platform components using cloud infrastructures as well as several software components required by data scientists. lead the design of reference architecture models for structured and unstructured data integration define technical evaluation criteria for product and technology selection and to determine preferred technical approaches for successful solutions within a coherent system design. participate in and execute proof of concept exercises for the adoption of new megadata management technologies, software engineering tools, and models within existing structures. use influence to recommend methods for improving data reliability, efficiency and quality. monitor the implementation of solutions through to delivery ensuring compliance with established architectures . what you offer completed bachelor s degree, related to the industry, and 10 years of relevant experience or completed master s degree, related to the industry and 7 years of relevant experience experience and knowledge of azure, aws cloud. experience building architectures related to data security, firewalls, encryption, identity and access management , networking, compliance and data protection hands on experience with several megadata tools experience designing data pipelines and automating megadata platform applications or services using python, pyspark, sql and javascript and automating them using devops processes and tools experience with git, ansible, terraform, jenkins in mission critical production environments desirable. excellent knowledge of container management practice and tools . excellent knowledge of architecture design, data modeling, and implementation of megadata platform architectures and analytics applications. knowledge and experience with advanced analytics capabilities, including machine learning using supervised and unsupervised techniques","['unstructured data', 'pyspark', 'jenkins', 'firewalls', 'encryption', 'big data', 'javascript', 'terraform', 'sql', 'python', 'software', 'analytics', 'data', 'integration', 'aws', 'machine learning', 'data pipelines', 'proof of concept', 'ansible', 'devops', 'security', 'git', 'networking', 'modeling']","['terraform', 'sql', 'python', 'pyspark', 'jenkins', 'git', 'data', 'big data', 'aws', 'javascript', 'ansible', 'identity and']","['unstructured data', 'access management', 'machine learning', 'data pipelines', 'proof of concept', 'software', 'devops', 'security', 'firewalls', 'container management', 'networking', 'analytics', 'encryption', 'integration', 'data', 'modeling', 'it strategies', 'reference']","['adoption', 'design', 'architecture']"
496,720,"Senior Applied Scientist, Alexa Speech","master s degree in electrical engineering, computer sciences, or mathematics with specialization in speech recognition, natural language processing, image processing, or machine learning. 5 years relevant industry experience experience with programming languages such as c or c , python, java or perl. amazon is looking for a passionate, talented, and inventive scientist with a strong machine learning background to help build industry leading speech and language technology. our mission is to push the envelope in automatic speech recognition , natural language understanding , and audio signal processing, in order to provide the best possible experience for our customers. as a scientist, you will work with talented peers to develop novel algorithms and modeling techniques to advance the state of the art in spoken language understanding. your work will directly impact our customers in the form of products and services that make use of speech and language technology. you will leverage amazon s heterogeneous data sources and large scale computing resources to accelerate advances in spoken language understanding. we are hiring in all areas of spoken language understanding asr, nlu, text to speech , and dialog management. position responsibilities participate in the design, development, evaluation, deployment and updating of data driven models and analytical solutions for machine learning and or or natural language applications. develop and or or apply statistical modeling techniques , optimization methods, and other ml techniques to different applications in business and engineering. routinely build and deploy ml models on available data. research and implement novel ml and statistical approaches to add value to the business. mentor junior engineers and scientists. phd in relevant fields 3 years relevant industry experience experience in building speech recognition and natural language processing systems solid machine learning background and familiar with standard speech and machine learning techniques. proficient in neural network and or or deep learning are pluses. scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field solid software development experience good written and spoken communication skills. to learn more about the digital products team at amazon, visithttp or or or careers or digitalproducts and apply now. amazon is committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act. if contacted for an employment opportunity, please advise human resources if you require accommodation.","['computing', 'c', 'java', 'python', 'image processing', 'software development', 'perl', 'electrical engineering', 'machine learning', 'speech recognition', 'audio', 'statistical', 'algorithms', 'deep learning', 'language processing', 'signal processing', 'programming languages', 'mathematics', 'optimization', 'modeling']","['python', 'programming languages', 'c', 'perl', 'java']","['deep learning', 'computing', 'electrical engineering', 'language processing', 'machine learning', 'speech', 'image processing', 'speech recognition', 'language understanding', 'software development', 'natural', 'mathematics', 'audio signal processing', 'statistical', 'modeling', 'language applications', 'optimization', 'algorithms']","['human resources', 'hiring', 'art', 'design']"
497,721,"Cloud Data Architect, Omnia AI","job type permanent primary location toronto, ontario, canada all available locations toronto calgary montreal vancouver learn from deep subject matter experts through mentoring and on the job coaching partner with clients to solve their most complex problems be empowered to lead and have impact with clients, our communities and in the office. you love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter if that is you, then omnia ai is where you want to be. what will your typical day look like as a cloud data architect on our data analytics modernization team within the omnia ai practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. you will play an active role throughout the entire engagement cycle, specializing in modern data solutions including data ingestion or data pipeline frameworks, data warehouse data lake architectures, cognitive computing and cloud services. you are enthusiastic about all things data, have strong problem solving and analytical skills, are tech savvy and have a solid understanding of software development. specifically, in this role, you will lead, define, design and implement end to end modern data platforms in support of analytics and ai use cases collaborate with enterprise architects, data architects, etl developers engineers, data scientists and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities address aspects such as data privacy security, data ingestion processing, data storage compute, analytical operational consumption, data modeling, data virtualization, self service data preparation analytics, ai enablement, and api integrations define and develop solution architectures, lead development teams, estimate effort and mentor junior colleagues lead technical meetings with client staff, and advise client with technical option analyses based on leading practices about the team omnia ai, deloitte s artificial intelligence practice is comprised of a collaborative team of experts who use their hands on experience with cutting edge information assets to facilitate successful ai transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. our data analytics modernization team helps clients design and implement the data platform architectures be it in the cloud or on premise required to enable cutting edge ai solutions. you will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on big data, bi or dw, data integration, data governance, master data and analytics applications. each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. enough about us, let s talk about you you are someone with 5 years experience leading engagements from design to implementation of creative data solutions leveraging the latest in big data frameworks, supporting on premise, cloud and hybrid architectures to enable use cases in analytics and ai 5 years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non traditional sources such as structured, unstructured, and semi structured using sql, nosql and data pipelines for real time, streaming, batch and on demand workloads 3 years experience with analytics or data management strategy formulation, architectural blueprinting, business case development and effort estimation of disruptor based analytics ability to simplify complex technical concepts into easy to understand non technical language in order to facilitate, communicate and interact with executives and business stakeholders, working with agile development methods in data oriented projects completed bachelor s degree in quantitative areas such as computer science, information management, big data analytics, or related field is desired certifications in architecture , data engineering and development on aws, azure, gcp and or or hadoop distributions are an asset. if you believe you have what it takes to be a successful member of our team, please apply now. we know your career is important to you and it s important to us, too. this role is just the first step of a highly successful career we can help you build. the time is right for you to join deloitte. get your career off to great start. what impact will you make why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally.","['computing', 'analytical skills', 'big', 'master', 'data analytics', 'sql', 'gcp', 'software development', 'data', 'analytics', 'integration', 'aws', 'pipelines', 'data engineering', 'nosql', 'modernization', 'data preparation', 'data pipelines', 'data privacy', 'metadata', 'artificial intelligence', 'information management', 'cloud services', 'data structures', 'bi', 'hadoop', 'data solutions', 'security', 'api', 'computer science', 'technology solutions', 'virtualization', 'modeling', 'data management', 'enablement', 'etl', 'ai']","['sql', 'gcp', 'bi', 'big', 'hadoop', 'api', 'technology solutions', 'big data', 'aws', 'pipelines', 'master data', 'nosql']","['computing', 'analytical skills', 'data ingestion processing', 'blueprinting', 'effort estimation', 'data analytics', 'software development', 'analytics', 'data', 'integration', 'data engineering', 'modernization', 'data preparation', 'data pipelines', 'data ingestion', 'data privacy', 'metadata', 'artificial intelligence', 'agile development', 'data storage', 'information management', 'cloud services', 'use cases', 'data structures', 'data solutions', 'security', 'computer science', 'virtualization', 'modeling', 'data management', 'enablement', 'etl', 'ai']","['subject matter experts', 'design', 'governance', 'engagements', 'business case development', 'architecture', 'mentoring']"
498,722,"Senior Data Analyst, Global Investments","why join us are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor if so, we would love to tell you our story. at omers we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in toronto, london, new york, singapore, sydney and other major cities across north america and europe. our culture is truly one of a kind. we get stuff done, and have fun doing it we take great pride in contributing to the communities where we live with an ever constant eye to the global investment markets. the senior data analyst, global investments technology will join a team that leads the delivery of the products and platforms that enable omers global investments to analyze opportunities, action investment decisions and optimize the omers investment portfolio. git works across investment teams including capital markets, infrastructure, private equity, growth equity and ventures, and in close collaboration with finance, risk compliance teams. as a key member of the global investments technology team, the senior data analyst is instrumental in enhancing data analytics capabilities by championing industry best practices and delivering high quality datasets, reports, and training to enhance business decision making. the senior data analyst will develop power bi datasets and reports to support omers investment entities, maintain a healthy business relationship to assist in meeting business demands and deliver training workshops to promote a data culture. the senior data analyst will also support and collaborate with data engineers, data scientists and investment professionals and engage in technical support, research and knowledge sharing through the implementation as part of 1 or more product team. as a member of this team, you will be responsible for technical organizing workshops with partners to gather requirements and develop low or high fidelity wireframes developing and monitoring power bi premium dataflows to gather, transform and democratize structured and unstructured data assets developing power bi datasets by applying best practice semantic modeling techniques building visually stunning reports that clearly communicate an effective story leading solution build, delivery, support and troubleshooting provisioning and managing resources of premium capacity managing the power bi or power platform infrastructure usage monitoring and auditing organizational operating in an agile development environment communicating effectively with analysts and various partners across multiple teams and with various other partners such as product managers, data engineers and members of senior management managing change and communicating impacts to partners and fellow team members facilitating collaboration and sharing through best practices of delivering and sharing content identifying, defining and implementing opportunities for improving existing processes exhibiting the ability to work on multiple projects simultaneously and ensuring timely delivery leading the power bi community of interest to review the latest features and updates collaborating with other teams and establishing power platform governance and support to succeed in this role, you have professional experience . 5 years solving complex technical projects as a full stack power bi developer a bachelor s degree in a scientific or engineering field of study or equivalent work experience microsoft certification data analyst associate industry knowledge of best practices learned from mvp product team articles and investments or finance. training . excited to support new power bi users by running various internal community initiatives such as presentations, hands on workshops, or troubleshooting end user obstacles. demonstrated success building deep technical relationships and aligning expectations across various partners. problem solving. the ability to trace data lineage and resolve technical issues with minimal direction. teamwork . motivated and keen to work in a collaborative environment with a focus on team success. technical a depth of power bi experience wrangling complex data using m functions and developing sophisticated semantic logic using dax expressions connect or transform. knows what m is, how to merge, append, and perform more advanced ui transforms model. basic knowledge of dimension or fact tables and can identify them in a dimensional model. comfortable with simple dax, knows the calculate function well and can explain how it works. visualization. recommends appropriate visualizations to answer business questions and references examples of published materials that explain how to choose a visual. proficient at all ways to manipulate look feel. admin or architecture . has experience configuring administrative features in the tenant. knows how to install and manage a gateway. basic levels of understanding of licensing. embed or custom visuals . understand that power bi can be embedded internally and knows how to add and share in teams. breadth of technical experience and knowledge in the msft data and analytics ecosystem, with subject matter expertise in two or more of the following items power bi service administration power bi desktop tabular editor and dax studio azure synapse analytics azure data factory azure machine learning azure databricks our story founded in 1962, omers is one of canada s largest defined benefit pension plans, with 105 billion in net assets as at december 31, 2020. omers is a jointly sponsored pension plan, with 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. omers members include union and non union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children s aid societies across ontario. contributions to the plan are funded equally by members and employers. omers teams work in toronto, london, new york, amsterdam, luxembourg, singapore, sydney and other major cities across north america and europe serving members and employers and originating and managing a diversified portfolio of high quality investments in public markets, private equity, infrastructure and real estate. omers is committed to having a workforce that reflects the communities in which we live and work. we are an equal opportunity employer committed to a barrier free recruitment and selection process. at omers inclusion and diversity means belonging. how we create a sense of belonging is through our employees and our vast network of employee resource groups. whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","['unstructured data', 'administration', 'data analytics', 'visualization', 'machine learning', 'provisioning', 'semantic', 'auditing', 'bi', 'datasets', 'dax', 'git', 'troubleshooting', 'mvp', 'analytics', 'modeling']","['mvp', 'bi', 'provisioning', 'git']","['unstructured data', 'data analytics', 'visualization', 'machine learning', 'semantic', 'auditing', 'data lineage', 'datasets', 'dax', 'service administration', 'technical support', 'troubleshooting', 'analytics', 'agile development', 'modeling']","['utilities', 'environment', 'risk compliance', 'presentations', 'finance', 'electrical', 'materials', 'licensing', 'real estate', 'governance', 'employee resource groups', 'capital markets', 'workshops', 'investments', 'private equity', 'public', 'architecture']"
499,723,Senior Java/Data Engineer (Backend/Middleware) (VP),"citi s innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to citi s capital markets, securities services and banking lines of businesses. our mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurial spirit. we are looking for a senior data engineer with experience in developing data pipelines to join our team, part of the citi s innovation lab, working on a trade surveillance platform used across multiple businesses within our institutional clients group. as a senior data engineer on our team, you will be responsible for designing, building and integrating data pipelines. the trade surveillance platform will be looking at running various models at scale on large data sets to identify and act upon possible market abuse in the market. you will work with our stakeholders and data consumers to ensure we are meeting their requirements. you will contribute to the team s strategy around security, development, testing, and deployment best practices. this is an exciting opportunity to work on a mission critical project, take a leading role in evolving our platform, and be a difference maker at citi. job background or context we believe the future s here. right here with us. home to where we define, ideate, develop and distribute production ready financial solutions of far reaching impact. and right now, the door s open to direct the future of our technology for a truly global client base. this means collaborating with the keenest minds in data science, big data, software engineering, web development, ux design and more. doers looking to bring the next bold ideas to life for a fascinating array of clients investing, trading and transacting at the forefront of change in markets and economies the world over. if you have this kind of vision, capable of seeing ahead, of developing a clear path forward in a quest to try the as yet untried, here is the opportunity. in a supported, resource rich, vibrant co working environment, part of an ecosystem of globally interconnected labs, realizing a broader mission of enabling growth and economic progress on a scale you won t find anywhere else. key responsibilities working closely with a global team building large distributed data centric applications in the trade surveillance and compliance space. designing and building message and data processing or streaming services to enable seamless integration with multiple business systems. on boarding of new data streams from external systems. working closely with data scientists to ensure data is of the highest quality and is available when needed. act as data pipeline subject matter expert to the global application team as well as other internal and external stakeholders. building close relationships with clients and stakeholders to understand the use cases for the platform and prioritising work accordingly. working well in a multidisciplinary devops focused team and building close relationships with engineers, data scientists, business analysts, and production support teams. holds themselves accountable for ensuring high quality results and acts as a mentor and coach to other team members. skills qualifications you have experience driving the technical direction on data intensive projects. you will have specific examples of times that you have delivered value to business by getting applications into production. designed systems from scratch that can scale with large volumes of data. you have expertise in multiple programming languages and building data pipelines, ideally using spark and java. you have expertise working with message or event streaming services, ideally using kafka or solace. you have experience working with both relational and non relational databases, ideally oracle, mongo and elastic search you understand the full spectrum of the data processing and integration ecosystem, including testing strategies. you have experience working in a devops culture and are comfortable working with ci or cd tools ideally, you have experience working in virtualized environment, as well as container orchestration services such as kubernetes or openshift. you have experience in systems observability including monitoring and health patterns and the tools to ensure the highest production stability. you have high development standards, especially for code quality, code reviews, unit testing, continuous integration and deployment. you have proven capability to interact with clients and deliver results from ideation to production. you have experience working in fast paced development environments. you agree that verbal and written communication skills are vital. citi canada is an equal opportunity employer. accordingly, we will make accommodations to respond to the needs of people with disabilities during the recruitment process and otherwise in accordance with law. individuals who view themselves as aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. job family group technology job family applications development time type citi is an equal opportunity and affirmative action employer. qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. citigroup inc. and its subsidiaries invite all qualified interested applicants to apply for career opportunities. if you are a person with a disability and need a reasonable accommodation to use our search tools and or or apply for a career opportunity review accessibility at citi. view the eeo is the law poster. view the eeo is the law supplement. view the eeo policy statement. view the pay transparency posting","['openshift', 'business systems', 'technical direction', 'ci', 'big data', 'java', 'kubernetes', 'forefront', 'data processing', 'cd', 'software', 'data science', 'integration', 'data pipelines', 'relational databases', 'testing', 'streams', 'unit', 'ux', 'banking', 'securities', 'programming languages', 'devops', 'security', 'web development']","['kubernetes', 'forefront', 'openshift', 'programming languages', 'big data', 'streams', 'java']","['business systems', 'technical direction', 'production support', 'ci', 'container orchestration', 'data processing', 'cd', 'software', 'data science', 'integration', 'unit testing', 'data pipelines', 'relational databases', 'continuous', 'testing', 'ux', 'use cases', 'banking', 'securities', 'devops', 'security', 'web development']","['environment', 'investing', 'and compliance', 'surveillance', 'trading', 'design', 'team building', 'capital markets', 'law']"
500,724,"Manager, Data Science - Machine Learning TORONTO, ONSOFTWARE","who we are tonal is the smartest home gym and personal trainer. it has completely revolutionized the way people work out at home, with its sleek design and advanced a.i. technology. we ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging. with this in mind, we want to bring that same innovative approach to the workplace. at tonal, we continue our shift of emphasis by growing our instrumental team. we collectively weave our knowledge and creativity, as we redefine the future of fitness. we are passionate about building products that transform lives, and building teams that transform the status quo. together, we can be our strongest. what you will do lead a team of passionate data scientists focused on modeling members fitness performance and providing weight recommendations develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more. review the team s designs, algorithms, and code while also spending time developing your own lead the initiative to fully leverage the world s largest and best fitness data set collaborate closely with fitness experts on training methodologies. validate and innovate on new more effective training methodologies using a data driven approach work closely and collaborate with front end and back end teams to take the team s work to production drive the direction of tonal s architecture, data collection, analytics, infrastructure, tools, and learning systems leverage your creativity to identify innovative opportunities for new data driven features who you are advanced degree in engineering, scientific, or mathematical field 5 years data science experience 2 years leading and or or managing technical teams knowledge of machine learning and signal processing algorithms working experience with data filtering and cleansing techniques strong knowledge of python and sql working knowledge of software development, including restful apis team player with high integrity open to feedback and constantly striving to learn and improve high degree of self awareness tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. should you have any accommodation requests, please reach out to us via our confidential email, all requests will be addressed and responded to in accordance with tonal s accessibility policy and local legislation.","['sql', 'python', 'machine learning', 'signal processing', 'computer vision', 'data collection', 'data science', 'software development', 'analytics', 'cleansing', 'integration', 'modeling', 'working experience', 'algorithms']","['sql', 'python']","['machine learning', 'signal processing', 'learning systems', 'computer vision', 'data collection', 'data science', 'software development', 'analytics', 'cleansing', 'integration', 'modeling', 'working experience', 'algorithms']","['legislation', 'design', 'architecture']"
501,725,Product Development Confectionary Scientist,"at cronos group, we hire talented people who thrive on solving difficult problems and give them the opportunity to hone new skills and approaches. if you want to play a part in shaping an innovative industry and help build a historically significant company, we want to meet you. if you are an experienced confectionary scientist with a strong work ethic, enjoy collaborative multi disciplinary projects and are a motivated self starter, then this is the job for you as the confectionary scientist you will be leading the development and commercialization of new confectionary products and enhancing existing products. you will work closely with key interdisciplinary stakeholders to drive products forward from concept to implementation. there is a key emphasis on administrative and organizational skills while managing and administrating multidisciplinary projects to take confectionary product concepts from benchtop r d to commercialization. the ideal candidate is energetic, collaborative, and forward thinking. this position is based out of stayner, ontario canada. what you ll be doing lead the development of cannabis edible products including product formulations, specifications, packaging, stability, nutritional fact calculations and critical production parameters. taking ownership for the development and commercialization of new and enhancement of existing products that meet regulatory, quality, operational, sales, marketing, and financial expectations. familiar with regulatory requirements of confectionary and edible products in the cannabis act and canadian food inspection agency requirements ensuring that products comply with government regulations and certification requirements. maintain r d workspace and r d equipment for the development and design of confectionary and chocolate products. designing experiments and leading formulation design, recipe development and standardization of final formulation specifications. collaborate with operations for manufacturing equipment selections, technical transfer of production manufacturing, and final product quality and integrity ensuring critical control parameters and product attributes are successfully transferred to the operations teams. ensure inventory traceability and administrative documentation of all cannabis product being used for product development activities collect, organize and interpret data from experiments, prepare reports and present results work with procurement and quality teams to select qualify suppliers and draft raw material specifications. collaborate with innovation and finance team to help develop costings of product and assist in business case development. track and report on industry trends and competitor intelligence track and develop subject matter expertise regarding economic, regulatory, and marketing issues and trends including monitoring new product filings and other product development related publications. work with consumer insights and marketing teams to discovery new opportunities and define technically feasible products to meet novel consumer needs and existing market gaps. you ll need to have post secondary education in food science, science, engineering, culinary or related field. a minimum of 5 years in food product development or cannabis edible product development experience with all types of confectionary manufacturing processes we are committed to fostering a diverse and inclusive work environment, and we welcome and encourage applications from people with disabilities and people with diverse backgrounds, identities, and cultures. for candidates with disabilities, accommodations are available upon request in all phases of the selection process.","['calculations', 'specifications', 'documentation', 'r']","['documentation', 'r']","['calculations', 'specifications']","['environment', 'manufacturing', 'procurement', 'education', 'material', 'business case development', 'regulatory requirements', 'marketing', 'commercialization', 'marketing filing', 'design', 'finance', 'product quality', 'product development', 'government', 'sales', 'food science', 'regulations', 'inspection']"
502,726,Software Development/Engineering Manager - Data Science,"description requirements description data science is a crucial part of ukg. our team builds statistical and machine learning models that support product features across the company, with the goal of empowering thousands of organizations and millions of employees to thrive. we tackle problems in the fields of machine learning, natural language processing, document processing, sociology, and statistics... and we re just getting started. we re looking for a software engineering manager to join the team and help it grow. you will lead a team of data scientists and software engineers. the team is distributed, working across multiple time zones, in an agile environment with daily stand ups and regular releases. this position requires excellent technical, tactical, and strategic leadership, along with a strong ability to communicate both within the team, and across the organization. as part of the team, you will support and grow a team of highly motivated people. focus on data driven processes that lead to continuous improvement for the team. support the professional, technical, and personal growth of a diverse group of people, with a wide range of experiences. collaborate with the team to set the product and technical roadmaps, along with the plans for achieving them. work with your peers to help support and drive cultural changes across the organization. qualifications previous engineering leadership experience, preferably with a data science team university degree in computer science, statistics, mathematics, preferably at the graduate level or equivalent experience. passionate about people, processes, and technologies and with the ability to use that passion to inspire and motivate others. strong outcome based work ethic with a sense of ownership, urgency, and drive and an unwavering commitment to do the right thing. proven leadership in facilitating complex discussions to achieve goals and solve problems. an understanding of the importance of being data driven, and the value that kpis can bring to continuous improvement and innovation. a technical background in software engineering, data engineering, or data science. ability to build and maintain productive relationships with a diverse array of stakeholders and groups throughout the organization. experience in lean agile development processes such as kanban or scrum. experience working in an enterprise scale saas production environment. corporate overview here at ukg, our purpose is people. ukg combines the strength and innovation of ultimate software and kronos, uniting two award winning, employee centered cultures. our employees are an extraordinary group of talented, energetic, and innovative people who care about more than just work. we strive to create a culture of belonging and an employee experience that empowers our people. ukg has more than 13,000 employees around the globe and is known for its inclusive workplace culture. ready to be inspired learn more at or careers eeo statement equal opportunity employer ultimate kronos group is proud to be an equal opportunity employer and is committed to maintaining a diverse and inclusive work environment. all qualified applicants will receive considerations for employment without regard to race, color, religion, sex, age, disability, marital status, familial status, sexual orientation, pregnancy, genetic information, gender identity, gender expression, national origin, ancestry, citizenship status, veteran status, and any other legally protected status under federal, state, or local anti discrimination laws.","['agile environment', 'machine learning', 'statistics', 'kanban', 'language processing processing', 'kronos', 'software', 'scrum', 'data science', 'computer science', 'saas', 'mathematics', 'data engineering', 'engineering']","['kronos', 'kos']","['agile environment', 'language processing', 'machine learning', 'statistics', 'document', 'kanban', 'software', 'scrum', 'data science', 'computer science', 'natural', 'mathematics', 'agile development', 'saas', 'data engineering', 'engineering']","['environment', 'continuous improvement']"
503,727,Solution Architect (Big Data) - Canada,"wavicle data solutions designs and delivers data and analytics solutions to reduce time, cost, and risk of companies data projects, improving the quality of their analytics and decisions now and into the future . as a privately held consulting service organization with popular, name brand clients across multiple industries, wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions. our 250 local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost effective, right fit solutions leveraging our team s deep business acumen and knowledge of cutting edge data and analytics technology and frameworks. at wavicle, you ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. employees appreciate being part of something meaningful at wavicle. wavicle has been recognized by industry leaders as follows chicago tribune s top workplaces inc 500 fastest growing private companies in the us crain s fast 50 fastest growing companies in the chicago area talend expert partner recognition microsoft gold data platform competency about the role we are looking for a solution architect who will perform mission critical duties in our data engineering strategy, contributing to and leading the development of our enterprise data and analytics platforms. a passionate professional who can blend the ever evolving technology landscape of cloud and advanced analytics with the complex and high impact space of e commerce and direct sales. the solution architect will be responsible for leading a team of talented engineers to develop and maintain the foundation of next generation data platforms. this role will be responsible for expanding, optimizing, and monitoring our expanding data pipelines through meticulous architecting, intelligent business logic, consistent data governance, testing and continuous delivery. responsibilities lead and provide advanced data engineering expertise for projects that enable analytics to drive optimization of decisions for client, within a team of engineers. design new methods and processes to ensure maximum effectiveness of client data. partner with data analysts or scientists to provide solutions enabling statistical analysis tools and data visualization applications. identify processes and tools that can be shifted towards automation to enable seamless development and self service analytics workloads. partner with various business units and data stewards to understand the business needs. obtain and or or maintain technical expertise of available data manipulation and preparation tools as well as programming languages ensure data is secure, relevant, and maintains high quality standards. identify and implement industry best practices. evaluate new data sets to determine appropriate ingestion techniques. build, manage and optimize data pipelines through a variety of etl tools, including custom infrastructure and 3rd party tooling . work with internal engineering teams and vendors to understand business logic to ensure veracity in datasets. generate documentation on existing production data logic and its influencing business processes in order to reconcile knowledge gaps between the business, engineering, and data collection. requirements 8 10 years of experience in delivering data engineering solutions that include batch and streaming capabilities. 5 years of strategic or management consulting experience is highly preferred. experience building, testing, automating and optimizing data pipelines. experience using aws, databricks, snowflake or similar products. strong understanding and prior use of sql and be highly proficient in the workings of data technologies . deep understanding of data testing techniques, and a proven record of driving sustainable change to the software development practice to improve quality and performance. proficiency with data querying languages , programming languages . expertise selecting context appropriate data modeling techniques, including kimball dimensional modeling, slowly changing dimensions, snowflake, and others. passion for software development and data and be highly skilled in performing data extraction, transformation and processing to optimize quantitative analyses on various business functions. familiarity with scrum, devops, and dataops methodologies, and supporting tools such as jira. experience with aws technologies such as redshift, rds, s3, glacier, ec2, lambda, api gateway, elastic map reduce, kinesis, and glue. experience with managing aws infrastructure as code, including the use of cloud formation, git, and gitlab. excellent oral and written communication skills. strong presentation skills and the ability to communicate analytical and technical concepts with confidence and in an easy to understand fashion to technical and non technical audiences. bachelor or master degree in computer science or relevant field is required. equal opportunity employer wavicle is an equal opportunity employer and committed to creating an inclusive environment for all employees. we welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.","['data visualization', 'documentation', 'statistical analysis', 'map', 'glue', 'sql', 'enterprise', 'software development', 'analytics', 'data', 'aws', 'data engineering', 'gitlab', 'data pipelines', 'continuous delivery', 'testing', 'scrum', 'data manipulation', 'data collection', 'automation', 'jira', 'programming languages', 'data extraction', 'devops', 'datasets', 'data solutions', 'api', 'git', 'computer science', 'optimization', 'modeling', 'snowflake', 'etl']","['glue', 'sql', 'gitlab', 'jira', 'programming languages', 'data manipulation', 'api', 'git', 'documentation', 'aws', 'rds', 'snowflake', 'map']","['data visualization', 'statistical analysis', 'software development', 'analytics', 'data', 'data engineering', 'infrastructure as code', 'data pipelines', 'continuous delivery', 'testing', 'scrum', 'data collection', 'automation', 'enterprise data', 'data extraction', 'devops', 'datasets', 'data solutions', 'computer science', 'optimization', 'modeling', 'etl']","['environment', 'commerce', 'fashion', 'offshore', 'talend', 'sales', 'design', 'direct', 'governance', 'consulting', 'private companies', 'growing companies', 'business units', 'management']"
504,728,Intermediate/Senior Data Analyst,"driven by the mission to democratize education, paper is the leader in personalized learning. partnering with innovative schools and school districts, paper helps deliver true educational equity through their category leading educational support system that offers virtual access to 24 or 7 tutors and essay reviewers. founded in 2014, paper philosophically believes that all students should be given the tools and resources to reach their academic potential, independent of socio economic status, geography, language or other barriers. today, paper is partnered with over 700 schools and supports over 750,000 students. we are headquartered in montreal, quebec with remote employees across the us and canada. paper is proud to have been named by gsv as one of the most transformational growth companies in digital learning . paper is looking for an experienced data analyst to join our growing r d and analytics team. this position will be responsible for conducting full lifecycle analysis for cross functional teams. this will include requirements elicitation, domain modeling, experiment design, data reporting, and long term reporting maintenance. the data analyst will also be expected to participate in maintaining and extending existing data transformation pipelines as well as monitoring performance and quality control plans to identify improvement opportunities. the ideal candidate is an experienced data enthusiast who enjoys acting as an enabler and gatekeeper for the company s data so stakeholders can understand and use it to make strategic business decisions. they must be self directed and comfortable supporting the data needs of multiple teams, systems and products. the right candidate will be excited by the prospect of uncovering new insights from data to support the company s mission and growth. responsibilities interpret data, analyze results using statistical techniques and provide ongoing reports, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts. acquire data from primary or secondary data sources. participate in fulfilling data requests from multiple teams. design and carry out experiments to test business assumptions or assess the impact of interventions. prepare reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data and suggest data driven interventions. collaborate with data engineers, data scientists, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. create appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary. work with management to prioritize business and information needs. requirements technical expertise regarding data models, database design development, data mining and segmentation techniques. knowledge of statistics and experience using statistical packages for analyzing datasets. strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. adept at queries, report writing and presenting findings. strong project management and organizational skills. experience supporting and working with cross functional teams in a dynamic environment. programming experience . we are looking for a candidate who has attained a degree in mathematics, physics, computer science, statistics, informatics, information systems or another quantitative field. having prior experience using the following software or tools is a plus experience with databases , experience with elt frameworks experience in experiment design experience with reporting packages position can be located in any geography in the us or canada. about paper a great place to work paper offers a fast paced, dynamic, inclusive work environment where all employees have an impact. you will be challenged to achieve, develop, and grow as part of a hyper growth company. the diverse experiences, ideas, and identities of paper s team members help us make better decisions and drive great results. we foster an inclusive work environment that welcomes team members of all backgrounds and perspectives. we are committed to providing a meaningful environment for every member of our team. we hire exceptional people and reward them with trust, autonomy, mentorship, and growth. we are naturally curious and have strong attention to detail. we love working in a team environment where trust is key and we all strive to make an impact every day. if this sounds like the right fit, please apply and come work with us.","['analytical skills', 'databases', 'documentation', 'quality control', 'statistics', 'software', 'reporting', 'physics', 'database design', 'analytics', 'data', 'programming', 'data models', 'pipelines', 'data mining', 'data transformation', 'data analysis', 'datasets', 'information systems', 'computer science', 'mathematics', 'modeling']","['databases', 'programming', 'documentation', 'data models', 'pipelines', 'r']","['database design development', 'data mining', 'analytical skills', 'statistics', 'data transformation', 'software', 'reporting', 'datasets', 'physics', 'information systems', 'data analysis', 'analytics', 'data', 'report', 'mathematics', 'modeling', 'computer science', 'quality control']","['environment', 'education', 'design', 'acting', 'project management', 'governance', 'geography']"
505,729,Data Engineer (Only for those on the autism spectrum),"specialisterne canada is recruiting on behalf of cibc specialisterne canada specializes in working with businesses to hire people on the autism spectrum or who identify as neurodivergent 1 . presently, specialisterne canada is working with cibc to recruit for a several positions in downtown toronto. specialisterne canada provides recruitment, staffing solutions and management support to businesses interested in creating a more neurodiverse workforce. specialisterne has an expertise in developing more comfortable processes and work environments where employees can feel productive and supported. we help managers understand the strengths of their employees and implement strategies to help them thrive in the workplace. cibc places a high value on diversity in its workforce, recognizes the business benefits that accrue from responding to challenges from multiple perspectives, and is exercising a leadership position in the hiring of people with disabilities. applications should be submitted in full no later than july 2nd, 2021. data engineer full time, permanent downtown toronto or remote are you interested in using and developing your skills in software development do you enjoy problem solving and critical thinking does transforming data into technology based solutions sound like something you would enjoy here is what you will do develop technology based solutions to identify potential money laundering as part of governmental compliance work alongside a team of business systems analysts to understand business requirements and define technical infrastructure design and develop various applications following an agile development process to meet business needs perform unit testing to identify bugs and make adjustments as needed to ensure system functionality work with data to construct pipelines, apply transformation and cleansing rules and assess data quality what you will bring have a degree or diploma in computer science, computer engineering, data science, analytics, information technology or a similar discipline use your scala or spark programming skills to perform analysis and develop applications in line with business requirements use your knowledge of sql or other relational databases to retrieve, manipulate and manage data enjoy taking an experimental approach to solving problems and challenges while leveraging your critical thinking skills nice to have knowledge or experience with hadoop 1 neurodiversity is the concept that there is great diversity in terms of how human brains are wired and work. for the purposes of this recruitment program, this umbrella term has been defined to include but not be limited to conditions such as autism, adhd or add, pdd nos, mental health conditions, learning disabilities, and similar ways of being. job types full time, permanent benefits casual dress dental care disability insurance extended health care life insurance paid time off rrsp match vision care schedule monday to friday work remotely temporarily due to covid 19","['sql', 'business systems', 'pipelines', 'relational databases', 'scala', 'computer engineering', 'hadoop', 'data science', 'data quality', 'software development', 'computer science', 'analytics', 'cleansing', 'programming', 'information technology', 'unit testing']","['sql', 'pipelines', 'scala', 'hadoop', 'programming', 'data quality']","['business systems', 'infrastructure design', 'relational databases', 'computer engineering', 'data science', 'software development', 'computer science', 'analytics', 'cleansing', 'agile development', 'information technology', 'unit testing']","['neurodiversity', 'functionality', 'recruiting', 'mental health', 'hiring', 'insurance']"
506,730,Data Engineer (4-month contract),"about us ci global asset management is one of the country s largest investment fund companies. ci is known for its innovation and ability to adapt quickly to the changing needs of canadian investors. it provides employees with a fast paced and challenging work environment with opportunities for advancement. ci is part of ci financial, a diverse group of financial services firms. position data engineer location toronto status contract job overview we are currently seeking a data engineer to join our client reporting and data management team. the successful candidate will work closely with our data science team on the development of our centralized predictive analytics function. in this role, you will assist with solving high value business problems by extracting and manipulating large, complex datasets for use by data scientists. the role will be a four month contract position, with an option to extend based on performance. what you will do collaborate with business analysts, data scientists, software engineers, and solution architects to develop data pipelines to feed our data marketplace extract, analyze interpret large, complex datasets for use in predictive modelling utilize aws tools to develop automated, productionized data pipelines identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. develop and support etl code for data warehouse and data marts to support the reporting and data analytic systems. what you will bring experience at least 1 year of work experience in quantitative analysis strong cs fundamental, data structure and algorithm knowledge strong understanding of statistics experience working and preparing data for data science or machine learning models preferred experience with large scale, aws big data storage such as s3 and ebs experience creating etl jobs using aws glue experience with aws data pipeline tools like cloudwatch and stepfunctions experience working with data preparation tools like talend experience in the financial services industry is an asset education or training post secondary degree in a quantitative discipline knowledge, skills, and abilities strong knowledge with programming methodologies and agile development methodologies. in depth knowledge of aws tools required to develop automated, productionized data pipelines in depth knowledge of and experience with relational, sql and nosql databases fluency with sql, r and python experience working with large, complex datasets excellent communication, writing and interpersonal skills what you can expect from us our dedication to the employee experience at ci is aimed at supporting, empowering and inspiring our talented team through recognition compensation training development health well being communication feedback if you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking apply . only qualified candidates selected for an interview will be contacted. ci financial corp. and all of our affiliates are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. if you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at or call 416 364 1145 ext. 4747. if you are contacted by ci regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. we will work with all applicants to determine appropriate accommodation for individual accessibility needs. posting tags ind li post","['databases', 'ci', 'big data', 'glue', 'sql', 'python', 'statistics', 'software', 'reporting', 'data science', 'analytics', 'data marts', 'aws', 'programming', 'nosql', 'machine learning', 'data preparation', 'data pipelines', 'testing', 'datasets', 'scalability', 'data management', 'etl', 'r']","['glue', 'sql', 'python', 'databases', 'talend', 'programming', 'big data', 'aws', 'predictive', 'nosql', 'r']","['machine learning', 'statistics', 'data pipelines', 'quantitative analysis', 'data preparation', 'software', 'reporting', 'datasets', 'ci', 'agile developmentologies', 'data science', 'scalability', 'testing', 'analytics', 'data marts', 'data management', 'feed', 'etl']","['environment', 'asset management', 'education', 'training development', 'design', 'financial services', 'compensation']"
507,731,Data Engineer - Salentica,"ss c is a global provider of investment and financial services and software for the financial services and healthcare industries. named to fortune 1000 list as top u.s. company based on revenue, ss c is headquartered in windsor, connecticut and has 20,000 employees in over 90 offices in 35 countries. some 18,000 financial services and healthcare organizations, from the world s largest institutions to local firms, manage and account for their investments using ss c s products and services. job description data engineer location king street, toronto ss c technologies holdings, inc. is a global provider of financial services software and software enabled services. founded in 1986, ss c has built the most comprehensive powerhouse of software technology in the financial services industry technology that complements our unrivaled expertise and professionalism in fund administration, insurance and pension funds, and asset and wealth management accounting and operations. named by forbes as one of america s best midsize employers, ss c has more than 20,000 employees and 15,000 clients worldwide, and is headquartered in windsor, connecticut, with offices throughout north america, europe, asia pacific, africa, and australia. ss c salentica, a subsidiary of ss c technologies is an industry leading provider of software and services to the financial services industry. we are currently looking for an industry proven, self motivated product manager to join our team of experienced professionals. the successful candidate will be a conscientious worker with a record of success, who has demonstrated they can work collaboratively and adapt to changing technologies. responsibilities build data driven systems, architectures, and platforms to provide innovative solutions for long term analytical outputs and cloud based application development projects. participate on cross functional teams of technology, product, and business specialists to deliver best in class, customer centric, big data projects by leveraging leading edge tools and technologies. use strong technical and quantitative knowledge and skills to identify new opportunities for business solutions within vast amounts and varieties of data, delivers compelling proposals, defines requirements, designs new projects, and guides them through successful delivery and validation to drive business growth. translate business problems into analytical, data driven methodology to improve business efficiencies and make significant financial gains. communicate complex analysis in a clear, understandable way to non experts. design and continuously improves algorithms. mines raw, relevant data from a variety of sources to identify patterns and correlations and to generate best in class actionable and meaningful insights. manage stakeholders and guides them in unlocking the value in their data. influences architectures that will lead to transformation of data analytics platforms and information technology overall. qualifications minimally requires a master s degree, or bachelor s degree and 2 years of related experience, or high school degree and 4 years of related experience. experience in the financial services industry experience with crm applications and or or digital reporting portal applications technical skills with any or all of java programming, aws infrastructure, linux, bash scripting self motivator able to grasp concepts quickly with minimal supervision, take ownership of problems and follow them through to completion intermediate professional working on projects of a moderate scope or on varied tasks that require resourcefulness, self initiative, and significant independent judgement outstanding communication skills both oral and written demonstrates a developing functional knowledge to evaluate the implications of issues and make recommendations for solutions. guide less experienced team members. may recommend new procedures. ss c offers an extensive health benefit plan rrsp matching program and bonus potential generous training allowance and tuition reimbursement program candidate referral program business casual work environment work or life balance close to all transit to further explore this opportunity, please apply now through our careers page on the corporate website. no phone calls please. we thank all candidates for their interest, but only those under consideration will be contacted. li lm1 unless explicitly requested or approached by ss c technologies, inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee based recruitment services. ss c offers excellent benefits including health, dental, 401k plan, tuition and professional development reimbursement plan. ss c technologies is an equal employment opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.","['linux', 'bash', 'c', 'big data', 'information technology', 'less', 'java', 'data analytics', 'software', 'reporting', 'scripting', 'complex analysis', 'programming', 'digital', 'aws', 'crm', 'application development', 'algorithms', 'administration']","['linux', 'c', 'programming', 'big data', 'aws', 'less', 'java']","['administration', 'data analytics', 'crm', 'bash', 'software', 'reporting', 'information technology', 'scripting', 'complex analysis', 'digital', 'methodology', 'application development', 'algorithms']","['validation', 'environment', 'accounting', 'healthcare', 'design', 'financial services', 'investments', 'insurance funds', 'business growth']"
508,732,"Data Engineer - Azure - Toronto, Canada","join a team of passionate thought leaders in a dynamic and collaborative environment the cognizant microsoft business group s global delivery center is growing fast and we re looking for our next azure data engineer to join us. what impact will you have in this role every role at the cognizant microsoft business group is equally important in the grand scheme of things and everything we do is team work. through team work, building relationships internally and at times with clients, understanding context at all times and what is important, and getting comfortable with influence and persuasion you will stand out as an expert in your field. as we continue to scale we re looking for the market s best azure data ai specialists to help us grow our business fastest growing practice. you ll be working with the industry s biggest players, delivering innovative greenfield data platform builds, data integration programmes and implementing bespoke high level data architectural designs. what type of experience do you need to be successful in this role strong experience using the microsoft azure data stack azure data migration patterns knowledge of c essential agile methodology experience essential ci or cd, azure devops experience, highly desirable customer or client facing consulting skills ability and desire to mentor junior team members. 3 years current and deep experience with implementing large engagements. proven experience managing projects through the entire project lifecycle. this includes managing multi phase or multi dimensional or multi resource projects to conclusion while maintaining high customer satisfaction 3 years experience assessing feasibility of migrating customer solutions and or or integrating with 3 rd party systems both microsoft and non microsoft platforms 2 years of experience and advanced domain knowledge in one or more vertical industries manufacturing, financial services, government, legal, healthcare, property management what personality traits and other capabilities are important for this role our consultants are self motivated and pragmatic with strong problem solving skills and a passion for crafting great solutions coming with a wealth of experience or talent that enables quality software delivery. they understand the best approach to architecture and development is through blending technologies and methodologies appropriate to the task at hand. the goal is to contribute to the clients long lasting success to enable us to expand our business and clientele. security responsibility all employees must act in accordance with the cognizant microsoft business group s corporate security standards. about the cognizant microsoft business group the cognizant microsoft business group has a singular purpose advancing your cloud modernization journey with focus, simplicity and scale. the microsoft business group is an end to end microsoft centric cloud solutions and managed services provider that leverages extensive experience and ip to deliver constant innovation and business value, powered by the microsoft cloud platform. we are designed to reflect how you think about cloud transformation from a platform native perspective. our dedicated experts and trusted blueprint deliver your digital difference through the microsoft cloud azure, microsoft 365 and dynamics 365. we turn digital potential into real business performance at speed. who we are we are the destination employer for microsoft committed professionals, providing depth of specialization and differentiated career paths. we have authentic conversations, build connections and grow careers while centering ourselves around our employees. we are a global team of certified consultants across all relevant technologies, coupled with cloud focused advisory consultants. with our supercharged talent, we are the world s best microsoft partner. we prioritize investing and expanding. equal employment opportunity as a global cloud transformation consultancy business, the cognizant microsoft business group understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. we are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment. the cognizant microsoft business group prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. this policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life cycle at cognizant microsoft business group .","['modernization', 'azure', 'scheme', 'cd', 'managed services', 'software', 'devops', 'ci', 'security', 'data migration', 'c', 'dynamics', 'data', 'integration', 'ip', 'bespoke', 'microsoft azure', 'ai']","['azure', 'c', 'ip', 'microsoft cloud platform', 'microsoft azure']","['modernization', 'scheme', 'cd', 'managed services', 'software', 'devops', 'ci', 'security', 'data migration', 'dynamics', 'data', 'integration', 'methodology', 'bespoke', 'ai']","['environment', 'genetics', 'financial services', 'recruiting', 'microsoft business', 'business value', 'consulting', 'customer satisfaction', 'corporate', 'property management', 'healthcare', 'blueprint', 'engagements', 'government', 'large', 'architecture', 'investing', 'microsoft 365', 'manufacturing']"
509,733,Data Engineer x 2 - Mississauga,"our retail industry client is looking for 2 data engineers to join their team on a permanent hire basis. you will be part of our innovation hub located in downtown toronto where your desire for impact will only be matched by your innate ability to collaborate with other like minded individuals to come up with creative solutions to our retail data science problems job description maintaining, streamlining and hardening existing data pipelines, from ingestion, through etl and batch processing in order to reliably process billions of records per day. build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real time m or l applications. working with analytics and product management to ensure optimal data design and efficiency. assisting data analysts and data scientists with pipeline and model deployment use an analytical, data driven approach to drive a deep understanding of our fast changing business. building data models to deliver insightful analytics while ensuring the highest standard in data integrity. . advantages work from home initially until quarantine is lifted be part of a new department working on high profile projects responsibilities job description maintaining, streamlining and hardening existing data pipelines, from ingestion, through etl and batch processing in order to reliably process billions of records per day. build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real time m or l applications. working with analytics and product management to ensure optimal data design and efficiency. assisting data analysts and data scientists with pipeline and model deployment use an analytical, data driven approach to drive a deep understanding of our fast changing business. building data models to deliver insightful analytics while ensuring the highest standard in data integrity. qualifications job requirements bachelor s degree in engineering, computer science, statistics, economics, mathematics, finance or related quantitative field, or equivalent practical experience. experience and proficiency with sql and sql like languages more than 3 years of software engineering experience, especially working on back end data infrastructure. proficiency with at least one of the following languages java, python, scala. proficiency with spark and or or similar tools in hadoop or yarn environment and comfortable with linux operating system. ability to creatively solve problems in a fast paced, rapidly changing environment ability to navigate ambiguity, drive solutions forward and bring stakeholders along. strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders. strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs. summary minimum 3 years software engineering especially working with back end data infrastructure proficiency with at least one of the following languages java, python, scala experience and proficiency with sql and sql like languages proficiency with spark and or or similar tools in hadoop or yarn environment and comfortable with linux operating system.","['personalization', 'analytical skills', 'linux', 'data integrity', 'data infrastructure', 'java', 'batch processing', 'sql', 'python', 'statistics', 'software', 'scala', 'reporting', 'data science', 'data', 'analytics', 'product management', 'data models', 'data pipelines', 'automation', 'economics', 'hadoop', 'computer science', 'mathematics', 'modeling', 'etl']","['sql', 'python', 'linux', 'scala', 'hadoop', 'data models', 'java']","['personalization', 'analytical skills', 'batch processing support', 'data integrity', 'data infrastructure', 'batch processing', 'statistics', 'software', 'reporting', 'data science', 'analytics', 'product management', 'data', 'data pipelines', 'test', 'automation', 'economics', 'computer science', 'mathematics', 'modeling', 'etl']","['retail', 'environment', 'design', 'finance']"
510,734,Data Solution Architect,"summary onix solution architect helps customers transform and evolve their business through the use of google s global data center and software products. as part of an entrepreneurial team in this rapidly growing business, you will help shape the future of how technology is used in the workplace. you swiftly problem solve technical issues for customers to show how our products can make businesses more productive, collaborative, and innovative. you work closely with a cross functional team of web developers and systems administrators, not to mention a variety of both regional and international customers. your relationships with customers are crucial in helping google grow its business and bringing our product portfolio into companies both big and small around the world. you are a solution architect with excellent technical, communication, and organizational skills. your previous experience with cloud platform and infrastructure products, search products, content or document management repository systems, and sql based relational databases will be on display as you engage with customers to understand their business and technical requirements. as a cloud platform solution architect, you will work hand in hand with the sales team to introduce google cloud platform to our customers. you will help prospective customers and partners to understand the power of google cloud platform, explaining technical features, and problem solving key technical issue scope or level of decision making this is an exempt position operating under limited decision making and supervision. position performs a variety of assigned activities, referring more complex issues to the manager. location remote nationwide, remote ontario, remote quebec primary responsibilities lead strategic cloud application development discovery session to help customers understand the value of cloud application development and how to position it within their organization. proactively help customers address all technical issues that may arise throughout the entire pre sales cycle. create customer and partner connections to help grow onix name recognition in the data space. establish strategic customer relationships and become their go to trusted advisor for big data needs. ability to facilitate demonstrations, proof of concepts, and public facing presentations. use google cloud platform and amazon web services tools to build enterprise grade big data solutions. architect new cloud based data pipelines. ability to bring together multiple data sources into a unified data warehouse. apply analytics and visualizations to customer data sets. assist in strategic direction and planning for the growth of the cloud data team. quickly architect sound cloud solutions to radically different customer environments. establish strategic customer relationships and become the technical go to resource for answers as well as a trusted cloud advisor. in depth understanding and the ability to demonstrate expertise in designing, deploying, and maintaining custom enterprise web applications. in depth understanding and the ability to demonstrate expertise in using a variety of development languages. in depth understanding and the ability to demonstrate expertise to determine the best migration path from legacy or on prem applications into public cloud environments. review and analyze customer architecture at the domain and product level and translate and evolve them into cloud ready applications. staying in constant communication with customers to ensure onix is addressing all of their needs during the pre sales cycle. learning and maintaining an in depth understanding of current and new development technologies and industry standards. assist account manager with technical discovery and responsible for all technical scoping activities during the creation of the statement of work. ability to frequently travel throughout the united states and canada. required skills and experience degree in computer science or math or equivalent practical experience . experience with big data concepts for complex and large data sets. experience with rest api development. experience with microservice applications and cloud based services, with data lake concepts for landing, refining, and analyzing data. developing canonical data models for enterprises. migrating large data sets from on prem to cloud environments. developing data pipelines for large scale etl transformations. experience with large data sets and enterprise grade databases . experience architecting and building data pipelines. deep understanding of the etl process. experience extracting data from multiple sources via apis and scripting. experience transforming data through field mapping, programmatic rulesets, and data integrity checking. able to expertly convey ideas and concepts to others. excellent communication skills creative problem solving skills and the ability to design solutions not immediately apparent. ability to participate in multiple projects concurrently. customer oriented and shows a bias for action. able to function in a highly dynamic team that moves rapidly from idea to planning to implementation. highly adaptable with the ability to learn new technologies quickly without direct oversight. strong knowledge of python machine learning standard libraries. mastery of n dimensional numpy arrays. mastery of pandas data frames ability to perform element wise vector and matrix operations on numpy arrays. strong knowledge of anaconda, virtualenv, and jupyter notebooks good functional knowledge of the tensorflow programming model. strong understanding of all commonly used machine learning models and the main algorithms that compose the models. ability to rapidly prototype proofs of concept and technical demonstrations. ability to conduct technical bd or ml workshops enabling the audience to adopt the cloud technologies to for the development and implementation of bd or ml for scientific research. good knowledge of common networking concepts. strong customer facing communication skills. experience in writing software in java or python. familiarity with web related technologies and network or web related protocols. creative problem solving skills and a drive to solve difficult issues. ability to stay positive and motivated while under pressure. ability to participate in multiple projects concurrently. excellent communication skills customer oriented and shows a bias for action. provide on time, well executed work that leads to excellent customer satisfaction. able to expertly convey ideas and concepts to others. highly adaptable with the ability to learn new technologies quickly without direct oversight. good understanding of the built in data types. . preferred skills and experience google cloud platform data engineer certification. experience with big data, paas, and iaas technologies. experience in and understanding of data and information management especially as it relates to iaas and paas. experience architecting and developing software for scalable, distributed systems. understanding of the public cloud market and pain points driving enterprise cloud adoption. education bachelor s degree travel expectation 25 travel expected it is the policy of onix to ensure equal employment opportunity in accordance with the ohio revised code 125.111 and all applicable federal regulations and guidelines. employment discrimination against employees and applicants due to race, color, religion, sex, , national origin, disability, age , military status, or veteran status is illegal. onix will only employ those who are legally authorized to work in the united states or canada. this is not a position for which sponsorship will be provided. individuals with temporary visas such as e, f 1, h 1, h 2, l, b, j, or tn or who need sponsorship for work authorization now or in the future, are not eligible for hire.","['go', 'databases', 'tensorflow', 'data integrity', 'document management', 'technical requirements', 'big data', 'paas', 'distributed systems', 'java', 'sql', 'python', 'software', 'scripting', 'pandas', 'analytics', 'programming', 'data models', 'customer data', 'application development', 'jupyter', 'amazon web services', 'machine learning', 'data pipelines', 'relational databases', 'iaas', 'numpy', 'google cloud platform', 'web applications', 'rest', 'algorithms', 'information management', 'authorization', 'public cloud', 'computer science', 'api development', 'networking', 'etl']","['go', 'databases', 'big data', 'paas', 'java', 'sql', 'python', 'anaconda', 'pandas', 'programming', 'data models', 'jupyter', 'amazon web services', 'iaas', 'numpy', 'google cloud platform', 'authorization', 'api', 'public cloud']","['tensorflow', 'data integrity', 'document management', 'technical requirements', 'development', 'distributed systems', 'new', 'software', 'scripting', 'analytics', 'customer data', 'application development', 'machine learning', 'data pipelines', 'relational databases', 'web applications', 'rest', 'algorithms', 'information management', 'planning', 'computer science', 'networking', 'etl']","['education', 'design', 'presentations', 'sales', 'sponsorship', 'customer satisfaction', 'adoption', 'regulations', 'workshops', 'architecture']"
511,735,Applied Deep Learning Scientist (Focus on Computer Vision),"location montreal, canada dans des march s en rapide volution, les clients travers le monde font confiance thales. thales est une entreprise o les personnes les plus brillantes du monde entier se regroupent pour mettre en commun leurs id es et ainsi s inspirer mutuellement. dans tous les secteurs o uvre thales, notamment l a rospatiale, le transport, la d fense, la s curit et l espace, nos quipes d architectes con oivent des solutions innovantes qui rendent demain possible d s aujourd hui. carrefour mondial de l intelligence artificielle, montr al est le foyer du nouveau centre de recherche et de technologie sp cialis en intelligence artificielle collaborant avec les principaux groupes canadiens de recherche en intelligence artificielle montr al et toronto. s appuyant sur ses comp tences dans les principaux march s industriels, thales donne vie l intelligence artificielle au profit de ses clients tout en cr ant de passionnants emplois pour les chercheurs et les d veloppeurs experts en intelligence artificielle en vue de trouver des solutions qui transformeront notre monde, du fond des oc ans aux confins de l univers et du cyberespace. ayant tr s t t opt pour le mod le d innovation ouverte et collaborative, thales proc de actuellement la cr ation de la structure du centre de recherche et de technologie sp cialis en intelligence artificielle . pilot par thales, le centre cortaix, en collaboration avec l institut qu b cois d intelligence artificielle , l institut de valorisation des donn es et l institut vector de toronto, est situ dans le c l bre quartier petite italie, au c ur de la communaut de l innovation montr al. in fast changing markets, customers worldwide rely on thales. thales is a business where brilliant people from all over the world come together to share ideas and inspire each other. in aerospace, transportation, defence, security and space, our architects design innovative solutions that make our tomorrow s possible. montreal a world leading ai hub, is home to new centre of research technology in artificial intelligence expertise collaborating with leading canadian ai research groups in montreal and toronto. with competencies in major industrial markets thales is bringing artificial intelligence to life for our customers creating exciting jobs for ai researchers and developers who will create solutions that will transform our world from the bottom of oceans to the depths of space and cyberspace. as an early adopter of open, creative and collaborative innovation model, thales is building the centre of research and technology in artificial intelligence expertise . led by thales, cortaix, in collaboration with the mila , the ivado and the vector institute of toronto, is located in montreal s famous little italy, in the heart of montreal s innovation community. raison d tre un chercheur en intelligence artificielle appliqu e en recherche et technologie est charg de d couvrir, d activer et d int grer des concepts d ia innovants dans les solutions thales. il or elle prouve leur viabilit travers la mise en uvre de proofs of concept et guide leur croissance de maturit travers des prototypes et des d monstrateurs qui leur tour illustreront et permettront leur plein potentiel commercial. missions principales en tant que chercheur en ia appliqu e la recherche et la technologie, vous dirigerez les activit s cl s tout au long de nos projets au rythme rapide. pour r ussir dans ce r le, la curiosit pour ce qui est nouveau, la volont de remettre en question le statu quo, l ouverture d esprit et la pens e originale sont essentielles. l individu doit rapidement apprendre et valuer les nouvelles techniques et technologies afin de d cider de les adopter, de les adapter ou de les abandonner. il doit galement tre capable de proposer de nouvelles id es, de les pr senter, de les remettre en question et de les am liorer continuellement. l individu doit poss der des comp tences techniques approfondies et pratiques et tre familiaris avec les derniers outils et environnements de d veloppement deep learning, avec un fort accent sur les applications de vision par ordinateur, afin de contribuer la mise en uvre de ces id es. proposer des concepts innovants et les mettre en uvre est rarement un processus individualiste. le scientifique fait partie d une quipe multidisciplinaire. un fort esprit d quipe et des capacit s de travail d quipe sont obligatoires. il or elle contribuera en tant qu expert technique des projets de recherche et technologie au sein de thales et de ses business units. par cons quent, de bonnes comp tences en communication sont n cessaires. exigences ma trise en informatique, ing nierie ou math matiques exp rience pr alable en intelligence artificielle, apprentissage automatique comp tences d montr es dans la conception de syst mes d ia bonne base en math matiques, statistiques et probabilit s solide connaissance des fondations de l apprentissage automatique avec un accent sur les applications de vision par ordinateur connaissance des architectures traditionnelles d apprentissage profond et des architectures d apprentissage g n ratif profond pour les t ches de vision par ordinateur. solides comp tences en d veloppement avec des frameworks d apprentissage automatique tels que scikit learn, tensorflow, keras, pytorch, theano solides comp tences en programmation python connaissance pratique du syst me d exploitation linux volont de contribuer dans un environnement ax sur l quipe capacit s de leadership d montr es dans des organisations scolaires, civiles ou commerciales capacit travailler de mani re cr ative et analytique dans un environnement de r solution de probl mes comp tences av r es en communication verbale et crite en anglais qualifications pr f r es doctorat en informatique, ing nierie ou math matiques minimum 3 ans d exp rience en machine learning en python avec un int r t pour le deep learning un historique de d veloppement de logiciels d ia exceptionnel avec des preuves github comp tences d montr es dans la conception de syst mes d ia int r t d montr pour le deep learning appliqu , y compris 1 or stade pr coce de pr paration des donn es, augmentation, g n ration, 2 or r glage syst matique du mod le deep learning, 3 or mod lisation d exp riences de machine learning r plicables, 4 or pipeline d apprentissage profond pour la s lection et la validation de mod les ml. exp rience de travail avec des langages de programmation tels que c, c , java, des langages de script ou similaires une expertise en apprentissage automatique embarqu est un atout majeur exp rience pratique de la visualisation des donn es, des outils or langages d analyse travail d quipe et collaboration d montr s dans des environnements professionnels capacit d tablir une cr dibilit aupr s des clients et des autres membres de l quipe exp rience pr alable dans un environnement de recherche et technologie ou d innovation historique des publications dans les grandes conf rences d intelligence artificielle cvpr, neurips, ijcai, aaai, etc. job purpose a research and technology applied artificial intelligence scientist is responsible for discovering, enabling and integrating innovative ai concepts into thales solutions. he or she proves their viability through the implementation of proofs of concept and guides their maturity growth through prototypes and demonstrators that will in turn illustrate and enable their full business potential. key job functions as a research and technology applied ai scientist, you will drive the key activities throughout our fast paced projects. to be successful in this role, curiosity for what is new, willingness to challenge the status quo, open mindedness and out of the box thinking are crucial. the individual should quickly learn and assess new techniques and technologies in order to decide whether to adopt, adapt or discard them. he or she also needs to be able to come up with new ideas, present them, challenge them and improve them continuously. the individual must possess deep, hands on technical skills and be familiar with latest deep learning development tools and environments, with a strong focus on computer vision applications, in order to contribute to the implementation of those ideas. coming up with innovative concepts and implementing them is rarely an individualistic process. the scientist is part of a multi disciplinary team. strong team spirit and teamwork capabilities are mandatory. he or she will contribute as a technical subject matter expert to research and technology projects across thales and its business units. therefore, good communication skills are required. essential skills and qualifications phd or masters degree in computer science, engineering or mathematics fields prior experience in artificial intelligence, machine learning minimum 3 years of machine learning experience in python with interest in deep learning a track record of outstanding ai software development with github evidence demonstrated abilities in designing ai systems demonstrated interest in applied deep learning, including 1 or early stage of data preparation, augmentation, generation, 2 or systematic deep learning model tuning, 3 or replicable machine learning experiments modeling, 4 or deep learning pipeline for ml model selection and validation. work experience with programming languages such as c, c , java, scripting languages or similar expertise in embedded machine learning is a strong plus good foundation in mathematics, statistics and probability strong knowledge of machine learning foundations with a focus on computer vision applications knowledge of mainstream deep learning architectures and deep generative learning architectures for computer vision tasks. strong development skills with machine learning frameworks such as scikit learn, tensorflow, keras, pytorch, theano strong python programming skills working knowledge of linux os eagerness to contribute in a team oriented environment demonstrated leadership abilities in school, civil or business organisations ability to work creatively and analytically in a problem solving environment proven verbal and written communication skills in english chez thales, nous proposons des carri res passionnantes, pas de simples emplois. fort de ses 80 000 collaborateurs dans 68 pays, thales a mis en place une politique de mobilit permettant, chaque ann e, des milliers d employ s de faire progresser leur carri re tant dans leur domaine d expertise que dans de nouveaux domaines de comp tences, cela aussi bien dans leur pays d origine qu l tranger. ensemble, nous pensons qu adopter une politique de flexibilit est une mani re plus actuelle de travailler. c est ici que commence votre parcours exceptionnel, postulez sans tarder at thales we provide careers and not only jobs. with thales employing 80,000 employees in 68 countries our mobility policy enables thousands of employees each year to develop their careers at home and abroad, in their existing areas of expertise or by branching out into new fields. together we believe that embracing flexibility is a smarter way of working. great journeys start here, apply now thales s engage promouvoir un lieu de travail diversifi et inclusif pour tous. thales s engage fournir des accommodements toute les tapes du processus de recrutement. les candidats retenus pour une entrevue qui ont besoin d accommodement sont pri s d en informer la suite de l invitation pour une entrevue. nous travaillerons avec vous pour r pondre vos besoins. toutes les informations relatives l accommodement fourni seront trait es de mani re confidentielle et utilis es uniquement dans le but de fournir une exp rience de candidat accessible. thales is committed to a diverse and inclusive workplace for all. thales is committed to providing accommodations in all parts of the interview process. applicants selected for an interview who require accommodation are asked to advise accordingly upon the invitation for an interview. we will work with you to meet your needs. all accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.","['linux', 'pytorch', 'tensorflow', 'c', 'java', 'github', 'python', 'statistics', 'keras', 'scripting', 'computer vision', 'development tools', 'software development', 'programming', 'machine learning', 'data preparation', 'ai', 'artificial intelligence', 'probability', 'deep learning', 'programming languages', 'security', 'computer science', 'mathematics', 'modeling', 'r']","['python', 'linux', 'keras', 'programming languages', 'pytorch', 'me', 'genera', 'c', 'programming', 'java', 'r']","['model', 'deep learning', 'machine learning', 'data preparation', 'statistics', 'tensorflow', 'computer vision', 'security', 'scripting', 'development tools', 'computer science', 'software development', 'artificial intelligence', 'mathematics', 'probability', 'modeling', 'github', 'ai']","['validation', 'environment', 'design', 'evidence', 'aerospace', 'business units', 'candidate experience']"
512,736,Software Developer – Data Science,"join our team the data strategy enablement team is on a continuous journey towards helping telus become a world class leader in data solutions, doing so by delivering data analytics capabilities built upon unified scalable platforms, advanced ai tooling, high quality data, and a data product and data platform oriented culture while always keeping an eye on the horizon, preparing for the next big thing. we are entrepreneurial and passionate, believers that so much more is possible and can be achieved by creating value and great outcomes for our customers, team members, communities, and environment and that through meaningful transformation we can integrate dynamic change in our professional lives. together, we will develop and execute strategic programs that will enhance the experience for telus subscribers and internal stakeholders across telus. always wanted to work with a team of innovators and be part of a culture that embraces creativity and collaboration if so, we d love to talk with you here s the impact you ll make and what we ll accomplish together as a software developer data science, you ll be a part of the team and journey that will transform the way we do business across various domains. you will provide vision and strategic guidance to evolve from common static analysis to dynamic machine learning deployment. you will combine your expert knowledge of data science with your strong software development skills to automate and facilitate machine learning model development, training and deployment and will leverage your experience in building reusable algorithms, functions and libraries. you will be working in an environment defined by continuous integration on multiple solutions that will exchange information. you will have to understand a complex architecture and guide its evolution. you ll collaborate with teams across the company to help identify new business opportunities while championing data driven decision making and the accelerated adoption of ai. here s how lead the software development and implementation of ml ai and big data solutions support and evolve the advanced analytics and data management roadmap by leveraging industry research, best practices and emerging tools or technology on software development focus on code quality and timely delivery of ai products and solutions with a focus on performance, maintainability and scalability build and maintain a strong engagement with key stakeholders to understand business needs and priorities identify opportunities for code optimization and refine to improve effectiveness or accuracy and enhance roi collaborate with data scientists and data engineers within telus as well as external business stakeholders influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset qualifications you re the missing piece of the puzzle you are recognized for addressing business needs via your application of software development, data mining and analysis, predictive modeling, statistics and other advanced analytical techniques in which you have previous hands on work experience 3 years of experience working in a software engineering role with a track record of building highly scalable and robust systems you are sought out when it comes to analyzing and translating technicalities into business implications you have solid development experience with consuming and designing restful apis in python you are comfortable using various front end frameworks like react you are familiar with at least one of the cloud computing platforms gcp, aws, azure strong understanding of application level and system level software design patterns great to haves bs or ms degree in computer science, engineering, or relevant field machine learning and data science knowledge experience with agile methodology and work in a start up environment gcp or other cloud certifications a bit about us our business is connecting canadians. our social impact is using our world leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. when you join our team, you re helping us make the future friendly. we re committed to diversity and equitable access to employment opportunities based on ability your unique contributions and talents will be valued and respected here. primary location ca on toronto other locations ca bc victoria, ca qc montreal, ca qc quebec city, ca bc vancouver, ca on toronto, ca ab edmonton, ca on ottawa, ca bc burnaby, ca ab calgary schedule full time","['data analytics', 'python', 'gcp', 'statistics', 'software', 'data science', 'software development', 'analytics', 'integration', 'aws', 'cloud computing', 'software design patterns', 'data mining', 'analytical techniques', 'machine learning', 'ai data solutions', 'algorithms', 'model', 'maintainability', 'data solutions', 'scalability', 'optimization', 'modeling', 'data management', 'enablement', 'ai']","['gcp', 'python', 'big', 'aws']","['data analytics', 'statistics', 'software', 'data science', 'software development', 'analytics', 'integration', 'cloud computing', 'data mining', 'analytical techniques', 'machine learning', 'design patterns', 'continuous', 'predictive', 'algorithms', 'model', 'methodology', 'maintainability', 'data solutions', 'scalability', 'optimization', 'modeling', 'data management', 'enablement', 'ai']","['adoption', 'environment', 'new business opportunities', 'architecture']"
513,737,"Senior Actuarial Manager, Data Science","what you will do join a leadership team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. the insurance industry is undergoing a data driven, technology revolution and you will be in the driver s seat. insurance pricing, underwriting, claims and other core insurance functions are all looking for actionable insights that can be coaxed out of our data. you and your team will work with these business areas to realize this value further embed data science in our operations. our leadership team collectively seeks to expand our very strong and diverse talent base. you will take shared ownership for continuing this successful growth. what you need to succeed as a senior manager, you will need the following skills and experience to succeed in the role 7 years of experience in the general insurance industry. expert knowledge in at least one insurance discipline eg pricing, claims, underwriting, marketing, fraud or other. ideal candidates have experience leading teams in multiple disciplines. the capacity to oversee, develop and mentor a highly productive team of data scientists, actuaries insurance professionals cross functional skills that allow you to straddle the worlds of data scientists, actuaries, engineers core insurance functions. the ability to establish a vision with stakeholders and create a culture that treats data as an essential asset the drive to advance our department s capability to evolve the business by leading the development and deployment of long term tools. what sets you apart amazing people skills . you are able to translate and communicate complex algorithms to non technical experts. you are someone who understands that it is not enough to just have a great algorithm but critical to generate buy in for the solution. excellent leadership skills . you constantly seek to improve the engagement, innovation and empowerment of our team members subject matter expert. you are recognized as an expert in one or more areas of pricing, underwriting, claims, predictive modeling, data science, marketing or other specializations. a can do team player. you are willing to roll up your sleeves and do whatever is needed to move projects forward. that means you will take opportunities be a project manager, developer, modeler and chief communicator of solutions. customer focused. you prioritize building relationships with business partners to identify their needs and develop innovative solutions. additional information a viva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation.","['modeling', 'algorithms', 'forefront', 'data science']",['forefront'],"['modeling', 'algorithms', 'predictive', 'data science']","['underwriting', 'actuaries', 'insurance industry', 'marketing', 'general', 'hiring', 'insurance']"
514,738,"Senior Data Engineer, R&D","benchsci s vision is to help scientists bring novel medicine to patients 50 faster by 2025. we do this by empowering scientists to run more successful experiments with the world s most advanced, easy to use biomedical artificial intelligence software platform, thereby avoiding delays that slow the progress of medicine to clinical trials. backed by f prime, inovia, golden ventures, and google s ai fund, gradient ventures, we provide an indispensable tool for more than 41,000 scientists that accelerates research at 15 top 20 pharmaceutical companies and over 4,300 leading academic centers. we re a cix top 10 growth company, certified great place to work , and top ranked company on glassdoor. we are currently seeking a senior data engineer, r d to join our machine learning team. reporting to the engineering manager, you will work on creating the data infrastructure that supports benchsci s supervised learning pipeline for the r d problems that we are solving. in this role, you will work closely with domain experts and ml engineers in the earliest stages of building a new feature through domain modelling, data preparation, feature engineering, and rapid prototyping of heuristics or baseline models. success will be measured by the continuous improvement of our model quality through a data centric approach to model training, as well as the velocity with which we can ship new r d features. this position is open to candidates who would like to work remotely or in person at our toronto office . for candidates who will be working within the gta once we return to the office, we will continue to have ongoing remote flexibility of up to 4 days per week . you will collaborate closely with ml and domain experts to solve interesting and challenging problems with respect to extracting ground truth data to train high quality models employ best practices in modern machine learning workflows within a cloud based environment set the baseline performance to beat by the rapid development of specialized heuristics or baseline models analyze and evaluate our data sets across the ml lifecycle to ensure they are fit for purpose for both labeling and model training work on projects involving some of the largest pharmaceutical companies in the world provide troubleshooting analysis and resolution in a timely manner have opportunities to work both independently and in pair programming settings be given an unmatched opportunity for growth and development, and to learn from a team of outstanding engineers you have 4 years of experience working as a professional developer expertise in python and programming fundamentals expertise in intermediate or advanced sql and bigquery or similar serverless data warehousing solutions experience with statistical analysis of datasets experience with cloud reference architectures for common patterns in data pipelines strong cross team communication and collaboration skills nice to haves, but not mandatory qualifications a background in life science working knowledge of data versioning tools such as dvc for machine learning working knowledge of distributed systems and data processing fundamentals knowledge of distributed data processing abstractions like beam or spark working knowledge of machine learning data fundamentals such as data splits, training serving skew, common data representations such as embeddings or multi hot encodings, sampling strategies for active learning working knowledge of how to evaluate classification model quality, such as precision, recall, f1, pr or roc curves our benefits and perks a compensation package that includes equity options in the company an annual executive health assessment at medcan all employees get the executive treatment effectiveness coaching for managers onsite, personalized coaching from an executive coach with a doctorate in clinical psychology mental health tools and support optional mindfulness sessions and a free headspace account complimentary genome sequencing from 23andme find out what your dna says about your health, traits, and ancestry three weeks of vacation, plus another week get 15 days to use anytime, and we re closed dec 25 jan 1 additional days off company summer day, your birthday, and earn 1 vacation day annually work from anywhere flexibility every day right now, and up to 4 days per week once we return to the office an onsite gym keep fit, conveniently, with a peloton and other great equipment a great benefits package including health and dental our culture we believe culture is critical to success and invest accordingly. we live and promote our fastt values of focused, advancement with speed, tenacity, and transparency. we work hard to maintain an engaging, supportive environment where everyone can do their best work. to learn more, read our culture deck. diversity, equity and inclusion we re committed to creating an inclusive environment where people from all backgrounds can thrive. we believe that improving diversity, equity and inclusion is our collective responsibility, and this belief guides our dei journey. to learn more, read about our dei initiatives. accessibility accommodations benchsci provides accessibility accommodations during the recruitment process. should you require any accommodation, we will work with you to meet your needs.","['data infrastructure', 'troubleshooting', 'distributed systems', 'statistical analysis', 'medicine', 'sql', 'python', 'data processing', 'software', 'reporting', 'programming', 'data warehousing', 'machine learning', 'data pipelines', 'ai', 'artificial intelligence', 'prototyping', 'datasets', 'sampling']","['model', 'sql', 'python', 'programming', 'r']","['pair', 'data infrastructure', 'troubleshooting', 'distributed systems', 'statistical analysis', 'medicine', 'data processing', 'software', 'reporting', 'data warehousing', 'clinical', 'machine learning', 'data pipelines', 'ai', 'rapid', 'artificial intelligence', 'prototyping', 'datasets', 'feature', 'sampling']","['environment', 'sequencing', 'continuous improvement', 'compensation', 'mental health', 'clinical trials', 'assessment']"
515,739,Data Engineer - Toronto Hub,"veeva nyse veev is the leader in cloud based software for the global life sciences industry. committed to innovation, product excellence, and customer success, our customers range from the world s largest pharmaceutical companies to emerging biotechs. veeva s software helps our customers bring medicines and therapies to patients faster. we are the first public company to become a public benefit corporation. as a pbc, we are committed to making the industries we serve more productive, and we are committed to creating high quality employment opportunities. veeva is a work anywhere company which means that you can choose to work in the environment that works best for you on any given day. whether you choose to work remotely from home or in our toronto office it s up to you. veeva is looking for a data engineer to create etl pipelines for our veeva data cloud product. we re building a system to provide our customers with access to billions of records a day with insightful analysis along with aggregations and transformations. for this role, we need someone who can design flexible data processes and leverage their python and scala skillsets to implement them in an aws cloud environment. you ll be responsible for creating and owning the implementation of numerous data analysis features as well as the pipelines that process those features in a multi tenant, highly parallel system. what you ll do design and build scripts and tools that perform data analysis, transformations, aggregations, and other augmentations on large sets of in a spark based aws environment evaluate various pipeline models, tools, and environments and implement these to push data from our sources through your transformations and finally to our customers work with product management and data research teams to prototype and test new ideas then take those to production work in a fast paced, test driven environment requirements bs degree in computer science, engineering or related subject 3 years experience working on apache spark applications in either python and or or scala experience creating spark jobs that work on at least 1 billion records. intermediate or greater sql knowledge experience creating data pipelines in a production system experience working on aws environments nice to have experience working with data quality techniques java development experience experience working with machine learning or ai models experience with aws glue familiarity with agile methodologies experience with the following tools jira, git, terraform perks benefits allocations for continuous learning development annual budget to donate to the non profit of your choice health wellness programs li remote veeva s headquarters is located in the san francisco bay area with offices in more than 15 countries around the world. veeva is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","['data research', 'glue', 'sql', 'python', 'terraform', 'software', 'scala', 'product management', 'aws', 'pipelines', 'machine learning', 'data pipelines', 'apache spark', 'data analysis', 'data quality', 'agile methodologies', 'jira', 'git', 'computer science', 'etl', 'ai']","['glue', 'sql', 'python', 'terraform', 'jira', 'scala', 'san', 'apache spark', 'git', 'data quality', 'aws', 'java development', 'pipelines']","['data research', 'agile methodologies', 'machine learning', 'data pipelines', 'software', 'computer science', 'product management', 'data analysis', 'etl', 'ai']","['customer success', 'environment', 'design', 'life sciences', 'regulations']"
516,740,Machine Learning Scientist - Senior,"machine learning scientist since ron glozman founded chisel ai in 2016 we ve evolved to be the machine learning leader in the insurance industry. our software reads insurance forms and extracts key policy data hundreds of times faster than a human. our advanced ai platform and intelligent workflows automate high volume, repetitive manual underwriting and brokering processes, enabling insurance carriers and brokers to double their business, reduce operating costs, and deliver a better digital customer experience without adding staff. our customers include some of the world s largest commercial lines insurance carriers and brokers. the opportunity we have a rare opportunity for a senior machine learning scientist who wants to take the latest advances in ml and nlp and build out technology for delivery in production. this is a chance to take your passion for solving complex problems, and apply your findings tactically not just theoretically, as you create solutions to solve a major industry challenge faced by large global customers. you will lead the collaboration within our team between machine learning and software development, implement best practices, and further iterate on our core ai information extraction competency. you will be a mentor and technical lead to machine learning scientists at chisel ai who are still in the early stages of their machine learning careers. this is a unique opportunity to get in at the ground level as we scale to influence the ai roadmap for our entire organization and to revolutionize an industry with data that s actionable. our new machine learning scientist will develop. in this role, you ll hit the ground running creating production level code for our core ai capability within your first month. you ll work closely with the product development manager, software developers and machine learning scientists to create new ml algorithms and models, to execute on our product roadmap, and will push the envelope forward in document information extraction. research. you will spend 10 of your time researching the latest trends and breakthroughs in nlp and related fields in ml, especially document information extraction. whether you find this information on reddit, stackexchange, hackernews, or in academic journals is up to you, but you ll be expected to share key takeaways with us. collaborate. you will work with our various product development teams to iterate, develop and mature best in market product solutions. mentor. you will lead and guide the work of chiselers, suggesting the right approach and tools, quality assuring their work, and helping them grow increasingly knowledgeable and autonomous in using machine learning to develop our products. our new machine learning scientist has the experience. you have 5 years of experience developing production level code, preferably in a machine learning or saas software environment. you have a strong understanding of machine learning development in python and have an understanding of information extraction problems and related areas in ml. the coaching. you have exposure guiding the work of individuals or a small team. you are comfortable working side by side with team members and providing technical leadership and best practices for a b2b environment. the education. ideally, you hold a master s degree or ph.d. in machine learning, computer science, physics, mathematics, statistics, or a related analytical field. we do, however, recognize that not everyone gains their skills this way. if you have a bachelor s degree in software engineering or computer science and the technical work experience to match, we d still like to see your profile. the technical skillset. you have a deep knowledge of python ml tools, including scikit learn, and pandas or similar frameworks. you ve successfully applied these technologies in the past and are eager to learn new ways to leverage these frameworks. the intellectual curiosity. you are a solutions oriented individual who wants to dig deep into and apply the latest research to solve real business problems. you are known for keeping on top of best practices and industry breakthroughs you are eager to share your expertise with our team. what do you need to know about chisel ai we are technology enthusiasts and experts pushing the limits on how ai will shape the future of insurance. having successfully raised one of the largest seed rounds in canadian history and with partners like venrock, a leading silicon valley venture firm, by our side very little stands in the way of our success. chisel ai was named a digital disruptor to watch in 2021 by next canada, named to the 2020 insurtech100 list of the world s most innovative insurtech companies, won gold at the 2019 zurich innovation world championship and made the cix top 20 early companies list celebrating the most innovative technology companies in canada. venture backed and well funded, chisel ai has been named as an analytics arms dealer by novarica, an idc innovator for insurance sales automation solutions, featured in cb insights research on insurtech startups modernizing the p c value chain, and included in the recent strategy meets action report, the top 50 insurtechs in p c. why join chisel ai we re a company with heavy traction, big clients, and a plan to expand rapidly. we ve assembled a strong and diverse leadership team and are poised to scale and develop talented people of all levels. this is a place where failures turn into opportunities, where we learn from each other and where everyone s voice is heard. we re at a unique and rare stage of growth that will give our team and those who join us a chance to put their mark on everything we build. what you can expect when you apply to chisel ai we know that diversity and belonging makes for the best problem solving and creative thinking. chisel ai is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. we want to know what motivates you and we don t believe that everyone follows the same career path. we are dedicated to adding new perspectives to our team and encourage you to apply if your experience is close to what we are looking for. we are committed to providing reasonable accommodations, if required, and will work with you to meet your needs. due to covid 19 please expect changes to our standard recruitment process. in all instances, the safety of our team and our candidates is of our utmost concern so we will be conducting interviews virtually and online. we will keep you informed on these changes and ensure that you are prepared in advance with the necessary instructions to conduct the next steps in the recruitment process. khgahqdjn3","['information extraction', 'c', 'technical leadership', 'insurtech', 'python', 'statistics', 'software', 'physics', 'software development', 'pandas', 'saas', 'analytics', 'machine learning', 'algorithms', 'automation', 'nlp', 'computer science', 'mathematics', 'ai']","['python', 'reddit', 'nlp', 'c', 'pandas']","['information extraction', 'technical leadership', 'insurtech', 'statistics', 'software', 'scikit', 'physics', 'software development', 'computer science skills', 'saas', 'analytics', 'hit', 'machine learning', 'information', 'algorithms', 'automation', 'computer science', 'mathematics', 'ai']","['underwriting', 'environment', 'insurance industry', 'education', 'forms', 'customer experience', 'sales', 'startups', 'product development', 'insurance']"
517,741,"Senior Data Analyst, Growth","we make small businesses more successful through better banking. our company is looking for a senior data analyst, growth to join our growing team as we enter a new phase of expansion we are a toronto, new york and san francisco based, venture backed startup at the heart of the fintech movement that is shaping the way financial services are delivered. we are backed by some of the best vcs in the world and are growing fast. our story our company s purpose is to eliminate the pain that small business owners face through their financial management and banking. to achieve this, we re rebuilding business banking from the ground up. imagine you could start with a clean slate and think of a different way to deliver banking to small businesses. what would you change what would you keep these are the decisions that we make every day. our product northone is a mobile, tech powered bank account built for startups, freelancers, and small or medium sized businesses . poor financial literacy has an outsized impact on the costs and failure rates amongst smbs, and we are on a mission to eliminate these problems. we are more than a banking platform, we are the world class finance department that smbs could never afford. our team we growth. as a senior data analyst, growth, you ll partner with our world class growth team on generating insights to identify the best areas of opportunity. this is the first hire of its kind at northone the potential for growth is big reporting to our senior product manager, growth, you ll also benefit from our experienced management team, who have already created and exited startups and come from leadership roles at brands like square, mckinsey, google, frank and oak, strava, instacart, prodigy, ebay and more. we re building a product that solves real pain vs the imagined kind. small businesses are the bedrock of every community and of the american economy. their storytelling potential is endless, they have been underserved by banking and fintech for far too long, and you ll be their champion. ready to start what you ll be doing analyzing data to derive insights which identify new opportunities for growth and help us to solve customer problems building predictive growth models and dashboards to measure ongoing performance partnering with engineering, data science, and other analytics teams to build long term solutions that allow the business and our customer base to grow effectively sharing your findings with the team to make sure stakeholders have all the information they need to make the best strategic decisions contributing growth ideas to the team based off insights derived from your own analysis and research requirements today you might be a data analyst, senior data analyst, data scientist, product analyst or the equivalent in your company...or something that we haven t heard of yet we keep an open mind. the most important characteristic for our senior data analyst, growth is your attitude. we want you to join because you don t see roadblocks, you see opportunities to be at your best. you know that somehow, you can figure anything out. the skills required for this role you have experience working with digital products and or or saas you get giddy about building awesome quantitative models using python or sql or excel or looker you re a natural communicator and you love diagnosing and solving problems you re a pro at making complex technology and business processes simple you know how to connect the dots between departments and stakeholders bonus points you ve supported teams that work on quick release and testing cycles you ve worked with atlassian tools before you geek out over technology and or or fintech if you are this close to what we ve described but aren t sure, apply. let s figure out together if this is where you could shine. benefits our mission is big and audacious, but we re assembling a team to take the challenge head on. as a senior data analyst, growth, you ll be joining a team that prioritizes people our company is more than just a business. we re a band of brothers and sisters supporting each other on our mission to rebuild business banking. we re really serious about mission, fit, and the people we work with. you ll be part of a rapidly scaling team that reflects these values and keeps this place special. diversity you ll find yourself in an environment that values diversity and inclusivity. we believe that a broad array of lived experiences and backgrounds are essential for creating the best possible product and company culture. leadership you re right in the thick of it, making critical decisions that will clear our path forward. you ll receive top tier health or dental benefits we care about the people we work with and put their health first. northone is proud to offer inclusive health and dental coverage. flexible working hours we don t clock in and out at set times. you know when you do your best work. we celebrate accomplishments, not how many hours are spent at the office. unlimited paid time off we hire talented people and know that they need time off to be at their best. take as much time off as you need to recharge and make sure you re working sustainably. the latest computer equipment we make sure you have the best equipment so you can produce great work. professional development budget we support lifelong learners by covering the cost of classes, workshops and conferences. you ll also get access to our ever growing library of industry related books. remote get togethers bond with your teammates over shared interests at regular get togethers. find like minded people who are passionate about everything from sport and music to gaming and cooking. one hell of an adventure if you recognize yourself in this job description, let s talk. northone is proud to be an equal opportunity employer and celebrates diversity. we welcome all applicants regardless of race, colour, gender, age, religion, sexual orientation, disability status or national origin.","['sql', 'python', 'looker', 'financial literacy', 'banking', 'quantitative', 'reporting', 'testing', 'dashboards', 'data science', 'analytics', 'saas', 'gaming']","['san', 'python', 'sql', 'looker']","['financial literacy rates', 'banking', 'reporting', 'testing', 'dashboards', 'data science', 'analytics', 'saas', 'gaming']","['environment', 'customer base', 'fintech', 'finance', 'financial services', 'startups', 'financial management', 'workshops']"
518,742,Data Management Specialist - Immunogenicity,"for 70 years, charles river employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. when you join our family, you will have a significant impact on the health and well being of people across the globe. whether your background is in life sciences, finance, it, sales or another area, your skills will play an important role in the work we perform. in return, we ll help you build a career that you can feel passionate about. important in order to be considered for this position, a resume or cv must be uploaded and submitted during the application process. please make sure work history and education are added correctly. job summary support the scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with good laboratory practices , standard operating procedures , analytical procedures , and study plans. we are currently looking for a data management specialist for our immunogenicity team located in senneville, quebec. the following are the responsibilities related to the position contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. follow and ensure the application of glp, sops, special procedures and health and safety rules on their assigned studies. perform and review tabulation of results and participate in writing the study report. collaborate with the scientist to compile and assemble study deliverables in an audit ready state for submission to the quality assurance department and answer qa findings. preparing or revision of the study summary when required. perform all other related duties as assigned. the following are minimum qualifications related to the position dec in sciences or aec laboratory experience an equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above. be able to work as part of a team. have a positive attitude, good interpersonal relationships and professionalism. adapt to changes. actively participate in departmental meetings to improve performance and quality. good understanding of microsoft office software and data generating software used in the department relevant to their role. important a resume is required to be considered for this position. if you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume or cv. about safety assessment charles river is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state of the art facilities and expert regulatory guidance. from individual specialty toxicology and ind enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. each year approximately 120 investigational new drug programs are conducted in our safety assessment facilities.","['quality assurance', 'software', 'documentation', 'data management', 'quality control']","['documentation', 'quality assurance']","['software', 'data management', 'quality control']","['and safety', 'education', 'glp', 'forms', 'sales', 'finance', 'life sciences', 'microsoft office', 'art', 'toxicology', 'design', 'laboratory', 'drug development', 'assessment', 'safety']"
519,744,Java - Software Developer (Data Services),"the senior java developer cloud will work in collaboration with java developers and data scientists on the data services team in supporting three major projects a surfacing engine that serves millions of users per day, crawlers that scour the web and use computer vision, and an infrastructure that processes, aggregates and filters billions of events per day. you will make a difference your work will be used by more than a hundred million users per day. what you ll be doing work in close collaboration with the product owner to understand the requirements work closely with the software development team to maintain a high level of product quality propose solutions to our unique challenges work with existing devops teams to implement requirements work with data science team to architect their solutions following best practices innovate and communicate new practices, technologies and methodologies what you ll need to be successful must haves a minimum of 3 years in a similar role experience with leading cloud providers such as aws, azure and google cloud engine and their offerings working knowledge of python, java, docker, kubernetes, mesos, etc. experience using ci or cd tools ability to setup monitoring of cloud based solutions excellent communication and presentation skills in english. french is an asset. nice to have experience with distributed solutions experience with high availability and high throughput architecture experience with big data solutions experience with leading on premises cloud solutions such as mesos and kubernetes can build poc to demonstrate new tools, versions or opportunities. an obsession with security and vulnerability testing as an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees in this role, you may be exposed to adult content","['kubernetes', 'python', 'high availability', 'cd', 'devops', 'data services', 'computer vision', 'ci', 'data science', 'high throughput data solutions', 'software development', 'security', 'aws', 'java']","['kubernetes', 'high availability', 'python', 'aws engine', 'big data', 'java']","['cd', 'devops', 'data services', 'computer vision', 'ci', 'data science', 'high throughput', 'software development', 'security', 'vulnerability testing']","['product quality', 'environment', 'events', 'architecture']"
520,745,Data Management Specialist - Immunotoxicology,"for 70 years, charles river employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. when you join our family, you will have a significant impact on the health and well being of people across the globe. whether your background is in life sciences, finance, it, sales or another area, your skills will play an important role in the work we perform. in return, we ll help you build a career that you can feel passionate about. important in order to be considered for this position, a resume or cv must be uploaded and submitted during the application process. please make sure work history and education are added correctly. job summary support the scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with good laboratory practices , standard operating procedures , analytical procedures , and study plans. we are currently looking for a data management specialist for our immunotoxicology group located in senneville, qc. the following are responsibilities related to the position contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. follow and ensure the application of glp, sops, special procedures and health and safety rules on their assigned studies. perform and review tabulation of results and participate in writing the study report. collaborate with the scientist to compile and assemble study deliverables in an audit ready state for submission to the quality assurance department and answer qa findings. preparing or revision of the study summary when required. perform all other related duties as assigned. the following are minimum qualifications related to the senior analyst position dec in sciences or aec an equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above. be able to work as part of a team. have a positive attitude, good interpersonal relationships and professionalism. adapt to changes. actively participate in departmental meetings to improve performance and quality. good understanding of microsoft office software and data generating software used in the department relevant to their role. important a resume is required to be considered for this position. if you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume or cv. about safety assessment charles river is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state of the art facilities and expert regulatory guidance. from individual specialty toxicology and ind enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. each year approximately 120 investigational new drug programs are conducted in our safety assessment facilities.","['quality assurance', 'software', 'documentation', 'data management', 'quality control']","['documentation', 'quality assurance']","['software', 'data management', 'quality control']","['and safety', 'education', 'glp', 'forms', 'sales', 'finance', 'life sciences', 'immunotoxicology', 'microsoft office', 'art', 'toxicology', 'design', 'drug development', 'assessment', 'safety']"
521,746,SAS Data Engineering Consultant,"we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are as a sas engineer, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. you will play an active role throughout the entire engagement cycle, specializing in modern data solutions including designing and delivering performant business intelligence sas applications to our clients by supporting our engagement teams in collaboration with the project manager. you are enthusiastic about all things data, statistics, data mining, customer intelligence and advanced analytics. if you have strong problem solving and analytical skills, are tech savvy and have a solid understanding of software development, then this role may be for you. in this role, you will deliver proof on concepts using appropriate sas technology support analysis, design, development and testing phases document business processes, business requirements and system requirements provide specifications for etl or any service oriented dataflow support sas cloud strategy database design for the following solutions customer intelligence, in memory analytics, customer intelligence and marketing intelligence support integrated and uat testing performance tuning support the project manager and the scrum master define good development practices and methodology for the team guide developers throughout the development phases deploy solutions in regards to our client s devops approach participate in project proposals and rfi participate in business development activities here s what you need bachelor s degree in computer science strong working experience in an environment with sas, with 3 years of experience delivering various projects involving sas cloud analytics technologies experience in agile methodology proven design and development experience as a sas programmer in complex environments experience in developing using version control tools knowledge of ms project, any agile platforms and visio demonstrate experience in performing gap analysis and impact analysis experience supporting business users working on projects or programs involving multiple highly inter dependent applications and or or data sources demonstrated capacity to work collaboratively with client organizations ability to work with diverse remote teams ability to develop and present new ideas and conceptualize new approaches and solution proven analytical skills and systematic problem solving we are a global collective of innovators applying the new every day to improve the way the world works and lives. help us show the world what s possible as you partner with clients to unlock hidden value and deliver innovative solutions. empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. our expertise spans 40 industries across 120 countries and impacts millions of lives every day. we turn ideas into reality. to learn more about accenture, and how you will be challenged and inspired from day 1, please visit our website at accenture.ca or careers.https or or accntu.re or 2hcjdtn it is currently our objective to assign our people to work near where they live. however, given the nature of our business and our need to serve our clients our employees must be available to travel when needed. accenture does not discriminate on the basis of race, religion, color, sex, age, non disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. accenture is committed to providing employment opportunities to current or former members of the armed forces. we are committed to employment equity. we encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply. accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the world s largest delivery network accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. with 469,000 people serving clients in more than 120 countries, accenture drives innovation to improve the way the world works and lives. visit us at","['https', 'analytical skills', 'visio', 'working experience', 'performance tuning', 'statistics', 'system requirements', 'database design', 'software development', 'analytics', 'sas', 'cloud', 'customer', 'data mining', 'machine learning', 'testing', 'scrum', 'specifications', 'gap analysis', 'business intelligence', 'automation', 'devops', 'data solutions', 'computer science', 'technology solutions', 'version control', 'etl', 'ai']","['https', 'technology solutions', 'visio', 'business intelligence', 'sas']","['analytical skills', 'working experience', 'performance tuning', 'statistics', 'version control tools', 'system requirements', 'database design', 'software development', 'aimo', 'analytics', 'customer', 'data mining', 'machine learning', 'testing', 'scrum', 'specifications', 'gap analysis', 'automation', 'devops', 'data solutions', 'computer science', 'methodology', 'etl', 'ai']","['business development', 'environment', 'professional services', 'marketing', 'design', 'consulting', 'business', 'law', 'architecture']"
522,747,Intermediate Data Engineer,"about clir we are on a mission to minimize humankind s impact on the climate. we do this by turning renewable energy data into action. we have global growth across 15 countries and 4 continents, with growth of 300 per year. founded in canada we are continuously expanding with team members located in north america, europe, and south america. guided by our core values, we are passionate, excited, and determined to fulfill our mission about the role we are focused on changing the renewable energy industry and as an intermediate data engineer you will have an opportunity to be part of this mission. we are looking for a candidate who wants to do work that has an impact, not just in the industry but also on the environment. your ability to ask questions, solve problems, and be an integral part of an open and collaborative team will be a catalyst for your success. who you are passionate about our core values excited about the opportunity to join the new and growing data team and champion data driven decision making throughout the company team focused, collaborative, and eager to learn motivated to work in an environment where everyone is focused on creating value for our customers comfortable with focusing among multiple competing priorities and approaching hard questions through a lens of curiosity what you ll be doing design, develop, implement and test new data pipelines and data infrastructure as part of your team maintain and improve the performance of existing data pipelines and data infrastructure communicate with management and colleagues on a regular basis recommend and implement improvements to existing data pipelines, data infrastructure, and team processes mentor and support developers on your team and across the company what you ll need 2 years of hands on development experience implementing successful, robust, and secure features and systems, preferably in the data domain strong, applied knowledge of at least one modern programming language experience in delivering written and verbal technical feedback in form of code reviews to peers familiarity with effective agile and software development practices such as scrum or kanban, ci or cd, test automation, infrastructure as code bonus experience with any of python, go, aws systems, relational databases experience with data engineering tools airflow, docker, database build tool , spark, kafka experience with a data warehouse bigquery, redhsift, snowflake. experience working in a startup environment experience with data analysis and interest in machine learning familiarity with data visualization and charting tools what s in it for you opportunity to work in an inclusive and diverse workplace be part of a team who are focused on reducing our impact on the environment a chance to grow your skills and career alongside a supportive team of mentorship focused developers medical insurance dental care professional development benefits flexible schedule work from home friendly at clir renewables, diversity and inclusion are not words we take lightly. these are words we take to heart, we drive to better understand our biases, and recognize that we have more work to do to create a workforce that truly represents those who our product serves. we strongly encourage applicants of all genders, ages, ethnicities, cultures, abilities, sexual orientations, and life experiences to apply. as a partially remote organization, clir works hard to ensure the safety of all clients and employees through the authentication of prospective employees and their backgrounds. successful candidates may be subject to a background check conducted by clir, and will need to demonstrate the legal right to work in canada, the uk, or any area in which they wish to conduct work by showing proof of a valid work permit, visa, residency, or citizenship.","['go', 'data infrastructure', 'ci', 'data visualization', 'authentication', 'python', 'kanban', 'cd', 'software development', 'programming', 'aws', 'data engineering', 'machine learning', 'data pipelines', 'relational databases', 'scrum', 'data analysis', 'automation', 'airflow', 'snowflake']","['go', 'python', 'programming', 'aws', 'snowflake', 'airflow']","['kanban', 'machine learning', 'data pipelines', 'cd', 'test', 'relational databases', 'software development practices', 'scrum', 'data infrastructure', 'ci', 'data visualization', 'authentication', 'data analysis', 'data engineering', 'infrastructure as code', 'automation']","['environment', 'design', 'renewable energy industry', 'renewable energy', 'insurance']"
523,748,Cloud Data Platform Senior Delivery Lead,"cloud data platform senior delivery lead and architect about capco capco is a distinctly and positively different place to work. much more than consultants, we are active participants in the global financial services industry. our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. we are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in banking, capital markets, finance risk compliance, insurance, and wealth and investment management. experience capco for yourself at capco.com let s talk about you you want to own your career. you re serious about rising as far and as fast as your work and achievements can take you. and you re ready to write the next chapter of your career story a challenging and rewarding role as a capco cloud data platform senior delivery lead and architect. let s get down to business capco is seeking talented, innovative, and creative individuals to join our cloud practice, to help our customers become successful in their cloud journey. about the role capco is seeking talented, innovative, and creative individuals to join our data practice, to help our customers become successful in their data transformation and cloud journeys. as a cloud data platform senior delivery lead and architect, you will be an integral part of the data and cloud practices, working with other like minded individuals. you will get involved in projects ranging from cloud data strategy, architecture, and migration. our solution leads are talented, innovative, and creative individuals who bring with them diverse experience and skillsets related to data, cloud and and devsecops practices. about you experience as a capco cloud data platform senior delivery lead and architect you lead the strategy, design and implementation of cloud based data platforms running on aws, gcp or azure. you have 8 10 years of experience delivering data solutions including 4 5 years in big data and cloud based technologies. you take ownership of data solution architecture, in conjunction with other associated teams. you are comfortable in your ability to consult on the administration, monitoring, and deployment of large scale data systems and services on the cloud. you can collaborate closely with our clients and facilitate across both the business and technology on solution requirements and delivery. you can provide support and leadership to capco s data practice community. you can lead capco data analysts, data engineers, and data scientists to create and operationalize dynamic data model pipelines with automated provisioning of workloads. you can collaborate closely with business on consumption requirements and interpret these into data platform strategy, design and execution. you have successfully conquered processing and transformation of massive data through machine learning models and have familiarity using spark based solutions like databricks. you are familiar and have hands on knowledge in setting up data related solutions using platforms like snowflake. you have extensive experience with data processing and engineering tools, such as kafka, informatica, and talend. you have experience with employing automated testing solutions for data migrations to the cloud. you have deep experience implementing data governance and data quality solutions. you have a solid understanding of devops automaton principles to automate repetitive tasks and requests. you bring with you experience working with ci or cd pipelines related to data applications, scripts and service or tools instantiation and configurations. you are well versed in various monitoring communication channels, tools, and related systems to ensure stability, health, and performance of the cloud data solution and infrastructure. you have a good awareness and application of various data security standards, including pci dss, fips 140 2, nist 800 171, gdpr and others. you have a good understanding and know how to leverage tools, such as tableau for data visualization. as a leader in the capco data practice you are self motivated, pro active and have a team player attitude. you can understand and communicate complex solutions to both business and technology stakeholders. you can effectively organize and prioritize your workload. you possess excellent oral, listening, and written communication skills. you operate with an automation first mind set and are obsessed with continuous growth and improvement. you deliver on your commitments and are a great collaborator while also confident in your individual abilities. you bring new ideas to the team, are known to be a good problem solver, take time to validate your own ideas and help shape other s. you continue to build your awareness, understanding and experiment with new technologies in the data, cloud and financial services industries. you have excellent people skills with ability to lead by example and motivate team members. you are quick, but methodical, and able to function in a fast paced environment while following best practices and organizational processes. professional experience is important. but it s paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. from day one, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage. now take the next step if you re looking forward to progressing your career with us, then we re looking forward to receiving your application. capco is well known for its thought leadership and client centric model that distinguishes it from other consulting firms. capco s strong technology and digital knowledge base, it s global experience of the financial service enables us to deliver projects from strategy through to delivery. we are committed to providing new areas of expertise from which our clients will greatly benefit. we have access to industry focused talent globally ability to leverage best of breed, innovative products and solutions for complex architecture and large scale transformation extended global geographic market reach ability to capitalize on our client footprint and deep domain expertise within financial services for more information about capco, visit capco is an equal opportunity employer. we evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.","['devsecops', 'tableau', 'ci', 'data visualization', 'big data', 'gcp', 'data processing', 'cd', 'talend', 'data', 'aws', 'data systems', 'pipelines', 'solver', 'investment management', 'machine learning', 'informatica', 'provisioning', 'data transformation', 'testing', 'data quality', 'automation', 'administration', 'banking', 'devops', 'data solutions', 'security', 'snowflake']","['solver', 'gcp', 'provisioning', 'devsecops', 'pipelines', 'tableau', 'talend', 'data', 'big data', 'aws', 'cap', 'data quality', 'snowflake']","['investment', 'ci', 'data visualization', 'gdpr', 'data processing', 'cd', 'data', 'data systems', 'dss', 'machine learning', 'informatica', 'data transformation', 'testing', 'model pipelines', 'automation', 'administration', 'banking', 'devops', 'data solutions', 'security', 'solution']","['environment', 'risk compliance', 'design', 'finance', 'governance', 'consulting', 'financial services', 'capital markets', 'architecture', 'insurance']"
524,749,Senior AI Research Scientist – Machine Learning & eXplainable Artificial Intelligence (XAI) (Principal level position also available),"company description the bosch research and technology center north america with offices in sunnyvale, california, pittsburgh, pennsylvania and cambridge, massachusetts is part of the global bosch group is committed to providing technologies and system solutions for various bosch business fields primarily in the areas of human machine collaboration , robotics, energy technologies, internet technologies, circuit design, semiconductors and wireless, and mems advanced design. the focus of our global research on human machine collaboration includes big data visual analytics, explainable ai, audio analytics, nlp, conversational ai, mixed reality and smart wearables, etc. we develop intuitive, interactive and intelligent solutions to enable inspiring ux for bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems , industry 4.0 and internet of things , security systems, smart home and building solutions, health care, and robotics. as a part of the global research unit, our visual analytics explainable ai group is responsible for shaping the future industrial ai experience for bosch products and services by combining cutting edge technologies of machine learning, data analysis and interactive visualization. we research and develop scalable, transparent, and intelligent big data analytic solutions for various domains including industry 4.0 , iot, autonomous driving, connected vehicles, etc. with our award winning talents , we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., ieee vis, tvcg, sigkdd, neurips, aaai, icml, icassp, interspeech, and ieee signal processing magazine. job description conduct research and engineering in explainable ai and machine learning for related business domains of autonomous driving, connected vehicles, industry 4.0, iot, car multimedia etc. work with an international team of experts to transfer the results of advanced research to bosch business units. when necessary, build prototypes to verify research ideas. apply research results to real world use cases with high quality implementation. integrate the resulting systems or software into existing bosch platforms. actively scout for the latest technology and predict market trends by monitoring news, technical events and seminars. provide expert opinions on relevant technology areas to management team to facilitate strategic planning, r d roadmap development, and business investment. summarize research findings in high quality paper and or or patent submissions. qualifications basic qualifications ph.d in computer science or related fields 3 years of research experience or equivalent graduate research experience for explainable artificial intelligence , machine learning and deep learning 2 years of industry experience in r d for deep learning, explainable artificial intelligence algorithms systems experience with one or more programming languages for machine learning applications preferred qualifications strong publication records in top venues of machine learning, deep learning and computer vision deep knowledge in machine learning and deep learning, with applications to explainable ai, computer vision, high dimensional data analysis, and event sequence mining familiar with one or more main stream machine learning platforms knowledge in full stack web development on both frontend and backend good communication and teamwork skills strong leadership skills to drive research topics additional information bosch is a proud supporter of stem initiatives first robotics awim by choice, we are committed to a diverse workforce eoe or protected veteran or disabled.","['visualization', 'robotics', 'big data', 'software', 'computer vision', 'analytics', 'r', 'machine learning', 'iot', 'audio', 'artificial intelligence', 'data analysis', 'algorithms', 'visual', 'deep learning', 'ux', 'signal processing', 'internet of things', 'programming languages', 'nlp', 'system', 'web development', 'computer science', 'ai']","['internet of things', 'programming languages', 'iot', 'nlp', 'system', 'robotics', 'big data', 'r']","['visualization', 'security systems', 'software', 'computer vision', 'analytics', 'conversational', 'machine learning', 'artificial intelligence', 'data analysis', 'algorithms', 'visual', 'planning', 'deep learning', 'ux', 'signal processing', 'use cases', 'strategic', 'web development', 'computer science', 'ai']","['events', 'business units', 'design', 'infotainment']"
525,750,Data Science Manager - (Spendscape),"the data science manager oversees all data, analytics, experimentations and insights across spendscape inc. identify future product opportunities and drive efforts to determine and implement new ideas, consulting service, and key metrics and the levers to influence them. the incumbent applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex, high volume data from a variety of sources. analyzes large quantities of data and presents insights and predictions to support management planning, execution and monitoring of business decisions. this role will collaborate with various groups across moneris and spendscape to build accurate and effective data analytics products. the incumbent will be a creator and leader of external analytics and data products to support commercialization of data. key accountabilities include develops agreed analytical solution by applying suitable statistical machine learning techniques to test, verify, refine hypotheses. deliver better predictions and or or intelligent automation that enables smarter business decisions, and drive productivity applies strong communication and story telling skills to summarize findings, draw business conclusions, and present actionable insight in a way that resonates with business or groups. applying new and cutting edge methodologies in order to create new data products. lead and leverage analytics and insights to advance the commercialization and monetization of data. identify industry insights and business trends to provide business opportunity for spendscape to expand consumption, commercialization and monetization of data. partner with engineers to ensure that data is appropriately identified, recorded, transformed, and furnished for consumption collaborate with developers, sales, and other data scientists to embed data science findings within analysis and reporting. evangelize the power of analytics to improve the business and its operation. additionally, the information collected is used to comply and facilitate all legal and regulatory requirements. data science manager applies expertise and thinks creatively to address unique or ambiguous situations and to find solutions to problems that can be complex and non routine. lead the development of statistical models to extract trends, measure results, and predict future performance of our product. comply with corporate policies established by moneris corporation including but not limited to code of conduct, technology policy privacy policy. designation post secondary education in data science, computer science, mathematics, statistics, or engineering, ideally with a masters in one of these fields preferred, phd considered an asset 5 7 years of experience in a programming role involving statistical modelling and machine learning minimum experience, technical skills ability to understand complex business problems and break down analytics projects into a structured approach. explaining complex terms in simple language programming preferably with r, python, and sql experience in deployment of models in a production environment such as azure and databricks proficient with microsoft windows or ms office applications fluent in english though bilingualism in french considered an asset. develops and fosters exceptional relationships across various stakeholders, including senior management. dedicated and committed to our customers. highly developed and proven consulting, change management, project management and strategic thinking capability soft skills passionate with a deeply analytical mindset strong written and verbal communication skills. excellent time management ability to manage multiple priorities in an agile environment with ability to meet time compressed deadlines. a team player that can support the team to accomplish our mission to be a world class company driven by data.","['data analytics', 'python', 'machine learning', 'business analysis', 'statistics', 'sql', 'agile environment', 'data products', 'reporting', 'data science', 'windows', 'computer science', 'analytics', 'mathematics', 'programming', 'modeling', 'automation', 'r']","['sql', 'python', 'windows', 'programming', 'language', 'r']","['data analytics', 'agile environment', 'machine learning', 'business analysis', 'statistics', 'data products', 'reporting', 'data science', 'computer science', 'analytics', 'mathematics', 'predictive', 'modeling', 'automation', 'planning']","['key', 'environment', 'change management', 'regulatory requirements', 'education', 'metrics', 'commercialization', 'sales', 'project management', 'consulting', 'business trends']"
526,756,"Senior Manager, Data Science (DOE)","about judi.ai smart analytics that grow customer relationships there has never been a better time to redefine small business lending. judi.ai is at the forefront of the smb lending space, providing a software platform that makes it easy for credit unions and community banks to digitally transform lending processes, become smarter lenders and build deeper relationships with their small business customers. at judi.ai, we find ways to supplement traditional credit data sources to make better informed credit decisions. apply ai and machine learning to risk detection logic, enabling loan providers to lend more with less risk. continuously assess the financial health of small business loan recipients to provide valuable post lending advice and business growth insights when they are needed the most. the result is small business lending redefined as fast, less risky and more profitable for everyone. judi.ai pledges 1 of our equity, revenue, time and product to not for profits of our customers choice. about our team unique thinkers. game changing attitudes. judi.ai is home to entrepreneurs, rainmakers and data wizards a family of financial analysts, software developers, data scientists, marketers and salespeople. we are also home to a collaborative group of musicians, skiers, acrobats, runners, kite boarders, sailors and yogis. we are a small company of about 15 employees in downtown vancouver with team members also located in toronto. our management team comes from a range of high growth and blue chip technology companies like nokia, paypal, visioncritical, blastradius and diply. about the role a key piece of our puzzle the senior manager, data science will be the senior leadership role on the data science team. the role will report to the head of product engineering and will manage the data and analytics team. the successful candidate will lead all analytics initiatives at judi.ai, and will work closely with the product and development teams to implement and apply state of the art technologies and methodologies to credit decisioning. additionally, this person will plan conceive and prioritize data projects across the organization. identify new data sources and evaluate emerging technologies and analytic trends for data discovery and visualization. conduct proof of concept studies for new functionality build, manage execute provide hands on leadership and oversight of data science and analytics. support recruitment and training of a team specialized in advance analytics and data science. lead projects connecting business needs to analytics and development applying best practices for artificial intelligence and machine learning. establish analytical standards and best practices across the enterprise. support model governance programs, from designing to testing, validation and monitoring. oversee documentation to outline data sources, transformations, models and implementation. coordinate, communicate lead partner across teams and coordinate stakeholder expectations to support interpreting and analyzing data challenges. work closely with judi s executive team to support the long term vision of the company and manage resources. act as a thought leader on the subject both externally and internally communicate analytics and data science findings to executives, clients and internal teams. about you a resilient company builder you are looking to join on a journey with a team dedicated to building something amazing from the ground floor. you enjoy and can envision the rewards from an early stage company and overcoming the struggles inherent in our position you see opportunity early and are relentless in the face of obstacles. you get up quickly when knocked down, because getting knocked down is part of company building. if it were easy everyone would be doing it. you are entrepreneurial, agile, and nimble a get your hands dirty team player. key capabilities have demonstrated business acumen and a proven track record of achieving commercial value through the application of advanced analytics are a leader, communicator, and collaborator and you re entrepreneurial, agile and nimble a get your hands dirty team player. your qualifications m.s. or ph.d. in a quantitative discipline . 2 5 years of professional experience in data analytics and related projects. preferred prior experience in the financial services experience strong quantitative or statistical modelling and programming skills. hands on coding skills with python, r, unix scripting. familiarity with query languages like sql experience building and leading data science teams. deep knowledge of supervised and unsupervised regression and classification techniques, such as neural networks, decision trees, clustering, boosting, svm, and nlp. experience working in an agile environment with frequent, incremental coding, testing and deployment.","['visualization', 'documentation', 'less', 'data analytics', 'forefront', 'python', 'sql', 'agile environment', 'software', 'scripting', 'decision trees', 'data science', 'unix', 'analytics', 'programming', 'machine learning', 'ai', 'proof of concept', 'testing', 'product engineering', 'artificial intelligence', 'model', 'neural networks', 'nlp', 'risk', 'r']","['sql', 'forefront', 'python', 'judi', 'nlp', 'unix', 'documentation', 'programming', 'less', 'ju', 'r']","['visualization', 'data analytics', 'agile environment', 'software', 'scripting', 'decision trees', 'data science', 'analytics', 'data', 'machine learning', 'proof of concept', 'testing', 'product engineering', 'artificial intelligence', 'model', 'risk detection', 'neural networks', 'query languages', 'sv', 'ai']","['validation', 'art', 'governance', 'financial services', 'functionality', 'lending', 'small', 'business growth']"
527,758,Cloud Data Consulting Sr Manager,"cloud data consulting sr manager location toronto or montreal or ottawa we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are a big data and cloud leader someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. you re passionate about digital technology, and you take pride in making a tangible difference. you have communication and people skills in spades, along with strong leadership chops. complex issues don t faze you thanks to your razor sharp critical thinking skills. working in an information systems environment makes you more than happy. work you ll do cloud data consulting architects at the senior manager level will be responsible for providing solutions to digital age data challenges in multiple industries through architecture, design and implementation of an ecosystem of big data, nosql, self service data preparation, ai, machine learning and other modern data technologies on cloud and also on prem. the solutions typically will include re engineering the data acquisition, storage, processing, security, data management, governance and analysis using these technologies leading to the implementation of a modern data platform. a solid experience and understanding of considerations for planning, scaling, deployment and operations that are unique to big data, nosql and other emerging modern data technologies is required. we are looking for candidates who have a broad set of skills across these areas and who can demonstrate an ability to identify and apply modern data and cloud technologies to architect and implement innovative and differentiated data solutions. our architects are expected to work with our clients in defining the future state architectures of their data platforms enabling analytical intelligence and then play a lead role to implement a roadmap to reach that state basic qualifications bachelor s degree in computer science, engineering, technical science or 8 years of it or programming experience minimum 5 years of architecting, implementing and successfully operationalizing large scale data solutions in production environments using big data and nosql ecosystem on premise or on cloud using many of the relevant technologies such as nifi, spark, kafka, hbase, hive, cassandra, emr, kinesis, bigquery, dataproc, databricks, azure data lake etc. minimum 5 years of architecting data and building performant data models at scale for hadoop or nosql ecosystem of data stores to support different business consumption patterns off a centralized data platform minimum 5 years of spark or pyspark processing, including java, python, scala, talend for data analysis of production big data applications minimum 5 years of architecting and industrializing data lakes or real time platforms for an enterprise enabling business applications and usage at scale minimum 5 years designing and implementing relational data models working with rdbms and understanding of the challenges in these environments bilingual french an asset bonus points minimum 4 years of experience implementing large scale secure cloud data solutions using aws data and analytics services e.g. s3, emr, redshift or minimum 4 years of experience implementing large scale secure cloud data solutions using google data and analytics services e.g. bigquery, dataproc or minimum 4 years of experience implementing large scale secure cloud data solutions using azure data and analytics services e.g. databricks, adls or minimum 4 years of experience building data management and governance solutions for modern data platforms that use hadoop and nosql on premise or on azure, aws, google and azure cloud minimum 4 years of experience securing modern data platforms on premise or on aws, google, azure cloud","['emr', 'pyspark', 'rdbms', 'big data', 'google', 'hive', 'java', 'python', 'data acquisition', 'scala', 'talend', 'analytics', 'data', 'digital', 'programming', 'data models', 'aws', 'nosql', 'machine learning', 'data preparation', 'data analysis', 'automation', 'cassandra', 'azure', 'hadoop', 'technical', 'information systems', 'security', 'data solutions', 'computer science', 'data management', 'nosqlbase', 'ai']","['emr', 'pyspark', 'rdbms', 'data lakes', 'big data', 'google data', 'hive', 'java', 'python', 'scala', 'talend', 'programming', 'digital', 'aws', 'data models', 'nosql', 'cassandra', 'hadoop', 'azure data lake']","['machine learning', 'data preparation', 'data acquisition', 'technical science', 'information systems', 'security', 'data solutions', 'computer science', 'analytics', 'data', 'planning', 'data analysis', 'data management', 'and', 'automation', 'aimo', 'ai']","['environment', 'design', 'governance', 'consulting', 'business applications', 'architecture']"
528,760,Machine Learning Data Engineer,"join our vancouver area sports tech venture bringing the worlds most advanced player or puck tracking system to hockey leagues across the globe. we re looking for a proven machine learning data engineer to join our talented team in building etl data pipelines, stat identification models and real time analytics apps. if you have passion for building quality systems, who likes to mix their passion of data with sports and the upside of owning equity in a high potential startup sports tech company, we would like to hear from you. we are offering a starting salary plus a healthy share options grant to own part of the venture as an early employee, and cash in on a future valuation. join us on our path as a key team member to becoming a world hockey data leader with our patent pending sensor based hockey tracking . job type permanent salary 60,000.00 70,000.00 per year benefits dental care extended health care flexible schedule stock options schedule monday to friday covid 19 considerations work from home during covid is ok, future work is in our r d lab. application question what interests you about working within the sports tech industry experience machine learning 2 years work remotely temporarily due to covid 19","['machine learning', 'data pipelines', 'analytics', 'valuation', 'etl']",['r'],"['machine learning', 'data pipelines', 'analytics', 'valuation', 'etl']",[]
529,761,"Senior Data Engineer (Marketing, Sales & Finance)","since being founded in 2011, prodigy education has grown from 3,000 local users to more than 100 million registered users worldwide. as one of the fastest growing edtech startups in north america, prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. anyone with an internet connection is welcome to create a free account for prodigy s popular math game for grades 1 to 8. prodigy education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. for more information visit our passion is our mission to help every student in the world love learning here at prodigy, we are working hard to achieve our mission of helping every child in the world to love learning. our data team is responsible for all aspects of data ingestion, storage, transformation, and analysis using modern tools and environments such as spark, databricks, dbt, airflow, snowflake, periscope, kafka, and aws. you will be working alongside our data engineering, data science, and data analysis teams to help build and manage all of our data pipelines and high quality datasets, focusing on our financial and payments domains. your impact create and manage key business data pipelines and high quality datasets work with stakeholders including the executive, product, data, and design teams to assist with data acquisition and data related technical issues, and other analytics needs. work cross functionally to explore and propose solutions to business problems that can be addressed using insights from data create and optimize data tools for analytics and data scientist team members that assist them in building our product into an innovative industry leader. support the development of new solutions for batch, real time data, and analytics use cases that align with business requirements maintain and troubleshoot the infrastructure built for optimal extraction, transformation, and loading of data from a wide variety of data sources identify, design, and implement process improvements automate manual processes, optimize data delivery, improve data reliability, efficiency, and quality, etc. build analytics tools that utilize the data pipeline to provide actionable insights into student learning, customer acquisition, operational efficiency, and other key metrics. aid in improving our data architecture and keeping our current architecture up to modern standards and best practices who you are at least 3 years of experience in data engineering. working familiarity with a variety of different storage mechanisms including sql nosql databases, data warehouses, and data lakes. experience working with aws cloud platforms and related systems experience building and optimizing data pipelines, architectures, and data sets. experience with big data tools databricks, spark, dbt, etc and how they fit into an overall data architecture. experience with data pipeline and workflow management tools, such as airflow experience with real time data processing and stream processing systems kafka, spark streaming, etc. experience in requirements analysis, design, implementation, and testing of software solutions, especially data related, using python, scala, and or or other programming languages a successful history of manipulating, processing, and extracting value from large disconnected datasets, especially related to financial, marketing, and sales data. experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. experience implementing backend data apis using nodejs, python, or other programming languages strong project management, organizational, and communication skills. university degree in engineering, computer science, stats, mathematics. a graduate degree in data science related discipline is a strong asset our core technologies data tools kinesis, lambda, kubernetes, ecs, dbt storage s3, snowflake, delta, postgres aurora, dynamodb coding world libs python, javascript , spark platforms aws, persicope, databricks, snowflake what we offer a culture of transparency, where team members are involved in important conversations full health benefits from day one for you and your family, fully covered we are a profitable company, with eligibility to participate in stock options for all full time permanent employees learning and development budget for all full time employees to use towards career growth and development opportunities we recognize 9 5 is not for everyone we offer flexible working hours that will allow you to schedule your workday with a bit more freedom while we operate 100 remotely, for the time being, we understand the importance of togetherness. we offer frequent and fun team and company events, to stay connected and in the know. please note during the covid 19 pandemic, in order to keep all our candidates and team members safe, prodigy is operating, hiring and onboarding 100 remotely for the time being. come as you are. we believe the power of our collective potential will transform education. we are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. we welcome applications from people from all underrepresented groups, including people of any gender, age, or religion, members of the lgbtqia2 community, bipoc and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of prodigy education. if you feel like you don t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we d still love for you to apply we are an equal opportunity employer and are committed to providing employment accommodation in accordance with the ontario human rights code and the accessibility for ontarians with disabilities act, 2005 . prodigy education will provide accommodations to job applicants with disabilities throughout the recruitment process. if you require accommodation, please notify us and we will work with you to meet your needs.","['databases', 'requirements analysis', 'workflow management', 'operational efficiency', 'big', 'software solutions', 'javascript', 'kubernetes', 'sql', 'python', 'data processing', 'data acquisition', 'scala', 'data science', 'analytics', 'data', 'aws', 'data engineering', 'nosql', 'data pipelines', 'testing', 'stream processing', 'data analysis', 'rest', 'edtech', 'airflow', 'programming languages', 'datasets', 'computer science', 'mathematics', 'ecs', 'snowflake', 'root cause analysis']","['kubernetes', 'sql', 'python', 'databases', 'programming languages', 'scala', 'data lakes', 'aws', 'big data', 'ecs', 'javascript', 'snowflake', 'nosql', 'airflow']","['requirements analysis', 'workflow management', 'operational efficiency', 'software solutions', 'data processing', 'data acquisition', 'data science', 'analytics', 'data', 'data engineering', 'data pipelines', 'data ingestion', 'testing', 'stream processing', 'data analysis', 'rest', 'edtech', 'use cases', 'datasets', 'computer science', 'mathematics', 'root cause analysis']","['events', 'dbt', 'education', 'metrics', 'marketing', 'onboarding', 'design', 'sales', 'project management', 'startups', 'hiring', 'architecture']"
530,762,Senior Data Analyst,"job requisition id 21wd48199 position overview autodesk is seeking an experienced data analyst to join the data science team in our data platform and insights group. the data platform and insights group is chartered with building innovative data products and analytics solutions for autodesk s strategy, marketing, sales and customer support teams. data analysts will play a critical role in discovering and communicating data driven insights to inspire product improvements. responsibilities leverage data mining techniques to find key business insights partner with data scientists to improve data science models collaborate with product managers to explore new product ideas or enhancements build reporting to measure progress in key initiatives become an expert in autodesk data work as an individual contributor with opportunities for management as we grow the team minimum qualifications 4 years in an analyst role strong sql coding skills and comfortable using it every day experience working with unstructured data experience working in python or r experience building data visualizations via python or r or a business intelligence tool preferred qualifications familiarity with data science concepts experience working in git experience using big data platforms a or b testing experience ideal candidate user design or front end development experience have interest in learning about data science have a strong attention to detail and care deeply about data quality proactively reach out to stakeholders to understand data better enjoy collaborating with team members to drive impact are a strong communicator you can adjust communication for technical stakeholders and non technical stakeholders at autodesk, we re building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. we also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law. are you an existing contractor or consultant with autodesk please search for open jobs and apply internally . if you have any questions or require support, contact autodesk careers .","['unstructured data', 'data mining', 'sql', 'python', 'user', 'data products', 'reporting', 'business insights', 'testing', 'data science', 'git', 'analytics', 'big data', 'business intelligence', 'data quality', 'r']","['sql', 'python', 'business insights', 'git', 'big data', 'business intelligence', 'data quality', 'r']","['unstructured data', 'data mining', 'data products', 'reporting', 'testing', 'data science', 'analytics']","['marketing', 'design', 'sales', 'user design', 'customer support', 'law']"
531,763,Intermediate Software Engineer - Data Applications,"xero is a beautiful, easy to use platform that helps small businesses and their accounting and bookkeeping advisors grow and thrive. at xero, our purpose is to make life better for people in small business, their advisors, and communities around the world. this purpose sits at the centre of everything we do. we support our people to do the best work of their lives so that they can help small businesses succeed through better tools, information and connections. because when they succeed they make a difference, and when millions of small businesses are making a difference, the world is a more beautiful place. about the team the data team is responsible for driving the adoption of data driven decision making across xero for both our internal users and our global audience of small business owners, bookkeepers and accountants. we create, manage and deliver a wide range of data services including machine learning toolsets, frameworks api prediction services, core reporting, key data dimensions, extensible and scalable analytical data processing and storage facilities. we are the centre of expertise for data architecture, data modeling, machine learning, ethical data usage and artificial intelligence service design. we also lead the work to raise the data and ai literacy levels across xero with a particular focus on the product management and engineering cohorts globally. about the role as an intermediate software engineer in the data team you will work closely with applied scientists, and data engineers to design and build the data pipelines and applications that will enable xero to bring intelligent, insightful products and beautiful experiences to millions of customers around the world. you will have a strong interest in building machine learning applications that can run and evolve at scale leveraging microservices and the latest technologies. what you ll do collaborate with colleagues from the science, evaluation measurement and data enrichment teams to build end to end machine learning pipelines for training and inference at scale. monitor, maintain and support the solutions you build including being part of an on call roster should an urgent issue come up. work with colleagues to maintain and operate the data team s pipelines, with an emphasis on monitoring for changes in data quality from ideation to production enable the development of easy to use infrastructure, tooling and monitoring for data applications and reproducible data science workflows stay current with emerging practices, techniques and frameworks in the fields of applied machine learning and artificial intelligence at scale. mentor and develop members of your team, increasing our capability to build and operate intelligent, data driven, products and services in our core customer offerings champion the ethical development of data processing systems which include ml or ai components and ensure your teams are always working with the best interests of our users in mind. what you ll bring with you proven experience in operating at an intermediate technical level. track record of solving customers problems through software. excellent written and verbal communication skills appreciation of best practices for building production grade maintainable web services experience coding in production and knowledge of application architecture experience working within commercial software development teams. understanding of sql and designing data models.working with infrastructure as code eg cloudformation, terraform, kubernetes. ideally you will also have demonstrable experience in developing both training and inference systems for machine learning pipelines at scale. why xero at xero, we are empowered to bring our whole self to work. our collaborative and inclusive culture is one we re immensely proud of. we know that a diverse workforce is a strength that enables businesses, including ours, to better understand and serve customers, attract top talent and innovate. we care about learning together and celebrate our teams continuous improvement and career development. we offer a great remuneration package, including compelling benefits and perks, like xero shares. we also support flexible working arrangements that allow you to balance your work, your life and your passions. our canadian xero family includes hubdoc, an automated data capture platform and we have offices in toronto, calgary, and vancouver. from the moment you step through our doors, you ll feel welcome and supported to do the best work of your life.","['prediction', 'data services', 'terraform', 'sql', 'kubernetes', 'data processing', 'software', 'reporting', 'data science', 'software development', 'data', 'product management', 'data models', 'pipelines', 'application', 'microservices', 'machine learning', 'data pipelines', 'web services', 'artificial intelligence', 'xero', 'api', 'modeling', 'ai']","['terraform', 'sql', 'kubernetes', 'api', 'data models', 'pipelines', 'xero']","['prediction', 'data services', 'data applications', 'data processing', 'software', 'reporting', 'data science', 'software development', 'data', 'product management', 'application', 'microservices', 'infrastructure as code', 'machine learning', 'data pipelines', 'web services', 'artificial intelligence', 'modeling', 'ai']","['continuous improvement', 'accounting', 'design', 'adoption', 'bookkeeping', 'architecture']"
532,764,Senior Engineer / Scientist - Remediation Practitioner,"if you are looking for a home for the best years of your career, where you can contribute to a dynamic employee owned firm, tackle challenging project work, and collaborate with industry recognized professionals, geosyntec is the place for you we are seeking an exceptional senior remediation practitioner with site investigation and remediation experience to grow our remediation and mining practices in our saskatoon, sk office and to help us lead, manage, and grow our practice in western canada. this individual should be interested in being a leader and contributing to innovative and challenging projects, including the financial and technical evaluation, design, permitting, and construction stages. our client base includes a diverse mix of industrial, institutional, and governmental clients. as a firm, we offer a breadth of services. in the mining sector our focus includes source evaluation, mine permitting, geotechnical engineering, tailings and mine waste engineering, water resource management, water treatment and complementary treatability testing, closure and reclamation, and corporate social responsibility or environmental social governance. our regional focus is on environmental services including geochemistry characterization and modelling, site wide water quality and water balance models, innovative water treatment and source control solutions, treatability and leachate testing , integrated closure planning and mine closure requirements. in the industrial sector, we focus on developing and implementing leading edge remedial solutions for soil and groundwater impacted sites. we collaborate with industry and academia to ensure that our clients get the best value possible. petroleum, chlorinated solvent, nitrate, pesticide, fertilizers, metals and emerging contaminants such as fluorinated organics are driving our practice. our clients ask us to address their new ventures and most challenging problems involving the environment, natural resources, and civil infrastructure. geosyntec is internationally known for its technical leadership, broad experience, and exceptional client service. learn more by visiting us at essential duties and responsibilities task and project management, including planning and implementing investigation and remediation projects, budgeting and budget management, adherence to schedule, quality, client satisfaction, and profitability. business development including bringing in new clients and obtaining repeat business from existing clients, leading proposal preparation, and developing and implementing a business development plan. management and mentoring of junior staff and managing subcontractors. work plan development, data evaluation, and report writing. preparing technical reports, letters, memoranda, plans, specifications, and proposals. reviewing and managing written document production. preparing for and participating in meetings with clients, regulatory personnel, and other parties. collaboration and mentoring are cornerstones of geosyntec s culture. we operate under a sell manage do culture, and so we expect that you d work on challenging technical projects while leveraging your existing knowledge and experience to help geosyntec expand its current practices and capabilities through business development and client management. you may also be asked to take on project management responsibilities, along with staff management and mentoring tasks. here are some other things you should know about this position training this position requires osha or msha health and safety, first aid, and cpr training and medical monitoring, paid for by the firm. we also offer professional development opportunities including technical conferences, in house seminars, webinars, and mentoring, that allow our professionals to build the technical and business skills necessary to become successful consultants. fieldwork and overnight travel up to 20 your success is our success. we encourage our professionals to continually develop their interests and skills. advancement is based on an individual s own performance and initiative. education and licensure bachelor s degree in engineering, environmental, civil, chemical, water resource, hydrogeology or geochemistry. advanced degree in the same. professional geoscientist or engineer registration in the province of saskatchewan, british columbia, alberta or ontario. project management certification, business development training, and leadership training. regional visibility through involvement in professional associations or trade organizations. skills, experience and qualifications at least 8 years of direct environmental consulting experience in the canadian and or or u.s. marketplace, or equivalent combination of education and experience. 8 years of experience in contaminated site assessment and remediation. mining experience. an entrepreneurial attitude and enthusiasm for supporting business development and technical efforts to expand geosyntec s market share are valued assets. thorough knowledge and experience with local regulations, and good relationships with regulators and indigenous groups. experience with multi disciplinary project teams. demonstrated success in the development and management of clients. excellent leadership skills. ability to succeed in a fast paced consulting environment, handling multiple project assignments, meeting strict deadlines, and traveling to client facilities as needed. current osha 4 hr hazwoper training and refreshers. valid canadian driver s license and a satisfactory driving record for business travel. culture or eeo statement geosyntec strives to hire and retain the best and brightest people in their fields. we look for exceptional interpersonal skills, communication skills, and problem solving abilities, plus the passion for technical excellence and quality. we seek individuals with leadership potential, a commitment to lifelong learning and growth, and the desire to build a long and rewarding career with a growing firm. geosyntec is a great place to build a career. if you re looking for an exciting place to work, a place with challenging and rewarding projects, and a place that has been nationally recognized for its employees quality of life, technical expertise, and business success, then geosyntec may be the place for you. you can learn more about careers and employment at geosyntec by visiting http or or or careers or geosyntec offers excellent compensation packages commensurate with experience, along with a comprehensive employee benefits package.","['budgeting', 'testing', 'site', 'market share', 'specifications', 'project work', 'remediation', 'technical leadership', 'technical reports', 'investigation', 'cpr']",['market share'],"['budgeting', 'testing', 'remediation', 'report', 'specifications', 'geotechnical engineering', 'project work', 'http', 'cpr', 'technical leadership', 'technical reports', 'investigation', 'planning']","['business development', 'environment', 'first aid', 'regulations', 'project management', 'resource management', 'employee benefits', 'and', 'hr', 'and safety', 'education', 'characterization', 'waste engineering', 'governance', 'consulting', 'assessment', 'design', 'new ventures', 'budget management', 'construction', 'water', 'compensation', 'environmental', 'proposal preparation', 'environmentalge', 'business travel', 'staff management', 'mentoring']"
533,765,"Manager, Data Science Engineering","this role will start off as work from home, gradually you will be required to work in the markham office location. join an exciting team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. the insurance industry is undergoing a transformation and you get to be in the driver s seat during this data driven, technology revolution. you will be part of a dynamic small team with exposure to different business stakeholders and direct influence on future products and innovative solutions. you will help build the foundation that enables our team to bring insights to the business and impact millions of customers. the team has already developed algorithms that are used in production systems and you will be part of the team that expands the scope of these algorithms. this is your chance to join the insuretech revolution your responsibilities as an engineering manager, you will provide technical leadership to build, develop and scale engineering teams influence and guide strategy, execution and innovation for key engineering projects. champion top software engineering practices such as continuous integration, testing, and deployment. use your expertise in software development, python, data science or data engineering to propose new and innovative solutions to the many interesting problems we work on. provide engineering and architecture oversight for new build infrastructure. drive projects forward, manage priorities with senior leadership and keep all stakeholders updated. recruit and hire top talent to support one or more engineering missions what you need to succeed you will need the following skills and experience to succeed in the role 5 years of experience managing engineering teams 10 years of relevant engineering experience great leadership skills coupled with technical expertise. the ideal candidate has a strong understanding of technical systems and is also able to jump in to help with coding or implementation tasks experience leading full stack engineering teams through the full software life cycle. a proven track record in successfully delivering moderate to complex agile projects excellent interpersonal relations and demonstrated ability to work with others effectively excellent interpersonal and communication skills ability to encourage and motivate team members what sets you apart strong background in software development with a good understanding of machine learning and ai. experience with python, hadoop, spark, aws, postgresql, kuberneties and docker are an asset. you understand the relationship between analytics and business outcomes and can focus on long term strategies for our team. aviva canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. if you require an accommodation because of a disability, we will work with you to meet your needs. applicants need to make their needs known in advance. if you are selected for an interview and require an accommodation, you are encouraged to advise the talent acquisition partner who will consult with you to determine an appropriate accommodation. we are an equal opportunity employer and value diversity at our company. we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status","['technical leadership', 'forefront', 'python', 'postgresql', 'software', 'data science', 'software development', 'kuberneties', 'analytics', 'integration', 'software life cycle', 'aws', 'data engineering', 'machine learning', 'testing', 'production systems', 'algorithms', 'hadoop', 'ai']","['python', 'forefront', 'postgresql', 'hadoop', 'kuberneties', 'aws', 'production systems']","['machine learning', 'continuous', 'software', 'testing', 'data science', 'software development', 'analytics', 'integration', 'software life cycle', 'data engineering', 'algorithms', 'technical leadership', 'ai']","['actuaries', 'hiring', 'architecture', 'insurance industry']"
534,766,Data Engineer(AWS / Pyspark),"job details job title data engineer job location mississauga ,on experience in building large scale batch and data pipelines with data processing frameworks in aws cloud platform using pyspark glue deep experience in developing data processing data manipulation tasks using pyspark such as reading data from external sources merge data perform data enrichment and load in to target data destinations proficiency with big data processing technologies hadoop hive or databricks experience in deployment and operationalizing the code using ci cd tools bitbucket and bamboo experience with sql and relational databases strong aws cloud computing experience extensive experience in lambda s3 emr redshift about capgemini capgemini is a global leader in consulting, digital transformation, technology and engineering services. the group is at the forefront of innovation to address the entire breadth of clients opportunities in the evolving world of cloud, digital and platforms. building on its strong 50 year heritage and deep industry specific expertise, capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. capgemini is driven by the conviction that the business value of technology comes from and through people. today, it is a multicultural company of 270,000 team members in almost 50 countries. with altran, the group reported 2019 combined revenues of 17billion what we offer your career matters to you and is important to us too. because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. this approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our university innovative and business focused learning curriculums. we promote a culture of diversity. we believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. diversity enriches our creative solutions and adds value for our clients. with the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve. our shared values have been at the heart of the group since our formation. they are honesty, boldness, trust, freedom, team spirit, modesty and fun. these values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within capgemini and in our partnerships. capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. we strongly encourage women, veterans and active military service personnel to apply. disclaimer capgemini is an equal opportunity employer encouraging diversity in the workplace. all qualified applicants will receive consideration for employment without regard to race, national origin, gender identity or expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law. this is a general description of the duties, responsibilities and qualifications required for this position. physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. whenever necessary to provide individuals with disabilities an equal employment opportunity, capgemini will consider reasonable accommodations that might involve varying job requirements and or or changing the way this job is performed, provided that such accommodations do not pose an undue hardship. click the following link for more information on your rights as an applicant http or or or resources or equal employment opportunity is the law","['glue', 'sql', 'forefront', 'data processing', 'data pipelines', 'pyspark', 'cd', 'relational databases', 'emr', 'hadoop', 'ci', 'data manipulation', 'altran', 'bitbucket', 'aws', 'cloud computing', 'hive', 'digital transformation']","['glue', 'sql', 'forefront', 'pyspark', 'emr', 'big', 'hadoop', 'data manipulation', 'bitbucket', 'aws', 'hive']","['data processing', 'relational databases', 'data pipelines', 'cd', 'ci', 'cloud computing', 'http', 'digital transformation']","['regulatory requirements', 'genetics', 'business value', 'consulting', 'environmental', 'law']"
535,769,Senior Scientist / Study Director,"bri, a frontage laboratories company, is a contract research organization located in vancouver, british columbia, canada with head office located in exton, pennsylvania, usa. bri is recruiting a study director level senior scientist to lead a team of experienced vivarium staff operating within a 3000 sf rodent vivarium in the design and conduct of the following oncology, pharmacology and immunology studies cell line derived or patient derived tumor xenograft efficacy, pharmacology, and immunology studies in vitro and in vivo pharmacological assays supporting preclinical development of oncology cytotoxic small molecules, nucleic acids and monoclonal antibodies in a separate facility led by bri s bioanalytical lc or ms or ms and elisa team, bri offers in vitro and in vivo drug metabolism or pharmacokinetics studies supporting preclinical and clinical development in a range of therapeutic areas for submissions in canada, usa, europe and japan. qualification m.sc. or ph.d. in pharmacology or a related discipline 7 years hands on experience with pharmacology, immunology or oncology 5 years supervisory experience within a research environment hands on experience in the conduct of animal models and in vitro or ex vivo assays demonstrated abilities in problem solving and troubleshooting strong written and verbal communication skills strong planning and organization abilities competent, self motivated and ability to work independently highly motivated, team player, and who enjoys a leadership role within a team of technically competent virvarium staff duties serve as a study director, functionally responsible for the overall conduct of a study including design, delivery and reporting to clients and bri management formulate and communicate project timelines, status, and data to clients provide resourceful input towards troubleshooting and resolving technical issues practice an attitude of continuous learning within a research environment to implement and expand assays and animal models capabilities manage the conduct, delivery quality and timeline of multiple projects train and mentor junior scientists within the vivarium and oncology team collaborate with the vivarium manager to ensure compliance of regulatory, health and safety operating standards of the vivarium please visit career page of our website to apply at","['clinical development', 'reporting', 'troubleshooting']",[],"['troubleshooting', 'reporting', 'planning']","['pharmacology', 'and safety', 'environment', 'immunology', 'in vitro', 'contract research', 'design', 'frontage', 'clinical development', 'antibodies vivo', 'oncology molecules', 'therapeutic areas', 'recruiting', 'oncology']"
536,770,Snowflake Data Engineer,"duration 8 months requirement years of experience 4 minimum 4 years recent experience in web development minimum 3 years recent experience in ecommerce projects. minimum 2 years recent experience in the demandware platform etc. expert in developing web applications for front end developmet proficient in managing the administration of the demandware platform in business manager current developer certification in salesforce commerce cloud b2c or demandware role description front end developer works more on the browser interaction side using javascript frameworks, advanced html, and css techniques to implement the layout and user experience specified in wireframes and psds delivered by our information architects and creative designers. this also includes the ecommerce platform technologies for static content management and server side dynamic content generation. the capgemini freelancer gateway is enabled by a cutting edge software platform that leads the contingent labor world for technology innovation. the software platform leverages machine learning and artificial intelligence to make sure the right people end up in the right job. a global leader in consulting, technology services and digital transformation, capgemini is at the forefront of innovation to address the entire breadth of clients opportunities in the evolving world of cloud, digital and platforms. building on its strong 50 year heritage and deep industry specific expertise, capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. capgemini is driven by the conviction that the business value of technology comes from and through people. it is a multicultural company of over 200,000 team members in more than 40 countries. the group reported 2018 global revenues of eur 13.2 billion.","['administration', 'forefront', 'machine learning', 'css', 'html', 'software', 'user experience', 'javascript frameworks', 'web development', 'artificial intelligence', 'web applications', 'technology services', 'digital transformation']","['forefront', 'technology services', 'javascript frameworks', 'css']","['administration', 'machine learning', 'html', 'software', 'user experience', 'web development', 'artificial intelligence', 'web applications', 'digital transformation']","['commerce', 'b2c', 'business value', 'content management', 'content', 'server side', 'consulting']"
537,771,Data Engineer - Toronto,"are you passionate about development we are looking for a passionate data engineer who will help us build the future for embedded analytics platform. this is a highly technical position in an exciting new development area we will be introducing into our retail analytics business platform. we are looking for you to help implement our web platform. you will be a key team player and an integral part of our excellent team. supported by a solid understanding of business, software architecture, software engineering and industry best practices, as well as strong hands on technical skills the data engineer is accountable to provide expert technical advice and recommend solutions to the development resources in the planning, strategizing, and the execution of high profile and complex data processing initiatives. who you are you bring positive energy to the team and thrive on strong collaboration. some others look to solve complex problems, bounce ideas off, and provide an alternate viewpoint. you are self motivated and thrive on developing solutions to open ended business problems. have 5 years of experience leading complex data architecture projects have a bachelor s degree in computer science, computer engineering, electrical engineering or other related disciplines why we need you lead the design, development and implementation of new and existing complex data processing solutions enabling teams to be more efficient and effective in analyzing data and getting to insights faster provide technical expertise and recommend data integration and management solutions to a diverse group of data analysts and data scientists as they develop best in class analytics solutions provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project reviews and approves specialized work products produced by the developer work alongside the technology team to put data processing solutions into the production environment sets standards and champions the agile process. what you ll do excellent sql coding and experience with a broad array of development tools and platforms, including a strong linux background and data integration, processing and transformation tools, such as sql, r, sas, python, etc. apply strong programming skills expertise in relational database design and data models experience with big data technologies like spark and hadoop experience with various analytical data platforms and technologies experience with using rest api, cloud experience in custom or structured data integration design, implementation, and maintenance understanding of machine learning experience with business intelligence tools such as sisense and microstrategy advantages lead the design, development and implementation of new and existing complex data processing solutions enabling teams to be more efficient and effective in analyzing data and getting to insights faster provide technical expertise and recommend data integration and management solutions to a diverse group of data analysts and data scientists as they develop best in class analytics solutions provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project responsibilities excellent sql coding and experience with a broad array of development tools and platforms, including a strong linux background and data integration, processing and transformation tools, such as sql, r, sas, python, etc. apply strong programming skills expertise in relational database design and data models experience with big data technologies like spark and hadoop experience with various analytical data platforms and technologies experience with using rest api, cloud experience in custom or structured data integration design, implementation, and maintenance understanding of machine learning experience with business intelligence tools such as sisense and microstrategy qualifications you are self motivated and thrive on developing solutions to open ended business problems. have 5 years of experience leading complex data architecture projects have a bachelor s degree in computer science, computer engineering, electrical engineering or other related disciplines summary provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project reviews and approves specialized work products produced by the developer work alongside the technology team to put data processing solutions into the production environment sets standards and champions the agile process.","['linux', 'big', 'sql', 'python', 'data processing', 'software', 'database design', 'development tools', 'data', 'analytics', 'integration', 'programming', 'data models', 'sas', 'structured', 'software architecture', 'electrical engineering', 'machine learning', 'embedded', 'computer engineering', 'business intelligence', 'rest', 'hadoop', 'api', 'computer science', 'r']","['sisense', 'sql', 'python', 'linux', 'hadoop', 'api', 'programming', 'big data', 'business intelligence', 'data models', 'sas', 'r']","['software architecture', 'electrical engineering', 'machine learning', 'data processing', 'embedded', 'software', 'computer engineering', 'database design', 'development tools', 'computer science', 'analytics', 'data', 'integration', 'agile', 'rest', 'analytical', 'structured', 'planning']","['environment', 'new', 'retail', 'design', 'microstrategy', 'architecture']"
538,772,Postdoctoral Research Scientist - Machine Learning for Audio Analytics,"company description the bosch research and technology center north america with offices in sunnyvale, california, pittsburgh, pennsylvania and cambridge, massachusetts is part of the global bosch group is committed to providing technologies and system solutions for various bosch business fields primarily in the areas of human machine collaboration , robotics, energy technologies, internet technologies, circuit design, semiconductors and wireless, and mems advanced design. the focus of our global research on human machine collaboration includes big data visual analytics, explainable ai, audio analytics, nlp, conversational ai, mixed reality and smart wearables, etc. we develop intuitive, interactive and intelligent solutions to enable inspiring ux for bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems , industry 4.0 and internet of things , security systems, smart home and building solutions, health care, and robotics. as a part of the global research unit, our visual analytics explainable ai group is responsible for shaping the future industrial ai experience for bosch products and services by combining cutting edge technologies of machine learning, data analysis and interactive visualization. we research and develop scalable, transparent, and intelligent big data analytic solutions for various domains including industry 4.0 , iot, autonomous driving, connected vehicles, etc. with our award winning talents , we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., ieee vis, tvcg, sigkdd, neurips, aaai, icml, icassp, interspeech, and ieee signal processing magazine. job description develop state of the art machine learning based audio signal processing and analysis technologies and modules collaborate with other colleagues to integrate audio signal processing and analysis modules into the prototype systems for bosch audio event detection applications and improve the performance with various technologies summarize research findings in high quality paper and or or patent submissions qualifications basic qualification ph.d. in computer science, electrical engineering or related fields experience in audio signal processing, machine learning and related fields hands on experience of audio event detection or audio scene classification technologies hands on experience of deep learning technologies and familiar with state of the art deep learning toolkits programming experience with c or c and or or python programming experience with matlab preferred qualification publication record in top machine learning and audio analytics venues . experience on noise cancellation or source separation experience on audio signal localization good communication and team working skills good leadership skills to drive research topics additional information bosch is a proud supporter of stem initiatives first robotics awim by choice, we are committed to a diverse workforce eoe or protected veteran or disabled.","['visualization', 'robotics', 'c', 'big data', 'python', 'analytics', 'programming', 'electrical engineering', 'machine learning', 'iot', 'audio', 'data analysis', 'visual', 'matlab', 'deep learning', 'ux', 'signal processing', 'internet of things', 'nlp', 'system', 'computer science', 'ai']","['python', 'internet of things', 'iot', 'nlp', 'system', 'robotics', 'c', 'programming', 'big data', 'matlab']","['conversational', 'ux', 'electrical engineering', 'machine learning', 'visualization', 'signal processing', 'deep learning', 'audio', 'computer science', 'analytics', 'data analysis', 'security systems', 'visual', 'ai']","['event', 'design', 'art', 'infotainment']"
539,774,Data Arch Strategy Manager,"data strategy manager location toronto, on we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are a curious leader who can connect and advise senior clients with storytelling and strong data driven mindset. as a manager, you will be a coach to develop our up and coming leaders in their careers, and a day to day leader of our diverse multi disciplinary workforces to solve our client s data challenges. as a data strategy manager, you will apply deep strategy development, architecting value, and operating model architecture skills to influence client agendas through business insight in a data driven reinvention and culture. you will partner with our clients to make bold decisions on priority c suite issues at the intersection of business, technology, and operations within a complex data management landscape. you will provide deep understanding of our clients industry landscape and options to mature data management practice from people, process and technology in the context of global, economic, technology and social trends. the work stream lead on short high impact data strategies for our client s senior leadership in their data organization leading small teams of motivated generalists and deep specialists day to day leader and client relationship management of diverse delivery teams working with mid level clients knowledgeable expert in data management and engineering to advise clients and accenture teams as a subject matter advisor support new sales opportunities in partnership with our diverse workforce fortify accenture s data analytics strategy practice and role as a thought leader by creating content active coach and mentor to our up and coming leaders in the practice racking up those air miles will have to wait, as weekly non essential travel to client sites is currently suspended. for now, all accenture business travel, international and domestic, is currently restricted to client essential sales or delivery activity only. here s what you need minimum 7 years of strategy consulting experience. minimum 7 years of experience in journey to cloud transformation from data strategy and data driven consulting standpoint, data driven technology roi or cost take out, data driven organization operating model, modern data engineering architecture, data driven enterprise, applied intelligence, modern data management and governance minimum 7 years of experience working with the interception of business and technology from the standpoint of various data management facets such as operating models, governance, veracity and trust, privacy etc. minimum 7 years of experience in build in trusted relationships with senior leaders at client organizations who own, steward, consume, manage and implement data management solution from both business and it. clear view on data led elements of an intelligent enterprise comprises and the business benefits therefrom practical knowledge and understanding of data and analytics role in the digital space and end to end strategy through execution cycle experience leading small high impact teams strong communication skills, an ability to write business cases, and structure solutions desire to coach and mentor others ability to travel and work in canada bonus points if you perform as a long term trusted advisor and partner by providing thought leadership for data driven consulting and profound knowledge of market trends in modern data engineering practice. you can manage budgeting and forecasting activities and build financial proposals. you have managed end to end projects and have reported and escalated to top levels.","['model', 'budgeting', 'data analytics', 'machine learning', 'data management strategies', 'data engineering', 'forecasting', 'c', 'analytics', 'data management', 'operating models', 'automation', 'ai']","['c', 'vera', 'operating models']","['model', 'budgeting', 'data analytics', 'machine learning', 'ai', 'data engineering', 'analytics', 'data management', 'and', 'forecasting', 'automation', 'aimorpes']","['new', 'business travel', 'sales', 'governance', 'consulting', 'architecture']"
540,775,Machine (deep) learning scientist for information retrieval/ Scientifique en apprentissage machine (profond) pour extraction d'information,"until sars cov 2, the fastest vaccine ever developed took about 4 years. sars cov 2 vaccines were developed in less than 12 months. imagine a world where every vaccine was developed at the speed of sars cov 2 vaccines. help genaiz make this a reality. join us. genaiz, a division of uni3t, is a young and dynamic software development company that is active in the life science and pharmaceutical industry. our mission is to increase collective well being by accelerating the creation of better products, processes and treatments, through a state of the art innovator s assistant. we are currently looking for a search engine researcher with building systems retrieving unstructured documents in response to a natural language queries to work on our genaiz search engine . as a genaiz ai researcher, you must enjoy documenting your research, sharing this knowledge and writing excellent code, while following typical agile development processes. responsibilities create knowledge and technology by owning research projects plan, propose, execute and analyze results act independently, completing each research step without significant supervision communicate and document research for technical and non technical audiences report and present research analysis or findings clearly and effectively to peers and management be a team player by participating in peer review, sharing ideas and helping everyone succeed work with the development teams to move research technology into production qualifications a master s or phd degree 5 years of industry experience on multidisciplinary research projects in either engineering or science disciplines theoretical and empirical research experience in machine learning, ai, computer science, applied mathematics, data science, or related technical fields. ml and ai is strongly preferred capable of completing research and analyzing results some experience with business team requirements experience implementation and evaluating machine learning models that meet the predefined metrics and product requirements history of working with large text, image or other datasets. experience manipulating and analyzing data from different sources able to write clean, re usable, and production ready code knowledge of statistics, linear algebra and data structures some knowledge of computational syntax, pragmatics or semantics experience building systems retrieving unstructured documents in response to a natural language query familiar with neural ranking models such as drmm, deepmatch, dssm, nrm f experience with search ranking metrics such as map, ndcg, ctr, dwell time knowledge of vector space models exposure to unsupervised document representation methods experience working with modern deep learning architectures such as lstm and transformers familiar with python, deep learning frameworks such as caffe, keras, tensorflow, pytorch, numpy and sklearn excellent written, verbal and interpersonal communication preferred qualifications phd degree experience with mongodb, git, gcp, docker, aws, k8s and micro services a background in information retrieval experience in the life sciences domain knowledge of classical nlp and information retrieval techniques such as lsa and lda benefits permanent full time position competitive base salary bonus comprehensive insurance coverage dynamic company culture with career development opportunities flexible working hours located between griffintown and the old montreal, in the cit du multim dia neighborhood, now part of montreal s holistic hub for innovation, education, and entrepreneurship the quartier de l innovation. genaiz group is an equal opportunity employer. all applicants will receive consideration for employment without regard to age, color, family or medical care leave, gender identity or expression, marital status, medical condition, national origin, physical or mental disability, political affiliation, race, religion, sex , sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. we thank all applicants for their interest, however only those candidates selected for interviews will be contacted. avant le sras cov 2, un vaccin qui tait d velopp rapidement prenait environ 4 ans. en comparaison, les vaccins contre le sras cov 2 ont t d velopp s en moins de 12 mois. imaginez un monde o chaque vaccin serait d velopp la vitesse des vaccins contre le sras cov 2... aidez genaiz faire de ce r ve une r alit . rejoignez nous maintenant genaiz, une division d uni3t, est une entreprise jeune et dynamique de d veloppement de logiciels, active dans l industrie pharmaceutique et des sciences de la vie. notre mission est d accro tre le bien tre collectif en acc l rant la cr ation de meilleurs produits, processus et traitements gr ce un assistant l innovateur la pointe de la technologie. nous recherchons actuellement un chercheur en moteur de recherche, sachant construire des syst mes qui r cup rent des documents non structur s suite des requ tes en langage naturel, afin de travailler sur notre moteur de recherche genaiz . en tant que chercheur en ia de genaiz, vous devez aimer documenter vos recherches, partager vos connaissances et crire un excellent code, tout en suivant des processus de d veloppement agiles. responsabilit s g n rer des connaissances et cr er des technologies en vous appropriant des projets de recherche planifier, proposer, ex cuter et analyser les r sultats r aliser de mani re ind pendante et proactive chaque tape de votre recherche avec un minimum de supervision communiquer facilement vos recherches or r sultats l aide de documentation pertinente devant diff rents publics avoir un bon esprit d quipe en participant activement des examens par les pairs, en partageant vos id es et en aidant vos coll gues atteindre leurs objectifs travailler de pair avec les quipes de d veloppement pour pousser la technologie de recherche en production. qualifications un dipl me de ma trise ou de doctorat plus de 5 ans d exp rience dans l industrie sur des projets de recherche multidisciplinaires, dans des disciplines scientifiques ou d ing nierie exp rience de recherche th orique et empirique en apprentissage automatique, ia, informatique, math matiques appliqu es, science des donn es ou domaines techniques connexes. une exp rience en apprentissage automatique et en ia est fortement souhait e capable de mener bien des recherches et d analyser les r sultats une certaine exp rience des exigences d quipes commerciales exp rience dans la mise en uvre et de l valuation de mod les d apprentissage automatique qui r pondent aux m triques pr d finies et aux exigences du produit exp rience de travail avec de grands ensembles de textes, d images ou d autres donn es exp rience en manipulation et analyse de donn es provenant de diff rentes sources capacit crire un code propre, r utilisable et pr t pour la production connaissance des statistiques, de l alg bre lin aire et des structures de donn es quelques connaissances en syntaxe, pragmatique ou s mantique informatique exp rience dans la construction de syst mes permettant de r cup rer des documents non structur s en r ponse une requ te en langage naturel familiarit avec les mod les de classement neuronaux tels que drmm, deepmatch, dssm, nrm f exp rience avec les m triques de classement de recherche telles que map, ndcg, ctr, dwell time connaissance des mod les d espace vectoriel familiarit avec les m thodes non supervis es de repr sentation de documents exp rience de travail avec des architectures modernes d apprentissage profond telles que lstm et transformers familiarit avec python et cadres d apprentissage profond tels que caffe, keras, tensorflow, pytorch, numpy et sklearn excellentes comp tences en communication verbale, crite et interpersonnelle qualifications pr f r es dipl me de doctorat exp rience avec mongodb, git, gcp, docker, aws, k8s et micro services une exp rience professionnelle en recherche d informations exp rience dans le domaine des sciences de la vie connaissance du nlp or tal et des techniques de recherche d information telles que lsa et lda avantages poste permanent temps plein salaire de base comp titif prime couverture d assurance compl te culture d entreprise dynamique avec des possibilit s de d veloppement de carri re horaires de travail flexibles situ entre griffintown et le vieux montr al, dans le quartier de la cit du multim dia, qui fait maintenant partie du p le holistique d innovation, d ducation et d entrepreneuriat de montr al le quartier de l innovation. le groupe genaiz est un employeur offrant l galit des chances. tous les candidats seront consid r s pour un emploi sans gard l ge, la couleur, aux cong s pour raisons familiales ou m dicales, l identit ou l expression sexuelle, l tat civil, la condition m dicale, l origine nationale, un handicap physique ou mental, l affiliation politique, la race, la religion, au sexe , l orientation sexuelle ou toute autre caract ristique prot g e par les lois, r glements et ordonnances applicables. nous remercions tous les candidats de leur int r t, mais seuls les candidats s lectionn s pour un entretien seront contact s.","['pytorch', 'tensorflow', 'space', 'documentation', 'linear algebra', 'mongodb', 'empirical research', 'less', 'map', 'python', 'gcp', 'statistics', 'keras', 'data science', 'software development', 'transformers', 'aws', 'valuation', 'r', 'machine learning', 'numpy', 'syntax', 'semantics', 'deep learning', 'data structures', 'information retrieval', 'datasets', 'pragmatics', 'git', 'nlp', 'computer science', 'applied mathematics', 'ai']","['space models', 'python', 'gcp', 'nuy', 'keras', 'pytorch', 'numpy', 'git', 'nlp', 'documentation', 'aws', 'less', 'map', 'r']","['tensorflow', 'linear algebra', 'mongodb', 'empirical research', 'statistics', 'data science', 'software development', 'transformers', 'valuation', 'machine learning', 'agile development', 'semantics', 'deep learning', 'data structures', 'information retrieval', 'datasets', 'computer science', 'applied mathematics', 'ai']","['research projects', 'commercial', 'insurance coverage', 'metrics', 'education', 'entrepreneurship', 'art', 'life sciences', 'construction', 'regulations']"
541,776,"Data Science Manager, Omnia AI","job type permanent primary location toronto, ontario, canada all available locations toronto ottawa vancouver partner with clients to solve their most complex business problems be encouraged to deepen your technical skills whatever those may be lead projects and teams to make an impact that matters are you passionate about solving complex analytical problems, learning about the latest in cutting edge ai, developing and nurturing client relationships and leading project teams if you answered yes, then we have an opportunity waiting for you what will your typical day look like as a data science manager you will assume full life cycle responsibility to lead and manage client engagements, with a focus on the consumer retail industry and lead and oversee the development of machine learning models to deliver best of breed solutions for clients business problems. you will drive growth and market eminence for the omnia ai data science practice through thought leadership and business development in the consumer retail industry. the data science manager will take a hands on role in delivering consulting services to high growth organizations with a diverse team consisting of data scientists, data architects, software developers, information designers, business or industry leaders, design analytical plans and communicate insights on client projects. you will also be providing mentorship to team of data scientists in project planning, data collection, modelling, insights development and lead development of pitches and proposal bids about the team deloitte omnia, deloitte s artificial intelligence practice is comprised of specialized experts with hands on experience, and cutting edge information assets that facilitate successful artificial intelligence transformations. we develop ai enabled solutions to address all aspects of a client s transformative journey with disciplined focus on business outcomes. enough about us, let s talk about you you are someone with 5 years of relevant work experience with applying analytics, data science and machine learning and working with data in the consumer retail industry. strong experience with machine learning agile project management end to end including planning budgeting, resourcing and delivery data science experience using python, could ml , or similar tools strong experience with other statistical analytical techniques, data mining, and predictive models database and programming languages experience and data manipulation and integration skills using sql, oracle, hadoop, nosql databases, or similar tools superior oral and written communication skills, with demonstrated ability to communicate insights to executive business audiences ba or bsc degree in computer science, applied mathematics, statistics, or related field is preferred. advanced degree is preferred why deloitte launch your career with the one firm where you can make an impact that matters in a way that you never thought possible. with endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, deloitte is the one firm for you to learn, grow, create, connect, and lead. we do this by making three commitments to you you will lead at every level we grow the world s best leaders so you can achieve the impact you seek, faster. you can work your way we give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful. you will feel included and inspired we create a deep sense of belonging where you can bring your whole self to work. the next step is yours sound like the one firm. for you at deloitte we are all about doing business inclusively that starts with having diverse colleagues of all abilities deloitte encourages applications from all qualified candidates that represents the full diversity of communities across canada. this includes candidates from indigenous communities in support of living our values and our commitments to our reconciliation action plan . we encourage you to connect with us at if you require an accommodation in the recruitment process, or need this job posting in an alternative format. we d love to hear from you by applying to this job you will be assessed against the deloitte global talent standards. we ve designed these standards to provide our clients with a consistent and exceptional deloitte experience globally. deloitte canada has 30 offices with representation across most of the country. we acknowledge our offices reside on traditional, treaty and unceded territories as part of turtle island and is still home to many first nations, m tis, and inuit peoples. we are all treaty people.","['project', 'databases', 'sql', 'python', 'statistics', 'software', 'data science', 'analytics', 'integration', 'nosql', 'budgeting', 'data mining', 'analytical techniques', 'machine learning', 'data manipulation', 'data collection', 'artificial intelligence', 'agile project management', 'programming languages', 'hadoop', 'computer science', 'applied mathematics', 'ai']","['sql', 'python', 'databases', 'programming languages', 'hadoop', 'data manipulation', 'nosql']","['budgeting', 'data mining', 'analytical techniques', 'machine learning', 'statistics', 'software', 'applied mathematics', 'data science', 'data collection', 'computer science', 'project planning', 'artificial intelligence', 'analytics', 'agile project management', 'planning', 'statistical', 'integration', 'ai']","['business development', 'retail', 'design', 'consulting', 'engagements']"
542,777,AWS Data Engineer,"senior aws data engineer, atlanta remote united states syntax is a leading managed cloud provider for mission critical enterprise applications and has been providing comprehensive technology solutions to businesses of all sizes since 1972. syntax has undisputed strength to implement and manage erp deployments in a secure, resilient, private, public or hybrid cloud. with strong technical and functional consulting services, and world class monitoring automation, they serve some of north america s largest corporations across a diverse range of industries. syntax has offices worldwide, and partners with oracle, sap, aws, microsoft, ibm and other global technology leaders. position summary we re looking for a passionate data engineer who is well versed in aws cloud technologies for etl modeling, data warehouse and data lake design or building and data movement to join our expanding bi and data analytics team this individual will be responsible for supporting existing data warehouse customers, as well as performing a senior lead role for new projects to implement various data solutions in aws. the position can be remote or in the atlanta, ga area. someday in a post covid future, a minimal amount travel may be required for this position. applicants for this role must be proficient data engineering experts already experienced in aws cloud technologies such as python, spark or pyspark, glue, redshift, s3, rds and data movement . data visualization skills in tableau or aws quicksight are a plus, but not required. this team members works primarily with aws data analytics technologies for existing projects and support customers, but also will need to regularly keep up with the ever emerging and evolving landscape of aws data offerings. responsibilities resource on various client engagement projects to implement and deliver custom data warehousing solutions help desk, trouble ticket support for our existing data warehouse managed services customers qualifications minimum two years of hands on aws data technology experience python, spark or pyspark, glue, redshift, s3, rds and data movement is well versed with the best practices of creating an aws well architected environment with the analytics lens aws certified cloud practitioner aws data analytics specialty certification possesses fantastic troubleshooting skills and ability to systematically break down problems to resolve issues and reach solutions prolific documentation author accountable to drive deliverables towards completion possesses an ethos of always striving for improvement and growth exposure to cloud based and saas data warehouse solutions experience with jd edwards and sap as a data source is a plus, but not required must possess an ethos of always striving for improvement and growth, and desire to flourish in an engaging, creative, hard working, fun loving corporate culture environment needs to be willing to constantly reinvent who they are to learn new technologies and approaches. must push beyond their current skillset and limitations. must love to learn and experiment. and not be afraid to make mistakes. the most successful candidates will regularly employ the rtfm, giyf and jfgi approaches to learning and problem solving. willingness to teach colleagues and knowledge sharing are mandatory in our work environment. you must be legally entitled to work in canada and or or in the u.s. we are unable to sponsor at this time.","['tableau', 'pyspark', 'data technology', 'data visualization', 'jd edwards', 'troubleshooting', 'erp', 'documentation', 'glue', 'data analytics', 'python', 'rt', 'enterprise', 'analytics', 'saas', 'aws', 'data engineering', 'data warehousing', 'hybrid cloud', 'syntax', 'automation', 'managed services', 'bi', 'data solutions', 'technology solutions', 'modeling', 'etl']","['glue', 'python', 'jfgi', 'tableau', 'pyspark', 'bi', 'jd edwards', 'giyf', 'erp', 'technology solutions', 'aws', 'rds', 'documentation', 'rtfm']","['data analytics', 'managed services', 'hybrid cloud', 'data solutions', 'data visualization', 'troubleshooting', 'syntax', 'enterprise applications', 'analytics', 'saas', 'modeling', 'data engineering', 'data warehousing', 'automation', 'etl']","['environment', 'private', 'functional', 'design', 'sap', 'sap culture', 'client engagement', 'consulting']"
543,778,Data Engineer/Consultant,"company description cardinal path, part of dentsu, is a leading digital analytics and digital marketing firm focused on delivering insight, understanding and outcomes that create competitive advantage for our clients. we engage at the strategic, business, and technical levels to generate tangible and quantifiable value for our partners. our clients include brands such as bridgestone, johnson and johnson, pfizer, asics and hundreds of others. cardinal path s mission is to know. to share. to be our partners competitive advantage. and our company culture reflects the importance of our people s expertise, wellness and happiness in everything we do. job description the data science consultant will have proven expertise in system architecture, database design, data integrations, and be an expert in sql and python. experience with delivering in big data platforms such as google bigquery, microsoft azure sql db or synapse, or amazon redshift is essential. expertise with traditional rdbms platforms such as sql server or oracle and nosql and hadoop environments would complement. data integration experience using etl platforms such as airflow, talend, alteryx, or fivetran is important. experience in the digital data and analytic ecosystem and intermediate knowledge in web analytic tools , and api expertise is a major plus act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts participate in product roadmap discussions and identifying key areas for improvement of products and services collect client project requirements, focusing on needs impacts and necessary technical outcomes create solution designs to solve for clients business and technical needs while keeping within budget produce documentation of data pipeline design and solution architecture for data warehousing and etl, following cardinal path s documentation standards create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security create ongoing standards and process for overall data architecture team, including developing governance, support and testing models perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps. qualifications bachelor s degree in statistics, mathematics, business analytics or related field quantitative field, required with a minimum of 3 5 years experience with database development experience with cloud or big data technologies such as bigquery, azure sql db or synapse, amazon redshift is required experience with relational database systems including sql server, oracle, mysql, postgres advanced skills in data scripting and database development technologies deep knowledge of etl tools and how they can be applied to a big data environment familiarity with analyzing digital marketing, advertising and ecommerce data api expertise for google analytics, facebook, twitter, etc. is a plus familiarity with web analytics tools such as adobe marketing cloud or google analytics experience with building and maintaining devops workflows experience with optimizing bi or visualization tools such as tableau, looker, domo or power bi experience with cloud platforms such as aws, azure, and google cloud familiar with nosql database technologies such as mongodb knowledge of technologies such as spark, hadoop, and airflow 3 years experience in marketing technology or data or analytics roles additional information we know through experience that different ideas, perspectives and backgrounds foster a stronger and more creative work environment that delivers better business results. we strive to create workplaces that reflect the clients we serve and where everyone feels empowered to bring their full, authentic selves to work. we are committed to working with our candidates from all ability levels throughout the recruitment process to ensure that they have what they need to be at their best. if you need accommodation during the application or interview process, please contact or to begin a conversation about your individual accessibility needs throughout the hiring process.","['visualization', 'business analysis', 'tableau', 'rdbms', 'big', 'alteryx', 'dashboards', 'data integrity', 'data standards', 'documentation', 'mongodb', 'business', 'mysql', 'microsoft azure', 'sql', 'python', 'looker', 'statistics', 'reporting', 'talend', 'database systems', 'database design', 'data science', 'data', 'analytics', 'integration', 'digital', 'aws', 'application development', 'data engineering', 'data warehousing', 'nosql', 'data mining', 'google analytics', 'testing', 'web', 'airflow', 'database development', 'devops', 'hadoop', 'datasets', 'security', 'api', 'system', 'bi', 'mathematics', 'azure sql', 'data management', 'etl']","['tableau', 'rdbms', 'alteryx', 'big', 'data standards', 'documentation', 'big data', 'big data bigquery', 'domo', 'mysql', 'sql', 'python', 'looker', 'talend', 'data', 'aws', 'amazon redshift', 'nosql', 'google analytics', 'microsoft azure sql redshift', 'airflow', 'bi', 'hadoop', 'api', 'azure sql']","['visualization', 'business analysis', 'exploratory', 'data integrity', 'dashboards', 'mongodb', 'business', 'statistics', 'reporting', 'scripting', 'database systems', 'data science', 'database', 'analytics', 'data', 'integration', 'application development', 'data engineering', 'data warehousing', 'data mining', 'testing', 'web', 'database development', 'devops', 'datasets', 'security', 'system', 'mathematics', 'solution', 'data management', 'etl']","['validation', 'environment', 'advertising', 'marketing', 'design', 'sales', 'adobe', 'governance', 'digital', 'hiring', 'architecture']"
544,781,Ingénieur de données I / Data Engineer I,"role and responsibilities ing nieur de donn es lorsque vous prenez l avion, peu importe la destination, il y a de fortes chances que le pilote ait t form par cae. le point focal tant les clients, l quipe acc l rateur num rique s engage rehausser l exp rience de formation afin de s assurer que les pilotes soient les meilleurs possible. voici quelques raisons pour lesquelles les employ s aiment travailler cae regardez la vid o d un or e coll gue qui partage sa passion https or or or watch v duwzmiez 9i list pl20be384270ba6c02 index 2 t 0s travail significatif qui favorise le perfectionnement professionnel possibilit de travailler dans l industrie technologique et de s y panouir environnement de travail ax sur la collaboration faire partie d une quipe haut rendement ce que nous avons offrir avantages sociaux enti rement flexibles pour que vous puissiez choisir ce qui est important retraite r gime de retraite prestations d termin es et r gime enregistr d pargne retraite collectif avantages financiers r gime d actionnariat et nombreux rabais d entreprise programmes personnels et familiaux plan de bien tre physique et prestations de maternit compl mentaires quilibre travail vie personnelle horaires flexibles et vendredis californiens toute l ann e plaisir au travail activit s sociales et communautaires tout au long de l ann e votre mission en tant qu ing nieur des donn es au sein de notre quipe de l acc l rateur num rique, votre mission est d am liorer l exp rience client en faisant la transformation des donn es dans un format pouvant tre exigeant sur un certain nombre de plans pour d autres intervenants en analyse. cela sera accompli principalement par l laboration, l entretien et la mise l essai d infrastructures destin s la production de donn es. cette quipe jouera galement un r le important dans la promotion de solutions d architecture pour des projets de science des donn es et de mod lisation avanc e. votre r le et responsabilit s principales cr er et maintenir une architecture de pipeline de donn es optimale et volutive. assembler des ensembles de donn es complexes qui respectent les exigences op rationnelles fonctionnelles et non fonctionnelles. concevoir l infrastructure requise pour l extraction, la transformation et le chargement de donn es optimaux partir d une grande vari t de sources de donn es et de technologies de donn es massives . d finir, concevoir et mettre en uvre des am liorations de processus internes l automatisation des processus manuels, l optimisation de la transmission de donn es, la nouvelle conception de l infrastructure pour une plus grande volutivit , etc. mettre au point des outils d analyse qui utilisent le pipeline de donn es pour fournir des perspectives applicables en mati re d acquisition de clients, d efficacit op rationnelle et d autres mesures cl s du rendement op rationnel. travailler avec des intervenants, y compris les quipes de la direction, de l exp rience client et de la conception pour les assister dans la r solution de questions techniques li es aux donn es et le soutien de leurs besoins en infrastructure. maintenir les donn es s par es et en s curit travers les fronti res nationales par l entremise de plusieurs centres de donn es. travailler avec des experts en donn es et en analyse pour parvenir une meilleure fonctionnalit de nos syst mes de donn es. tre un agent de changement et un promoteur de la mentalit agile contribuer au milieu de travail collaboratif et stimulant se garder l aff t des nouvelles tendances et apporter des id es d innovation vos qualifications baccalaur at en informatique, en ing nierie ou un domaine connexe au moins trois ans d exp rience dans l industrie en mati re de travail avec des donn es, de code, de cr ation de scripts , de conception, et de mise l essai au moins trois ans d exp rience en mati re d laboration et d administration de gros syst mes de donn es solides connaissances des principes fondamentaux du soutien la client le en mati re d algorithmes et de structures de donn es. exp rience en soutien et en travail avec des quipes interfonctionnelles dans un environnement dynamique exp rience en utilisation d outils de traitement de donn es massives hadoop, spark, kafka, etc. exp rience en utilisation de bases de donn es relationnelles sql et nosql, y compris postgres et cassandra. exp rience en utilisation de pipelines de donn es et d outils de gestion du flux de travail azkaban, luigi, airflow , etc. exp rience en utilisation de services infonuagiques aws ec2, emr, rds, redshift exp rience en utilisation de services infonuagiques microsoft azure, databrick , etc. exp rience en utilisation de syst mes de traitement de flux storm, spark streaming, etc. exp rience en utilisation de langages de script orient s objet et fonction d objet python, java, c , scala, etc. volont de participer tous les niveaux de l ex cution des travaux li s un projet, au besoin excellentes aptitudes pour la communication verbale et crite, en fran ais et en anglais cae, il est tr s important de cr er des liens avec les gens. si vous avez des questions au sujet de cette possibilit de carri re, n h sitez pas communiquer avec camille launay, sp cialiste de l acquisition de talents ou feriel hadjloum, gestionnaire de produits num riques . joignez vous au moteur de changement cae notre prochain horizon de croissance passe avant tout par l innovation num rique afin d appuyer la r ussite de nos clients. li cl1 data engineer if you ve taken a plane to any destination in the world, chances are, your pilot was trained by cae. with its strong customer focus, the digital accelerator team is dedicated to elevating the training experience to make pilots the best they can be. here are few reasons why folks love working at cae watch the video of a colleague sharing his or her passion https or or or watch v duwzmiez 9i list pl20be384270ba6c02 index 2 t 0s meaningful work that drives professional development ability to enter and grow within the technology industry work in a collaborative environment be part of a high performance team what we have to offer benefits fully flexible for you to choose what is important retirement defined benefits retirement plan group reg istered retirement savings plan financial perks employee stock purchase plan numerous corporate discounts personal and family programs physical wellness plan supplementary maternity plan work life balance flextime california fridays all year fun at work social and community events all year round your mission as a data engineer you will be asked to transform data into a format that can be consuming for other analytics stakeholders. this should be accomplished mainly through developing, maintenance and testing infrastructure for data generation. you will also play an instrumental role enabling architecture solutions for data science and advance modelling projects. your role main responsibilities create and maintain optimal and scalable data pipeline architecture assemble large, complex data sets that meet functional or non functional business requirements build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and big data technologies. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. work with stakeholders including the executive, cx and design teams to assist with data related technical issues and support their data infrastructure needs. keep data separated and secure across national boundaries through multiple data centers. work with data and analytics experts to strive for greater functionality in our data systems. be a change agent agile mindset promoter contribute to the collaborative and stimulating work environment be connected to the industry to know tendencies and suggest innovative ideas your qualifications bachelor s degree in computer science, engineering, or related field a minimum of 3 years industry experience working with data, coding and scripting , design and testing a minimum of 3 years experience developing and administering large data systems solid knowledge of cs fundamentals in algorithms and data structures experience supporting and working with cross functional teams in a dynamic environment. experience with big data tools hadoop, spark, kafka, etc. experience with relational sql and nosql databases, including postgres and cassandra. experience with data pipeline and workflow management tools azkaban, luigi, airflow, etc. experience with aws cloud services ec2, emr, rds, redshift experience with microsoft cloud services azure, databrick, etc. experience with stream processing systems storm, spark streaming, etc. experience with object oriented or object function scripting languages python, java, c , scala, etc. willingness to participate in all levels of project work when necessary excellent english and french written and verbal communication skills. at cae, connecting with people is very important. if you have any questions on this career opportunity, please do not hesitate to contact camille launay , talent acquisition specialist or feriel hadjloum, digital product manager . join the engine that is changing cae, pointing towards the next horizon of growth through digital innovations to support our customers in their success. position type regular cae thanks all applicants for their interest. however, only those whose background and experience match the requirements of the role will be contacted. equal employment opportunity at cae, everyone is welcome to contribute to our success. with no exception. as captured in our overarching value one cae , we re proud to work as one passionate, boundaryless and inclusive team. at cae, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age. the masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.","['https', 'databases', 'workflow management', 'emr', 'operational efficiency', 'data infrastructure', 'c', 'big data', 'java', 'microsoft azure', 'python', 'sqlql', 'scala', 'scripting', 'data science', 'analytics', 'aws', 'data systems', 'pipelines', 'nosql', 'testing', 'stream processing', 'data centers', 'project work', 'algorithms', 'cassandra', 'airflow', 'cloud services', 'administration', 'data structures', 'hadoop', 'scalability', 'computer science']","['https', 'databases', 'emr', 'c', 'rds', 'big data', 'cae', 'java', 'microsoft azure', 'sql', 'azka', 'python', 'scala', 'azkaban', 'aws', 'pipelines', 'nosql', 'data centers', 'databrick', 'cassandra', 'airflow', 'hadoop', 'nos', 'r']","['workflow management', 'operational efficiency', 'data infrastructure', 'cae', 'scripting', 'ca', 'data science', 'analytics', 'data systems', 'testing', 'stream processing', 'project work', 'algorithms', 'cloud services', 'administration', 'data structures', 'scalability', 'computer science', 'data generation']","['environment', 'events', 'customer acquisition', 'metrics', 'design', 'retirement', 'functionality', 'business performance', 'architecture']"
545,782,"Senior Scientist, Virology (Laval)","with unrivaled expertise in immunology, and operating sites in north america and europe, nexelis is a leading provider of assay development and advanced laboratory testing services in the infectious diseases, metabolic diseases, and oncology fields. our versatile team of scientists, working with our advanced technology platforms, were instrumental in the development, qualification, validation, and large scale sample testing of assays that supported the fda filing of almost 100 new molecular entities, including blockbuster vaccines, anti viral drugs, and immunotherapy, gene and cell therapy products. we are currently looking for a motivated candidate with experience to fill the senior scientist, virology position. this position reports to the associate director, laboratory operations. the scientist will have extensive expertise in virology, will be responsible to perform assay development, qualification and validation of virology assays. position responsibilities supervise and perform the development, qualification and validation of assays to assess the immune responses to various vaccine or drug candidates prepare presentations of scientific data for internal and external discussions prepare qualification or validation plans and reports, procedures that meet standards of written scientific standards and comply with nexelis quality assurance and operations standards and the client specific requirements conduct literature searches of science or medical search engines and libraries troubleshoot technical issues related to the assays provide mentoring or training over research associates and technical staff be compliant to all applicable regulations and biosafety or ehs standards ensure optimization of operational efficiency in the lab may interact with clients, business development, account management and operations management to support commercial proposals in terms of scientific design and lab workload assumptions. experience and qualifications expert of cell based assays for neutralizing antibody detection proficiency in immunoassays and or or immunogenicity based methodologies knowledge and experience in method development and validation of immunogenicity assays proven leadership and management skills team player, client oriented and strong organizational skills proficient with office tools . at least 3 to 5 year s experience in a cro and or or a pharmaceutical company excellent french and english, written and spoken. education m.sc. or ph.d. in virology or immunology.","['quality assurance', 'testing', 'operational efficiency', 'search engines', 'optimization', 'technology']","['search engines', 'quality assurance']","['scientific', 'testing', 'operational efficiency', 'optimization']","['business development', 'account management', 'fda', 'cro', 'educationrology', 'operations management', 'vaccinesmun', 'validation', 'presentations', 'design', 'assay', 'immunology', 'molecular', 'ehs', 'laboratory', 'oncology', 'regulations', 'therapy', 'virology', 'mentoring']"
546,783,Senior Scientist (Laval),"should you consider yourself to be among the best senior scientist in town, here is your chance to participate in the daily life of the most successful advanced testing service provider in the immunology field. involved in more than 15 sars cov 2 vaccine developments in partnership with multinational pharmaceutical companies, innovative biotechnology companies and prestigious ngos such as bill and melinda gates foundation or cepi, we also proudly serve the needs of our clients in fields such as flu , meningitis, respiratory syncytial virus, chikungunya, malaria, or hpv and are growing an immune oncology franchise. position responsibilities plans, organizes, and supervises and work on the execution of preclinical studies performs and provides direction for establishing, designing and executing new assay in response to the needs of clients. provides support to technical staff in executing and documentation of data in reports supervises and prepares advanced data analysis, merging and transforming files and data, and identification of outliers for further study. independently performs statistical tests as required for the assigned project, to study outliers, or to answer questions writes reports and bring scientific insight on complex research questions develops, writes and reviews assay methods and ensures good execution in the lab facilitates internal and external working relationships and communications promotes teamwork and cooperation among laboratory staff provides leadership or mentoring or training over technical staff serves as back up and help to the laboratory in routine testing as designated relays information in a timely manner to supervisory personnel regarding problems that may impact the laboratory s ability to meet expected service and turn around time works on assignments that are complex in nature where considerable judgment and initiative are required in resolving problems and making recommendations supervise, coordinates and mentor on a day to day basis in the context of a project coordinate and monitor projects on a daily basis to ensure that deadlines are met performs scientific review follow all applicable procedures and escalates any potential issue, deviation, ideas for improvement to operations management to ensure project execution efficiency performs other duties related to laboratory performance and efficiency as the need arises. experience and qualifications knowledge skills advanced specialized knowledge of theories and principles of immune read out well developed skills using office productivity applications such as spreadsheets, data reduction and statistical applications, and presentation graphics advanced math skills to conduct tests and analyze the significance of preclinical tests and statistical data additional knowledge of statistical methods, including computer aided statistical software well developed human relations skills to convey scientific concepts and consult with a range of internal and external contacts in formal settings for purposes of testing, conversion of data, and problem solving. abilities perform the functions of the position, including planning, testing, and reporting may analyze and interpret complex readouts from multiple assays think independently and resolve complex problems without supervision or guidance know how to operate the computers, operating systems, peripherals, and other equipment used by the company for information retrieval, storage, analysis, and processing work collaboratively, follow logical progressions of testing projects and to think logically, creatively, and in abstract terms employ critical thinking and evaluation techniques when developing and testing significance of scientific and research oriented data analyze and solve technical problems under time pressure. education masters in a biological science or equivalent at least 5 years of laboratory experience in the context of cro preclinical work.","['data reduction', 'software', 'information retrieval', 'testing', 'reporting', 'statistical', 'hpv', 'documentation', 'graphics', 'data analysis', 'operating systems', 'spreadsheets', 'peripherals']","['spreadsheets', 'hpv', 'documentation']","['tests', 'software', 'information retrieval', 'testing', 'reporting', 'data analysis', 'statistical', 'operating systems', 'graphics', 'peripherals', 'planning']","['operations management', 'immunology', 'education', 'biotechnology', 'human relations', 'oncology', 'developments', 'mentoring']"
547,786,Azure Data Engineer,"primary skills in depth project experience in hadoop and azure cloud technologies experience in ingestion of batch and streaming data with complex transformations using apache kafka, apache spark, scala, hive sql, shell script. work directly with business users and convert use cases into solutions independently. experience in working with very large volume of log data and building analytical insights based on user requirements experience in handling semi structured data in various data formats and manipulate data in complex data types. secondary skills knowledge on devops tools and experience in building ci or cd pipelines on azure. write programs to pull data from external applications and services using rest api with different authentication methods. knowledge on nosql database types like document and graph db is a plus. knowledge on machine learning libraries for data science and analytics is a plus. has worked in agile methodologies certification azure data engineer job type full time salary 79,138.00 104,618.00 per year application question do you have a linkedin account, if so drop the link below speak with the employer 91 19259518576","['project', 'ci', 'authentication', 'hive', 'sql', 'cd', 'scala', 'data science', 'analytics', 'pipelines', 'nosql', 'machine learning', 'apache spark', 'rest', 'user requirements', 'apache kafka', 'agile methodologies', 'devops', 'hadoop', 'api']","['sql', 'nosql', 'scala', 'apache spark', 'hadoop', 'shell script', 'api', 'pipelines', 'hive', 'apache kafka']","['agile methodologies', 'use cases', 'machine learning', 'cd', 'devops', 'ci', 'authentication', 'data science', 'analytics', 'rest', 'user requirements']",['linkedin']
548,788,Lead Data Engineer / Director,"are you looking for unlimited opportunities to develop and succeed with work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations. job description are you a go getter who has a passion in building next generation data solutions for business problems are you a big fan of simplification and automation are you a leader who paves the path for others within and outside your team manulife is seeking a director or lead data engineer , to join our rapidly expanding it organization and assist us as we work to be a digital leader in our industry as a lead data engineer and director, you will lead team of strong data engineers building and maintaining customer c360 platform lead the team from both technology and value perspective lead the team to deliver on prioritized roadmap that consists off both technology and business features lead the team to build innovative solutions and reduce reliance on expensive vendor products lead the team to modernize the platform, adopt cloud, simplify solutions and adopt automation lead the team to support mdm platform mentor and grow people in the team skills and experience you will have the following skills and experience expert in building and operationalizing data platforms in cloud using one of the public clouds, preferably ms azure. hands on experience in automating data pipelines, devops and cicd. experience with terraform or ansible or similar automation technology and iac. hands on experience in canary deployments, 0 downtime , 0 dataloss, hot hot dr hands on excellent with ms azure services to design a data ecosystem. hands on experience in apache data projects nifi, spark, map reduce, kafka, zookeeper, etc. hands on experience with big data streaming frameworks and tools experience in building open apis and microservices along with loosely coupled architecture. expert in developing data set processes for data modeling, mining and production hands on experience of using git flow understand different file formats and processing. excellent communication and interpersonal skills excellent analytical, problem solving and solutioning skills a capacity for constant learning from both success and failure, remaining open to change and continuous improvement nice to haves experience in exploratory data analysis query and process big data, provide reports, summarize and visualize the data experience programming in both compiled languages and scripting languages exposure to and an understanding of agile scrum methodologies and experience of working in an agile team experience in data processing, performance analysis, tuning and capacity planning experience with databricks experience with in memory datastores such as redis, used in streaming pipelines experience with implementing ml models in the stream producing alerts and enabling ai functionality. experience with traditional batch based etl processes and tools such as informatica, azure data factory, talend, pentaho or ssis. basic understanding of following will be useful but not required exposure to and basic understanding of business intelligence systems, dashboard reporting, and analytical reporting exposure to and basic understanding of collaboration tools like teams and jira what about perks manulife has lots of perks including, but not limited to competitive compensation retirement savings accounts including a rpp , rrsp , and tfsa manulife share ownership program with employer matching customizable benefits package including health, dental, vision, and 100 of mental health expenses financial support for ongoing training, learning, and education monthly innovation days wearing jeans to work every day an abundance of career paths and opportunities to advance a flexible work environment with flex hours, work from home arrangements, distributed teams, and condensed work week arrangements. this is a full time permanent role that can work from our toronto or waterloo office. if you are ready to unleash your potential, it s time to start your career with manulife or john hancock. about manulife manulife financial corporation is a leading international financial services group that helps people make their decisions easier and lives better. with our global headquarters in toronto, canada, we operate as manulife across our offices in canada, asia, and europe, and primarily as john hancock in the united states. we provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. at the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. as of december 31, 2020, we had 1.3 trillion in assets under management and administration, and in the previous 12 months we made 31.6 billion in payments to our customers. our principal operations are in asia, canada and the united states where we have served customers for more than 155years. we trade as mfc on the toronto, new york, and the philippine stock exchanges and under 945 in hong kong. manulife is an equal opportunity employer at manulife or john hancock , we embrace our diversity. we strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. we are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex , sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law. it is our priority to remove barriers to provide equal access to employment. a human resources representative will work with applicants who request a reasonable accommodation during the application process . all information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and manulife or john hancock policies . to request a reasonable accommodation in the application process, contact .","['big', 'apache', 'pentaho', 'public', 'map', 'terraform', 'data processing', 'reporting', 'scripting', 'talend', 'redis', 'data', 'programming', 'pipelines', 'microservices', 'informatica', 'data pipelines', 'scrum', 'performance analysis', 'business intelligence', 'data analysis', 'iac', 'ansible', 'automation', 'dashboard', 'administration', 'jira', 'devops', 'data solutions', 'git', 'modeling', 'capacity planning', 'analytical', 'ssis', 'etl', 'ai']","['dashboard', 'terraform', 'goter', 'jira', 'mdm', 'apache data projects', 'big', 'talend', 'git', 'redis', 'programming', 'azure data factory', 'business intelligence', 'pipelines', 'pentaho', 'ssis', 'ansible', 'map']","['exploratory', 'data streaming', 'data processing', 'reporting', 'scripting', 'data', 'microservices', 'informatica', 'data pipelines', 'scrum', 'performance analysis', 'data analysis', 'iac', 'automation', 'administration', 'devops', 'data solutions', 'modeling', 'capacity planning', 'analytical', 'etl', 'ai']","['environment', 'continuous improvement', 'mental health', 'education', 'asset management', 'human resources', 'design', 'expenses', 'retirement', 'insurance', 'financial services', 'functionality', 'compensation', 'law', 'architecture']"
549,792,Principal Scientist – Ligand Binding Assay Department,"principal scientist ligand binding assay department laval, qc, canada req 1503 wednesday, april 14, 2021 altasciences is a mid size contract research organization with a unique focus on supporting drug development from lead candidate selection to proof of concept. with over 25 years of industry experience, we provide preclinical and clinical solutions to an international customer base of biopharmaceutical companies. our full service offering in this critical stage of drug development includes program management, preclinical safety testing, clinical pharmacology services, manufacturing and analytical services, medical writing, biostatistics, data management, and bioanalysis services tailored to specific research requirements. altasciences has facilities in montreal, qc kansas city, ks, seattle, wa, and philadelphia, pa. our team is made up of over 1,300 professionals from the medical and scientific fields who work together to achieve a common goal to contribute to the advancement of life sciences. bring your talents and forward thinking approach to altasciences and help us develop medicines for those who need them, faster. the principal scientist, lba will supervise a team of scientists in the ligand binding assay department to ensure the scientific and regulatory excellence, client service, performance, productivity and efficiency of the group s operations and logistics. the principal scientist is an the expert in the field of oligonucleotides bioanalysis by hybridization elisa. he or she stays appraised of the status of all projects and recommends resource adjustment based on deliverable schedules. provides scientific and operational guidance within their area of expertise and promote efficiency initiatives that have impact on improving productivity and profitability. he or she may be assigned to projects based on scientific competency and training. main responsibilities responsible for personnel management activities of assigned staff such as scheduling, personnel actions, training and development, providing regular direction and feedback on performance, disciplinary actions and preparing and delivering annual performance and salary reviews manage direct reports to ensure project timelines are respected and communicates any delays in a prompt fashion provide scientific support to assigned bioanalytical principle investigator in the area of hybridization elisa for aso quantitation in various matrices to support both nonclinical and clinical studies responsible for set up and implementation of training for technical and scientific lba staff responsible for improved efficiency initiatives in the laboratory, including scheduling assays, operations and improving workflows review costing assessments and scheduling projects with business development and operation coordinator review forecast and identifying critical projects to maximize for revenue recognition support senior director as needed with client interactions, scientific troubleshooting and support of scientific staff contributes to the growth and development of altasciences ligand binding assay services, as well as participate in strategic planning responsible for working closely with other md management members and serve as back up when any of them is out of office can be assigned as bioanalytical principal investigator and will manage and conduct hybridization elisa method development, qualification, validation and production studies for clinical and non clinical studies in compliance with the protocol or study plan, amendments, gcp, glps, sops and best practices respecting health and safety standards in terms of personal protection, laboratory maintenance, and work procedures other related tasks. desired profile master s or bachelor s degree in biochemistry, immunology or relevant field preferred experience in regulated clinical and or or preclinical studies within the area of expertise with 5 10 years of experience in cro or pharmaceutical company or equivalent good organizational skills highly flexible and sense of urgency excellent troubleshooting skills and attentive to details client oriented and ability to coach or mentor people be able to easily read and understand study plans and protocols, good communication both written and verbal in french english. must understand general sops and have an excellent knowledge of gcp or glp regulations. altasciences is an equal opportunity employer committed to diversity and inclusion. our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. all qualified applicants will receive consideration for employment without regard to age, race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability or any other protected grounds under applicable legislation. reasonable accommodations for persons with disabilities during the recruitment process are available upon request. join us at altasciences other details job family valide positions pay type salary","['biostatistics', 'gcp', 'proof of concept', 'testing', 'matrices', 'drug', 'troubleshooting', 'data management', 'elisa']",['gcp'],"['biostatistics', 'proof of concept', 'hybridization', 'strategic', 'testing', 'matrices', 'troubleshooting', 'data management', 'planning']","['business development', 'glp', 'fashion', 'regulations', 'contract research', 'regulatory excellence', 'cro', 'and safety', 'customer base', 'drug development selection', 'legislation', 'pharmacology', 'validation', 'biochemistry', 'life sciences', 'hybrid', 'personnel management', 'drug development', 'immunology', 'program management', 'laboratory', 'manufacturing', 'salary']"
550,793,"Senior Analyst, Enterprise Data Management","senior analyst, enterprise data management equitable bank, 30 st. clair ave west, suite 700, toronto, ontario, canada req 1346 wednesday, march 24, 2021 canada s challenger bank equitable bank manages over 35 billion in assets and is a wholly owned subsidiary of equitable group inc. it was founded in 1970 as the equitable trust company and has become canada s ninth largest schedule i bank. equitable bank offers a diverse suite of residential lending, commercial lending, and savings solutions, including high interest savings products and gics. at equitable, we have no doubt that financial services are changing. consumers increasingly prefer to interact remotely through digital channels and are less likely to visit brick and mortar locations. that s why we launched eq bank in 2016. its approach to simple and convenient banking makes it a strong contender in the industry. we believe there s an opportunity for something different, to provide better service and a better deal for our customers through digital banking. job title senior analyst, enterprise data management department data management and governance reports to senior manager, enterprise data management purpose of job senior analyst of enterprise data management will have the responsibility for the design and maintenance of enterprise data warehouse for various projects, as well as providing on going support for activities impacting all enterprise databases. the incumbent will be accountable for the integrity of data, allowing for effective, accurate and timely generation of all enterprise reports. they will liaise with various development groups, business groups and customers to ensure the project related data requirements are satisfied. in addition, the incumbent will be accountable for ensuring the integrity of data, allowing for effective, accurate and timely generation of all enterprise reports. main activities business analysis participate in joint application development sessions with business units to gather and understand their data and reporting requirements play the role of data sme for initiatives liaise with the technical team to document the non functional requirements and understand system constraints document data interface requirements including but not limited to source to target mapping create test plan and execute test cases as needed develop reports based on requirements building of data models and supporting data operations design and update data models for initiatives document models and create technical documents that can be leveraged by various teams create entity relation diagrams , dfds and other data modelling diagrams as required work closely with enterprise data governance to help implement data governance policies responsible for identifying and implementing key data quality controls to support data management data strategy identify and provide recommendations for revising existing data structure as appropriate and needed assist in enablement of cloud based data and analytics support and maintenance of enterprise data warehouse support existing enterprise data warehouse objects provide data related technical support for downstream applications responsible for enhancing or creating documents for existing enterprise data warehouse objects skills or knowledge requirements 3 4 years of experience of working with data and database systems post secondary education, preferably in the areas of technology or commerce or business administration experience in integrating multiple sources into a centralized data platform or enterprise data warehouse experience in working with traditional structured row store data, semi structured and dynamic schemas such as xml, json experience with bi tools and their data needs experience in creating scalable data models supporting a wide variety of end user audience experience in writing data quality routines for cleansing of data and capturing confidence score experience identifying and defining data gaps and challenges during data migration efforts of system implementations excellent written and verbal communication skills excellent multi tasking and organizational skills excellent problem solving and analytical thinking skills excellent interpersonal skills nice to have experience with azure big data technologies experience working in financial industry experience in implementation of advanced internal ratings based approach experience in writing stored procedures, secure coding with safeguards against sql injection attacks dama certified data management professional isaca certified enterprise data management associate microsoft certified data analyst associate experience with cmmi data maturity model experience with agile and waterfall sdlc methodologies project or program or portfolio management experience familiarity with itil and it service management best practices experience with atlassian equitable bank is an equal opportunity employer and encourages applications from all qualified candidates. accommodations are available on request for candidates taking part in all aspects of the selection process. all candidates considered for hire must successfully pass a criminal background check and credit check to qualify for hire. while we appreciate your interest in applying, an equitable recruiter will only contact leading candidates whose skills and qualifications closely match the requirements of the position other details job family equitable bank pay type salary","['business analysis', 'schemas', 'enterprise data management', 'cleansing', 'big data', 'less', 'xml', 'itil', 'sql', 'enterprise databases', 'diagrams', 'reporting', 'json', 'database systems', 'enterprise', 'data', 'analytics', 'data models', 'application development', 'stored procedures', 'data migration', 'data quality', 'digital channels', 'enterprise data', 'banking', 'test cases', 'bi', 'sdlc', 'data operations', 'it service management', 'data management', 'enablement']","['sql', 'stored procedures', 'bi', 'json', 'big data', 'data models', 'less', 'data quality', 'xml']","['business analysis', 'schemas', 'enterprise data management', 'technical support', 'cleansing', 'and', 'itil', 'enterprise databases', 'diagrams', 'reporting', 'database systems', 'enterprise', 'data', 'analytics', 'application development', 'data migration', 'enterprise data', 'digital channels', 'banking', 'test cases', 'sdlc', 'data operations', 'it service management', 'data management', 'enablement']","['commerce', 'education', 'portfolio management', 'design', 'sme', 'governance', 'financial services', 'lending', 'business administration', 'business units']"
551,796,"Full Stack Developer, Data Visualization (English Services)","job family media production primary location toronto position language requirement english only language skill level language skill level language skill level status of employment contract work schedule full time please note that this is a 6 month contract opportunity. what it s like working at cbc at the cbc, we all have a story to tell. what s yours if you share our passion for canadian storytelling and you wish to help us engage with individuals and communities across our various digital platforms, this is where you ll want to be every day, you will have an opportunity to shape the way in which canadians see themselves reflected in our digital services. your work will have a direct impact on how millions of canadians from various communities connect with our products, with one another, and with the diverse voices that make our country so unique. you will have the opportunity to play a part in enlightening and entertaining canadians through our innovative work in building the mediums that deliver our content. we are an innovative hub, where the talented professionals we work with are respected and valued for their contributions. our product teams are vibrant and our work culture strives to achieve the highest standards of diversity and inclusion. we believe that hiring people with different career paths and backgrounds is fundamental in our shared success and in building healthy and highly performant teams. when you join our mission, you are not only shaping the vision of the cbc, but the future of our country. why is this role important as canada s public broadcaster, our mandate is to create content that resonates with communities across the nation. the machine intelligence retention s vision is to enable better decisions through data. our end goal is to build a product that provides information to cbc content producers about their specific audiences and the potential audiences they may reach as it relates to content creation. this is a unique opportunity that will combine your creative full stack development skills with data science. we are seeking a full stack developer to join our team as we build a data analytics platform from the ground up. this data platform will generate insights that will inform strategic content decisions across many of the cbc content areas . working in collaboration with full stack developers, product designers, data scientists and engineers, and a team of content producers, you will be fully involved in all stages of the software development lifecycle. we are looking for a team member who can bring ui or ux wireframes to life in a working application, creating an inventory of components and interfaces. this person will also be able to work though ambiguity and will show a passion for researching innovative solutions for sophisticated data displays and solving modelling challenges. here s why we should work together our digital teams values collaboration, learning, and continuous improvement embody who we are as a people focused, digital forward employer. we follow lean startup principles and use an agile approach. our dedicated people managers work closely with every individual to ensure we are leveraging their strengths, championing their ideas and supporting their pursuit of new skills and their desired career progression. here at cbc digital strategy products, we want you to be happy and feel good at work. it is essential that work be a safe space where our employees are able to share their authentic selves with one another and to push each other to challenge conventions. perks you can look forward to flexible work schedules, allowing you to prioritize yourself, your family and your work work from home opportunities competitive total rewards package 20 of time for innovation, learning and development wherever your interests lie opportunities to work with cutting edge technology opportunities for continued learning and professional development opportunities to become a member of our employee resource groups pair programming and mentorship opportunities, where you can learn from the best in the industry and help coach new talent a creative and dynamic work environment, where your ideas and contributions can be heard, valued and respected a supportive management team committed to upholding the highest standards of diversity and inclusivity an environment which favours experimentation and an iterative approach in order to achieve the highest form of technical innovation. how you will make an impact you will design, validate and develop our platform presentation layer optimized for user experience using your knowledge of data visualization and service design principles. you will drive the data to our platform by ingesting, storing, processing and analyzing big datasets. you will translate algorithmic models and analysis into visualizations that are easily understandable by non technical members of the organization you will collaborate with individuals, teams and communities of practice to ensure the highest quality product is developed and best practices are followed. you will continuously pursue knowledge through build, measure, learn processes in an agile environment and stay on top of the latest technology developments. what you could bring to our team the passion for data visualization. an understanding of front end design principles. you can implement business requirements through multiple phases of front end focused design to intuitive usage and optimal visualization. you like to experiment and explore bleeding edge technologies and techniques, and validate their effectiveness. you are comfortable with the level of ambiguity these new technologies and projects might bring. the experience. you have strong software development principles and apply them rigorously. you have worked with big data in the past and have tackled its challenges. you have extensive experience selecting and using modern tools to define and build an interface that can effectively gather, structure and process data from multiple sources, at scale. familiarity with end to end data science application development is a plus. to that end, we will be asking you to complete a timed technical assessment. we want to respect your time, evaluate your skills and ensure you have the knowledge that will enable you to thrive and grow in our environment. the education. a degree in computer science, engineering, math, or equivalent is preferred, but we know not everyone gains their programming skills this way. the technical skills. you have strong front end software development skills with at least two years experience in react and at least one year of experience integrating api endpoints and graphql. you are familiar with python and cloud services such as gcp. the bonus skills. ideally, you have an in depth understanding of the entire application flow, from the data layer to the ui. you are highly proficient with visualization libraries such as d3.js and material ui and have knowledge of data visualization or ux best practices and data modeling. to apply at the cbc, we recognize that not everyone takes the same path when it comes to building their skills. we value diversity of thought and of experience, and we are excited to hear from you hands on experience, intelligence, innovation, a passion for learning, and a team focused approach can combine to form the best set of qualifications. if you feel you meet most of the qualifications and you are excited by the possibility of adding to the rich culture of the cbc, take a chance and express your interest by applying now if you re interested in reading more about the various backgrounds of the talented people that make up our teams, our exciting new projects, and what we re currently working on, check out our digital labs blog on medium cbc or radio canada is committed to being a leader in reflecting our country s diversity. that s because we can only create and tell the stories that connect canadians, by having a workforce that mirrors the ever changing makeup of our country. that s why we, as an employer, value equal opportunity and nurture an inclusive workplace where our individual differences are not only recognized and valued, but also extend to and pervade all the services we provide as canada s public broadcaster. for more information, visit the diversity and inclusion section of our website. if you have accommodation needs at this stage of the recruitment process, please inform us as soon as possible by sending an e mail to you are invited to consult and familiarize yourself with our code of conduct, which can be found on our corporate website. all employees must adhere to the code as a condition of employment. we also invite you to take a look at our policy on conflicts of interest. in the event that you become an employee, it will be important to inform us, as quickly as possible, of any situation that, because of your hiring, constitutes or could appear to constitute a conflict of interest. if you require any type of accommodation during the hiring and interviewing process, please connect with us at job posting date jun 15, 2021, 1 50 43 pm unposting date jun 30, 2021, 1 59 00 am","['visualization', 'user experience', 'digital platforms', 'data visualization', 'big data', 'data analytics', 'interfaces', 'agile environment', 'python', 'gcp', 'data science', 'software development', 'data', 'programming', 'graphql', 'application development', 'design principles', 'digital services', 'cloud services', 'ux', 'datasets', 'technical', 'api', 'computer science', 'modeling']","['python', 'gcp', 'big', 'api', 'programming', 'big data']","['visualization', 'pair', 'user experience', 'digital platforms', 'data visualization', 'machine intelligence', 'data analytics', 'interfaces', 'agile environment', 'data science', 'software development', 'data', 'graphql', 'application development', 'design principles', 'digital services', 'cloud services', 'ux', 'datasets', 'technical', 'computer science', 'modeling']","['environment', 'continuous improvement', 'education', 'material', 'design', 'employee resource groups', 'assessment', 'hiring', 'developments', 'digital strategy']"
552,797,Exhaust Dispersion Scientist/Engineer/EIT,"do you want to be part of a team that works in a wind tunnel are you interested in air quality rwdi is seeking a motivated and dynamic individual to join our exhaust dispersion design team as a scientist or engineer or eit in the guelph office. as a member of the exhaust dispersion design team, you will solve challenging air quality design problems aimed at helping our clients design their buildings in a way that enhances safety and comfort. use, design, and maintain specialized desktop and physical dispersion modelling tools, conduct data analysis, and produce documentation that supports our clients design goals. lead technical development initiatives to advance our tools and knowledge. have an opportunity to contribute to industry via conferences and technical committees. work under the general supervision of senior staff with considerable latitude for the exercise of independent judgment. the ideal candidate will have the following qualifications keen interest in air quality issues and building design. combination of a post graduate education and experience in a science or engineering discipline with an environmental, mechanical, chemical, or meteorological focus. understanding of boundary layer fluid mechanics . knowledge of building science and building mechanical systems. experience with physical and or or numerical exhaust dispersion modeling are significant assets. strong excel skills, including vba. demonstrated initiative with ability to practically apply engineering principles. proven accountability and ownership mindset with a team focused attitude. an ability to adapt and work in a flexible, fast paced environment with minimal supervision. excellent written and verbal communication skills. creative problem solving skills and a high level of self motivation. please submit your cover letter and resume at the following link http or or rwdi.com or en ca or people or careers salary commensurate with experience thank you in advance for your application. only candidates selected for an interview will be contacted. rwdi endorses and practices the principles of equal opportunity employment. we are committed to diversity and inclusion. accommodations are available during all stages of the recruitment process in accordance with aoda and the human rights code.","['vba', 'technical', 'data analysis', 'documentation', 'modeling']","['vba', 'documentation']","['fluid mechanics', 'technical', 'data analysis', 'modeling', 'http']","['building', 'environment', 'education', 'mechanical', 'design', 'buildings', 'environmental', 'committees']"
553,800,"Senior Data Engineer, Remote","introduction as a senior data engineer, you will be a member of a fast paced software engineering team consisting of open minded and highly skilled individuals, that designs and continuously delivers a wide range of data analytics services for both clients and business partners. company infostrux is a select snowflake services partner building and operating reliable as code data cloud solutions for business intelligence, data analytics, and data product use cases. position overview participate in analysis, design and implementation of data analytics solutions suggest reusable patterns and process improvements to be implemented across the whole organization follow the trends and newest technologies in data architecture and data methodologies and bring them to practice where appropriate qualifications passion for data and engineering excellence experience building solutions based on formal and less formal data architectures, methodologies, designs and processes 7 years of hands on experience building data solutions using a variety of traditional and big data technologies 2 years of hands on experience building data solutions in aws, azure and or or gcp software engineering experience desired snowflake, fivetran, dbt python, javascript, kotlin or java aws redshift, kinesis, s3, azure synapse, sql, databricks, data lake gen2, stream analytics, apache spark, kafka, presto, airflow ml or ai devops, cloud infrastructure","['big', 'less', 'javascript', 'java', 'data analytics', 'python', 'gcp', 'sql', 'kotlin', 'software', 'data', 'analytics', 'aws', 'apache spark', 'business intelligence', 'airflow', 'devops', 'data solutions', 'cloud infrastructure', 'snowflake', 'ai']","['sql', 'python', 'gcp', 'kotlin', 'apache spark', 'java', 'big data', 'business intelligence', 'aws', 'less', 'javascript', 'snowflake', 'airflow']","['data analytics', 'use cases', 'software', 'devops', 'data solutions', 'data', 'analytics', 'cloud infrastructure', 'ai']","['dbt', 'design', 'architecture']"
554,806,Senior Food Scientist,"the senior food scientist is responsible for researching and conducting experiments, gathering data, developing preliminary findings and preparing written reports for the development of new products and reformulating of existing products to improve quality and or or margins. this position is designed with an emphasis on developing and demonstrating technical expertise in food product development. assists in keeping nature s path on the leading edge of new product development leads product development projects steps from concept through commercialization. researches new and current raw materials and applications. develop new product prototypes for presentation to management and marketing. organizes and participates in project presentations to brand management. independently designs, plans, and executes experiments. independently conducts plant trials and oversees new product start ups. interprets experimental results, provides recommendations, and implements next steps. keeps informed on current developments in the food industry, new technologies, and innovative ingredients. works with cross functional teams to accomplish project objectives with little or no support. manages multiple projects simultaneously, ensuring timely completion of project objectives in a fast paced environment. ensures operational standards for quality, cost, lean manufacture, food safety and sustainability improves existing products by optimizing product attributes . assists in cost containment and quality standards of ingredients by researching vendors and alternate suppliers. creates new product documentation including processing parameters, ingredient specifications, nutritional information, and disposition of final product. works with operations to optimize run parameters. participates in ongoing product shelf life testing of all new and revised products. leads the submissions for third party lab testing as per protocol. leads operation meetings to ensure documentation and review of pre and post new product runs. assists in the assurance of customer satisfaction with quality, consistent products determines optimal final product specifications for new product development. enters and tracks nutritional information using the genesis program to assure accuracy of nutritional facts for new product packaging. maintains up to date knowledge of all legal requirements for packaging changes. education bachelor degree in food science, or related degree, from a recognized university or college with relevant food science work experience. experience respect for or experience in the whole health or natural organics industry desirable. brings a solution focused approach to innovation and problem solving minimum 5 years of product development, r d experience from concept to commercialization able to accurately prepare specifications, label declarations and formulations strong business acumen and demonstrate business knowledge by leading discussion and direction on project work with the organization able to identify opportunities and exhibit high energy and a willingness to be involved. knowledge in food chemistry and statistical analysis as used in designing experiments and measuring process capabilities cereal extrusion, baking, and tortilla chip manufacturing experience desirable.","['testing', 'chemistry', 'specifications', 'documentation', 'project work', 'sustainability', 'statistical analysis', 'r']","['documentation', 'r']","['testing', 'chemistry', 'specifications', 'project work', 'sustainability', 'statistical analysis']","['brand management', 'environment', 'raw materials', 'education', 'food safety', 'commercialization', 'marketing', 'business knowledge', 'presentations', 'product development projects', 'food industry', 'food science', 'customer satisfaction', 'legal', 'product development', 'manufacturing', 'developments']"
555,807,Senior Clinical Quantitative Scientist - Oncology Data Analytics,"bayer is a global enterprise with core competencies in the life science fields of health care and agriculture. its products and services are designed to benefit people and improve their quality of life. at bayer you have the opportunity to be part of a culture where we value the passion of our employees to innovate and give them the power to change senior clinical quantitative scientist oncology data analytics your tasks and responsibilities the primary responsibilities of this role, senior clinical quantitative scientist oncology data analytics, are to develop and implement sound scientific approaches and technology to robustly evaluate the safety and benefit risk profile of cancer drugs based on data from clinical trials, spontaneous reports and real world in collaboration with clinical, regulatory and other strategic functions analyze clinical and molecular data from cancer patients to identify new scientific insights key tasks define and execute analysis plans to address scientific questions using clinical trial data develop and implement modern and innovative quantitative methodologies including modeling and simulation to solve complex problems analyze clinical and molecular data from cancer patients to gain new scientific insights and assist drug development explore quantitative models and tools to enable data driven decision making by testing and prototyping supervise development of quantitative tools to be used across the organization effectively communicate scientific findings to other clinical operations departments stay abreast of current and emerging quantitative methodologies and tools and provide assessment and recommendations lead programming activities to develop and validate exploratory and interactive data analysis packages needed for clinical studies and projects in collaboration with responsible statistician who you are your success will be driven by your demonstrations of our life values. more specifically related to this position, bayer seeks an incumbent who possess the following ms or phd in a relevant quantitative discipline or a degree in cancer biology, immunology, or molecular biology combined with significant previous experience with data analysis min. 2 years of relevant statistical analysis experience in the pharmaceutical, biotechnological, academic, or research institutes or similar sector strong knowledge of applied statistics used to analyze and interpret aggregate clinical data technical skills high technical competency in clinical research setting is required previous experience creating interactive data displays using statistical and or or visualization software or tools is required machine learning, nlp experience and web development is a plus communication presentation skills fluency in english is required capability of working independently and collaboratively demonstrated ability to prepare training materials such as use cases, user manuals, and formal presentations leadership skills good knowledge of the pharmaceutical industry including the understanding of clinical drug development process and associated documents and regulations proven problem solving capabilities to address complex issues independently and as a self starter experience in leading teams preferred knowledge of cdisc standards and oncology experience li ca bayer welcomes and encourages applications from people with disabilities. candidates participating in our selection process requiring accommodation due to a disability or medical need are encouraged to notify the bayer representative that they will be meeting with to ensure appropriate arrangements can be made. location canada ontario mississauga division pharmaceuticals reference code 384382","['data analytics', 'visualization', 'prototyping', 'statistics', 'machine learning', 'software', 'quantitative', 'testing', 'nlp', 'web development', 'data analysis', 'programming', 'clinical data', 'modeling', 'statistical analysis']","['programming', 'nlp']","['data analytics', 'visualization', 'prototyping', 'statistics', 'applied', 'machine learning', 'software', 'quantitative', 'testing', 'use cases', 'web development', 'data analysis', 'clinical data', 'modeling', 'statistical analysis']","['clinical operations', 'immunology', 'manuals', 'biology', 'oncology', 'regulations', 'presentations', 'molecular', 'materials', 'clinical research', 'clinical trials', 'agriculture', 'assessment', 'pharmaceuticals', 'drug development']"
556,811,Senior Scientist – ICP Mass Spectrometry R&D,"perkinelmer is a global technology leader driving growth and initiative in the environmental and human health science markets. the company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world. perkinelmer, a global leader in technology is searching for an experienced research and development scientist to help drive innovative solutions in our inductively coupled plasma mass spectrometry product line. the individual will become a key member of a group of senior perkinelmer researchers and liaise closely with other scientists at perkinelmer s partners and collaborators. this position is based in woodbridge, ontario, canada. duties and responsibilities initiate, direct, and execute scientific research with an emphasis on developing next generation technology, trade secrets, and intellectual property. act as a mass spectrometry scientific expert within the r d team during implementation and process confirmation phases, allowing thorough conceptualization and overall design and testing of new products. influence the scientific community and market via patents, publications, and conference presentations. provide research project planning and time estimates. evaluate competitive products and new technologies from research institutions, aiming to enhance future products. work with manufacturing, sustaining, and service personnel to improve quality, cost, manufacturability, and serviceability of products. demonstrate independent and creative scientific thinking, ability in solving complex problems, and resilience to setbacks and changes. experience and ability to lead and coordinate multiple collaborative projects in a cross functional program team environment. basic qualifications ph.d. in science, engineering, or related fields and 0 years of experience ms in science, engineering, or related fields and 3 years of experience. preferred qualifications prior instrumentation or application experience in icp ms. knowledge of mass spectrometry theory and components is a strongly preferred knowledge in design of mass spectrometry systems. strong instrumentation design skills and troubleshooting ability. proficient programming skills in one or more computer languages or firmware. ability solve to complex problems and dissect projects into manageable tasks excellent group interaction skills and negotiating skills. strong written and oral communication skills. demonstrated organizational skills to handle multiple tasks with different priorities. previous successful academic or work related experience mentoring peers. proven track record of publications in peer reviewed journals. job types full time, permanent pay from 88,000.00 per year benefits dental care extended health care flexible schedule paid time off vision care schedule 8 hour shift education master s degree experience icp ms 3 years covid 19 precaution remote interview process","['project', 'testing', 'firmware', 'troubleshooting', 'programming']",['programming'],"['troubleshooting', 'testing', 'firmware']","['mass spectrometry', 'environment', 'education', 'marketing', 'ancillary services', 'design', 'presentations', 'environmental science', 'project planning', 'manufacturing', 'scientific research', 'mentoring']"
557,812,Senior Scientist – ICP Mass Spectrometry R&D,"data engineer if you know python, perl, or tcl you ve probably heard of activestate s language distros. now we re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it this position is available to remote workers anywhere in the world, as long as you are able to work on a schedule that aligns with our north american business hours. you can also choose to work from our headquarters in beautiful vancouver, bc once the health situation makes this possible. this position is open to experienced candidates with a track record in this area. we re building up our data warehouse and analysis skills, and we re looking for someone who knows how to analyze, recommend, deploy, and use tools and techniques to help us get the most out of our data what you ll be doing as a data engineer, you ll help foster informed decision making and innovation within activestate by making our data understandable, actionable, and available in the relevant contexts. you ll be a part of our tools and infrastructure team, and will work closely with our in house data analyst and with most of our other teams from time to time, both inside and outside of engineering. your primary work will include designing, building, and managing etl and warehousing pipelines, including recommending tools, technologies, and practices for us to adopt. improving data accessibility within activestate by developing and training other developers in the use of monitoring, analysis, and visualization tools and techniques. ensuring data is managed in compliance with our in house policies. managing and designing the data and reporting environment, including data sources, tooling, security, and metadata. designing, building, deploying, and managing tools and processes to help colleagues understand data. testing and documenting your work. you ll work with others on the following tasks using code and data visualization tools to collect, validate, normalize, collate, analyze, interpret and present data. some of this work will be ad hoc, while some will be routine and automated. analyzing and optimizing data models, queries, and access patterns. building processes and systems to monitor data quality, ensuring that production data is accurate. updating our data collection and analysis policies. our team is mostly scattered around the us and canada, so we coordinate with each other and the rest of the company using slack for chat, zoom for video calls and screen sharing, asana for task management, and google drive. we like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. we embrace open sourcing both libraries and tools developed in house as long as those are not mission critical code. what s in it for you working for a stable and growing company that offers the environment and personal growth potential of a start up. the chance to work with a smart, passionate team of people. competitive salary and bonus plan. comprehensive benefits package and health or wellness credit program. requirements demonstrated experience with etl and data management technologies demonstrated ability to develop, customize, deploy, and maintain and develop business intelligence software. practical experience working with and enhancing data warehouses or data lakes. experience creating and optimizing data models. demonstrated ability to perform, validate and document both ad hoc and automated data analysis and reporting. ability to apply statistical methods to data sets is a plus. curiosity, an analytical mind, and strong problem solving skills. excellent written and spoken communication skills, both technical and non technical, including the ability to make data and analysis understandable and relevant to a diverse set of audiences. assets if you have experience with any of the following please make sure to highlight it in your cover letter data processing, messaging, and workflow technologies such as kafka, map or reduce, hadoop, hive, prestodb, luigi, airflow, storm, argo etc. analyzing marketing and sales data google data studio postgresql aws or data engineering in cloud environments kubernetes experience working with a wide variety of different data sets using one or more of the common data analysis languages , r, matlab, etc. as well as spreadsheets and visualization tools open source projects and culture agile processes, including breaking large projects up into smaller stories, estimation, working in branches , code review, and ci. go, perl, python, tcl, and ruby working at activestate activestate has a collaborative, respectful, and professional culture. we re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. there is a commitment from the ceo on down to making work at activestate a great experience for all. our company is a team of 55 and growing, with 2 or 3rds of the positions in technical roles including software development and qa. we maintain a set of core, overlapping hours, but we re flexible with specific start and end times and are understanding about appointments and life events. our vision is to have an activestate solution on every device on every planet, so we certainly don t lack for ambition but even though we re ambitious we don t expect work to become your life. we know you will do your best work in a positive environment free from death marches. for more about working at activestate and our glassdoor rating go to or careers. how to apply please submit your contact info, resume, and a cover letter below. submissions without a cover letter will not be considered. we look forward to hearing from you we are committed to creating a welcoming environment for everyone at activestate and we welcome applicants from all walks of life. even if you don t feel you meet every exact requirement, we still would love to hear from you and why you think you would be an awesome addition to our team and we encourage you to apply.","['go', 'visualization', 'ci', 'data visualization', 'google', 'hive', 'code review', 'map', 'kubernetes', 'ruby', 'python', 'data processing', 'postgresql', 'software', 'reporting', 'software development', 'perl', 'aws', 'data models', 'pipelines', 'data engineering', 'testing', 'sourcing', 'data collection', 'metadata', 'business intelligence', 'data analysis', 'data quality', 'rest', 'matlab', 'airflow', 'tcl', 'hadoop', 'security', 'zoom', 'spreadsheets', 'data management', 'etl', 'r']","['go', 'data lakes', 'hive', 'map', 'kubernetes', 'ruby', 'python', 'postgresql', 'perl', 'aws', 'data models', 'pipelines', 'google drive', 'business intelligence', 'google data studio', 'data quality', 'matlab', 'airflow', 'asana', 'hadoop', 'zoom', 'spreadsheets', 'r']","['visualization', 'data processing', 'software', 'reporting', 'testing', 'data engineering', 'security', 'data visualization', 'data collection', 'sourcing', 'ci', 'metadata', 'software development', 'data management', 'data analysis', 'rest', 'code review', 'etl']","['environment', 'events', 'task management', 'marketing', 'sales']"
558,814,"Director, Data Science Health R&D","les candidats r f r s ne doivent pas postuler directement pour ce poste. toutes les r f rences de candidats doivent d abord tre soumises dans workday par un coll gue de loblaw actuel. lieu 1 presidents choice circle, brampton, ontario, l6y 5s5 c est toute une d cision que de se joindre une entreprise. nous offrons des perspectives d emploi des personnes qui, comme vous, sont travaillantes, dynamiques et fiables. pourquoi ce role est il important are you at the top of your game bring your expertise and knowledge to canada s largest retailer. we are looking for smart, nice and curious team members to help bring our data analytics game to the next level. this is an exciting time to join our team we are changing the game in a big way if you are looking to join a company that offers unlimited opportunity, excellent leadership, world class training and makes a big impact on the community this is the role you ve been waiting for the data science health team is hiring a director of research development . the r d team pursues longer term projects that seek to improve health and wellness of our customers. the team aims to achieve this by developing health related data products or components that will be eventually integrated into customer or business facing solutions. this role is accountable for establishing a technical program management track and managing partnerships with health business teams and related external partnerships. the successful candidate must be a proven people lead who is also able to effectively communicate across domain boundaries and build trust with a variety of stakeholders including health business partners, data scientists, engineers and developers. refine high level intake and development processes in collaboration with sr. director of r d for delivery of data projects. mentor team members on adoption of the above processes and best practices. oversea distribution of resources across all active projects. foster the development and sustaining of a top performing r d team through weekly one on one sessions with direct reports. help team members thrive in their roles by mentoring them and help establish track their respective development goals. establish a technical program management stream within r d and develop this sub group by promoting and or or hiring into this role. mentor the adoption of project management and reporting practices across the r d team. manage interaction with health partners and ensure all projects are initiated with appropriate problem and scope definition. act as a communication bridge between health teams and data science pods to ensure constant alignment of projects with business needs. work closely with sr. director of r d to regularly review r d strategy and maintain alignment with overall business direction. work in collaboration sr. director of r d and data science lead to maintain competitive intelligence and identify ip value creation opportunities. requirements 5 or more years of experience leading teams developing health or medical solutions. excellent written and oral communication skills. design thinking evangelist. track record of supporting establishment and leading execution of r d processes. proven track record of transferring technology from research to production. passion for the health businesses within loblaw. strong organizational and leadership skills. able to build and maintain strong working relationships with internal and external partners using their prior appreciation for the value of bedside manner. background in data science, machine learning would be considered an asset. good financial and business acumen is considered an asset. li bt comment r ussir chez loblaw, nous recherchons toujours des personnes formidables pour continuellement renforcer notre culture. nous croyons que les gens formidables fa onnent nos valeurs, sont authentiques, b tissent la confiance et cr ent des liens. si cela vous ressemble et que vous tes ouvert d esprit, que vous avez une bonne attitude face aux changements et que vous aimez les d fis d un environnement de travail aux d tails dynamiques, postulez aujourd hui. en outre, nous croyons que la conformit aux lois consiste faire ce qu il faut. le respect de la loi fait partie de notre code de conduite il renforce ce que nos clients et nos parties prenantes attendent de nous. type d emploi temps plein role poste r gulier loblaw consid re que la diversit culturelle du canada est une source de fiert nationale et un symbole de force. nous nous sommes donn comme priorit de refl ter la diversit croissante du canada dans les produits que nous vendons, les gens que nous embauchons et notre culture d entreprise. des accommodements sont disponibles sur demande pour les postulants et coll gues atteints d un handicap. remarque si vous avez acc s libre service de l employ dans workday, veuillez postuler cet emploi en utilisant l application workday.","['data analytics', 'machine learning', 'design thinking', 'data products', 'reporting', 'data science', 'c', 'ip', 'r']","['c', 'ip', 'r']","['data analytics', 'machine learning', 'design thinking', 'data products', 'reporting', 'data science']","['program management', 'oversea', 'project management', 'adoption', 'hiring', 'mentoring']"
559,815,"Assistant Scientist II, Bioanalytics","those who join emergent biosolutions feel a sense of ownership about their future. you will excel in an environment characterized by respect, innovation and growth opportunities. here, you will join passionate professionals who advance their scientific, technical and professional skills to develop products designed to protect life. assistant scientist ii, bioanalytics 12 month term emergent biosolutions is currently seeking an assistant scientist ii, bioanalytics for our bioanalytical sciences department. the successful candidate will have a university degree or technical diploma in chemistry, biology or in another related field of study, and a minimum of two years of directly related experience. must have competence in laboratory and scientific practices, the ability to operate common scientific equipment and instrumentation and an understanding of immunology, immunochemistry and molecular biology concepts, statistics, sources of error and reporting of data. in addition, this individual will possess a strong work ethic and a commitment to excellence and innovation. the company emergent biosolutions is dedicated to one simple mission to protect and enhance life. as a global specialty pharmaceutical company, emergent offers specialized products to healthcare providers and governments to address medical needs and emerging health threats. we value the diversity that each employee brings, and while we look for people who share our core values, we thrive on difference as well. with hundreds of talented employees working around the globe, emergent is a growing organization with a wide variety of scientific, technical and professional career opportunities worldwide. the opportunity develop and qualify or verify or validate or transfer bioanalytical assays to support various functions, such as routine manufacturing, product discovery, proof of concept studies and candidate selection. characterize products and impurities to support process or product development, formulation development, licensure, and product investigations. support qc labs by supporting developed assays throughout their lifecycle, trending assay data, and supporting continuous improvement initiatives perform gxp compliant testing as required to support manufacturing, product release stability or nonclinical or clinical studies. duties responsibilities participate in the development and or or optimization of bioanalytical methods to support r d and quality laboratories participate in bioanalytical method validations or verifications and transfers, including assisting with authoring of associated protocols and reports support quality control laboratories by assisting with assay troubleshooting where required and trending assay data support emergent s quality culture by adhering to all effective sops and safety requirements, documenting laboratory work consistent with gxp requirements, taking action where deficiencies are found and identifying continuous improvement opportunities utilize scientific knowledge to contribute to development projects work productively with other team members as well as on independent assignments receive and test samples perform routine laboratory procedures make detailed observations, analyze data using appropriate statistical techniques , report data as appropriate and interpret results maintain laboratory records and inventory for supplies and reagents perform preventative maintenance on laboratory equipment maintain up to date knowledge on bioanalytical or laboratory or scientific methodologies and techniques maintain a clean and sanitary work area in accordance with standard laboratory practice and procedures the above statements are intended to describe the general nature of work performed by those in this job. it is not an exhaustive list of all duties, and other duties may be assigned. education, experience skills education university degree or technical diploma in chemistry, biology or related field of study experience minimum of two years directly related experience in a recognized professional or technical or scientific field. experience in a pharmaceutical cgmp environment is an asset, but is not required. knowledge, skills abilities competence in laboratory and scientific practices, including maintaining sufficiently detailed and compliant laboratory records. ability to operate common scientific equipment and instrumentation understanding of immunology, immunochemistry and molecular biology concepts, statistics, sources of error and reporting of data basic knowledge of analytical method validation skill in interpretation of data to support research and development work skill in communication of information in both written and verbal forms. strong organizational and interpersonal skills can work collaboratively with others. basic knowledge of microsoft office word, excel basic knowledge of pharmaceutical glps and gmps knowledge of general laboratory techniques and chemical and biological safety practices working knowledge of how to interpret or use information derived from hazardous product regulations that include whmis 2015 and canadian biosafety standard additional requirements citizenship or permanent resident or valid work permit. successful completion of a criminal record check. medical assessment required for this position. interested please visit .com under the career section to apply today as part of our team, you ll join talented and inspiring colleagues whose sense of purpose complements your own. we offer highly diverse career opportunities, a supportive culture, competitive salaries, flexible work arrangements and an extensive benefits package. information submitted will be used by emergent biosolutions for activities related to your prospective employment. emergent biosolutions respects your privacy and any use of the information submitted will be subject to the terms of our privacy policy .","['statistics', 'proof of concept', 'reporting', 'testing', 'chemistry', 'gxp', 'troubleshooting', 'optimization', 'quality control']","['g', 'r']","['statistics', 'proof of concept', 'reporting', 'testing', 'chemistry', 'troubleshooting', 'optimization', 'quality control']","['environment', 'reagents', 'glp', 'regulations', 'forms', 'laboratory equipment', 'and safety', 'continuous improvement', 'education', 'biology', 'assessment', 'laboratory procedures', 'validation', 'product discovery', 'healthcare', 'laboratory practice', 'microsoft office word', 'product development', 'immunology', 'development projects', 'molecular', 'gmps', 'manufacturing', 'immunologymunmist', 'laboratory workx']"
560,818,Senior Applied Scientist,"phd degree with 4 years of applied research experience or a masters degree and 6 years of experience of applied research experience 3 years of experience of building machine learning models for business application experience programming in java, c , python or related language amazon s sponsored products advertising business is one of the fastest growing areas in the company. have you ever wondered what happens behind that sponsored label you see on amazon the sponsored products marketplace team creates and optimizes the systems that match advertiser demand with page supply using a combination of data driven product innovation, machine learning, big data analytics, and low latency or high volume engineering. by the time organic search results are ready, we ve processed all of the candidate ads and determined which ones are delivered to the page. we do that billions of times per day, resulting in millions of engagements with products that otherwise might not have been seen by shoppers. the business and technical challenges are significant. fortunately, we have a broad mandate to experiment and innovate, and a seemingly endless range of new opportunities to build a big, sustainable business that helps amazon continuously delight all of our customers. we re looking for an innovative and customer obsessed sr. applied scientist who can help us take our products to the next level of quality and performance by creating state of the art models to improve our ability to predict entity relationships, forecast the impact of advertiser actions, and optimize ad selection for different contexts. we embrace leaders with a startup mentality those who have a disruptive yet clear mission and purpose, an unambiguous owner s mindset, and a relentless obsession for delivering amazing products. as sr. applied scientist on the product targeting team, you will work alongside business leaders, other scientists, and software engineers to deliver recommenders and forecasters based on ml, dl, and rl from idea to production. you will be responsible for bridging the experimental domain with the production domain by building robust and efficient computational pipelines to scale up models, keeping the models fresh, and ensuring that real world corner cases are handled correctly. you ll own significant products and features from inception through launch, and will work with product managers, other scientists, and engineers to make your efforts wildly successful. you will lead the science program for our team, providing input to strategic decision making on topics such as program direction or vision, roadmap, and staffing. if this sounds like your sort of challenge, read on. characteristics indicative of success in this role highly analytical you solve problems in ways that can be backed up with verifiable data. you focus on driving processes, tools, and statistical methods which support rational decision making. technically fearless you aren t satisfied by performing as expected and push the limits past conventional boundaries. your dial goes to 11 . engaged by ambiguity you re able to explore new problem spaces with unique constraints and non obvious solutions. team obsessed individual contributor you help grow your team members to achieve outstanding results. you ve learned that big plans generally involve collaboration and great communications. quality obsessed you recognize that professional scientists build high quality model development and evaluation frameworks to ensure that their models can provably meet launch criteria, or efficiently iterate in the framework until they do. humbitious you re ambitious, yet humble. you recognize that there s always opportunity for improvement. you use introspection and feedback from teammates and peers to raise the bar. primary responsibilities apply machine learning and analytical techniques to create scalable solutions for business problems work closely with software engineering and product teams across the organization to drive model implementations and new feature creations work closely with business stakeholders to identify opportunities for current model improvements and new models to significantly benefit the business bottom line collaborate with scientists within the ads organization as well as other parts of amazon to share learnings move the state of the art forward establish scalable, efficient, automated processes for data analyses, model development, model validation and model implementation research and implement novel machine learning and statistical approach impact and career growth you will invent new shopper and advertiser experiences, and accelerate the pace of machine learning and optimization. influence customer facing shopping experiences to helping suppliers grow their retail business and the auction dynamics that leverage native advertising, this role will be powering the engine of one the fastest growing businesses at amazon. define a long term science vision for our ad marketplace, driven fundamentally from the needs of our customers, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. this is a role that combines science leadership, organizational ability, technical strength, product focus and business understanding. why you love this opportunity amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self service performance advertising products that drive discovery and sales. our products are strategically important to our retail and marketplace businesses driving long term growth. we deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world class products. we are highly motivated, collaborative and fun loving with an entrepreneurial spirit and bias for action. with a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities. team video https or or youtu.be or zd 6lzw8rae strong publication record with novel research contributions proven success in applying ml or dl or rl models to practical problems experience with with any of nlp, transfer learning, bert, pair modeling, topic modeling, similarity, relevance. expertise in working with big data in map or reduce setting using spark, emr, pig, etc. experience with aws and data oriented tools such as sagemaker, airflow, elasticsearch, airflow, etc. experience in online advertising domain is a big plus. amazon is committed to a diverse and inclusive workplace. amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. for individuals with disabilities who would like to request an accommodation, please visit https or or or en or disability or ontario sspajobs spmpjobs sptargjobs","['https', 'emr', 'c', 'big data', 'java', 'map', 'data analytics', 'python', 'software', 'elasticsearch', 'dynamics', 'programming', 'aws', 'pipelines', 'analytical techniques', 'machine learning', 'airflow', 'model', 'low latency', 'nlp', 'optimization', 'modeling']","['https', 'python', 'emr', 'big', 'elasticsearch', 'nlp', 'c', 'model development', 'programming', 'big data', 'aws', 'airflow', 'pipelines', 'java', 'bert', 'map', 'r']","['model', 'data analytics', 'analytical techniques', 'machine learning', 'pair', 'software', 'topic', 'low latency', 'dynamics', 'optimization', 'modeling']","['validation', 'investing', 'advertising', 'online', 'applied', 'retail', 'business understanding', 'art', 'sales', 'engagements']"
561,819,Data & AI Strategy Senior Manager,"we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about accenture applied intelligence join accenture digital and leave your digital mark on the world, enhancing millions of lives through digital transformation. where you can create the best customer experiences and be a catalyst for first to market digital products and solutions using machine learning, ai, big data and analytics, cloud, mobility, robotics and the industrial internet of things. your work will redefine the way entire industries work in every corner of the globe. you are as a senior manager in our practice you will help shape and sell industry specific programs, including definition of the analytics or ai vision and strategies, redefine operating model and talent strategy, and help guide clients through their data and analytics journeys to deliver sustainable business value. you will act as the architect for our most transformative opportunities, enabling an end to end analytics journey by bringing the best of our accenture applied intelligence organization. you will also play a key role on the leadership team building a practice, assets, and thought leadership. the work 1. support applied intelligence consulting activities lead complex analytics transformation projects from defining the strategy, operating model, value targeting, proof of value and change management to enable data, analytics and ai capabilities and outcomes work with our canadian innovation hub to plan and define immersion sessions in core analytic and digital capabilities specific to client needs 2. sales origination business development educate internal accenture stakeholders about our analytics offerings and applicability to their industry or clients facilitate the development of request for proposals responses and contract development lead the development of businesses cases for further project sales as determined by the practice 3. practice offering management shape assets to accelerate sales and delivery drive the analytics innovation agenda, including publishable thought leadership play an active role building a practice including capability development and recruiting identify and help bring into the practice talented individuals both internally from accenture as well as externally qualifications here s what you need a bachelor s degree in a quantitative field like statistics or econometrics or mathematics or engineering or computer science 10 years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation industry and or or industry domain specific experience delivering data driven capabilities and solutions experience in designing and utilizing analytic solutions in enterprise wide organizations superior understanding of how to manage client relationship, deliver analytics value, and influence senior clients to define and expand data driven strategies into new applications and markets relevant experience could include one or more of the following marketing and customer experience analytics pricing and revenue management or optimization personalization and loyalty selling strategies and merchandising distribution channels operational effectiveness compliance, risk and fraud prevention ability to travel and work in canada bonus points if fluency in french language is a great to have. strong data management and data governance background strong cloud background in delivering data driven solutions on azure, aws and or or gcp exceptional presentation skills ability to convey technology and business value propositions proven industry knowledge and experience delivering data, analytics and ai solutions driving business outcomes experience interacting with clients or executives of all levels to review expected outputs, applicability to business challenges, and value measurement well versed with leading analytics techniques and confident about how to apply them to generate insights and recommendations experience guiding the data formulation process and exploratory data analysis experience guiding and managing a team of practitioners to execute data and analytics solutions, preferably both onshore and offshore evidence of thought leadership in defining innovative analytics within multiple complex applications spanning marketing, risk, and cost reduction","['personalization', 'robotics', 'big data', 'gcp', 'statistics', 'analytics', 'data', 'aws', 'econometrics', 'machine learning', 'data analysis', 'automation', 'internet of things', 'computer science', 'mathematics', 'optimization', 'data management', 'digital transformation', 'ai']","['gcp', 'internet of things', 'robotics', 'big data', 'aws']","['personalization', 'cost reduction', 'machine learning', 'statistics', 'exploratory', 'computer science', 'analytics', 'mathematics', 'optimization', 'data', 'data analysis', 'data management', 'digital transformation', 'automation', 'econometrics', 'ai']","['business development', 'change management', 'merchandising', 'marketing', 'business value', 'offshore', 'sales', 'customer experience', 'team building', 'evidence', 'governance', 'consulting', 'recruiting', 'revenue management', 'agenda']"
562,825,Senior Data Engineer (Azure),"about antuit.ai antuit.ai is the leader in ai powered saas solutions, empowering world class consumer products and retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. antuit.ai s executives, comprised of industry leaders from sap, sas, ibm, and accenture, and our team of ph.ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. antuit is funded by goldman sachs and zodius capital. the role antuit.ai is interested in hiring a senior data integration engineer to work closely with clients and the product engineering and ai teams to create data pipelines to support data driven ai based cloud applications. a senior data integration engineer will be responsible for understanding the client s technical requirements, design and build data pipelines to support the requirements. in this role, the sr. data integration engineer, besides developing the solution, will also oversee other engineers development. the successful candidate will have strong verbal and written communication skills and effectively communicate with the client and internal team. a strong understanding of databases, sql, cloud technologies, and modern data integration and orchestration tools like azure data factory , informatica, and airflow are required to succeed in this role. responsibilities responsibilities include, but are not limited to the following lead design sessions to develop etl logic that meets business and product requirements. implement data pipelines that meet the design and are efficient, scalable, and maintainable. provide technical guidance and meet best practices during the data pipeline development. work with clients to understand and document their data, technology, and how it would integrate with antuit s cloud solutions. act as a technical escalation lead for customer and development team issues. qualifications and skills 7 10 years as a data integration engineer with at least 3 years as a senior data integration engineer strong understanding of data models that feed advanced ai driven applications. at least 3 years of experience with azure data factory , informatica and similar, is critical. at least 1 year of spark experience experience with relational databases, sql, and python is preferred. experience working with retail, consumer goods, and manufacturing data models is a plus. information security responsibilities understand and adhere to information security policies, guidelines, and procedures and practice them to protect organizational data and information systems. take part in information security training and act accordingly while handling information. report all suspected security and policy breaches to the infosec team or appropriate authority . eeoc antuit.ai is an at will, equal opportunity employer. we consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age, marital status, disability, veteran status, or any other legally protected status under local, state, or federal law. to apply, please send your resume or cv to antuit.ai thanks all applicants however, only those selected for an interview will be contacted.","['databases', 'cloud applications', 'technical requirements', 'sql', 'python', 'data', 'saas', 'integration', 'data models', 'sas', 'informatica', 'data pipelines', 'relational databases', 'product engineering', 'information', 'airflow', 'security', 'information systems', 'escalation', 'etl', 'ai']","['sql', 'python', 'databases', 'azure data factory', 'data models', 'sas', 'airflow']","['information', 'informatica', 'data pipelines', 'relational databases', 'security', 'information systems', 'product engineering', 'cloud applications', 'saas', 'data', 'integration', 'technical requirements', 'product requirements', 'escalation', 'feed', 'etl', 'ai']","['law', 'merchandising', 'marketing', 'retail', 'capital', 'sap', 'design', 'consumer products', 'manufacturing', 'hiring']"
563,826,Senior Data Engineer ( 100 % remote work ),"fed it, a recruitment firm specializing in it job recruitment, we work on two types of recruitment temporary and permanent. all our consultants are it experts who speak your language and evolve in your universe. do not hesitate to follow our company page to discover all our open positions in the it, development, decision making and infrastructure fields. we are currently looking for a senior data engineer to work for our client, a technology driven company. responsibilities complete data processing so that reports are understood, analyzed and used wisely by the end user be proactive and efficient in developing the road map be proactive and constantly push code into production writing viable and reusable programs revision of uml diagrams and documentation be accountable for code quality by conducting adequate testing responsible of the performance, reliability, scalability and resilience of at least one technical component owned by the squad solve complex technical problems and mentor or support other technical staff on data modeling and etl related issues knowledge sharing and coaching participate in the integration of new data engineers share knowledge of technical design with junior developers so that they can participate in document writing qualifications bachelor s degree in computer science, engineering, master s degree an asset at least 5 years in functional programming and or or object oriented at least 3 years writing sql queries as well as using apache spark excellent knowledge of python programming and its libraries wide knowledge in data modeling and an advanced comprehension of its architecture extremely comfortable with relational databases and nosql databases ability to use devops tools proficiency with cloud resources like amazon web service, google cloud etc. certification would be an asset. knowledge of big data technology an asset familiarity with continuous integration proeficient in git bilingual written and spoken english and french skills highly analytical and detail oriented ability to lead and mentor junior team player with a high sense of accountability and ownership actor of change solution oriented ability to thrive in a high pressured and being on point with technology","['databases', 'big', 'technical design', 'uml', 'documentation', 'map', 'sql', 'python', 'data processing', 'diagrams', 'data', 'programming', 'integration', 'nosql', 'relational databases', 'testing', 'apache spark', 'amazon web', 'devops', 'git', 'scalability', 'computer science', 'modeling', 'etl']","['sql', 'python', 'databases', 'google cloud', 'amazon web service', 'apache spark', 'functional', 'git', 'uml', 'programming', 'documentation', 'big data', 'nosql', 'map']","['data processing', 'relational databases', 'continuous', 'diagrams', 'testing', 'devops', 'technical design', 'scalability', 'computer science', 'data', 'integration', 'modeling', 'etl']",['architecture']
564,828,"Sr. Research Scientist, Evidence Synthesis","do you consider yourself a highly organized, self starter with a real passion for projects involving innovative health economic concepts are you passionate about putting in the hard work to conduct high quality research and programming if you re a born problem solver and enjoy when no day is the same keep reading we are looking for a sr. research scientist to join our dynamic heor practice senior research scientists have a thorough understanding of how to create the data foundation needed to provide the statistical analysis framework for projects. may conduct statistical analysis and modeling procedures, and interpret the results from statistical procedures and models in order to address client s research questions. what you can expect day to day leads projects with little oversight and supervises others on project team displays leadership capabilities and client management skills independently and logically identifies issues and problems across all tasks, whether directly or indirectly involved and carries out solutions or seeks additional input for particularly challenging problems creatively develops fact base where data are hard to access and tailors analysis to meet future tasks goals and align with big picture project objectives applies analytic tools techniques creatively to solve complex problems prepares initial strategies for implementation, obtains insight from others to address gaps or complexities, and assumes role of final decision maker when appropriate while taking accountability for outcomes develops written materials with little direction and reviewing or editing by others delivers effective presentations and is in command of the audience proactively identifies potential challenges and adjusts plans to accommodate unexpected problems or opportunities anticipates the key risks and proactively develops and executes mitigating strategies while mentors others in execution demonstrates valued contributions to internal and client discussions draws team together and motivates others to achieve common goal delegates effectively by assessing availability, skill, and interest and leads by example, particularly during challenging situations proactively manages client expectations and works with others to resolve any issues within reason when client needs are not met builds client relationships and is perceived as scientific partner anticipates potential opportunities for future work qualifications required ph.d. in a discipline related to health services research economics, public policy, health policy, epidemiology, biostatistics, or public health, with a minimum 5 years of relevant research experience ms or ma plus 7 years of relevant research experience other required thorough understanding of statistical programs excellent oral and written communication skills ability to work effectively individually and as part of a diverse team exceptional organizational and time management skills proficiency with microsoft office preferred experience conducting meta analysis experience in conducting network meta analysis experience overseeing the work of others experience crafting health technology submissions experience working in statistical programs who we are precisionheor is an award winning global healthcare market access consultancy within precision medicine group. we provide our clients with unified health economics and outcomes research, global pricing, access strategy and analytics, payer and physician pull through, and data management. we provide powerful research skills to positively impact payer and purchaser decision making, which allows organizations to assess appropriate populations for therapies and potential expand access for life saving and altering medical interventions. with offices in new york, boston, la, vancouver and london, our team has experienced rapid growth and includes a collection of professionals from around the globe with experience across multiple disciplines former payer executives, academics, pharma marketers, and consultants all passionate about generating solutions to our customers value and access needs. any data provided as a part of this application will be stored in accordance with our privacy policy . precision medicine group is an equal opportunity employer. employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. 2020 precision medicine group, llc if you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact precision medicine group at .","['biostatistics', 'economics', 'meta analysis', 'analytics', 'programming', 'data management', 'modeling', 'medicine', 'statistical analysis', 'epidemiology', 'solver']","['solver', 'programming']","['biostatistics', 'economics', 'precision', 'analytics', 'meta', 'modeling', 'medicine', 'data management', 'statistical analysis', 'epidemiology']","['healthcare', 'public policy', 'public health', 'health economics', 'presentations', 'microsoft office', 'materials', 'market access', 'health policy', 'health', 'precision', 'law']"
565,829,Ingénieur de données / Data Engineer - 312613,"ing nieur de donn es dans le cadre de ses ententes avec ses diff rents clients, procom est actuellement la recherche d un ing nieur de donn es. notre client est situ montr al. description des t ches et responsabilit s ing nieur de donn es les responsabilit s du poste incluent contribuer directement la conception et au code des pipelines de donn es fonctionnant sur les donn es de production am liorer les approches pour traiter efficacement un volume de donn es en constante augmentation diriger la conception et la mise en uvre de bout en bout des composants communs qui acc l rent et am liorent notre capacit crire des pipelines de donn es efficaces et fiables maintenir l efficacit et la fiabilit de la production des ensembles de donn es critiques valuer et proposer les meilleurs outils et processus pour l acc s aux donn es et leur analyse fournir une aide la conception et la r vision aux quipes d ing nieurs travaillant sur le traitement des donn es valuer continuellement les processus de l quipe afin de maintenir une culture d ing nierie positive et efficace. exigences du poste ing nieur de donn es connaissances des langues et outils que nous utilisons scala, scalding, python, airflow vous avez de l exp rience dans un environnement qui soutient l analyse des donn es, l exp rimentation et la mod lisation du machine learning ou son int gration dans un produit vous poss dez une compr hension av r e des syst mes backend et distribu s et une forte exp rience de travail avec des architectures bas es sur mapreduce vous avez une large connaissance de l cosyst me de l infrastructure de donn es et une exp rience de travail avec des donn es grande chelle vous tes familier avec la m thodologie standard d ing nierie logicielle, par exemple les tests unitaires, les revues de code, la documentation de conception vous aimez travailler dans un environnement collaboratif et interagir efficacement avec les autres vous fondez vos d cisions sur des donn es et un raisonnement et pouvez vous adapter de nouvelles informations pour faire des choix clair s vous apportez des perspectives r fl chies, de l empathie, de la cr ativit et une attitude positive pour r soudre des probl mes grande chelle. type de poste contractuel 6 mois avec de fortes possibilit s de renouvellement. date de d but imm diatement num ro de r f rence bh312613 english version data engineer as a part of its agreements with its various clients, procom is currently seeking a data engineer. our client is located in montr al. job details data engineer key responsibilities for this position include directly contribute to the design and code of data pipelines operating on production data improve approaches to efficiently handle ever increasing volume of data lead end to end design and implementation of common components that accelerate and improve our ability to write efficient and reliable data pipelines maintain efficiency and reliability of production of the critical datasets evaluate and propose the best tooling and processes for data access and analysis provide design and review support to the engineering teams working on data processing continuously evaluate team s processes to maintain a positive and efficient engineering culture. mandatory skills data engineer knowledge of languages and tools we use scala, scalding, python, airflow who you are you have experience working in an environment that supports data analysis, experimentation, and machine learning modeling or its integration into a product you possess a proven understanding of backend and distributed systems and strong experience working with mapreduce based architectures you have a broad knowledge of the data infrastructure ecosystem and experience in working with large scale data you are familiar with standard software engineering methodology, e.g. unit testing, code reviews, design documentation you enjoy working in a collaborative environment and interact effectively with others you ground your decisions with data and reasoning and can adapt to new information to make informed choices you bring thoughtful perspectives, empathy, creativity, and a positive attitude to solve problems at scale. assignment length 6 month contract renewable start date immediately reference number bh312613","['python', 'machine learning', 'unit testing', 'data pipelines', 'data processing', 'scala', 'software', 'datasets', 'data infrastructure', 'documentation', 'integration', 'modeling', 'pipelines', 'r', 'distributed systems', 'airflow']","['python', 'scala', 'documentation', 'airflow', 'pipelines', 'r']","['methodology', 'machine learning', 'data pipelines', 'tests', 'data processing', 'software', 'datasets', 'data infrastructure', 'integration', 'modeling', 'distributed systems', 'unit testing']","['environment', 'design']"
566,830,Scientist - Analytical & Synthetic Chemistry,"olds softgels inc. is an established pharmaceutical and nutraceutical softgel manufacturer with a developing portfolio in cannabis products located in olds, alberta. we are looking for an enthusiastic, passionate scientist with experience in analytical and synthetic chemistry to fill a temporary role in new drug development. the focus will be on the effect of catalyst structure on reaction kinetics of polyphenols and the analysis of secondary metabolites content in plants. duties and responsibilities chemical modelling of reaction paths development and validation of analytical methods for pharmaceutical testing troubleshooting issues related to analytical methods or data management of synthesis and characterization of reference standards for apis and impurities candidates should have the following experience phd in chemistry with minimum 5 years of experience experience in synthesis and analysis of esterified monophenols and polyphenols evaluation of polyphenolic acid esters knowledge and understanding of analytical chemistry methodologies for drug substance and drug product development ability to work independently on projects job types full time, temporary schedule 8 hour shift work remotely no","['troubleshooting', 'data management', 'testing', 'chemistry']",[],"['testing', 'chemistry', 'troubleshooting', 'data management', 'analytical']","['drug development', 'validation', 'product development', 'characterization']"
567,831,Digital Sr Data Engineer,"digital sr data engineer mon17877 description bombardier bombardier is a global leader, creating innovative and game changing planes. our products and services provide world class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. we are a global organization focused on working together with a team spirit. in your role, you will manage the end to end process of designing, developing, testing and deploying data integration workflows . plan and execute secure, best practice data strategies and approaches. collaborate with stakeholders to develop and improve the current data architecture, data quality, monitoring and data availability schemas. design and building robust data ingest transformation pipelines and solutions needed to acquire, ingest, and process data from multiple sources and systems into modern data platforms. restructure and wrangling data into forms suitable and valuable for a variety of downstream usage including business analytics, machine or deep learning model development, as well as in systems and applications for operational, business and commercial purposes. create and maintaining underlying cloud data infrastructure responsible for managing data flow from ingestion to storage, and to consumption. work cross functionally with our consultants and tech leads to ensure solutions developed aligns comfortably within the organizational preferences on basis of technology and methodology. keep up to date with advancements in data technologies and leveraging the initiatives to improve and scale existing data architectures leading to improved bombardier aviation customers experience. qualifications as our ideal candidate, you possess a bachelor s or master s degree in computer science, engineering, mathematics, or a related technical discipline. you have a minimum of 7 to 10 years of industry experience in data engineering, software development, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets. you have experience with different etl techniques data modeling approaches. you have industry experience using java, scala, python, sql, or similar for data manipulation. you have expertise with data technologies such as s3, parquet, athena, redshift, rds, as well as with integrating with rest apis using json or xml. you possess effective interpersonal, communication and leadership skills, and have the ability to work under pressure and meet strict deadlines you have strong analytic skills related to working with structured or unstructured datasets. you have the ability to effectively articulate recommendations or conclusions verbally and in writing you have an expertise in data engineering or architecture role in a company with large, complex data sources, and have experience working with aws data technologies . you have expertise building or operating highly available, distributed systems of data extraction, ingestion, and processing of large datasets, as well as etl, data modeling, data injection, transformation and processing. bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected characteristics to apply. whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone. join us at https or or bombardier.com or en or careers or career opportunities your ideas move people. job project or program management primary location ca qc montreal dorval organization aerospace schedule full time employee status regular job posting 01.06.2021, 12 57 54 pm unposting date ongoing","['https', 'schemas', 'data flow', 'data infrastructure', 'distributed systems', 'business', 'java', 'data injection', 'sql', 'python', 'scala', 'json', 'data science', 'software development', 'data', 'analytics', 'integration', 'aws', 'pipelines', 'data engineering', 'testing', 'data manipulation', 'model development', 'business intelligence', 'data quality', 'rest', 'athena', 'deep learning', 'data extraction', 'datasets', 'computer science', 'mathematics', 'modeling', 'xml', 'etl']","['https', 'sql', 'python', 'pipelines', 'scala', 'athena', 'json', 'data manipulation', 'model development', 'rds', 'business intelligence', 'aws', 'data quality', 'xml', 'java']","['schemas', 'data flow', 'data infrastructure', 'data ingest', 'modeling', 'distributed systems', 'business', 'data injection', 'data science', 'software development', 'data', 'analytics', 'integration', 'data engineering', 'cloud', 'unstructured', 'testing', 'rest', 'data strategies', 'deep learning', 'data extraction', 'datasets', 'computer science', 'mathematics', 'methodology', 'etl']","['and safety', 'forms', 'design', 'aerospace', 'aviation', 'hiring', 'architecture']"
568,832,"Senior Data Engineer, KPMG Lighthouse","overview you ve got big plans. we have opportunities to match, and we re committed to empowering you to become a better you, no matter what you do. when you join kpmg you ll be one of over 219,000 professionals providing audit, tax, advisory and business enablement services across 147 countries. with the support to do things differently, grow personally and professionally and bring your whole self to work, there s no limit to the impact you can make. let s do this. the opportunity innovate. collaborate. shine. lighthouse kpmg canada s center of excellence for data valorization, advanced analytics applies data science to solve real word business problems, operationalize ai and optimize emerging technologies for its mission. join a diverse team which is always curious and learning, thinking independently, working collaboratively, has a passion to solve difficult problems, and has fun doing it. kpmg lighthouse quebec has an exciting opportunity for a data analytics senior engineer, to join our team this role will be a rewarding experience for you if you thrive on challenges and work best in a fast paced environment where each day is different work well in a project team environment and have strong collaboration and interpersonal skills have a permanent figure it out mindset what you will do use advanced analytics to enable greater insight into business drivers and outlook to proactively inform business decisions using supervised and unsupervised techniques. build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. lead the planning and implementation of data collection and management tools. assemble large, complex data sets that meet functional or non functional business requirements. identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re designing infrastructure for greater scalability, etc. enforce data security best practices for on premises and cloud environments, including hipaa or gdpr or client requirements. build your technical and analytical expertise by delivering high quality results on time and proactively identifying and resolving project issues. analyze and translate project and user needs into data, analytics and technology requirements. develop, implement, monitor and efficiently deliver of multiple projects in advanced analytics via, among others, cloud technologies. coach and mentor more junior staff on the team and engage in skill development conversations. what you bring to this role 5 years of professional experience in a related field bachelor s or graduate degree in computer engineering, mathematics, data science or related disciplines experience using the following software or tools is a must experience with relational sql and nosql databases, including ms sql server, postgresql and cosmos db experience with cloud environment azure, gcp, ibm cloud pak and aws cloud data services and solutions like docker, etc. experience with api experience using the following software or tools is a plus experience with big data tools hadoop, spark, kafka, etc. experience with data warehousing solutions such as azure synapse. experience with data pipeline and workflow management tools azkaban, luigi, airflow, etc. experience with stream processing systems spark streaming, databricks, azure event hubs, etc. experience with object oriented or object function scripting languages python, java, c , scala, etc. experience deploying and maintaining high performance computing vms in on premise and cloud environment. strong experience working in teams to perform etl of data from a variety of databases experience working in a multi disciplinary team to tack structured and unstructured data processing problems across a diverse range of industries experience in developing, implementing and identifying opportunities for data valuation projects including machine learning , deep learning or the field of data engineering, etc. keys to your success an insatiable curiosity to learn, an aptitude to figure it out and a hunger to make a difference strong communication in english and french and interpersonal skills ability to think critically and laterally problem solve and innovate within a team environment high level of attention to detail, excellent time management skills using agile methodology and ability to perform under pressure learn more about where a career at kpmg can take you. our values, the kpmg way integrity, we do what is right excellence, we never stop learning and improving courage, we think and act boldly together, we respect each other and draw strength from our differences for better, we do what matters kpmg in canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier free workplace that allows all of our people to reach their full potential. a diverse workforce is key to our success and we believe in bringing your whole self to work. we welcome all qualified candidates to apply and hope you will choose kpmg in canada as your employer of choice. if you have a question about accessible employment at kpmg, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact kpmg s employee relations service team for support at email or phone 416 777 8002 or toll free 1 888 466 4778 option 3. for general recruitment related inquiries, please contact the hr delivery centre at","['computing', 'databases', 'workflow management', 'data services', 'c', 'big data', 'java', 'data analytics', 'sql', 'gcp', 'python', 'data processing', 'postgresql', 'software', 'scala', 'scripting', 'data science', 'analytics', 'data', 'aws', 'valuation', 'data engineering', 'data warehousing', 'nosql', 'machine learning', 'computer engineering', 'stream processing', 'data collection', 'airflow', 'deep learning', 'hadoop', 'security', 'api', 'scalability', 'mathematics', 'enablement', 'etl', 'ai']","['object function', 'sql', 'python', 'databases', 'gcp', 'postgresql', 'scala', 'azkaban', 'hadoop', 'api', 'c', 'data', 'aws', 'big data', 'java', 'nosql', 'airflow']","['computing', 'workflow management', 'data services', 'gdpr', 'data analytics', 'data processing', 'software', 'scripting', 'data science', 'analytics', 'valuation', 'data engineering', 'data warehousing', 'unstructured', 'machine learning', 'computer engineering', 'stream processing', 'data collection', 'planning', 'deep learning', 'security', 'scalability', 'mathematics', 'methodology', 'enablement', 'etl', 'ai']","['environment', 'hr', 'design', 'employee relations']"
569,833,Data Modeler,"freshbooks has an ambitious vision. we launched in 2003 but we re just getting started and there s a lot left to do. we re a high performing team working towards a common goal building an extraordinary online accounting application to help small businesses better handle their finances. known for extraordinary product and customer service experiences and based in toronto, canada, freshbooks serves paying customers in over 120 countries. the opportunity data modeler freshbooks is seeking a data modeller to join our team. you will help design and organize new features and update existing ones in our current data and analytics infrastructure. if you re committed to great work and are constantly looking for ways to improve the systems you re responsible for, we d love to chat with you what you ll do collaborate with data engineers, data analysts, data scientists, and product teams working on data and analytics features for our stakeholders. apply data modelling methodologies and best practices in designing solutions. focus on data management functional areas of data quality, data lineage, data cataloging and data security. provide designs and documentation that fit into the data engineering team s agile framework. participate and share your ideas in technical design and architecture discussions. develop your craft and build your expertise in data and analytics systems. champion the cause of data literacy. what you bring enthusiasm for data and analytics strong data modeling fundamentals including experience with dimensional modeling, 3nf, star and snowflake schemas, etc., and strong application knowledge concepts like normalization, referential integrity, data domains, etc. experience building and maintaining conceptual, logical and physical data models for reporting and analytics use cases. experience with analytics platforms and methodologies strong sql skills and experience with rdbms and mpp relational databases. experience with gcp data storage products bigquery cloudsql, or similar technologies e.g. snowflake, redshift, azure sql database experience enabling data governance practices as part of solution implementation. experience with semi structured and unstructured data. experience working in an agile environment. the ability to balance a desire to build data and analytics features quickly for internal customers, with the responsibility of making good technical decisions. what you might bring a passion for keeping up to date in current technologies and future trends. experience with bi tools like looker, tableau, microstrategy, periscope, etc. experience with pub or sub, spark, kafka, kinesis or other streaming technologies. experience using github, reviewing code, receiving and providing feedback. a limitless imagination for where data could go and what we can do with it to make our customers and our people awesome why join us we re an ambitious bunch, with our eyes laser focused on shipping extraordinary experiences to small business owners. in this role, you will be working at the forefront of marketing analytics surrounded by talented team members who share a common vision for building an amazing software company right west of downtown toronto. if this sounds like something you would be interested in, we d like to meet you. apply now have we got your attention submit your application today and a member of our recruitment team will be in touch with you shortly freshbooks is an equal opportunity employer that embraces the differences in all of our employees. we celebrate diversity and are committed to creating an inclusive environment for all freshbookers. all applicants are evaluated based on their experience and qualifications in relation to this position. here at freshbooks, we welcome and encourage applications from people with disabilities. should you require any accommodations during the recruitment process, please advise your recruiter on how we can meet your needs to ensure a fair and equitable selection process in a confidential manner.","['unstructured data', 'go', 'schemas', 'rdbms', 'technical design', 'documentation', 'laser', 'mpp', 'github', 'sql', 'agile environment', 'gcp', 'looker', 'forefront', 'software', 'reporting', 'analytics', 'data', 'data models', 'data engineering', 'tableauiscope', 'relational databases', 'data quality', 'bi', 'security', 'modeling', 'azure sql', 'data management', 'snowflake']","['go', 'sql', 'looker', 'gcp', 'forefront', 'tableau', 'bi', 'rdbms', 'data', 'documentation', 'azure sql', 'data models', 'data quality', 'laser', 'snowflake', 'mpp']","['unstructured data', 'schemas', 'data lineage', 'data cataloging', 'technical design', 'clouds', 'github', 'agile environment', 'software', 'reporting', 'analytics', 'data', 'data engineering', 'relational databases', 'data storage', 'use cases', 'security', 'modeling', 'data management']","['internal customers', 'environment', 'accounting', 'marketing', 'design', 'customer service', 'governance', 'microstrategy', 'architecture']"
570,834,MDM Data Engineer,"as an informatica master data management engineer, you will be responsible for designing, building and running the data driven applications which enable innovative, customer centric digital experiences. you will be working as part of a friendly, cross discipline agile team who helps each other solve problems across all functions. as a custodian of customer trust, you will employ best practice in development, security, accessibility and design to achieve the highest quality of service for our customers. our development team uses a range of technologies to get the job done informatica mdm, informatica idq, nifi . node.js you will be part of the team implementing informatica master data management hosted on amazon web services . you are a fast learner, highly technical, passionate person looking to work within a team of multidisciplinary experts to improve your craft and contribute to the data development practice. here s how learn new skills advance your data development practice design, develop, test, deploy, maintain and improve batch and real time data pipelines continuous refinement of mdm processes to deliver best version of truth assist with design and development of rapid prototyping of solutions support consumers with understanding the data outcomes and technical design collaborate closely with multiple teams in an agile environment qualifications you re the missing piece of the puzzle a passion for data quality strong data analysis skills interest and ability to learn new skills and technologies as needed proficient in configuring and building end to end informatica mdm solutions experience with informatica idq, apache nifi, api development testing, node.js great to haves 3 years of relevant applied mdm experience experience building mdm integrations with aws and or or gcp services experience with informatica idq, informatica powercenter, bmc control m, java, gcp, iics a bit about us our business is connecting canadians. our social impact is using our world leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. when you join our team, you re helping us make the future friendly. we re committed to diversity and equitable access to employment opportunities based on ability your unique contributions and talents will be valued and respected here. primary location canada other locations ca on scarborough, ca qc montreal, ca ab calgary, ca bc vancouver, ca on toronto schedule full time","['amazon web services', 'informatica', 'prototyping', 'data pipelines', 'agile environment', 'gcp', 'testing', 'iics', 'security', 'technical design', 'data quality', 'api', 'data', 'aws', 'data analysis', 'master data management', 'java']","['quality of service', 'amazon web services', 'gcp', 'mdm', 'api development', 'aws', 'data quality', 'apache nifi', 'java']","['agile environment', 'informatica', 'prototyping', 'data pipelines', 'mdm', 'testing', 'security', 'technical design', 'data development', 'data analysis', 'master data management']","['design', 'customer']"
571,837,Data Manager (Research Institute),"job description research institute of the muhc the research institute of the mcgill university health centre is a world renowned biomedical and hospital research centre. located in montreal, quebec, the institute is the research arm of the mcgill university health centre affiliated with the faculty of medicine at mcgill university. the ri muhc is supported in part by the fonds de recherche du qu bec sant . position summary stenoa is a machine learning startup striving to make fundamental breakthroughs in real time video analysis for guiding the diagnosis and treatment of cardiovascular disease, the leading cause of death globally. our research and development team has access to a very large dataset of cardiac catherization videos. with all this data, the data science team is looking for talented engineers to help us manage the annotation and analysis of the videos and the associated medical records. if you are data curious, excited about designing data pipelines, and motivated by having impact on the clinical practice, we want to hear from you. general duties upload and organize videos on an online annotation platform. export labels and annotations continuously following the progress of the annotations team. implement techniques for augmenting the database of annotations produced by trained medical specialists. organize the videos in a hdf5 database. export annotations the labelling software to the hdf5 database. develop technical documentation for the database. lock a complete version of the database for descriptive quantitative analysis. design and implement a scalable infrastructure for expanding the hdf5 database to new sites and patients. website of the organization https or or rimuhc.ca or en education or experience minimum bsc in computer science, software engineering or a related scientific discipline. fluency in python and experience with hdf5 databases. ability to perform summary statistical analysis of texts and database object attributes. ability to write scripts to process json, csv and plain text files. an inquisitive nature in diving into data inconsistencies to pinpoint issues ability to operate in a multidisciplinary team of physicians and computer scientists. capable of thriving in a collaborative environment involving different stakeholders and key opinion leaders. demonstrated ability of working on projects to successful completion involving a wide variety of technologies and systems. additional information status temporary, full time pay scale to be determined based on experience work shift monday to friday, 35hr or week work site glen, ri muhc, 1001 decarie blv, montreal h4a 3j1 https or or rimuhc.ca or careers to learn more about our benefits, please visit http or or rimuhc.ca or en or compensation and benefits this is not a hospital position. note the masculine gender has been used for brevity and includes the feminine gender. equal opportunity employment program le cusm applique un programme d acc s l galit en emploi et invite les femmes, les autochtones, les minorit s visibles, les minorit s ethniques et les personnes handicap es pr senter leur candidature. des mesures d adaptation peuvent tre offertes aux personnes handicap es qui en font la demande en fonction de leurs besoins.","['https', 'python', 'machine learning', 'databases', 'data pipelines', 'software', 'json', 'data science', 'computer science', 'video', 'technical documentation', 'statistical analysis', 'medicine']","['https', 'python', 'databases', 'json']","['http', 'machine learning', 'data pipelines', 'quantitative analysis', 'software', 'csv', 'data science', 'computer science', 'technical documentation', 'statistical analysis', 'medicine']","['environment', 'design', 'education', 'compensation']"
572,838,"Director, Data Science","director, data science montreal, canada at octave group, we believe in the power of music to inspire emotional connections in shared spaces, transforming the way people interact with each other and with their surroundings. we are a group of passionate, diverse, and driven individuals who all share a common goal pioneering new ways humans and music interact through technology. we continuously strive to stay ahead of the curve with our products. our use of cutting edge tech stack, an agile mindset, and a strong focus on the user experience, all make for a challenging learning environment. octave group is looking for a dynamic director who will provide strategic leadership to our data science department. the director, data science will manage a team of data scientists, engineers and analysts and lead and develop our data roadmap and infrastructure, provide business insights, scope, design and implement machine learning models. the director, data science, is innovative, analytical and has excellent communication skills to work cross functionally, with engineering, marketing, finance, and operations to support all data projects. this is a fantastic opportunity for a seasoned leader to grow this department and play a central role at octave group with the very strategic mandate of using data science to impact our users through smarter products and services. what your day to day looks like partner with managers, directors, and executives to identify key opportunities where the data team s input can play a major role. be very active in the data ecosystem of the company by pairing your analytical mind with a knack for data driven storytelling to help transform our products. spearhead the development of our machine learning activities by providing experience and expertise. manage the compilation, analysis, cleaning, and reporting of large datasets using advanced analytics methodologies, driving business improvements. foster a culture of healthy collaboration and partnership within the team by acting as a functional manager, mentor, precious collaborator, and subject matter expert. manage the workload and level of involvement of different roles in the cross functional team balance scope, schedule, budget, quality, and risks. develop and or or review estimates for project schedule, effort, and cost using established estimating models, best practices, and past experience. promote a culture of data driven decision making throughout the organization, supported by scalable processes and protocols, appropriate reporting, and modern tools. what you bring to the table natural leader and mentor, willing and ready to foster a healthy team dynamic. ability to adapt to a new business and comprehend its intricacies. education in statistics, applied math, or any related field. high attention to detail, and a keen eye for discrepancies, non conformities, etc. ability to communicate complex data insight in business terminology for executives and senior managers. ability to work in a global faced paced environment. experience managing and leading data science teams. knowledge of statistical and predictive modeling methodologies and technologies. knowledge of machine learning or statistical modeling. experience in consumer products environments, understanding of consumer behavior and interactions. expert user of data statistics technologies or platforms, and data visualization tools. experience with sql, python and related libraries and technologies experience with big data modeling technologies what s in it for you working alongside a team of talented individuals from diverse backgrounds, origins, and technical knowledge an open and stimulating working environment focused on crafting performant and intuitive user experience. challenging and stimulating projects be implicated with our internal culture collective group to drive events, parties, social clubs, lunch learns and more. working with modern techs, in a culture that drives innovation. pc or mac, you pick. free access to a virtual health care application. long gone are the days of waiting 8 hours at the clinic. conferences, training on the latest and greatest techs, weekly presentations and more. very competitive insurance package which is mostly covered by octave group beautiful offices right next to jarry park flexible hours and full time work from home directeur science des donn es montr al, canada octave group est la recherche d un directeur dynamique qui assurera un leadership strat gique au nouveau d partement des sciences des donn es. l quipe se concentrera sur l analyse des donn es actuelles et historiques, en d composant les tendances et les sch mas, ainsi qu en pr sentant leurs r sultats via des visualisations claires et cibl es, qui seront utilis es pour prendre des d cisions commerciales cl s dans toute l entreprise. il s agit d une occasion unique pour un dirigeant chevronn de cr er ce d partement, de le munir de talents de premi re classe et de mettre en place les bases et strat gie n cessaires. ce r le vous permettra de combiner l analyse, les technologies de pointe, la musique, le comportement du consommateur, tout en collaborant avec des marques de renomm e mondiale. vos efforts joueront un r le principal dans la d finition des d cisions commerciales critiques dans le d veloppement des gammes de produits d octave group, partout travers l organisation. ton quotidien ressemblera ceci d velopper, documenter et communiquer la strat gie et la vision du d partement. agir en tant qu expert sur les technologies appliqu es au sein du d partement. agir en tant que responsable fonctionnel de l quipe au quotidien. tirer parti des donn es usagers d og pour am liorer l efficacit du processus d cisionnel. pr senter et expliquer les r sultats aux principaux intervenants et dirigeants. d velopper et monitorer des indicateurs de performance cl s pour les rapports internes et externes. collaborer avec les quipes produit et plate forme pour assurer un flux de donn es efficace et fiable ainsi que la conformit aux processus et protocoles tablis. tant support par des processus et des protocoles volutifs, des rapports appropri s et des outils modernes, encourager une culture de prise de d cision bas e sur les donn es dans l ensemble de l organisation. embaucher et d velopper des talents de premi re classe. collaborer avec les gestionnaires, les directeurs et les dirigeants pour identifier les principales opportunit s dans lesquelles la contribution de l quipe peut jouer un r le majeur. g rer la compilation, l analyse et la cr ation de rapports pour de grands ensembles de donn es l aide de m thodologies d analyse avanc es, favorisant ainsi les am liorations commerciales. d finir les meilleures pratiques pour la mod lisation, l analyse et la cr ation de rapports de donn es dans l ensemble du service et de toutes les quipes de l organisation. trouver et cr er de nouvelles opportunit s o la science des donn es pourra avoir un impact sur des secteurs d activit nouveaux et existants. agir en tant qu expert en ce qui concerne les statistiques et l apprentissage automatique pour l quipe, en assurant la formation et le mentorat. tablir les outils et l infrastructure de science des donn es, en aidant l quipe et l organisation trouver les meilleures technologies pour analyser, visualiser, extraire et stocker des donn es. ce que l on recherche forte capacit d adaptation une nouvelle entreprise et la compr hension de ses subtilit s. dipl me sup rieur en statistiques, math matiques appliqu es ou tout domaine connexe. grand souci du d tail et sens aigu des divergences, des non conformit s, etc. capacit communiquer aux responsables et aux cadres sup rieurs des informations complexes dans une terminologie commerciale. leader et mentor naturel capacit travailler dans un environnement multinational et tr s dynamique. exp rience dans la gestion et la direction d quipes de science des donn es. connaissance des m thodologies et des technologies de mod lisation statistique et pr dictive. solide connaissance de l apprentissage automatique et de la mod lisation statistique. exp rience dans les environnements de produits grand public, compr hension du comportement du consommateur et de ses interactions. utilisateur expert des technologies or plates formes de donn es et statistiques, ainsi que de leurs outils de visualisation. une personne influente, persuasive et munie de fortes capacit s oratoires. exp rience avec l ensemble des technologies n cessaires pour produire des r sultats de science des donn es collecte, analyse, visualisation, cr ation de rapports, etc. exp rience avec le traitement automatique des langues et du moissonnage du web. exp rience avec sql, r et python et les biblioth ques et technologies associ es exp rience avec les technologies de mod lisation big data ce que l on te propose voluer aux c t s d un groupe de personnes super talentueuses et chaleureuses un environnement amusant, diversifi , ouvert et qui volue rapidement, ax sur une atmosph re familiale et sur la cr ation d une exp rience utilisateur optimale des projets stimulants et amusants travailler avec des technos modernes, dans une culture qui pr ne l innovation constante pc ou mac, votre choix 50 de r duction sur votre abonnement mensuel opus acc s gratuit une application offrant un support de sant virtuel. fini les attentes interminables en clinique conf rences, budgets de formation, pr sentations hebdomadaires et autres programme d assurance tr s comp titif, principalement couvert par octave group horaires et environnement de travail flexibles superbes bureaux 2 pas du parc jarry","['user experience', 'big', 'data visualization', 'big data', 'sql', 'python', 'statistics', 'reporting', 'data science', 'analytics', 'data', 'machine learning', 'statistical', 'mac', 'terminology', 'business insights', 'datasets', 'compilation', 'modeling', 'r']","['sql', 'python', 'big', 'business insights', 'mac', 'big data', 'r']","['machine learning', 'statistics', 'user experience', 'reporting', 'datasets', 'data visualization', 'data science', 'compilation', 'analytics', 'statistical', 'data', 'modeling', 'terminology', 'data scienceive']","['environment', 'events', 'education', 'marketing', 'design', 'finance', 'acting', 'presentations', 'consumer products', 'insurance']"
573,839,Jr. Data Engineer (ETL/SQL),"next pathway the automated cloud migration company listed as one of canada s hottest start ups by the globe and mail, next pathway is a technology services company providing clients a pathway from existing to emerging technologies. our automation technology helps our customers accelerate the migration of complex applications and workloads to the cloud. next pathway is full of bright and diverse thinkers. with deep exposure to ai, machine learning and robotic process automation, our team members have opportunities to be trailblazers in the technology space. we encourage self starters, transparency and team connectivity. we know diverse teams make strong teams. we welcome people of diverse backgrounds, experiences, and perspectives. our work environment is based on 3 core principles emphasize quality first, each and every time put people in roles where they will succeed and feel challenged build a team of well qualified individuals that can share ideas and learn from each other next pathway rewards people for hard work, loyalty, innovation and mutual support. we aim to match people s strengths, skills and talents to our requirements. identifying this ideal match between attitude, skill and need, leads to success. next pathway is located in the heart of the financial district, minutes from union station and the subway. we are looking for a skilled jr. data engineer to join our team the candidate needs to have extensive experience as follows minimum of 3 years of proven experience in a core competency proven hands on software development experience strong data warehouse knowledge and experience strong sql knowledge and experience, including developing and optimizing complex queries, creating efficient udfs to extend the functionalities experience in any rdbms is nice to have experience with cloud technologies experience with etl tools experience with major programming languages strong understanding and experience of relational database, include design and implementation develop and maintain unit tests and integration tests, and test automation. adoption of agile and scrum development methodology ba or ms or phd degree in computer science, engineering, or a related subject other technologies you might work with include microsoft office suite basecamp project management team communication slack messaging platform zoom meetings and video conferencing confluence collaboration tool jira project management software other skills team player with excellent interpersonal and communication skills strong work ethic with a positive attitude and a passion for data and development strong analytical and problem solving skills excellent time management skills contract length 6 months job types full time, contract schedule monday to friday experience sql 3 years python 2 years pl or sql 2 years scripting 2 years work remotely yes","['rdbms', 'confluence', 'cloud migration', 'sql', 'python', 'software', 'scripting', 'software development', 'integration', 'technology services', 'machine learning', 'scrum', 'process', 'automation', 'jira', 'programming languages', 'zoom', 'computer science', 'etl', 'ai']","['sql', 'python', 'jira', 'programming languages', 'rdbms', 'zoom', 'udfs', 'confluence', 'technology services']","['machine learning', 'cloud migration', 'tests', 'test', 'software', 'scrum', 'scripting', 'process', 'software development', 'computer science', 'video', 'integration', 'methodology', 'automation', 'etl', 'ai']","['environment', 'microsoft office', 'design', 'project management', 'adoption']"
574,840,Data Integration Engineer,"main purpose we are recruiting a data integration engineer who is knowledgeable in the full data integration lifecycle in a complex and demanding commercial environment. based in calgary, ab, the engineer will be part of a global team responsible for the ingestion, management, provision of both market data, and fundamental data for the use of business analysts, data scientists, traders and applications such as dashboards and trading systems. knowledge skills and abilities, key responsibilities knowledge skills and abilities, key responsibilities financial or commodity market data ingestion, data integration etl or elt pipeline design, data modelling, data provisioning data virtualization and logical data warehouse architecture python, sql aws data stack data quality management experience with data related to energy and metal commodities, power generation, weather or shipping would be an asset abilities, experience and qualifications bachelor s degree in computer science, information systems or related subjects aws certifications are a plus experience with enterprise scale data systems competencies ability to communicate effectively with a diverse set of stakeholders across business lines and technology understanding and experience implementing software engineering best practices ability to work as part of a global team utilising agile management methods key relationships and department overview the data science and engineering team researches, develops, and provides advanced analytics and data services to the trading business, and other commercial operations at trafigura. it is comprised of data scientists, data engineers, and quantitative finance experts. it is a commercially driven, front office aligned team that works in close partnership with the trading desks, global research and enterprise technology.","['data services', 'dashboards', 'sql', 'python', 'software', 'data science', 'data', 'analytics', 'integration', 'aws', 'data systems', 'provisioning', 'quantitative', 'trading systems', 'information systems', 'computer science', 'virtualization', 'market', 'etl']","['sql', 'python', 'provisioning', 'data', 'aws']","['data systems', 'data ingestion', 'software', 'market data', 'agile management', 'dashboards', 'information systems', 'data science', 'data services', 'computer science', 'data', 'market', 'integration', 'virtualization', 'trading systems', 'analytics', 'etl']","['power generation', 'environment', 'commercial operations', 'trading', 'design', 'finance', 'front office', 'recruiting', 'architecture', 'business lines']"
575,842,Research Scientist - Fisheries Acoustic,"fisheries and oceans canada fisheries and ecosystem sciences division moncton se res 01 se res 02, se res 03, se res 04, se res 05 59,441 to 153,645 for further information on the organization, please visit fisheries and oceans canada closing date 30 june 2021 23 59, pacific time who can apply persons residing in canada and canadian citizens residing abroad. apply online important messages we are committed to providing an inclusive and barrier free work environment, starting with the hiring process. if you need to be accommodated during any phase of the evaluation process, please use the contact information below to request specialized accommodation. all information received in relation to accommodation will be kept confidential. assessment accommodation duties the department of fisheries and oceans canada, gulf region is looking to hire a scientific researcher to develop abundance and distribution indices from hydroacoustic data, for a variety of fish species in the southern gulf of st. lawrence. the work consists of exploring the appropriate analysis methods in the literature , developing an analysis method specific to the species targeted by the survey, carrying out the analysis of a temporal series of hydroacoustic data using echoview software, using the acoustic data to develop abundance indices using statistical methods of spatial analysis, writing associated publications. intent of the process the intent of this process is to staff a 18 months temporary research scientist position in moncton, nb. could be extended based on funding. the pool of qualified or partially qualified candidates may be used to staff similar positions with various language requirements and tenures. positions to be filled 1 information you must provide your r sum . in order to be considered, your application must clearly explain how you meet the following education graduation with an acceptable doctoral degree within the last 3 years from a recognized post secondary institution in a field related to the duties of the position. degree equivalency experience experience in planning and conducting independent research on fish and or or fisheries biology. experience in performing quantitative analyses and interpreting data using statistical methods or tools associated with biological and spatio temporal studies. experience in producing briefing materials and presentations, as well as presenting research results at scientific symposia, workshops or meetings. experience creating scientific publications in international peer reviewed journals with at least two articles within the past 5 years and at least one who is as a first author. experience working with a team of researchers and support staff. experience with hydroacoustic data analysis. experience in working with the r environment for statistical computing and graphics. note the term fish includes finfish and invertebrates. if you possess any of the following, your application must also clearly explain how you meet it the following experience qualifications could be deemed essential depending on the position. asset experience experience doing independent research in a field of the natural sciences related to the duties of the position. experience in using fisheries acoustic technologies and methods. experience in analyzing fisheries acoustic data. experience in developing and applying acoustics classification algorithms for fish species. the following will be applied or assessed at a later date various language requirements english or french essential bbb or bbb, and cbc or cbc information on language requirements abilities ability to communicate effectively orally and in writing. ability to work within a multidisciplinary team. personal suitability initiative dependability effective interpersonal skills the following may be applied or assessed at a later date selection may be limited to members of the following employment equity groups aboriginal persons, persons with disabilities, visible minorities, women information on employment equity conditions of employment reliability status security clearance medical suitability as required by the position other information the public service of canada is committed to building a skilled and diverse workforce that reflects the canadians we serve. we promote employment equity and encourage you to indicate if you belong to one of the designated groups when you apply. information on employment equity a variety of assessment tools may be used in the assessment of candidates, such as oral interview, written test, and reference checks. some assessment tools may be administered electronically, others, in person. you must provide proof of your education credentials. persons are entitled to participate in the appointment process in the official language of their choice. our intention is to communicate with candidates through emails and or or through the or government jobs applicant account. candidates participating in this selection process must include in their application a valid email address and make sure that this address is functional at all times and that their system accepts messages from unknown users . preference preference will be given to veterans and to canadian citizens, in that order, with the exception of a job located in nunavut, where nunavut inuit will be appointed first. information on the preference to veterans we thank all those who apply. only those selected for further consideration will be contacted.","['echoview', 'computing', 'software', 'spatial analysis', 'security', 'interpreting data', 'statistical', 'graphics', 'data analysis', 'algorithms', 'r']",['r'],"['computing', 'software', 'spatial analysis', 'security', 'interpreting data', 'statistical', 'graphics', 'data analysis', 'algorithms', 'planning']","['environment', 'education', 'biology', 'materials', 'briefing', 'acoustics', 'government', 'workshops', 'assessment', 'hiring', 'presentationsmposia']"
576,843,"Data Engineer - SQL, Shell Scripting and Python - 312096","data engineer sql, shell scripting python on behalf of our client in the banking sector, procom is looking for a data engineer sql, shell scripting python. data engineer sql, shell scripting python job description the main function of the data engineer is to develop, evaluate, test and maintain architectures and data solutions within our organization the typical data engineer executes plans, policies, and practices that control, protect, deliver working closely with 40 different data scientist as well as data strategist opportunity to collaboratively work together, use analytical and critical thinking skills exposure to many different team members within bank identifying data sources and create data pipeline using shell script or python script working on the code versioning on bit bucket writing python scripts to extract data from various sources and ingest data from or to google cloud data engineer sql, shell scripting python mandatory skills 4 6 years of experience with data engineering skills 4 6 years of hands on experience with sql, shell scripting and python 4 6 years of hands on experience ingesting data using apis 4 6 years of hands on experience with bi tools or big data technologies like hadoop, spark, scala data engineer sql, shell scripting python nice to have skills knowledge of dialogflow es and cx apis, bigquery, google cloud data loss prevention, dataflow bachelors or masters in related studies data engineer sql, shell scripting python assignment start date asap 4 months to start data engineer sql, shell scripting python assignment location toronto, on work remotely","['sql', 'python', 'shell', 'banking', 'scala', 'bi', 'scripting', 'hadoop', 'data solutions', 'big data', 'data engineering', 'shell scripting']","['sql', 'python', 'scala', 'bi', 'hadoop', 'shell script', 'big data', 'shell scripting']","['data solutions', 'data engineering', 'banking']",[]
577,844,Staff Application Data Engineer,"requisition id 100504 join the global community of scotiabankers to help customers become better off. the team scotiabank s global technology services technology operations site reliability engineering is responsible for the operations engineering required to provide highly available and resilient systems. in gts enterprise data warehouse reference data management techops sre, we are responsible for providing critical data platform services, following sre and data governance best practices, as well as consulting and coordinating with the bank s technology teams to meet business expectations. the role you will contribute to the application and platform support of the edw ecosystem through the solution and test strategy design, development, testing and implementation of availability, performance, security, currency, and problem remediation solutions. you will partner with the product owner, engineering teams, and operations to deliver a high quality product by recommending, creating, developing, and testing solutions for that are aligned with best practices within the sre framework. you will be a technical lead of like minded data engineers, prioritizing their focus areas, reviewing their solutions and providing feedback as required. you will maintain and recommend continuous improvements to code quality, documentation, organization, and performance meeting security, change, and release management standards ensuring sre targets are met or improved. you will identify opportunities, recommend, and implement solutions to improve data availability, optimize data retention, and enhance data security. you will identify opportunities for quality improvements recommending and implementing automation to prevent problem recurrence and reduce toil. you will create and continuously improve functional and non functional testing ensuring tests are automated, repeatable, and benchmarked. you will inventory, build and maintain application artifacts creating a robust repository of living documentation including application, deployment and operational guides. you will provide knowledgeable, and skilled support for deployments and lead production incident response, striving to meet or exceed service level objectives. you will provide after hours support as required. is this role right for you you are a skilled application data engineer who possesses a broad set of skills and is familiar with sre software engineering culture and practice. you enjoy creating solutions that encompass people, process, and technology. you enjoy looking for opportunities to be proactive, automate, and solve problems before they happen. you want to be challenged with problem solving in time sensitive situations to reduce system downtime and customer impact, taking those learnings forward as continuous improvements. do you have the skills that will enable you to succeed in this role you have strong communication and good interpersonal skills to build relationships with internal and external business partners and vendors. you have a track record as a strong team player with a proven ability to create technical specifications, develop, and implement solutions for highly available and resilient systems. you have at least 4 years of hands on technical working experience in designing solutions and authoring technical specifications. you have at least 6 years of hands on technical working experience as an application data engineer in and or or delivering for organization that have large, complex data warehouse. you have at least 6 years of hands on technical working experience as an informatica developer. technical working experience with sas, python, cobol and cognos is an asset. you have at least 4 years of hands on technical working experience in designing test strategies and quality assurance testing. you can demonstrate a technical understanding with security, firewalls, and network protocols. you can demonstrate a solid understanding of data governance. you possess excellent problem solving skills, prefer to identify and resolve issues before they become a problem, and can work under pressure in a dynamic environment. you have hands on experience responding to production incidents that cross application and technology boundaries. you have completed a post secondary education in computer science, engineering or in a related technology field. what s in it for you you will be a part of a site reliability engineering team that will help you grow you will have an opportunity to bring valuable and long lasting contributions to the bank. we are technology partners who help the business transform how our employees around the world work. you ll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world. we have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success we also foster an environment of innovation and continuous learning. we care about our people, allowing them to design how they work to deliver amazing results. we offer a competitive total rewards package, including a performance bonus, company matching programs , generous vacation health or medical or wellness benefits employee banking privileges. while we currently work remotely from home, when it is deemed safe to return physically to work, our primary location in downtown toronto is design focused on enabling collaboration through both environment and technology. located in the heart of toronto s financial district, the work site is located right above the ttc s line 1 king subway station. this location has access to the path is located minutes from go transit or via rail hub at union station as well as the ttc s king 504 streetcar line. minutes from the gardiner expressway the dvp. located next door is the commons, a dining space for employees, where breakfast lunch are served. also, the bean server hot or cold beverages snacks with plenty of room to lounge recharge. also, many meal or snack options shopping services for your everyday needs in the path without venturing outside. location canada ontario toronto as canada s international bank, we are a diverse and global team. we speak more than 100 languages with backgrounds from more than 120 countries. our employees are committed to a superior customer experience and use the bank s six guiding sales practice principles to ensure they act with honesty and integrity. at scotiabank, we value the unique skills and experiences each individual brings to the bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. if you require accommodation during the recruitment and selection process, please let our recruitment team know. if you require technical assistance, please click here. candidates must apply directly online to be considered for this role. we thank all applicants for their interest in a career at scotiabank however, only those candidates who are selected for an interview will be contacted.","['go', 'quality assurance', 'firewalls', 'documentation', 'remediation', 'working experience', 'cobol', 'technology operations', 'python', 'data retention', 'encompass', 'software', 'enterprise', 'data', 'sas', 'technology services', 'informatica', 'testing', 'specifications', 'automation', 'banking', 'security', 'computer science', 'data management']","['go', 'technology operations', 'python', 'quality assurance', 'data', 'documentation', 'technology services', 'cobol', 'sas']","['informatica', 'tests', 'banking', 'software', 'technical understanding', 'testing', 'reference data management', 'security', 'firewalls', 'network protocols', 'computer science', 'data', 'specifications', 'remediation', 'release management', 'working experience', 'automation', 'enterprise data']","['environment', 'education', 'encompass', 'incident response', 'currency', 'design', 'customer experience', 'sales', 'operations', 'governance', 'consulting']"
578,846,Data Engineer,"about project x the heart of what we do is drive for unique and innovative solutions that solve our customers problems. we are trusted advisors who create data and analytics solutions for complex client problems. we do this through collaboration, creativity and an innate need to solve tough data problems. data runs deep in our veins and is what makes up who we are, individually and as a team, allows us to do the work we re passionate we think differently. you are all about being that data engineer who receives detailed and high level requirements specifications from the client for implementation. you will analyze, design, develop, optimize, test, and document data programs and solutions to meet our clients needs. you will work with architects, designers, business analysts, and other developers to provide quality development deliverables. this position does not have any direct reports. what you need to bring experience in designing and implementing technical enhancements of data warehouse, big data or business intelligence as required. a proven understanding and track record in one of aws, azure, gcp, or other open source stacks. object oriented programming, api integration and understanding of the modern data engineering stack. ability to build high quality code in python for data integration. strong ability and understanding of rdbms and sql data structures. utilize scripting, library and other external programming languages to complement and enhance the functionality the data integration tools provide. apply scheduling, automation and innovation on new and existing data platforms for those development projects aligned to the client s business or organizational strategies. participate in the requirements gathering, analysis and solutions design. conduct unit integration tests, assisting in test preparations to ensure data integrity, data quality, and program functional completeness correctness. create detailed technical documentation for all programs and other deliverables. implement processes aligned to data management best practices and standards, ensure data quality and process performance within all system development deliverables. own the responsibility to meet deadlines and strive to complete work in accordance with project plans. participate in the development of project plans to establish appropriate workload expectations and schedules. demonstrate collegial teamwork internally and with clients, by communicating clearly with all project team members to identify and resolve issues for delivery success. contribute to lessons learned and process improvements. apply new technologies to improve work efforts when available through r d and pocs. maintain an up to date knowledge of, and adopt, relevant market trends and practices. over 2 years of required skills, knowledge and experience working on technical projects as a data pipeline developer or engineer providing technical solutions through the use of big data tools. detailed, practical working knowledge in big data pipeline, data query or ingestion tools like glue, hive, sqoop, spark, kafka, impala. hadoop, oozie, etc. proven experience using restful webservices and json. working knowledge in scripting languages like python, java, shell, bash, sql programming, creating or optimize complex queries, tables, view, and procedures scheduling tools airflow, luigi, oozie, cron cloud and on premise technology from infrastructure through the technology stack like aws, gcp or azure general knowledge in data modeling, working knowledge of data modelling and data modelling concepts such as logical or physical modelling. data warehousing, including data mapping and transformations, data dependencies, data source analysis and profiling above average skills in communication, solution based approaches to solving problems, level headed decision making, time management, prioritizing effectively while delivering high quality work, as well as collaborating with internal teams , external teams , and client team members demonstrated skills in leadership and integrity and working independently proven ability to meet deadlines and commitments, adaptive and flexible and approach situations with a consultative mindset agile delivery methodology, devops, continuous integration or continuous deployment concepts and method. testing automation and other related or emerging technologies is an asset education and experience bachelor s degree, preferably in software or computer science or engineering fields or have related industry experience or acumen 2 years of proven data engineering experience on aws, azure, gcp or other open source platforms. work environment we are currently a virtual working organization. in the future we may move back to where our work takes place in office environments, either at project x hq or on various client sites. in our commitment to promote fair and equitable treatment of all employees and applicants, project x ltd. provides equal employment opportunities for all individuals regardless of age, sex, disability, race, ethnic origin, citizenship, creed, sexual orientation, marital status or any other ground as described in the ontario human rights code. in addition, accommodation will be provided during the hiring process. due to the current covid 19 pandemic interview will be conducted online project x ltd. staff currently work from home m9hgcuxwgc job type full time","['bash', 'rdbms', 'big', 'data integrity', 'big data', 'hive', 'java', 'data mapping', 'glue', 'sql', 'python', 'gcp', 'software', 'scripting', 'json', 'analytics', 'programming', 'aws', 'integration', 'data', 'data engineering', 'data warehousing', 'testing', 'requirements gathering', 'specifications', 'business intelligence', 'data quality', 'automation', 'airflow', 'sqoop', 'data structures', 'programming languages', 'devops', 'hadoop', 'api', 'computer science', 'technical documentation', 'modeling', 'data management']","['system development', 'rdbms', 'big data', 'hive', 'java', 'glue', 'sql', 'python', 'gcp', 'json', 'programming', 'aws', 'business intelligence', 'data quality', 'airflow', 'sqoop', 'programming languages', 'hadoop', 'api', 'gcp oriented']","['bash', 'data integrity', 'data mapping', 'tests', 'software', 'scripting', 'data', 'analytics', 'integration', 'data engineering', 'data warehousing', 'continuous', 'webservices', 'testing', 'requirements gathering', 'specifications', 'automation', 'unit', 'methodology', 'data structures', 'devops', 'computer science', 'technical documentation', 'modeling', 'data management']","['environment', 'education', 'project plans', 'development projects', 'design', 'functionality', 'hiring', 'r']"
579,847,"Senior Data Engineer, Corporate Systems","company description make an impact at a global and dynamic investment organization when you invest your career in cpp investments, you join one of the most respected and fastest growing institutional investors in the world. with current assets under management valued in excess of 400 billion, cpp investments is a professional investment management organization that globally invests the funds of the canada pension plan to help ensure long term sustainability. the cpp fund is projected to exceed 450 billion by 2025. cpp investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed income instruments, and is headquartered in toronto with offices in hong kong, london, luxembourg, mumbai, new york city, san francisco, s o paulo and sydney. cpp investments attracts and selects high calibre individuals from top tier institutions around the globe. join our team and look forward to diverse and inspiring colleagues and approachable leaders stimulating work in a fast paced, intellectually challenging environment accelerated exposure and responsibility global career development opportunities being motivated every day by cpp investments important social purpose and unshakable principles a deeply rooted culture of integrity, partnership and high performance if you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here s an opportunity for you to invest your career at cpp investments. job description the data engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy. as senior data engineer you will be responsible for developing, constructing and testing large scale data processing systems based on aws cloud that will help address the disparate data consumption or integration or operation challenges of a growing organization. through close partnership with investment professionals, you will see firsthand how your contribution is delivering long term value to the cpp fund for the benefit of 20 million cpp contributors and beneficiaries. you are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry. the opportunity design solutions aligned with long term architecture and technology strategy using amazon web services for cloud development. participate in the development life cycle from start to completion requirements analysis, development, testing, and deployment. work in a fast paced environment collaborating with developers, data engineers and architects. develop dataset processes for data modelling, mining and production. ensure architecture will support the requirements of cpp investments business. prepare, transform, combine and manage structured and unstructured data for use by cpp investments business users. recommend ways to improve data reliability, efficiency and quality. define and shape cpp investments future technology and research process. qualifications university degree in engineering or computer science preferred. deep experience working with big data including cleaning or transforming or cataloging or mapping or etc. familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud . experience of etl pipelines, managing multiple datasets and providing necessary support. familiarity building applications in an aws environment familiarity working with data lakes using s3 or redshift. exposure to big data workflows and analytics tools . deep proficiency in python with experience using spark, pandas or pyspark. familiar with one or more analytic tools such as tableau or qlik. an understanding of ci or cd pipelines and experience with devops. experience building flexible solutions that can adapt quickly to changing requirements. ability to work in an entrepreneurial environment and be a self starter. interests in the financial industry. exemplify cpp investments guiding principles of integrity, partnership and high performance. additional information visit our linkedin career page or follow us on linkedin. li post at cpp investments, we are committed to diversity and equitable access to employment opportunities based on ability. we thank all applicants for their interest but will only contact candidates selected to advance in the hiring process. our commitment to inclusion and diversity in addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. if you require an accommodation for any part of the recruitment process , please let us know and we will work with you to meet your needs. disclaimer cpp investments does not accept resumes from employment placement agencies, head hunters or recruitment suppliers that are not in a formal contractual arrangement with us. our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web site job postings. any resume or other information received from a supplier not approved by cpp investments to provide resumes to this posting or web site will be considered unsolicited and will not be considered. cpp investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information.","['unstructured data', 'requirements analysis', 'tableau', 'investment', 'pyspark', 'ci', 'big data', 'sustainability', 'python', 'data processing', 'cd', 'pandas', 'analytics', 'aws', 'integration', 'data systems', 'pipelines', 'data engineering', 'investment management', 'amazon web services', 'testing', 'enterprise data', 'devops', 'datasets', 'computer science', 'cloud development', 'etl']","['amazon web services', 'python', 'tableaulik', 'pyspark', 'san', 'pandas', 'data lakes', 'aws', 'big data', 'cpp', 'pipelines', 'cp']","['unstructured data', 'investment management', 'requirements analysis', 'data processing', 'cd', 'testing', 'datasets', 'ci', 'devops', 'computer science', 'analytics', 'integration', 'cloud development', 'data systems', 'sustainability', 'data engineering', 'etl', 'enterprise data']","['environment', 'linkedin', 'job postings', 'design', 'real estate', 'public equity', 'cpp', 'hiring', 'investments', 'private equity', 'architecture', 'cp']"
580,848,Data Engineer (AWS),"tiger analytics is a fast growing advanced analytics consulting firm. our consultants bring deep expertise in data science, machine learning and ai. we are the trusted analytics partner for multiple fortune 500 companies, enabling them to generate business value from data. our business value and leadership has been recognized by various market research firms, including forrester and gartner. we are looking for top notch talent as we continue to build the best global analytics consulting team in the world. the big data engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. the right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges.we are looking for someone who can bring their vision to the table and implement positive change in taking the company s data analytics to the next level. requirements bachelor s degree in computer science or similar field 5 years of experience in a data engineer role experience with relational sql and nosql databases like mysql, postgres strong analytical skills and advanced sql knowledge experience with aws cloud services ec2, emr, athena experience with object oriented or object function scripting languages python, java, scala, etc. experience extracting or querying or joining large data sets at scale a desire to work in a collaborative, intellectually curious environment strong communication and organizational skills benefits this position offers an excellent opportunity for significant career development in a fast growing and challenging entrepreneurial environment with a high degree of individual responsibility.","['analytical skills', 'visualization', 'databases', 'emr', 'dashboards', 'big data', 'mysql', 'java', 'data analytics', 'sql', 'python', 'scala', 'scripting', 'data science', 'database design', 'analytics', 'aws', 'nosql', 'machine learning', 'athena', 'cloud services', 'computer science', 'ai']","['object function', 'sql', 'python', 'databases', 'emr', 'scala', 'athena', 'java', 'big data', 'aws', 'mysql', 'nosql']","['data analytics', 'analytical skills', 'machine learning', 'visualization', 'scripting', 'dashboards', 'database design', 'data science', 'computer science', 'analytics', 'cloud services', 'relational sql', 'ai']","['environment', 'business value', 'consulting', 'market research']"
581,849,"Product Manager, Data","summary wikimedia is looking for an experienced and collaborative product manager to join our product team while working closely with our analytics engineering team, data engineering team, and numerous other teams at wikimedia to strengthen our data and analytics products. wikipedia is one of the largest internet properties in the world, visited by 1 billion people a month across 280 different languages. our properties and api s generate a huge amount of data that we process through our custom built open source stack. we use this data to inform our strategy, make specific product decisions, inform academic research, and, increasingly, plug this directly into the product itself. due to our scale, our commitment to opensource, our desire to share our data with academics, and our strict privacy restrictions, this is no easy task. in fact, today, core capabilities like a or b testing, funnel analysis, and metrics like user retention are not readily available to our teams. you will work with experienced teams of data engineers, data scientists, analysts, and product managers to set and execute a strategy and roadmap for improving our end to end data infrastructure to make collecting data, processing it and using it to make decisions as efficient as possible. in doing so, you will learn from and partner with stakeholders across data science, research, design and product as well as academics and wikimedia volunteers. this is an opportunity to do good while having a high level of impact on a large scale media property. you are responsible for partner closely with data leaders across the organization to help define and set a coordinated data strategy across the organization ideate and develop data products and experiences that enable data scientists, analysts, product managers, and lay people to discover and consume information about wikipedia. collaborate closely with product and engineering teams to handle new requests, prioritize work, communicate progress, and ensure that we deliver impactful work that aligns with our strategic priorities. understand the needs of users in order to prioritize new features balance privacy concerns against the value of the insights your team enables. del iver iterative products that drive incremental value and enable quick feedback from stakeholders wherever feasible use both qualitative and quantitative methods to measure the impact of your work work to expand global access to free knowledge skills and experience 2 years of experience designing and building data products that span across data analytics, data flows, etc. as a product manager or equivalent role proven track record implementing complex data systems leveraging supporting data analysis, reasoning, and optimization as part of the decision making process expertise in data handling approaches and technologies with good understanding of system development lifecycles and modern data architectures experience working with structured and unstructured data understanding of data governance, data modeling, data pipelines, and data infrastructure familiarity working in an agile software development environment capability to work within cross functional teams to drive results outstanding written and verbal communication skills with the ability to translate complex technical requirements bachelor s degree or equivalent in relevant work experience qualities that are important to us problem solver passionate about data and how it can be leveraged to drive data driven decisions additionally, we d love it if you have background in software development, engineering, data science or analytics experience working with microservice architectures experience with open source technology experience interacting with free and open source software projects and communities experience editing wikipedia or contributing to other wiki projects the wikimedia foundation is... ...the nonprofit organization that hosts and operates wikipedia and the other wikimedia free knowledge projects. our vision is a world in which every single human can freely share in the sum of all knowledge. we believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. we host the wikimedia projects, build software experiences for reading, contributing, and sharing wikimedia content, support the volunteer communities and partners who make wikimedia possible, and advocate for policies that enable wikimedia and free knowledge to thrive. the wikimedia foundation is a charitable, not for profit organization that relies on donations. we receive financial support from millions of individuals around the world, with an average donation of about 15. we also receive donations through institutional grants and gifts. the wikimedia foundation is a united states 501 tax exempt organization with offices in san francisco, california, usa. as an equal opportunity employer, the wikimedia foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. we encourage people with a diverse range of backgrounds to apply. we do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics. if you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at or 839 6885. u.s. benefits perks fully paid medical, dental and vision coverage for employees and their eligible families the wellness program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more the 401 retirement plan offers matched contributions at 4 of annual salary flexible and generous time off vacation, sick and volunteer days, plus 22 paid holidays including the last week of the year. family friendly 100 paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room. for those emergency moments long and short term disability, life insurance and an employee assistance program pre tax savings plans for health care, child care, elder care, public transportation and parking expenses telecommuting and flexible work schedules available appropriate fuel for thinking and coding and monthly massages to help staff relax paid travel to wikimedia foundation events all around the world equipment including a laptop, monitor, plus a one time stipend to cover any additional needs to make sure you have the best work experience great colleagues diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission driven and intensely passionate people please note that for remote roles located outside of the u.s., we defer to our peo to ensure alignment with local labor laws. more information wikimedia foundation blog wikimedia 2030 wikimedia medium term plan our commitment to equity this is wikimedia foundation facts matter our projects our tech stack","['unstructured data', 'data infrastructure', 'technical requirements', 'data analytics', 'software', 'data science', 'software development', 'analytics', 'data', 'data systems', 'data engineering', 'solver', 'data pipelines', 'data products', 'testing', 'agile', 'data analysis', 'api', 'optimization', 'modeling', 'software projects']","['sania', 'solver', 'api']","['unstructured data', 'data infrastructure', 'technical requirements', 'data analytics', 'software', 'data science', 'software development', 'analytics', 'data', 'data systems', 'data engineering', 'data pipelines', 'data products', 'testing', 'agile', 'data analysis', 'complex', 'optimization', 'modeling', 'software projects']","['environment', 'events', 'education', 'metrics', 'design', 'donations', 'expenses', 'retirement', 'governance', 'academic research', 'insurance']"
582,850,Senior Cloud Data Architect,"overview you ve got big plans. we have opportunities to match, and we re committed to empowering you to become a better you, no matter what you do. when you join kpmg, you ll be one of over 219,000 professionals providing advisory and business enablement services across 147 countries. with the support to do things differently, grow personally and professionally and bring your whole self to work, there s no limit to the impact you can make. let s do this. the opportunity join a growing cloud advisory focused on next gen solutions in a fast paced environment. we care about building great relationships and we re looking for experienced candidates who are drawn to technology. this is a chance to get in on the ground floor and a unique leadership opportunity to be part of a team dedicated to developing tomorrow s cloud based solutions. we are seeking passionate and driven individuals who bring thought leadership to the exciting space of cloud data architecture what you will do you re a seasoned leader with a track record for enabling the adoption of next gen data technologies within regulated industries. you re a builder at heart and have designed, architected, implemented, and have a track record for deploying elegant solutions to complex problems. in your career you ve supported enterprises in modernizing their data platforms and bi systems. you develop proof of concepts to demonstrate the possibilities. you perform data analysis, map data elements and understand core bi concepts. you ve been significantly involved in the migration of on premise data silos to cloud based data lakes within the context of hybrid cloud architectures. you have served the needs of key stakeholders in this space including application developers, data scientists and risk controls partners. you understand the importance of data governance and data stewardship and how these concepts translate into data architecture. you have a broad and deep understanding of canadian enterprise landscape and ideally have finance industry experience. you have a clear and empathetic understanding of where canadian enterprises are in their cloud journeys, what makes them tick and how to effectively drive change. you re ahead of the curve and understand where the industry is going. when working with clients you strive to bring everyone with you and elevate the teams you work with. these roles can be filled in various locations across canada, though you will be asked to work on projects outside your local office. we are a dynamic and innovative team and equally passionate about what we do and the quality of services we provide to our clients. what you bring to this role 10 years of experience in sdlc with strong emphasis on current big data technologies including cloud based services. examples spark, scala, spark mlib, hadoop, tableau, cassandra, databricks, synapse, asdl, datafactory, aurora, dynamo, kinesis, emr, s3, elastic cache, redshift, rds airflow, etc. 10 years of factory, informatica, python, cognos, 10 managing bi frameworks, design principles, and standards. working with azure good understanding of data governance and data lineage and how current technology solutions intersect with these concepts in related technology platforms. experience implementing big data and data warehouse architectures including relevant current and legacy patterns star schema, snow flake schema , fact and dimensional tables, physical and logical data modeling using relevant tools architect, design develop big data solutions including roadmap design and development, developing supporting infrastructure, organization structures that support big data initiatives. architecting and implementing analytics engines, in both batch and streaming scenarios, using hadoop mr, oozie, spark sql, spark mlib and cassandra, sqoop, flume, kafka, spark streaming, spark mllib, etc. candidate should also have good understanding of public cloud platforms that provide these or competing options. excellent understanding of hadoop architecture and underlying framework including hive, hdp, pig, flume, storm and map reduce open source tools or technologies and storage management. extensive experience in data modeling, data architecture, solution architecture, data warehousing business intelligence concepts and master data management . expertise in architecting big data pipelines covering key milestones ingestion, staging, cleansing, transformation, model, analyse and report. experienced with nosql databases hbase, cassandra mongodb, database performance tuning data modeling. extensive knowledge in architecture design of etl or elt environments leveraging popular platforms e.g. informatica power center, teradata and large data volumes. experience in migrating data warehouses and databases into hadoop or nosql platforms in cloud environments. experience in financial industry is a plus. keys to your success ability to work independently with minimal supervision as well as work effectively within a multi disciplinary team. superior verbal and written interpersonal communication skill. excellent client service skills. well organized with good prioritization or workload management abilities. professional discipline and importance of outstanding work. commitment to self learning and continuous skill and professional knowledge development. professional curiosity. learn more about where a career at kpmg can take you. our values, the kpmg way integrity, we do what is right excellence, we never stop learning and improving courage, we think and act boldly together, we respect each other and draw strength from our differences for better, we do what matters kpmg in canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier free workplace that allows all of our people to reach their full potential. a diverse workforce is key to our success and we believe in bringing your whole self to work. we welcome all qualified candidates to apply and hope you will choose kpmg in canada as your employer of choice. if you have a question about accessible employment at kpmg, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact kpmg s employee relations service team for support at email or phone 416 777 8002 or toll free 1 888 466 4778 option 3. for general recruitment related inquiries, please contact the hr delivery centre at","['databases', 'tableau', 'emr', 'big', 'cleansing', 'mongodb', 'hive', 'performance tuning', 'map', 'master', 'sql', 'dynamo', 'python', 'scala', 'data', 'analytics', 'data warehousing', 'design principles', 'nosql', 'teradata', 'informatica', 'data pipelines', 'hybrid cloud', 'business intelligence', 'data analysis', 'technology platforms', 'cassandra', 'airflow', 'sqoop', 'storage management', 'bi', 'sdlc', 'hadoop', 'data solutions', 'public cloud', 'technology solutions', 'modeling', 'data management', 'enablement', 'etl']","['databases', 'tableau', 'emr', 'data lakes', 'big data', 'rds', 'hive', 'map', 'mlib', 'sql', 'dynamo', 'python', 'scala', 'nosql', 'hbase', 'teradata', 'snow flake', 'business intelligence', 'cassandra', 'airflow', 'mllib', 'sqoop', 'bi', 'hadoop', 'public cloud', 'technology solutions']","['data lineage', 'cleansing', 'mongodb', 'performance tuning', 'data', 'analytics', 'technology', 'data warehousing', 'design principles', 'cloud', 'informatica', 'hybrid cloud', 'data analysis', 'master data management', 'data stewardship', 'sdlc', 'solution', 'modeling', 'enablement', 'etl']","['environment', 'design', 'finance', 'governance', 'employee relations', 'adoption', 'hr', 'architecture']"
583,851,Sr Scientist Formulation,"let s grow tomorrow, together would you like to join a team of passionate people who will help you learn and actively participate in the company s success like nowhere else then read on and become part of our story how will you help change the landscape of technology and innovative products at medicago your role reporting to the director formulation development, the incumbent is mainly responsible for the planning and scientific monitoring of projects, the analysis of results and the writing of technical documents. in addition, he supports his immediate supervisor in his duties and guides team members towards achieving corporate objectives. he works in a dynamic and highly collaborative environment, where he demonstrates scientific creativity and identifies innovative solutions. your responsibilities manage and prioritize the formulation development activities for different projects prepare strategic formulation development plans and monitor internal or external projects supervise and participate in the writing of protocols and technical or scientific development reports related to his sector of activity collect, verify, compile and present data relating to current activities and projects carry out multifactorial statistical analyzes of the design of experiments type write documents to ensure the technological transfer of processes to other teams supervise the activities of continuous improvement and scientific and technical innovation carry out a scientific watch in connection with the development of stable formulation participate in the development and monitoring of budgets. minimum qualifications phd in science or engineering with a minimum of 10 years of experience in the biopharmaceutical or in biotechnology, and preferably in drug product formulation development, or equivalent combination of education and work experience in depth expertise in the fields of protein structure and chemistry in depth knowledge of analytical and biophysical protein characterization methods expertise in the development of formulation screening tools and techniques that can predict protein stability proficient with data management and analysis programs as well as statistical analyzes knowledge of regulatory guidance on the requirements for stability studies and on the use of excipients for various modes of administration experience of container or closures systems for drug product knowledge of freeze drying or lyophilization of biologics, an asset knowledge of gmp standards, an asset training in technical writing, an asset leadership and excellent verbal communication skills proficiency of written and spoken english excellent capacity for synthesis and analysis interest in teamwork. medicago is changing the game our vision a world better prepared to deal with any disease. our mission to create and deliver effective responses to new global health challenges. innovation, collaboration, integrity, adaptability, ownership and involvement of our colleagues are the keys to the success of our research. we have been cultivating the future together since 1999. medicago s journey is a story of innovation and perseverance. even the company s name the latin name for alfalfa, the first plant we worked with is a reminder of our culture of adaptability. we re proud of our humble beginnings and our current growth and global reach. as a pioneer in transient expression and plant based manufacturing, medicago has always sought a more effective way to improve human health. with nearly 20 years of experience and wisdom behind us, we are poised to revolutionize the traditional approach to vaccines and therapeutics. medicago promotes an open and inclusive work environment for all our employees. it is important that you are legally entitled to work in the us or canada at the time the job offer is made to you. you may be asked to provide proof of eligibility. li cm1","['administration', 'reporting', 'chemistry', 'screening', 'technical writing', 'data management']",[],"['administration', 'reporting', 'technical', 'chemistry', 'screening', 'data management', 'planning']","['environment', 'continuous improvement', 'education', 'biotechnology', 'characterization', 'design', 'therapeutics', 'protein', 'development', 'biologics', 'manufacturing', 'gmp']"
584,852,Senior Data Engineer,"about us our mission at wrapbook is to increase the prosperity of the project economy. a significant shift has occurred within the workforce recently and 50m americans are now engaged in freelance or project based work. the popularity of project based employment has introduced flexibility for both employers and employees but also added complexities from a compensation and administrative standpoint. our vertical fintech platform enables companies to seamlessly onboard, pay and insure their workforces. we re building the best product for the entertainment industry but operate in a 50b market and have big goals we want to achieve. with legacy competition slow to react and over 30m raised from andreessen horowitz, equal ventures, uncork capital, jeffrey katzenberg and caa co founder michael ovitz, we are at an exciting stage of growth and there isn t a better time to join the opportunity senior data engineer wrapbook is looking for a senior data engineer who will play a hands on role in driving our mission to build an outstanding technology company. you will be working as part of a cross functional team, building high quality data architecture. more than just understanding the strategic importance of data, you re eager to roll up your sleeves and build the infrastructure to support it. you will take complex product roadmap features and will be engaged in identifying, designing, and implementing process improvements for the team. what you ll do build and deliver high quality data architecture to support data analysts design, implement, and maintain low latency etl pipeline from different data sources design data pipelines to extract data from a variety of sources, including unstructured, semi structured, and fully structured data maintaining data infrastructure to keep up with the product roadmap work closely with data analyst on testing and deciding on what bi tools to use partner with our devops engineers to build a secure infrastructure for our data stack what you ll have 3 years of experience building and optimizing data pipelines, architectures, and data sets experience using any cloud platform such as aws, azure or google cloud experience working with relational databases demonstrated experience with data modeling, etl and data performance tuning experience using python for data processing exceptional communicator with the ability to translate technical concepts into easy to understand language for our stakeholders. desire to continuously learn how to implement the latest tech and analytical tools into our tech stack ability to think holistically about uses of data, designing for ease of data access a degree in computer science, mathematics or related field is preferred why join us at wrapbook, creativity meets technology and not just in the product. in addition to a competitive salary and all the benefits you can expect from a fast growing technology company, you ll get access to a team of creative problem solvers and the chance to see your contributions make large impacts benefits include unlimited paid time off work from anywhere in canada and usa health and dental benefits it set up for your home 401k and rrsp learning and development allowance our pledge to fostering an inclusive and safe workplace wrapbook pledges to be a harassment and discrimination free space for everyone, regardless of age, disability, ethnicity, gender identity or expression, nationality, neurotype, personal appearance, political affiliation, professional background, race, religion, or sexual identity or orientation. apply now have we got your attention submit your application today and a member of our talent team will be in touch with you shortly","['python', 'data pipelines', 'relational databases', 'data processing', 'bi', 'testing', 'devops', 'data infrastructure', 'low latency', 'computer science', 'data', 'mathematics', 'aws', 'modeling', 'performance tuning', 'etl']","['python', 'bi', 'data', 'aws']","['data pipelines', 'relational databases', 'data processing', 'testing', 'devops', 'ca', 'low latency', 'data infrastructure', 'computer science', 'data', 'mathematics', 'modeling', 'performance tuning', 'etl']","['fintech', 'capital', 'design', 'compensation', 'architecture']"
585,854,Big Data Solution Architect - Verdun,"about the role do you have a solid experience in big data and would like to exploit it by designing innovative and innovative solutions do you want to influence the bank s it strategies and orientations do you want to use your expertise to build the digital bank of tomorrow the it advanced analytics ecosystem team is looking for a big data solutions architect to join a project at the heart of our data strategy. we need someone who is creative in designing analytical solutions, able to deliver concrete results while meeting commitments, and able to collaborate with pleasure and efficiency in multidisciplinary teams. working within an architectural team means being at the center of the bank s transformation and playing a key role in the design of secure and forward thinking solutions. more details on responsibilities in collaboration with domain architecture, development teams and operations, design and implement complex big data solutions. define big data and analytics strategy using relevant technologies and analytics industry trends. lead the implementation of the strategy defined in the design and architecture of the components of the customer analytical platform using cloud infrastructures as well as several software components required by data scientists. lead the design of reference architecture models for the integration of structured and unstructured data define technical evaluation criteria for the selection of products and technologies and to determine the technical approaches to be favored for the solutions to be successful, within a design of coherent systems. participate and execute proof of concept exercises for the adoption of new big data management technologies, software engineering tools and new models within current structures. use its influence to recommend methods to improve the reliability, efficiency and quality of data. follow the implementation of solutions until their deliveries while ensuring compliance with established architectures . what you are offering completed bachelor s degree, related to the industry, and 10 years of relevant experience or completed master s degree, related to the industry and 7 years of relevant experience experience and knowledge of azure cloud, aws. experience in establishing architectures related to data security, firewalls, encryption, identity and access management , networks, compliance and protection datas hands on experience with several big data tools experience in designing data pipelines and automating big data platform applications or services using python, pyspark, sql and javascript and in their automation through development and operations processes and tools experience with git, ansible, terraform, jenkins in mission critical production environments desirable. excellent knowledge of container management practices and tools . excellent knowledge of architecture design, data modeling and implementation of big data platform architectures and analytical applications. knowledge of and experience with advanced analytical capabilities, including machine learning using supervised and unsupervised techniques advantages responsibilities qualifications summary","['unstructured data', 'pyspark', 'jenkins', 'big', 'firewalls', 'encryption', 'big data', 'javascript', 'terraform', 'sql', 'python', 'software', 'analytics', 'data', 'integration', 'aws', 'big data solutions', 'machine learning', 'data pipelines', 'proof of concept', 'automation', 'ansible', 'security', 'git', 'modeling', 'data management']","['terraform', 'sql', 'python', 'pyspark', 'jenkins', 'big', 'git', 'data', 'big data', 'aws', 'javascript', 'ansible', 'identity and']","['unstructured data', 'firewalls', 'container management', 'encryption', 'reference', 'software', 'analytics', 'data', 'integration', 'machine learning', 'data pipelines', 'proof of concept', 'automation', 'access management', 'data solutions', 'security', 'modeling', 'it strategies', 'data management']","['adoption', 'exploit', 'design', 'architecture']"
586,855,Data Science Architect,"as a full spectrum aws integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. we take customers on their journey to enable, operate, and innovate using cloud technologies from migration strategy to operational excellence and immersive transformation. if you like a challenge, you ll love it here, because we re solving complex business problems every day, building and promoting great technology solutions that impact our customers success. the best part is, we re committed to you and your growth, both professionally and personally. overview as a data science architect, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. you will play an active role in delivering modern data solutions for clients including data ingestion or data pipeline design and implementation, data warehouse data lake architectures, cognitive computing and cloud services. you are enthusiastic about all things data, have strong problem solving and analytical skills, are tech savvy and have a solid understanding of software development. if you get a thrill working with cutting edge technology and love to help solve customers problems, we d love to hear from you. it s time to rethink the possible. are you ready what you ll be doing lead, define and implement end to end modern data platforms in support of analytics and ai use cases collaborate with enterprise architects, data architects, etl developers engineers, data scientists, and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities address aspects such as data privacy security, data ingestion processing, data storage compute, analytical operational consumption, data modeling, data virtualization, self service data preparation analytics, ai enablement, and api integrations be the technical liaison between customers and engineering teams directly collaborate with the sales team to formulate and execute a sales strategy to facilitate the adoption of aws and big data technologies and help build offerings be an aws evangelist by educating a variety of customers on the value of aws and aws s data services traveling up to 50 of the time qualifications experience 5 years experience leading engagements from design to implementation of creative data solutions leveraging the latest in big data frameworks, supporting on premise, cloud and hybrid architectures to enable use cases in analytics and ai 5 years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non traditional sources such as structured, unstructured, and semi structured using sql, nosql and data pipelines for real time, streaming, batch and on demand workloads 3 years experience with analytics or data management strategy formulation, architectural blueprinting, business case development and effort estimation of disruptor based analytics 3 years working in the cloud or multi server complex environments. experience with aws a requirement. ability to simplify complex technical concepts into an easy to understand non technical language in order to facilitate, communicate and interact with executives and business stakeholders experience with agile development methods in data oriented projects strong candidates will also have some of the following capabilities strong sql, database, data modeling, data warehousing and development skills strong programming or scripting experience using various languages such as java, .net, python, scala, javascript, etc. experience in cloud big data analytics services on the cloud experience with dashboarding and reporting tools used in the industry experience with industry etl tools have strong people management skills leading teams, training, onboarding, offboarding, etc. certifications in architecture, data engineering and development from aws subject matter data expertise in financial services , consumer products , energy resources, life sciences and government industries experience with implementation of data security, encryption, pii or psi legislation, identity and access management across sources and environments knowledge of software configuration management environments and tools such as jira, git, jenkins, tfs, shell, powershell, bitbucket, etc. educational qualifications bachelor s degree or higher in quantitative areas such as computer science, information management, big data analytics, or a related field is desired onica li remote li vm about rackspace technology we are the multicloud solutions experts. we combine our expertise with the world s leading technologies across applications, data and security to deliver end to end solutions. we have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. named a best place to work, year after year according to fortune, forbes and glassdoor, we attract and develop world class talent. join us on our mission to embrace technology, empower customers and deliver the future. more on rackspace technology though we re all different, rackers thrive through our connection to a central goal to be a valued member of a winning team on an inspiring mission. we bring our whole selves to work every day. and we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. we welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. if you have a disability or special need that requires accommodation, please let us know.","['computing', 'analytical skills', 'jenkins', 'big', 'data services', 'powershell', 'encryption', 'bitbucket', 'big data', 'javascript', 'java', 'sql', 'python', 'data analytics', 'scala', 'software', 'reporting', 'scripting', 'rackspace', 'data science', 'configuration management', 'software development', 'data', 'analytics', 'aws', 'programming', 'pipelines', 'data engineering', 'data warehousing', 'nosql', 'data preparation', 'data pipelines', 'data privacy', 'metadata', 'information management', 'cloud services', 'jira', 'data structures', 'data solutions', 'security', 'api', 'git', 'computer science', 'technology solutions', 'virtualization', 'modeling', 'data management', 'enablement', 'etl', 'ai']","['jenkins', 'big', 'powershell', 'bitbucket', 'big data', 'javascript', 'java', 'sql', 'python', 'scala', 'rackspace', 'data', 'programming', 'aws', 'pipelines', 'nosql', 'identity and', 'jira', 'api', 'git', 'technology solutions']","['computing', 'analytical skills', 'data ingestion processing', 'data services', 'encryption', 'blueprinting', 'effort estimation', 'data analytics', 'reporting', 'scripting', 'data science', 'software development', 'analytics', 'data', 'data engineering', 'data warehousing', 'software configuration management', 'data preparation', 'data pipelines', 'data ingestion', 'data privacy', 'metadata', 'agile development', 'data storage', 'information management', 'cloud services', 'access management', 'use cases', 'data structures', 'data solutions', 'security', 'computer science', 'virtualization', 'modeling', 'data management', 'enablement', 'etl', 'ai']","['onboarding', 'design', 'sales', 'life sciences', 'operational excellence', 'government', 'architecture', 'engagements', 'adoption', 'people management', 'legislation', 'financial services products', 'business case development', 'sales strategy']"
587,856,Big Data Engineer,"who we are semios is a market leader in leveraging the internet of things and big data to improve the sustainability and profitability of specialty crops. with 500 million data points being reported by our sensors every day, we leverage our big data analytics, such as in depth pest and disease modeling, to empower tree fruit and tree nut growers with decision making tools to minimize resources and risks. check this video out as it shows what we do and our positive environmental impact our innovative work has received several industry awards thrive top 50 leading agtech recognized as exemplifying some of the best in agriculture technology around the globe. global cleantech top 100 identified as one of the companies best positioned to solve tomorrow s clean technology challenges. google accelerator selected as 1 of 9 companies for the inaugural google for startups accelerator canada cohort, who are all using technology to solve complex challenges. we know our journey is only achievable by having a great team who shares ideas, tries new things and learns as we go. who you are motivated by meaningful work, you are looking for more than just a job you want to work for a dynamic, growing company that finds solutions to real life problems, such as helping the world reduce the use of pesticides and helping nature feed a growing population. your ideal work environment includes a collaborative team spirit with the opportunity to learn and grow as you take the initiative to try new things. you are looking to make a difference, you want to know your work with big data has real world benefits. you are curious, eager to learn and collaborative. you are excited to contribute to the future of semios data engineering approaches and infrastructure. what you will do the di team at semios plays a very important role in shaping the various products and features that the company provides to customers. we as a team are growing very rapidly, so you will always have the opportunity to contribute towards shaping the architecture, design and scalability of our processes and pipelines. you will collaborate with a very passionate and diverse group of individuals that love data engineering, and work with the latest technologies in the industry. as a big data engineer, you have the opportunity to help design and build complex and exciting data engineering solutions to help growers make data driven decisions, which in turn will have a real world impact on peoples lives and in agriculture. requirements we want you to succeed, so you will need fluency in python and popular data packages including object oriented programming techniques. advanced sql knowledge and direct experience working with relational databases, data warehouses, and nosql stores. professional experience developing data solutions on cloud platforms like gcp or aws. professional experience with workflow management tools like airflow, prefect, and or or dagster. excellent verbal and written communication skills with a talent to distill complex ideas to different audiences. flexibility in working both autonomously and within a team environment. solid understanding of data benchmarking and performance tuning. excellent troubleshooting skills to rapidly identify and resolve issues. ability to evaluate new technologies, determine suitability, and integrate into the environment effectively. nice to have advanced education or certificate in big data. google bigquery. experience with analytics engineering tools . experience with container management systems like kubernetes, helm, and or or docker compose. experience working in agile methodology. knowledge of project management tools like jira and or or confluence. knowledge of data visualization charting tools like bi systems, matplotlib, and or or seaborn. benefits why this is the opportunity for you sleep better knowing you re making the world a better place through more sustainable food production work with a team that values fun, laughter, and each other have a lasting impact as you help to build a company learn a lot along the way","['go', 'workflow management', 'big', 'data visualization', 'confluence', 'troubleshooting', 'big data', 'sustainability', 'performance tuning', 'kubernetes', 'data analytics', 'python', 'sql', 'gcp', 'matplotlib', 'analytics', 'programming', 'aws', 'pipelines', 'data engineering', 'nosql', 'relational databases', 'airflow', 'internet of things', 'jira', 'sensors', 'bi', 'data solutions', 'scalability', 'modeling']","['go', 'kubernetes', 'sql', 'python', 'gcp', 'internet of things', 'jira', 'bi', 'big', 'confluence', 'programming', 'big data', 'aws', 'pipelines', 'google bigquery', 'nosql', 'helm', 'airflow']","['data analytics', 'methodology', 'relational databases', 'workflow management', 'sensors', 'matplotlib', 'management systems', 'data solutions', 'data visualization', 'scalability', 'troubleshooting', 'data', 'analytics', 'modeling', 'sustainability', 'data engineering', 'feed', 'performance tuning']","['environment', 'education', 'benchmarking', 'design', 'project management', 'startups', 'food production', 'agriculture', 'environmental', 'architecture']"
588,858,Head of International Analytics & Data Science,"about the role the analytics data science team is looking for an individual to lead our international analytics team. this role is critical for doordash as we expand our logistics platform into new countries. this individual will lead a team that works cross functionally with product management, strategy operations, marketing, analytics, and senior leadership to accelerate growth in our current international markets and lead the strategy and execution of new market launches as a leader on the analytics data science team, you ll use your quantitative background to lead mentor other data scientists and dive into large datasets to guide decision making. you won t simply copy paste what worked in the us to other countries you ll need to understand the unique needs of each countries users and evaluate the needs of all three sides of the marketplace consumers, merchants, and dashers. you ll manage, hire, and lead a global team to tackle a multitude of exciting challenges including opportunity sizing, experimentation, and ongoing tracking of our business progress and product market fit in countries around the world. you re excited about this opportunity because you will build and lead a global team that creates quantitative analysis to provide insights that help marketing, business, and product leaders understand performance, customer quality, user behaviors work closely with our product management, engineering, and strategy operations teams to build best in class and beloved products while finding scaling product market fit in countries around the world create full cycle analytics experiments, reports, and dashboards using sql, r, python, or other scripting and statistical tools present in key meetings and business reviews with our executive team and founders be excited to travel to meet with business partners and the team in each market build a world class international team that includes hiring new leaders as well as mentoring junior analysts on how to use more advanced methods we re excited about you because you have a degree in math, physics, statistics, economics, computer science, or similar domain 10 years of experience in data analytics, data science, consulting, or related quantitative role 5 years of direct people management experience in analytics prior experience in building a b2c business from scratch with a focus on a dynamic marketplace, logistics or economics environment desired but not required expertise with sql queries, etl, a or b testing, and statistical analysis with statistical packages, such as matlab, r, sas or python proficiency in one or more analytics visualization tools the insight to take ambiguous problems and solve them in a structured, hypothesis driven, data supported way a self starter with the determination to initiate and lead projects to completion in a scrappy environment prior experience working abroad or in international expansion preferred but not required fluent english required, proficiency in additional languages a plus why you ll love working at doordash we are leaders leadership is not limited to our management team. it s something everyone at doordash embraces and embodies. we are doers we believe the only way to predict the future is to build it. creating solutions that will lead our company and our industry is what we do on every project, every day. we are learners everyone here is continually learning on the job, no matter if we ve been in a role for one year or one minute. we are customer obsessed our mission is to grow and empower local economies. we are committed to our customers, merchants, and dashers and believe in connecting people with possibility. we are all doordash the magic of doordash is our people, together making our inspiring goals attainable and driving us to greater heights. we offer great compensation packages and comprehensive health benefits. about doordash doordash is a technology company that connects customers with their favorite local and national businesses in all 50 us states, canada, and australia. founded in 2013, doordash empowers merchants to grow their businesses by offering on demand delivery, data driven insights, and better in store efficiency, providing delightful experiences from door to door. by building the last mile delivery infrastructure for local cities, doordash is bringing communities closer, one doorstep at a time. read more on the doordash engineering blog or at . our commitment to diversity and inclusion we re committed to growing and empowering a more inclusive community within our company, industry, and cities. that s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. we believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.","['visualization', 'dashboards', 'statistical analysis', 'sql', 'python', 'data analytics', 'statistics', 'physics', 'scripting', 'data science', 'product management', 'analytics', 'sas', 'testing', 'matlab', 'economics', 'datasets', 'computer science', 'etl', 'r']","['sql', 'python', 'sas', 'matlab', 'r']","['data analytics', 'visualization', 'statistics', 'quantitative analysis', 'physics', 'datasets', 'scripting', 'dashboards', 'data science', 'economics', 'testing', 'computer science', 'product management', 'analytics', 'statistical analysis', 'etl']","['environment', 'customer quality', 'compensation', 'marketing', 'b2c', 'international markets', 'consulting', 'people management', 'hiring', 'mentoring']"
589,859,"Director, Data Sciences","full timevancouver june 14, 2021 job id 21291 abcellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. we are seeking a director, data sciences to manage and unify the interrelated projects between the diverse teams within the department of data sciences . this person will be accountable for the project portfolio within dsci management, execution, translation, continuity, improvement and life cycle. this position will be key to integrate, unify and align the portfolio of interrelated projects, tools and required infrastructure across the dsci teams. we are seeking an experienced manager with a scientific and technical background, as well as knowledge of how to manage, productionize, maintain continuity of, and integrate technically diverse but interrelated systems projects. this position will report to the cto and manage the team leads group leaders of the five dsci teams. how you might spend your days overseeing the department in the development of new insights and tools and advanced data science capabilities playing a strategic role to build and manage cross team data integration, data visualization, dashboards, predictive analytics, and data mining distilling project requirements into problem definitions, dealing with ambiguity and competing objectives communicating the findings to key stakeholders through reports and presentations collaborating with department leads and key stakeholders to create a unified roadmap tailored to constantly aid the dsci teams, end users and partners we d love to hear from you if you have a master s degree in statistics, machine learning, mathematics, computer science, statistics economics, or similar at least 10 years of working experience in data sciences, with at least 5 years experience in managing machine learning scientists, data scientists, research scientists, applied scientists, or similar 4 years of academic or industry experience in a scientific sector exceptional communication skills to convey technical messages in a clear and understandable manner, leading to business wide understanding of departmental performance. has experience with data services, data architecture and integration of infrastructure, tools and project portfolios possess superior computer and technological knowledge or skills and have passion for analytics and software architecture. proficiency in one or more scripting languages exceptional leadership skills, ability to lead a cross functional group in a unified direction as well as an ability to influence leadership and executives. must demonstrate an ability to form strong and meaningful connections with others. software project management skills an asset offers benefits the opportunity to work with an inspired team on challenging problems that matter an attractive compensation package, including health and lifestyle benefits a minimum of 4 weeks vacation opportunities for personal and professional development about abcellera at abcellera, we re solving tough problems and creating innovative solutions from the ground up custom immunizations, microfluidics, high throughput imaging, genomics, computation, machine learning and laboratory automation. we re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. this is life changing research and you could be a part of it. you ll join a diverse and multi disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists all working together to bring better therapies to patients. we re a growing company with a high throughput pipeline and the drive to be the best in the industry. this isn t just about having the best technology. we know we need a world class team of visionaries and innovators. we look for people with drive and energy. idealists. people we love and people we trust. this may be unconventional, but it is the key to our success. we re looking for someone like you to help us get there. to apply please send us your application through our website and refer to job id 21291 in your cover letter. we apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","['data services', 'data visualization', 'dashboards', 'working experience', 'statistics', 'software', 'scripting', 'data science', 'data', 'analytics', 'integration', 'data mining', 'software architecture', 'machine learning', 'translation', 'automation', 'economics', 'high throughput', 'computer science', 'mathematics']",['predictive'],"['data sciences', 'data services', 'data visualization', 'dashboards', 'working experience', 'statistics', 'software', 'scripting', 'data science', 'data', 'analytics', 'integration', 'data mining', 'software architecture', 'machine learning', 'micro', 'translation', 'automation', 'economics', 'high throughput', 'computer science', 'mathematics']","['antibodies', 'genomics', 'presentations', 'project management', 'compensation', 'architecture']"
590,860,Data & AI Strategy Manager,"we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about accenture applied intelligence you are a consultant that other consultants admire. you ve spent years helping clients use analytics to make their companies more effective and more efficient. clients listen to you and rely on you to guide them through crucial digital transformations. the work work with clients to understand how analytics can help their businesses retail, financial, health or government be a thought leader for data and analytics that fit your industry specialization help generate insights and recommendations for clients guide the early stages of data and analytical transformations help senior clients understand and use data driven strategies in new ways and markets get data, analytics and ai projects across the line for clients manage and motivate teams here s what you need a bachelor s degree in a quantitative field like statistics, econometrics, mathematics, engineering at least 5 years working as a consultant helping clients, building strategies, designing and using data and analytics, especially in a professional services environment at least 5 years running business transformation and data management projects at least 3 years experience with major cloud technologies conceptual bonus points if exceptional presentation skills ability to convey technology and business value propositions experience in foundational data capabilities such as data management, data governance, visualization and data science ability to understand and apply statistical methods and outputs to create client value in a business context experience with evolving approaches and technologies such as big data, artificial intelligence, machine learning, cognitive systems, and robotics handling different projects at the same time comes easily to you","['machine learning', 'statistics', 'visualization', 'big', 'data science', 'robotics', 'data', 'analytics', 'mathematics', 'artificial intelligence', 'data management', 'econometrics', 'automation', 'ai']","['robotics', 'big data']","['machine learning', 'statistics', 'visualization', 'data science', 'analytics', 'mathematics', 'data', 'artificial intelligence', 'data management', 'econometrics', 'automation', 'aimo', 'ai']","['environment', 'business transformation', 'client value', 'professional services', 'retail', 'business value', 'governance', 'helping clients', 'government']"
591,861,Data Engineer - Remote within Canada,"the data engineer is a critical role for tgod as our business hits unprecedented scale. you will provide and grow in house expertise on elt or etl formulations and api interactions. our data is a critical business asset how we handle and manage that data must enable our agile business and be compliant with laws or regulations to preserve its confidentiality, availability and integrity. this role forms part of tgod s data science functions and will support the director of data science in leading and managing all data related activities including business intelligence. key responsibilities support and develop data pipelines for all core systems and 3rd party integrations into the data lake and analytics database. leverage api endpoints for operational use of centralized data assets develop broad domain and technical knowledge in aws solutions. demonstrate strong verbal or written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams. basic qualifications bachelor s degree in computer science, information systems management, it security, finance, technology or related field or 3 years relevant work experience in a data related field 2 years python, sql is a must. strong elt or etl background 1 years using apis for data extract and load 1 years with linux shell or bash for automation and server administration experience with apache airflow and docker is preferred experience with web scraping is preferred experience in the bi or analytics or data warehousing space is preferred experience with amazon web services ecosystem and general cloud architecture demonstrate critical inquiry with attention to detail ability to effectively articulate recommendations or conclusions verbally and in writing preferred qualifications tableau server and tableau desktop sap hana cloud data model, data extraction and api use cases version control best practices highly independent, organized and efficient. snowflake data warehouse data presentation skills to both business and technical teams. job types full time, permanent benefits dental care employee assistance program extended health care life insurance paid time off vision care work from home schedule monday to friday experience python 2 years aws cloud 1 year linux 1 year snowflake 1 year work remotely yes","['linux', 'bash', 'tableau', 'sql', 'python', 'data science', 'analytics', 'data', 'aws', 'data warehousing', 'cloud', 'apache airflow', 'amazon web services', 'server', 'data pipelines', 'web', 'business intelligence', 'automation', 'administration', 'data extraction', 'bi', 'security', 'api', 'computer science', 'version control', 'snowflake', 'etl']","['sql', 'python', 'linux', 'amazon web services', 'tableau', 'bi', 'api', 'aws', 'business intelligence', 'snowflake', 'apache airflow scraping']","['information systems management', 'administration', 'bash', 'server', 'data pipelines', 'use cases', 'data extraction', 'security', 'data science', 'version control', 'computer science', 'analytics', 'data', 'data warehousing', 'cloud', 'automation', 'etl']","['sap', 'forms', 'finance', 'insurance', 'regulations', 'architecture']"
592,862,"Senior Data Engineer, ClearAngel","clearangel is building yc for the 99 of founders. those who traditionally don t have access to advice, capital or network we want to support that long tail. most founders don t live in silicon valley or have the pristine pedigree to get in front of the right people. for far too long, startups have played on a scarcity model. this is limiting the potential of founders. we fundamentally believe that great founders and companies are everywhere. where there are problems, opportunities exist. we want to empower those founders. we are building clearangel to democratize access to advice, network and capital. we do this by scaling access to the rest of the world access to advice access to network access to capital the role of the senior data engineer is to lead and build pipelines and solutions for the analytic and product challenges surrounding the features and vision of the clear angels product and platform. your responsibilities will be a superset of a typical senior data engineer, as there are often experiments and uncertainty that require creative solutioning at the earliest stages. responsibilities you will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development working closely with every member of the team, vendors and external partners, you will produce significant components of the clearangel code collaborate with all functions of clearco, ranging from core engineering team to data science team to the marketing team you be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary you will scope out business needs for clearangel, and action them with speed and accuracy and then lead and execute on it yourself. you will run and participate in founder townhalls, communicating closely with early stage entrepreneurs when it comes to product and engineering on clearangel, buck stops with you. coordinate, roll up your sleeves, do what s necessary to get the ball moving forward what we look for great communication skills, with a desire or experience to lead a small team of other devs in the near future desire to help founders. we take a strong founder first stance on this team be self sufficient when it comes to execution. figure out how to solve problems and make things happen, not waiting for help or permission on this team, we maximize learning. you will fail if you re not learning fast enough comfort working in a high growth, constantly changing environment heavy bias towards action. ability to solve problems end to end on their own. you will implement ideas and experiments on your own with minimal support have experience working in a senior software engineering role, you are an expert when it comes to coding and you re ready to roll up your sleeves to get the job done have a strong business sense, you can foresee potential issues and solve them quickly demonstrated ability to collaborate effectively across multiple teams strong interest in building businesses, ecommerce and fintech technical requirements ideally, you have worked on 3 or more different stacks in your career in a professional setting for at least 8 months each. this means you probably have between 2 years and 6 years of experience. bonus points for systems managing time series able to architect and scale data integrations from third party api docs independently, extracting the right business value for the vision and roadmap of clear angel interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes comfortable working in server and database environments that are changing constantly comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff comfortable with relational databases and schemas involving time series skills and interest in python, sql, snowflake, kubernetes and pipeline management or orchestration tools","['kubernetes', 'sql', 'python', 'schemas', 'relational databases', 'software', 'data products', 'data science', 'api', 'technical requirements', 'uncertainty', 'pipelines', 'rest', 'snowflake']","['kubernetes', 'sql', 'python', 'api', 'pipelines', 'snowflake', 'clear']","['schemas', 'relational databases', 'software', 'data products', 'data science', 'technical requirements', 'uncertainty', 'rest']","['environment', 'fintech', 'capital', 'marketing', 'business value', 'design', 'team building', 'startups', 'architecture']"
593,863,Data Driven Marketing Analyst,"our culture lifts you up there is no ego in the way. our common purpose we all want to win for our customers. we aim to always be evolving, dynamic, and ambitious. we believe in the power of genuine connections. each employee is a part of what makes us unique on the market agile, dedicated, problem solvers. time type regular job description sommaire des responsabilit s du poste as marketing data driven analyst, you will play an active role in cogeco s marketing strategies. reporting to the director of data driven marketing media roi, your role will be to support cogeco s marketing team to better understand marketing performance and identify opportunities. recognized as a growth hacker, you will access multiple data sets to help understand performance, identify trends and room for optimisation. you will work in close collaboration with data scientists, media and marketing specialists to make sure data is at the center of our decision process and to generate insights. principales responsabilit s work with stakeholders throughout the digital sales and marketing team and regional managers teams to identify opportunities for leveraging company data to drive data driven marketing campaigns. analyze closely the data from the company marketing campaigns and customer base to drive optimization and improvement of campaigns and business strategies. interpreting data, analyzing results using statistical techniques. identify, analyze, and interpret trends or patterns in complex datasets. support business users to make sure that they become self sufficient and autonomous from an analytics perspective. coordinate with different functional teams to make, implement or present marketing campaign dashboards, reports and other data visualizations. develop processes and tools to monitor business performance. exigences essentielles formation acad mique master in bi, machine learning, data science, mathematics, computer science. exp riences de travail 3 5 years as leading a data function in industry. comp tences particuli res knowledge of data science frameworks sql, r, python, spark, scala, or equivalent. knowledge of visualization tools such as tableau, power bi, qlik or equivalent. understanding of best practices in visualization, kpi definition and storytelling. ability to help internal customer to become more autonomous and empathy towards the end users of dashboards and reports. strong problem solving, time management and work organization skills. strong knowledge of statistics. solid understanding of modern data infrastructure. skills with in google cloud plateform, big query. ability to combine qualitative and quantitative insights. strong business and product intuition. understanding of broad spectrum of methods and disciplines in data science, and the applicability of different techniques for different contexts, e.g. not just focused on deep learning. constantly learning or growth mindset. you ll benefit from flexibility yes, we think that what you do matters. at work and at home. fun we laugh a lot, it makes every day brighter. discounted services we provide amazing services to our clients, and you ll get them at home, because you deserve them. rewarding pay let s be honest, everybody likes to make a good salary. we offer attractive compensation packages, and it comes with a great culture. benefits we ve got you covered. career evolution join us and we will give you the tools to achieve your career goals technology you have a passion for technology excellent, we do too. here, you will manage, influence, play, create, fix, and shape the industry. location montr al, qc company cogeco connexion inc being inclusive is simply welcoming you to be yourself being inclusive also means fostering a climate of trust and respect, and encouraging diversity and equity for every candidate wanting to be part of the cogeco team. being inclusive allows us to reduce barriers in the workplace and to take actions to enable accessibility for all being inclusive is more than a word, it s our commitment to you if you need any accommodations to apply or as part of the recruitment process, please contact us confidentially at","['visualization', 'tableau', 'data infrastructure', 'dashboards', 'sql', 'python', 'statistics', 'scala', 'reporting', 'data science', 'analytics', 'machine learning', 'interpreting data', 'deep learning', 'bi', 'datasets', 'computer science', 'mathematics', 'optimization', 'r']","['sql', 'python', 'qlik', 'tableau', 'scala', 'bi', 'solve', 'r']","['deep learning', 'machine learning', 'visualization', 'statistics', 'reporting', 'datasets', 'data infrastructure', 'dashboards', 'data science', 'computer science', 'analytics', 'mathematics', 'optimization']","['customer base', 'marketing', 'sales', 'marketing campaigns', 'digital', 'compensation', 'campaigns']"
594,864,"SENIOR DATA ENGINEER, SOPHI","senior data engineer, sophi position code 2021 077 location the globe and mail, toronto salary commensurate with qualifications and experience position overview we re looking for experienced individuals with deep knowledge of data streaming, serialization, databases and distributed systems, and proficient in writing custom libraries but also know when to use off the shelf solutions when necessary. ideal candidates are self motivated engineers with a passion for both business and technology innovation, more importantly they quickly adapt with changing technologies. we value people who are passionate about system design and have an eye for improving product quality. we currently work with scala, kotlin, java, python, nodejs, postgres, go, kafka, and flink. responsibilities develop and optimize system components for maximum performance and scalability across a vast array of environments. have a commitment to collaborative problem solving, sophisticated design, and product quality ensure that system components and the overall application are robust and easy to maintain. contribute to backlog reviews, technical solutions design and implementations be disciplined in implementing software in a timely manner while ensuring product quality isn t compromised minimum qualifications strong analysis and problem solving skills deep understanding of good programming practices, design patterns, functional programming, and object oriented analysis and design successfully implemented and released a large number of data pipelines and web services using modern engineering frameworks in the past 3 years formal training in software engineering, computer science or computer engineering. worked as part of a mature engineering team ideal candidate have strong working knowledge with scala and or or kotlin. understands reactive programming, threads and futures. successfully implemented realtime and batch analytics using kafka, flink, apache beams and or or google dataflow. strong working knowledge of data warehouses include redshift, snowflake, and or or apache druid. have a working knowledge with containerization and build pipelines successfully implemented data systems for very large data volumes such as click streams and or or iot sensors data. the globe and mail is dedicated to diversity and inclusion in the workplace the globe and mail is committed to fostering an inclusive, accessible work environment, where all employees feel valued, respected and supported. we believe this strengthens our business and our journalism. we welcome and encourage applications from individuals from all groups, regardless of race, ethnicity, culture, gender, sexual orientation, religion, socio economic status, age, and physical ability. as required by the federal contractors program, the globe also tracks the proportion of staff in the four employment equity categories to ensure we are reflecting the areas in which we work. the globe and mail offers accommodation for applicants with disabilities as part of its recruitment process. if you are contacted to arrange for an interview, please advise us if you require an accommodation.","['go', 'databases', 'threads', 'sophi', 'containerization', 'distributed systems', 'apache', 'java', 'data streaming', 'python', 'real', 'kotlin', 'scala', 'software', 'analytics', 'programming', 'data systems', 'pipelines', 'design patterns', 'data pipelines', 'iot', 'computer engineering', 'web services', 'streams', 'sensors', 'scalability', 'computer science', 'snowflake']","['go', 'databases', 'apache druid', 'threads', 'google dataflow', 'sophi', 'containerization', 'apache', 'java', 'python', 'kotlin', 'scala', 'programming', 'pipelines', 'reactive', 'iot', 'streams', 'functional', 'snowflake']","['design patterns', 'data pipelines', 'software', 'sensors', 'computer engineering', 'scalability', 'computer science', 'web services', 'analytics', 'batch', 'data systems', 'distributed systems', 'data streaming']","['journalism', 'product quality', 'environment', 'design']"
595,865,Azure Data Engineering Consultant,"we are applied intelligence, the people who love using data to tell a story. we re also the world s largest team of data scientists, data engineers, and experts in machine learning and ai. a great day for us solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. we believe a mix of data, analytics, automation, and responsible ai can do almost anything spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. want to join our crew of sharp analytical minds visit us here to find out more about applied intelligence. you are a big data consulting pro someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. you re passionate about digital technology, and you take pride in making a tangible difference. you have communication and people skills in spades, along with strong leadership chops. complex issues don t faze you thanks to your razor sharp critical thinking skills. working in an information systems environment makes you more than happy. the work data and analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes. big data professionals use big data methodologies, solutions and tools to help organizations optimize their business performance by managing, sorting and filtering volumes of data as well as extracting meaningful value from these large volumes of data. a professional at this position level within accenture has the following responsibilities design and build robust data pipelines using scalable tools and techniques to produce high quality data structures implement quicker data processing methods and integrate complex business logic compatible with daily or real time or streaming frameworks increase automation and scaling of complex data sets based on the customer s analytic use case, such as structured data delivery for business analysis, daily extraction of mission enabling data for data mining or exploration, and transforming data for applied intelligence to power impactful data visualizations here s what you need minimum 3 years of designing, building and operationalizing large scale enterprise data solutions and applications using azure data and analytics services in combination with custom solutions spark, azure data lake, hdinsights, sql dw, documentdb, search, elastic pool etc. minimum 3 years of hands on experience analyzing, re architecting and re platforming on premise data warehouses to data platforms on azure. minimum 3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using java, python, scala etc. high emphasis on consulting or client facing experience, this is a must have bilingual french is an asset bonus points if bachelor s degree in computer science, engineering, technical science or 3 years of technical architecture and build experience with large scale solutions. minimum 3 years of experience in architecting large scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with it and business stakeholders. 3 years of hands on experience architecting and designing data lakes on azure cloud serving analytics and bi application integrations. 3 years of experience in designing and optimizing data models on azure minimum 3 years of architecting and operating large production hadoop or nosql clusters on premise or using cloud services. minimum 3 years architecting and implementing metadata management on azure architecting and implementing data governance and security for data platforms on azure. designing operations architecture and conducting performance engineering for large scale data lakes a production environment. craft and lead client design workshops and provide tradeoffs and recommendations towards building a solution. accenture overview we are a global collective of innovators applying the new every day to improve the way the world works and lives. help us show the world what s possible as you partner with clients to unlock hidden value and deliver innovative solutions. empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. our expertise spans 40 industries across 120 countries and impacts millions of lives every day. we turn ideas into reality. important information to learn more about accenture, and how you will be challenged and inspired from day 1, please visit our website at accenture.ca or careers.https or or accntu.re or 2hcjdtn our commitment to inclusion diversity at accenture, inclusion and diversity are fundamental to our culture and embedded in our core values. we are committed to creating a workforce where our people can feel comfortable, be themselves and contribute. like canada itself, accenture employees represent a tremendous variety of cultures, ethnicities, beliefs, backgrounds and languages. we offer an inclusive environment regardless of personal characteristics such as ethnicity, religion, gender, sexual orientation, gender identity or expression, age or disability. requesting an accommodation accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. if you are hired by accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired. if you would like to be considered for employment opportunities with accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 889 9009, send us an email or speak with your recruiter. other employment statements it is currently our objective to assign our people to work near where they live. however, given the nature of our business and our need to serve clients, our employees must be available to travel when needed. job candidates are not required to disclose any offence for which a pardon has been granted.","['https', 'metadata management', 'business analysis', 'big data', 'java', 'sql', 'python', 'data processing', 'scala', 'enterprise', 'analytics', 'data', 'data models', 'nosql', 'data mining', 'machine learning', 'data pipelines', 'technical science', 'automation', 'cloud services', 'data structures', 'bi', 'hadoop', 'technical', 'information systems', 'data solutions', 'security', 'computer science', 'performance engineering', 'ai']","['sql', 'python', 'scala', 'bi', 'httpsnt', 'hadoop', 'azure data lake', 'data lakes', 'big data', 'digital', 'data models', 'java', 'nosql']","['metadata management', 'business analysis', 'data processing', 'enterprise', 'analytics', 'data', 'data mining', 'machine learning', 'data pipelines', 'technical science', 'automation', 'cloud services', 'data structures', 'technical', 'information systems', 'data solutions', 'security', 'computer science', 'performance engineering', 'aimo', 'ai']","['environment', 'design', 'governance', 'consulting', 'recruiting', 'business', 'workshops', 'architecture']"
596,866,Senior Java/Data Engineer (VP),"citi s innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to citi s capital markets, securities services and banking lines of businesses. our mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurial spirit. we are looking for a senior data engineer with experience in developing data pipelines to join our team, part of the citi s innovation lab, working on a trade surveillance platform used across multiple businesses within our institutional clients group. as a senior data engineer on our team, you will be responsible for designing, building and integrating data pipelines. you will work with data publishers, data consumers, the development team and stakeholders to ensure we are meeting our requirements. you will contribute to the team s strategy around security, development, testing, and deployment best practices. this is an exciting opportunity to work on a mission critical project, take a leading role in evolving our platform, and be a difference maker at citi. key responsibilities working closely with a global team building large distributed data centric applications in the trade supervision and surveillance technology space. designing and building message and data processing or streaming services to enable seamless integration with multiple business systems. designing and building pipelines for data analytics. on boarding of new data streams from external systems. working closely with data scientists to ensure data is of the highest quality and is available when needed. act as data pipeline subject matter expert to the global application team as well as other internal and external stakeholders. building close relationships with clients and stakeholders to understand the use cases for the platform and prioritising work accordingly. working well in a multidisciplinary devops focused team and building close relationships with engineers, data scientists, business analysts, and production support teams. holds themselves accountable for ensuring high quality results and acts as a mentor and coach to other team members. skills qualifications you have experience driving the technical direction on data intensive projects. you will have specific examples of times that you have delivered value to business by getting applications into production. designed systems from scratch that can scale with large volumes of data. you have expertise in multiple programming languages and building data pipelines, such as java, python, spark, and kafka. you have expertise working with message or event streaming services, ideally using kafka. you have experience working with both relational and non relational databases, such as mongodb, elastic, oracle, redis, zookeeper, and others. you understand the full spectrum of the data processing and integration ecosystem, including testing strategies. you have experience working in a devops culture and are comfortable working with ci or cd tools such as ibm urbancode deploy, teamcity, and jenkins you have experience in systems observability including monitoring and health patterns and the tools to ensure the highest production stability. you have high development standards, especially for code quality, code reviews, unit testing, continuous integration, and deployment. you have proven capability to interact with clients and deliver results from ideation to production. you have experience working in fast paced development environments. you agree that verbal and written communication skills are vital. experience creating pipelines that serve machine learning, statistical, and predictive algorithms is an asset. experience with analytical tools such as tableau is an asset. experience working in virtualized environment, as well as container orchestration services such as kubernetes or openshift is an asset. citi canada is an equal opportunity employer. accordingly, we will make accommodations to respond to the needs of people with disabilities during the recruitment process and otherwise in accordance with law. individuals who view themselves as aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. job family group technology job family applications development time type citi is an equal opportunity and affirmative action employer. qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. citigroup inc. and its subsidiaries invite all qualified interested applicants to apply for career opportunities. if you are a person with a disability and need a reasonable accommodation to use our search tools and or or apply for a career opportunity review accessibility at citi. view the eeo is the law poster. view the eeo is the law supplement. view the eeo policy statement. view the pay transparency posting","['openshift', 'business systems', 'tableau', 'jenkins', 'technical direction', 'ci', 'mongodb', 'java', 'kubernetes', 'data analytics', 'python', 'teamcity', 'data processing', 'cd', 'redis', 'data', 'integration', 'pipelines', 'machine learning', 'data pipelines', 'relational databases', 'testing', 'streams', 'algorithms', 'unit', 'banking', 'securities', 'programming languages', 'devops', 'security']","['kubernetes', 'python', 'openshift', 'teamcity', 'tableau', 'programming languages', 'jenkins', 'redis', 'streams', 'pipelines', 'java']","['business systems', 'technical direction', 'production support', 'ci', 'mongodb', 'container orchestration', 'data analytics', 'data processing', 'cd', 'integration', 'unit testing', 'algorithms tools', 'machine learning', 'data pipelines', 'relational databases', 'continuous', 'testing', 'use cases', 'banking', 'securities', 'devops', 'security']","['environment', 'surveillance', 'team building', 'capital markets', 'law']"
597,867,Director of Data Engineering Intelligence,"associate director of data engineering the data engineering teams build and maintain the tools, data pipelines and infrastructure that support our client s data management and analytics needs. our solutions bring structure to customer systems and customer data across mid tier and enterprise customers. we are looking for a data engineering intelligence leader who loves to design, combine and build data systems using best of breed technologies. this role will focus on everything from the requirements and documentation phase , dws deployment, etl, ssas and data cube buildings, and deployment of various presentation layer tools. if that describes you, please join us in building scalable platforms for our global customers. the right leader must possess a fine balance with their ba skills and deep technical knowledge a passion for data and enthusiasm for building a strong data foundation for our clients. what you will do optimize existing and architect from scratch new data platforms to collect, transform and enable clients ease of query and analysis. integrate and leverage machine learning infrastructure to empower data scientists to more easily gain access to a consistent view of client s data. be a subject matter expert on market leading data trends, technologies tools and their compatible components for data injection, processing and presentation. conduct business requirements session plans and flows summarize technical design to non technical audiences while at the same time providing direction to the delivery team to execute upon along with the data practice lead, execute on the vision and strategy for the data engineering teams provide thought leadership on data technologies what are the best practices on identifying, storing, provisioning, processing, and governing data, with particular attention to compliance and security needs recruit talented individuals to the team. support the sales team on data services opportunities and conversations with clients requirements full stack bi development experience. everything from the e part of etl through the t and l and all the way through the presentation layer. data integration experience is a plus. fluency in a programming language such as python or scala, and their respective standard data processing libraries. python is preferred. experience working with data lakes and data processing systems that operate across a large organization and that make use of technologies such as spark, hive, presto, databricks or snowflake. skill with stakeholder management to collect and prioritize requests and translate to roadmap cube building, data mart building, and dimensional modeling experience. bachelor s degree in mis, business administration, computer science or related field.","['data services', 'technical design', 'documentation', 'analytics systems', 'hive', 'data injection', 'python', 'data processing', 'scala', 'data', 'programming', 'integration', 'data systems', 'customer data', 'data engineering', 'machine learning', 'data pipelines', 'provisioning', 'mis', 'bi', 'security', 'computer science', 'modeling', 'data management', 'snowflake', 'etl']","['ssas', 'python', 'provisioning', 'scala', 'bi', 'mis', 'data lakes', 'programming', 'documentation', 'hive', 'snowflake']","['dimensional', 'data services', 'technical design', 'analytics systems', 'data injection', 'data processing', 'data', 'integration', 'data systems', 'customer data', 'data engineering', 'data mart', 'machine learning', 'data pipelines', 'security', 'computer science', 'modeling', 'data management', 'etl']","['attention', 'design', 'sales', 'buildings', 'stakeholder management', 'business administration']"
598,868,Sr. Data Product Manager - RBC Ventures ( Ampli ),"rbc ventures is a new kind of business one that marries the strength of one of the world s most trusted and successful financial institutions with a mission to reimagine the role we play in people s lives to move rbc beyond banking . we re building a world class organization focused on designing exceptional experiences, exploring new business models and creating exponential value. in 2020, we were named by fast company as one of the 100 best workplaces for innovators and we re looking for team members with the curiosity to explore, the capabilities to build and capacity to help us deliver our mission. what is the opportunity ampli, an rbc venture, is a free cash back app focused on helping canadians get rewarded for their everyday purchases. https or or or company or myampli or we are hiring a sr. data product manager who will be responsible for the roadmap of our data platform. the ideal candidate is logical, analytical, and curious. they understand the technical aspects of data engineering and analysis but are focused on what the data is saying and how we can use it to provide a more personalized and targeted experience for our customers. this person will work closely with the product managers in the other areas of ampli, the data engineers and the data scientist. machine learning will be a core part of this process and the data pm will work closely with the data scientists to determine the questions we need answered. this person will build strategies and implement solutions that drive data oriented decisions across the organization. what you ll do value creation, evolution stewardship seek out ways to derive and yield new value from our data, especially via ml, nlp, etc and working with the other product managers on how to use the data to improve the ux in their areas of the product. product roadmap develop ml product or platform roadmap and requirements working with cross functional teams to execute by planning and managing expectations with stakeholders across the company. deliver key ml features and capabilities from concept to launch. coordinate and communicate work with cross functional and vertical leads to absorb, prioritize and lead everyday challenges. operational efficiencies analyze data and developer feedback to understand needs, reduce time to onboard and build on the platform, and improve overall stakeholder experience. prioritization make hard trade offs between competing priorities as well as architectural improvements and operational excellence. measure success define a set of success metrics to measure customer satisfaction and business impact and utilize them in decision making. what we re looking for degree in computer science or equivalent with 5 years of data analysis and product management experience. hands on data extraction and analytical experience with sql, google firebase, metabase and tableau. self starter, thinker in action, a planner and a doer, can work well with ambiguity always a team player. possess the entrepreneurial drive to develop and grow disruptive products and thrive in an ever changing and agile environment. proven ability to think big picture strategy and roll up your sleeves to deliver. demonstrated experience in building or delivering data store or warehouse solutions using ml, nlp, etc. excellent communication skills and ability to explain learnings to both technical and non technical partners. nice to have experience with python. saas or cloud based app product experience. experience and success in both small startup environments and large matrix organizations. experience working with large financial institutions. experience exploring new capabilities and technologies to drive innovation. rbcventures join our talent community stay in the know about great career opportunities at rbc. sign up and get customized info on our latest jobs, career tips and recruitment events that matter to you. expand your limits and create a new future together at rbc. find out how we use our passion and drive to enhance the well being of our clients and communities at jobs.rbc.com. job summary city toronto address 20 bay street work hours or week 37.5 work environment office employment type permanent career level experienced hire or professional pay type salary variable bonus required travel 0 exempt or non exempt n or a people manager no application deadline 07 or 16 or 2021 platform technology and operations req id 377759 ad code rbc ventures","['https', 'ux', 'sql', 'machine learning', 'agile environment', 'banking', 'metabase', 'tableau', 'data extraction', 'python', 'nlp', 'computer science', 'product management', 'saas', 'google', 'data analysis', 'data engineering']","['https', 'sql firebase', 'python', 'metabase', 'tableau', 'nlp', 'rb']","['ux', 'agile environment', 'machine learning', 'banking', 'data extraction', 'computer science', 'product management', 'saas', 'data analysis', 'data engineering', 'planning']","['environment', 'events', 'metrics', 'financial institutionsc', 'operational excellence', 'customer satisfaction', 'financial institutions', 'hiring']"
599,869,Research Scientist - Visual Analytics,"company description the bosch research and technology center north america with offices in sunnyvale, california, pittsburgh, pennsylvania and cambridge, massachusetts is part of the global bosch group is committed to providing technologies and system solutions for various bosch business fields primarily in the areas of human machine collaboration , robotics, energy technologies, internet technologies, circuit design, semiconductors and wireless, and mems advanced design. the focus of our global research on human machine collaboration includes big data visual analytics, explainable ai, audio analytics, nlp, conversational ai, mixed reality and smart wearables, etc. we develop intuitive, interactive and intelligent solutions to enable inspiring ux for bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems , industry 4.0 and internet of things , security systems, smart home and building solutions, health care, and robotics. as a part of the global research unit, our visual analytics explainable ai group is responsible for shaping the future industrial ai experience for bosch products and services by combining cutting edge technologies of machine learning, data analysis and interactive visualization. we research and develop scalable, transparent, and intelligent big data analytic solutions for various domains including autonomous driving, industry 4.0 , connected vehicles, iot, car multimedia etc. with our award winning talents , we also actively collaborate with leading groups in academia to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., ieee vis, tvcg, sigkdd, neurips, aaai, and icml. job description conduct advanced research and engineering in visual analytics and information visualization for related business domains of autonomous driving, connected vehicles, industry 4.0, iot etc. apply research results to real world use cases with high quality implementation. integrate the resulting systems or software into existing bosch platforms. summarize research findings in high quality paper and patent submissions. actively scout for the latest technology and predict market trends by monitoring news, technical events and seminars. provide expert opinions on relevant technology areas to management team to facilitate strategic planning, r d roadmap development, and business investment. summarize research findings in high quality paper and or or patent submissions. qualifications required ph.d students in computer science or related fields 3 years of research experience or equivalent graduate research experience in visual analytics, information visualization, hci, applied machine learning and related fields strong programming skills for full stack web development on both frontend and backend good communication and teamwork skills desired publication record in top venues of visualization, data mining, or machine learning research knowledge in machine learning and data mining, with application to explainable ai, high dimensional data analysis, event sequence or log mining and computer vision familiar with one or more main stream machine learning platforms knowledge in interaction and user experience design knowledge in graphical design good leadership skills to drive research topics. additional information major computer science or related fields degree level ph.d start date june, 2021","['visualization', 'user experience', 'robotics', 'big data', 'software', 'computer vision', 'analytics', 'programming', 'data mining', 'machine learning', 'iot', 'audio', 'data analysis', 'visual', 'ux', 'internet of things', 'nlp', 'system', 'information visualization', 'computer science', 'web development', 'log mining', 'ai']","['internet of things', 'iot', 'nlp', 'system', 'robotics', 'programming', 'big data']","['visualization', 'user experience', 'visual analytics', 'security systems', 'software', 'computer vision', 'analytics', 'conversational', 'data mining', 'machine learning', 'data analysis', 'visual', 'planning', 'ux', 'use cases', 'strategic', 'information visualization', 'web development', 'computer science', 'ai']","['events', 'design', 'infotainment']"
600,870,Intermediate Environmental Engineer or Scientist,"at exp, we know that great experiences start with the right people. we believe that work should be challenging, and the challenge should be fun. we also know that exponential possibilities are more likely to occur with a respectful, satisfying and empowering company. we value and respect our employees their experience and expertise as well as their energy, passion and diversity and their innovative approach to work and to life. your challenge exp services inc. is currently looking for an intermediate environmental engineer or scientist to join our environmental team in our ottawa, on office. reporting to the discipline manager, the successful applicant will be part of an active contaminated sites and environmental services team. your responsibilities this individual will be responsible for assessing, reporting, controlling and managing contaminated site projects and other environmental assignments as necessary. duties will include preparation of technical reports project management including phase i, ii environmental site assessments , remediation, hazardous material surveys and abatement programs and related environmental project duties design of remediation programs and soil vapour mitigation systems is an asset budget tracking and cost control proposal preparation review and evaluate technical work of other staff field work manage data as needed liaising with contractors and clients coordinating and conducting environmental field programs, as needed maintain excellent client relationships in various industries. the skills and knowledge you bring university degree or college diploma in a related field is required, such as environmental, chemical or civil engineering, environmental science or geology. 5 years of progressive experience in environmental assessment and remediation, experience as a project manager is an asset. licensure or potential for licensure in ontario through peo or pgo is an asset. experience conducting phase i, ii and iii esas, hazardous material surveys or abatement programs, environmental compliance audits, remediation design and or or hydrogeology. expertise in environmental assessment and remediation techniques, budget management, report preparation, and client relationship management project execution timely, on budget, well organized and client focused understanding of the applicable legislation a motivated, self starter with a demonstrated ability to work independently as well as within a team environment. strong organizational and time management skills as well as attention to detail. excellent oral and written communication skills, as well as advanced technical writing abilities. a valid driver s license and access to a vehicle are required. must be comfortable in the field on construction or environmental project sites. opportunity to participate in business development activities knowledge of microsoft office. what exp can offer with a mission to understand, innovate, partner and deliver, exp provides engineering, architecture, design and consulting services to the world s built and natural environments. our heritage dates back to 1906, when the earliest of exp s predecessor companies started its engineering infrastructure practice. today, over 3,000 creative exp professionals across north america provide the passion and expertise needed to deliver successful projects around the world. our promise is to offer you a challenging career in a positive and dynamic work environment, and it is a promise we take seriously. join a dynamic team at exp that provides you with innovative projects, the capacity to develop your career, a full range of benefits, flexible working hours, and much more when you explore what exp has to offer, you ll find exponential possibilities. for more information, visit .","['cost control', 'reporting', 'remediation', 'technical writing', 'technical reports']",[],"['cost control', 'reporting', 'remediation', 'technical writing', 'technical reports']","['business development', 'environment', 'microsoft office', 'project management', 'environmental science', 'designgeology', 'report preparation', 'material', 'consulting', 'surveys', 'assessment', 'legislation', 'civil engineering', 'design', 'soil', 'budget management', 'construction', 'environmental', 'architecture', 'geology', 'proposal preparation']"
601,871,Sr. Data Engineer - FinTech,"5 years of experience as a data engineer or in a similar role experience with data modeling, data warehousing, and building etl pipelines experience in sql knowledge of batch and streaming data architectures experience with aws technologies including redshift, rds, s3, emr, eml or similar solutions built around hive or spark etc. experience communicating with senior management as well as with colleagues from engineering, analytics, and business backgrounds. exceptional written communication skills experience using big data technologies demonstrated strength in data modeling, etl development, and data warehousing knowledge of data management fundamentals and data storage principles knowledge of distributed systems as it pertains to data storage and computing proficiency in python or other similar languages. amazon financial technology team is looking for a results oriented data engineer, who can help us build the next generation of distributed, scalable financial systems. our ideal candidate thrives in a fast paced environment, enjoys the challenge of highly complex business contexts that are typically being defined in real time. we need someone to design and develop data solutions that facilitate global financial transactions worth billions annually. as a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world s largest and most complex data warehouse environments. you will work closely with the business teams in analysis on various cost savings initiatives, many non standard and unique business problems and use creative problem solving to deliver actionable output. you will be responsible for designing and implementing an analytical environment using third party and in house reporting tools, modeling metadata, building reports and dashboards. you will have an opportunity to work with leading edge technologies like redshift, hadoop or hive or pig. you will be writing scalable queries and tuning performance on queries running over billion of rows of data. you should be analytical, have a high level of customer focus and a passion for process improvement. you should be motivated self starter that can work in a fast paced, ambiguous environment. you should have excellent business and communication skills to be able to work with business owners to develop and define key business questions. masters in computer science, mathematics, statistics, economics, or other quantitative fields. knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations excellent knowledge of advanced sql working with large data sets. knowledge of advanced statistics and implementing ml models. demonstrated ability to mentor junior team members in all aspects of their engineering skill sets proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strateg experience providing technical leadership and mentoring other engineers for best practices on data engineering strong business acumen, proven ability to influence others, strong attention to detail, excellent organization skills, and ability to manage multiple projects","['computing', 'emr', 'big', 'dashboards', 'financial technology', 'coding standards', 'eml', 'distributed systems', 'hive', 'technical leadership', 'sql', 'python', 'statistics', 'software', 'reporting', 'data', 'analytics', 'aws', 'pipelines', 'data engineering', 'data warehousing', 'testing', 'metadata', 'agile methodologies', 'financial systems', 'amazon', 'economics', 'hadoop', 'data solutions', 'computer science', 'mathematics', 'modeling', 'data management', 'etl']","['sql', 'python', 'emr', 'hadoop', 'eml', 'aws', 'rds', 'big data', 'pipelines', 'hive']","['computing', 'dashboards', 'financial technology', 'coding standards', 'distributed systems', 'technical leadership', 'statistics', 'software', 'reporting', 'analytics', 'data', 'data engineering', 'data warehousing', 'testing', 'metadata', 'data storage', 'agile methodologies', 'financial systems', 'economics', 'data solutions', 'computer science', 'mathematics', 'modeling', 'data management', 'etl']","['environment', 'cost savings', 'process improvement', 'design', 'financial transactions', 'mentoring']"
602,873,Senior Data Engineer,"it s an exciting time to be at infoblox. named a top 25 cyber security company by the software report and one of inc. magazine s best workplaces for 2020, we are leading the way to next level ddi with our secure cloud managed network services, bringing next level security, reliability, and automation to cloud and hybrid systems all managed through a single pane of glass. our success depends on bright, energetic, talented people who share a passion for building the next generation of networking technologies and having fun along the way. we are looking for a senior data engineer to join our cloud engineering team in burnaby, bc, reporting to the senior manager, software engineering. in this role, you will develop platforms and products for infoblox s saas product lines. this is an excellent opportunity to work closely with data scientists and product development teams to curate and refine data powering our latest cloud products. come join our growing cloud engineering team and help us build world class solutions you re the ideal candidate if you are a savvy software engineer with experience in data engineering and a solid background in spark and python. preferably you know that countminsketch is not a children s game. you have worked in a cloud environment and are comfortable wearing several hats in a small organization with a wide range of responsibilities. you know that big data is both a blessing and a curse without sound data engineering, it loses its potential. you are passionate about the nexus between data and computer science driven to figure out how best to represent and summarize data in a way that informs good decisions and drives new products. when someone says, my spark job failed, your first question is, what s the skew what you ll do curate very large scale data from a multitude of sources into appropriate sets for research and development for the data science, threat analysts, and developers across the company design, test, and implement storage solutions for various consumers of the data design and implement mechanisms to monitor data sources over time for changes using summarization, monitoring, and statistical methods leverage computer science algorithms and constructs, including probabilistic data structures, to distill extensive data into sources of insight and enable future analytics convert prototypes into production data engineering solutions through disciplined software engineering practices, spark optimizations, and modern deployment pipelines collaborate on design, implementation, and deployment of applications with the rest of the software engineering team support data scientists and product teams in building, debugging, and deploying spark applications that best leverage data build and maintain tools for automation, deployment, monitoring, and operations create test plans, test cases, and run tests with automated tools what you ll bring 6 years of experience with python3, and 2 years experience with spark. scala experience is helpful 5 years of experience in data engineering, data science, and related data centric fields using large scale data environments 3 years of experience in using sql and working with modern relational databases, including mysql or postgresql 3 years of experience with developing etl pipelines and data manipulation scripts proficient in object oriented design and s.o.l.i.d principles strong emphasis on unit testing and code quality proficient with aws products ms or bs in computer science or a related field, or equivalent work experience required what success looks like after six months, you will complete onboarding by demonstrating knowledge of the data lake and associated technologies and ci or cd processes by deploying etl pipelines for curation warehousing to production complete rotations on bug duty where you will gain experience with the different systems, tools, and processes in the data lake by resolving reported issues contribute to the team s velocity by participating in scrum and driving stories to completion after about a year, you will be an expert on the data lake target state architecture and drive engineering design and grooming sessions for new feature development apply coding best practices and provide in depth reviews on the team s pull requests be a thought leader in one or more domains of the data lake, driving development and mentoring teammates in this domain we ve got you covered our holistic benefits package includes coverage of your health, wealth, and wellness as well as a great work environment, employee programs, and company culture. we offer competitive compensation, a comprehensive benefits package including health, dental, and vision coverage, and an employee and family assistance program to support the wellbeing of our employees and their families. we have a strong culture and live our values every day we believe in transparency, curiosity, respect, and above all, having fun while delighting our customers. speaking of a great work environment, here are just a few of the perks you may enjoy boutique office space with state of the art amenities, located in the heart of metro vancouver area bike friendly and steps from skytrain and metrotown mall onsite parking paid for by the company generous company contribution towards rrsp onsite massages, gym membership, fitness classes, ping pong table, dartboard, and a nap room or wellness room for moms stay fueled with healthy snacks, free bean to cup gourmet coffee options and selections of exotic teas, juices, and refreshing beverages, and biweekly thirsty thursday local craft beers, bc wines, and bc ciders enjoy our generous pto policy and flexible work environment because we know the importance of having a great work life balance we are passionate about lifelong learning and growth and offer opportunities through a world class learning platform , training, workshops, mentorship, and an annual up to 5,000 career development reimbursement benefit our teams spend time together outside of work, too we have several annual team outings, have gone on hikes and grouse grind, hosted family bbqs, go karting, boat cruises, etc. be confident bringing your whole self to work we re proud to be an inclusive company with diverse teams and our values grounded in ethics and equality why infoblox we ve created a culture that embraces diversity, equity, and inclusion and rewards innovation, curiosity, and creativity. we achieve remarkable results by working together in a supportive environment that focuses on continuous learning and embraces change. so, whether you re a software engineer, marketing manager, customer care pro, or product specialist, you belong here, where you will have the opportunity to grow and develop your career. check out what it s like to be a bloxer. we think you ll be excited to join our team. li ab1","['go', 'ci', 'big data', 'mysql', 'sql', 'python', 'cd', 'postgresql', 'software', 'scala', 'reporting', 'data science', 'saas', 'data', 'analytics', 'aws', 'pipelines', 'data engineering', 'unit testing', 'engineering', 'relational databases', 'scrum', 'data manipulation', 'debugging', 'rest', 'algorithms', 'pipelinesrationhousing', 'automation', 'test cases', 'storage solutions', 'security', 'networking', 'computer science', 'etl']","['go', 'sql', 'python', 'postgresql', 'scala', 'object oriented', 'data manipulation', 'debugging', 'big data', 'aws', 'pipelines', 'mysql']","['engineering design', 'ci', 'tests', 'cd', 'summarization', 'software', 'network services', 'reporting', 'data science', 'saas', 'data', 'analytics', 'unit testing', 'data engineering', 'relational databases', 'scrum', 'software engineering', 'rest', 'algorithms', 'automation', 'test cases', 'storage solutions', 'security', 'networking', 'hybrid systems', 'computer science', 'feature', 'etl']","['environment', 'product development', 'marketing', 'onboarding', 'design', 'art', 'customer care', 'sky', 'product lines', 'compensation', 'workshops', 'architecture', 'mentoring']"
603,877,Behavioral Scientist,"duties or responsibilities analyzing a breadth of data points to uncover human truths apply learnings to tactical creative and strategy work on a weekly and monthly basis assist in biometric creative testing using a proprietary structure build testing recommendations and test studies proactively collaborate with creative, strategy, and analytics teams to ensure agency partners comprehend and apply findings collaborate with the analytics team to craft social media tests and strategies that drive consumers through business and engagement funnels requirements or qualifications in depth knowledge of behavioral sciences base understanding of psychology, social psychology, evolutionary psychology, and or or consumer neuroscience understanding of behavioral economics cognitive process including heuristics and biases understanding of cognitive motivations including explicit and implicit motivational territories. demonstrated knowledge of traditional and behavioral science research in depth knowledge of traditional qualitative and quantitative marketing research techniques in depth knowledge of behavioral qualitative and quantitative marketing research techniques in depth understanding of the scientific method and random control trials in depth understanding of consumer neuroscience techniques. demonstrated ability to discover what business questions internal and external stakeholders are trying to answer and formulate and execute a behavioral science research plan and provide actionable results.","['quantitative', 'economics', 'testing', 'test studies', 'analytics', 'neuroscience']",[],"['tests', 'quantitative', 'testing', 'economics', 'test studies', 'analytics', 'neuroscience']",['marketing research']
604,878,Senior Data Engineer - Remote,"about koho koho is a quickly scaling fintech company backed by leading investors and advisors from around the world. we started koho because we believe in doing two things democratizing access to the best financial products and giving everyone a great financial foundation. since our journey began 6 years ago, we ve raised more than 130m, grown the koho collective to over 200 employees and created accounts for more than 300,000 canadians. about the role as our newest senior data engineer, you would bring your database design sense and meticulous standards for clean data to the table. more than just understanding the strategic importance of data in a financial context, you re eager to roll up your sleeves and build the infrastructure to support it. we value potential as much as we value experience, so if you think you d be a great fit we d love to hear from you. please note this is a remote position based in canada that is available to those who are legally entitled to work in canada. responsibilities maintaining clean and consistent access to all our data sources providing a solid foundation for calculating key business metrics maintaining data infrastructure to keep up with the product roadmap understanding data lineage and governance for a variety of data sources communicating updates and changes to the broader data team as well as contributing to and maintaining data related documentation participate in rotating on call duties, including incident management desired skills experience minimum of five years of experience working with data able to design efficient and scalable cloud architectures experience writing complex sql queries knowledge of etl patterns, including testing and maintenance familiar with relational or non relational database approaches and knowing which to apply where and when understanding of hot or warm or cold data concepts and when each is appropriate understanding of event driven and stream based processing patterns ability to think holistically about uses of data, designing for ease of data access working knowledge of one of python, java experience with kubernetes cluster management is an asset experience with data processing frameworks such as apache spark nice to have skills experience with google cloud platform knowledge of go joining the koho team we invest time and resources into making sure koho is as good as the people we hire. our culture is one of collaboration, creativity, and diverse perspective. here are some of the reasons we attract the best people balance your life unlimited pto, generous vacation, and a lifestyle spending account work anywhere in canada permanently remote and 1,000 to set up your home office level up access to an in house certified performance coach reach your goals salary assessments twice a year, annual training allowance the koho culture we have won 5 great place to work awards since 2019 the fine print we are an equal opportunity employer and value diversity and uniqueness at our company. koho is trusted with highly sensitive information. upon joining the team, you may be asked to undergo security screening including a criminal record check. li remote","['go', 'kubernetes', 'sql', 'python', 'data processing', 'testing', 'apache spark', 'data infrastructure', 'security', 'database design', 'google cloud platform', 'screening', 'documentation', 'cluster management', 'java', 'etl']","['go', 'kubernetes', 'sql', 'python', 'apache spark', 'google cloud platform', 'documentation', 'java']","['data processing', 'data lineage', 'testing', 'data infrastructure', 'security', 'database design', 'screening', 'cluster management', 'and', 'etl']","['incident management', 'metrics', 'fintech', 'design', 'governance', 'business']"
605,879,Senior Marketing Scientist,"senior marketing scientist who is pod marketing pod marketing is an innovative digital marketing agency whose strategy is to build specific capabilities and programs within industries. we are a full service agency and can offer our clients solutions such as branding, website development, lead generation, digital advertising, content creation, seo, video creation, marketing automation, etc. we discover what works for one client and help apply those learnings to new clients within the same industry. currently, we are supporting the following verticals eye care dental home services chiropractors senior living citizen coming soon our company was founded in 2014, and has built a tremendous culture for the people and clients we work with. we have grown quickly over our 6 years in business, now working with over 200 clients across north america and employing an amazing team of over 50 employees. to learn more about our culture, visit the pod marketing youtube channel. we are looking for a full time senior search engine marketing specialist to join our team. if this sounds like a position that you would be interested in, please read the job description below. role overview the senior sem or ppc specialist will have 2 5 years of hands on experience developing and managing advertising campaigns on platforms including google, facebook, instagram, linkedin and microsoft bing ads. the ideal candidate is results oriented and data driven performance marketer with demonstrated experience managing multiple paid advertising campaigns. you take a customer centric approach, and you re passionate about doing what s right for our customers and brand. you are highly analytical and count a or b testing, optimizing customer acquisition costs, and analyzing campaign performance among your core competencies. you likely have some deep experience in a few marketing channels, and have the aptitude to learn new channels quite quickly. most importantly, you are eager to roll up your sleeves to find opportunities and efficiencies in a fast moving company at the forefront of digital marketing. responsibilities plan, develop, build, manage and optimize all digital advertising solutions including but not limited to pay per click , online display and social media ads manage campaign expenses, staying on budget, estimating monthly costs and reconciling discrepancies track, report, and analyze website analytics, pay per click initiatives and social media campaigns generate necessary codes that will be placed on a client s website to measure conversions. collaborate with internal teams to manage accounts and execute client specific marketing roadmaps required experience skills must have bachelor s degree in marketing or business or related field 2 5 years of sem experience and success managing pay per click campaigns across google 1 2 years of experience setting up analytics and conversion tracking codes on client websites up to date with the latest trends and best practices in search engine marketing in depth experience with bid management tools experience with website analytics tools strong analytical skills and experience generating sem reports familiarity with a or b and multivariate experiments analytical and data driven mindset ability to manage multiple projects and deadlines nice to have post secondary degree in stem mentorship and training experience advanced knowledge of google analytics and paid advertising basic knowledge of seo prior agency experience self driven projects this person should have passion above all else. they are a person who wants to grow their career, not just find a job. how to apply at pod, we believe that most job requirements and conceptual knowledge are easily trainable. but you can t teach drive, ambition, or passion. . our hiring managers consider alignment with our core values and passion for our company culture to be as valuable as experience and education. after reading this job description, we want you to ask yourself am i the exact right person for this role do i align with pod s core values and culture if you ve answered yes to both questions, we want to hear from you here are a few easy steps that will help us get to know you better. ensure your professional resume is up to date and highlights some of the key points we are looking for. create an engaging and personalized cover letter for us to read. if you don t include a cover letter, you will not be considered for this role. make sure to highlight your google ads or facebook ads experience. video cover letters are given extra attention. apply through our website all successful candidates will be contacted via email to discuss next steps. we appreciate all applications and wish you all the best of luck.","['seo', 'forefront', 'analytical skills', 'google analytics', 'testing', 'analytics', 'ppc', 'automation']","['google analytics', 'search engine', 'forefront']","['seo', 'analytical skills', 'testing', 'analytics', 'ppc', 'automation']","['linkedin ads', 'advertising', 'education', 'marketing', 'expenses', 'advertising campaigns', 'content creation', 'google ads', 'campaigns', 'lead generation', 'digital', 'marketingm', 'hiring', 'branding', 'customer']"
606,880,"Senior Scientist - Instrument Design, ICP Mass Spec. R&D","senior r d scientist icp ms perkinelmer is a global technology leader, driving growth and initiative in the environmental and human health science markets. the company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world. perkinelmer is searching for an experienced research and development scientist to help create innovative solutions in our inductively coupled plasma mass spectrometry product line. the successful candidate will become a key member of a group of senior perkinelmer researchers, and will liaise with other scientists at perkinelmer s partners and collaborators. this position is based in woodbridge, ontario, canada. duties and responsibilities initiate and execute scientific research and product development, with primary focus on next generation instrument development, technology, trade secrets, and intellectual property. provide mass spectrometry expertise and guidance within the r d product development team, ensuring thorough conceptualization, design, and validation of new products. conduct scientific experiments to evaluate new technologies adapt, modify, improve, develop, and apply them to future products. prepare reports on research progress and technical feasibilities based on findings from the experiments. influence the scientific community and instrument market via patents, publications, and conference presentations. work with applications, manufacturing, engineering, and service personnel to improve real world performance, quality, value, manufacturability, and serviceability of icp ms products. demonstrate independent and creative scientific thinking, ability to solve complex problems, and resilience to setbacks and changes. contribute effectively to multiple collaborative projects in a lean, agile, cross functional team environment. basic qualifications ph.d. in science or related fields and 3 years of mass spectrometer instrument development experience. or ms in science, engineering, or related fields and 6 years of mass spectrometer instrument development experience. prior mass spectrometry instrument industrial design experience preferred qualifications knowledge of mass spectrometry theory and components strong hands on instrumentation design, optimization, and troubleshooting skills. ability to solve complex problems and dissect projects into manageable tasks excellent group interpersonal skills. proven track record of patents and or or publications in peer reviewed journals. strong written and oral communication skills. demonstrated organizational skills to effectively manage multiple tasks with different priorities. previous successful academic or work related experience mentoring peers.","['troubleshooting', 'optimization']",[],"['troubleshooting', 'optimization']","['mass spectrometry', 'validation', 'environment', 'mass spectrometer', 'instrumentation', 'marketing', 'ancillary services', 'design', 'presentations', 'product development', 'manufacturing', 'environmental', 'scientific research', 'industrial design', 'mentoring']"
607,884,Senior AI / ML Scientist,"antuit.ai is the leader in ai powered saas solutions, empowering world class consumer products and retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. antuit.ai s executives, comprised of industry leaders from sap, sas, ibm, and accenture, and our team of ph.ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. antuit is funded by goldman sachs and zodius capital. the role antuit.ai is interested in hiring an ai and machine learning researcher to design and develop advanced machine learning algorithms and systems in the programming language of choice . the successful candidate should also have ample experience in developing and deploying machine learning algorithms and data transformation modules. experience of working in the demand forecasting or supply chain domain would be an added advantage. responsibilities responsibilities includes, but are not limited to the following research and implement ai algorithms and tools as a proof of concept and move it to the production ready state pefrom appropriate feature extraction and data representation optimize and transform data science prototypes or solutions for speed, reliability, and scale implementing scalable algorithms using spark and dask. collaborate cross functionally with domain experts to identify gaps and structural problems qualifications and skills the successful candidate will have the following profile or experience d. or m.s. in computer science, computer engineering, electrical engineering, statistics, applied mathematics, or other related fields. 5 years experience working in applied machine learning. extensive experience in designing, tunning, and deploying scalable deep learning models with tensorflow and keras. experience in developing scalable machine learning pipelines using pyspark and dask familiarity with linear and non linear regression models and time series forecasting models and libraries in python. experience in developing ml or ai algorithms using nvidia cuda is an advantage. skilled in developing and deploying machine learning models and solutions, analytical problem solving, pattern recognition, and predictive modeling understanding of data structures, data modeling, and software architecture. the experience of working on cloud infrastructures will be helpful. strong communication skills. strong work ethic and passion for learning and contributing to the development collaborative mindset. able to collaborate closely and effectively with teams information security responsibilities understand and adhere to information security policies, guidelines and procedure, practice them for protection of organizational data and information system. take part in information security training and act accordingly while handling information. report all suspected security and policy breach to infosec team or appropriate authority . eeoc antuit.ai is an at will, equal opportunity employer. we consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age , marital status, disability, veteran status, or any other legally protected status under local, state, or federal law. to apply, please send your resume or cv to antuit.ai thanks all applicants however, only those selected for an interview will be contacted.","['pyspark', 'tensorflow', 'pattern recognition', 'python', 'statistics', 'keras', 'data science', 'saas', 'programming', 'data', 'pipelines', 'sas', 'software architecture', 'electrical engineering', 'machine learning', 'data transformation', 'proof of concept', 'computer engineering', 'information', 'algorithms', 'forecasting', 'deep learning', 'data representation', 'data structures', 'security', 'computer science', 'modeling', 'applied mathematics', 'ai']","['python', 'keras', 'pyspark', 'programming', 'cuda', 'pipelines', 'sas']","['tensorflow', 'data modeling', 'pattern recognition', 'statistics', 'data science', 'saas', 'software architecture', 'electrical engineering', 'machine learning', 'data transformation', 'proof of concept', 'computer engineering', 'predictive', 'information', 'algorithms', 'forecasting', 'deep learning', 'data representation', 'time series', 'data structures', 'linear regression', 'security', 'computer science', 'modeling', 'applied mathematics', 'feature', 'ai']","['law', 'merchandising', 'marketing', 'retail', 'capital', 'sap', 'design', 'consumer products', 'hiring']"
608,889,Sr. Data Engineer (Python),"td description tell us your story. don t go unnoticed. explain why you re a winning candidate. think td if you crave meaningful work and embrace change like we do. we are a trusted north american leader that cares about people and inspires them to grow and move forward. stay current and competitive. carve out a career for yourself. grow with us. department overview the team our team is made up of a number of business smes and data engineering enthusiasts coming from a variety of diverse backgrounds and industries. we take pride in innovation and developing futuristic analytics apps for the front office. our app provides much needed metrics and client information to the front office that enables informed decision making and supplements revenue generation opportunity identifications. we have already delivered solutions to a number of front office desks, and are seeking to speed up the delivery for the remaining desks. we also collaborate with multiple teams across the dealer to brainstorm on data pipelines. being a downstream consumer of huge amounts of data, we drive key decisions around how or when or where of the data elements. our team is a high visibility team, as the data is used across the dealer, by all the desk heads, and senior management. and, this visibility is going to increase along with onboarding new workstreams and data sets for the remaining front office desks. we also know how to have fun by organizing and participating in various social events. though coronavirus pandemic spoiled our in person team get togethers this year, but, we do organize team trips to the driving range, bowling, baseball games, ski trips, and of course frequent trips to the bar. job description brief role description an experienced data engineer to work on a fast paced front office facing client analytics data engineering team at a leading wholesale bank with a great culture. analyze, design and develop highly impactful analytics that help support and drive decision making, and highlight areas of revenue generation. this role will focus heavily on analyzing huge data sets, writing python code, and working closely with the business to elicit requirements. required skills 5 years data analytics experience, with significant experience in jupyter notebooks and python specifically, in pandas, numpy, plotly and dash. should have experience in both data analysis requirements gathering as the role involves high engagement with the users. excellent communication skills required as this is a front office facing client analytics application with heavy user interaction with traders and salespersons. experience in capital markets is necessary, as the team is involved in trade data, market data and reference data analytics. experience in fixed income, foreign exchange derivative products at least intermediate understanding of the inner workings of various products offered in the above asset classes. passion for data analytics with strong sense of best practices. self starting and motivated, with sense of responsibility strong sense of ownership enjoys working in a fast paced environment has an eye for design and usability job requirements the role data engineer on a fast paced front office facing client analytics data engineering team at a leading investment bank with a great culture. lead individual data analysis and insights workstreams from start to finish, in close collaboration with the front office. gather requirements from the stakeholders, analyze data based on the requirements, present finding to the stakeholders, and iterate over the process until methodologies and metrics are finalized. perform data analysis on huge sets of trade data, market data and reference data to generate metrics that can be used to support and drive decision making for the front office. add to the python codebase, the novel ideas and techniques that can be used to innovate and improve upon the existing infrastructure. provide user training and support to front office for the ui as well as for jupyter notebooks. translate business requirements to functional specifications for the development team. take part in design sessions to brainstorm on the best approach and design that should be followed to implement the solution. should not be afraid to speak their mind. follow agile approach in monthly release cycles. perform analysis, planning and testing of the requirements to ensure accurate delivery of the solution. help debug and solve issues in different envs and identify any potential bugs that can harm the application. willingness to work hard in a flexible environment using agile methodologies. comfortable working with new software tools not afraid of new technology. help support existing production applications update confluence site and documentation to reflect additions or changes to the workstreams, or other essential information. ensure effective communication of estimates timelines to the rest of the team, including status updates of current work contribute to the development of project plans by providing input and manage project estimates or initiatives, communicating project status to business and management and providing timely escalation of issues support releases as needed teamwork collaborate with other team members and stakeholders in order to understand or gather business requirements and analyze data. responsible for turning business requirements into functional specification, interacting directly with the front office traders for further requirements elaboration discussion work closely with project managers, delivery or partner management, data engineers, sponsors and relevant stakeholders to clarify requirements, develop analysis plans and strategies teamwork work effectively as a team, supporting other members of the team in achieving business objectives and providing client services participate in knowledge transfer within the team and business units as needed desired interpersonal skills takes great personal pride in building robust analytics solutions strong sense of ownership passionate about data and data analysis enjoys working in a fast paced environment has excellent written and verbal communication skills has strong customer focus additional information join in on what others in td technology solutions are doing inspire a positive work environment and help champion quality, innovation, teamwork and service to the business. learn voraciously, stretch your thinking, inclusiveness at td, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. we are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. if you require an accommodation for the recruitment or interview process , please let us know and we will work with you to meet your needs. job family business systems analysis job category primary technology solutions job category technology solutions hours 37.5 business line corporate time type full time employment type regular country canada province or state ontario city toronto work location td centre north 77 king street west job expires 22 jun 2021","['go', 'confluence', 'documentation', 'usability', 'data analytics', 'python', 'pandas', 'analytics', 'reference data', 'functional specifications', 'data engineering', 'jupyter', 'data pipelines', 'testing', 'numpy', 'requirements gathering', 'data analysis', 'business systems analysis', 'rest', 'agile methodologies', 'market data', 'project managers', 'technology solutions', 'escalation', 'reference']","['go', 'jupyter', 'plotly', 'python', 'numpy', 'confluence', 'pandas', 'technology solutions', 'documentation']","['software tools', 'usability', 'business', 'data analytics', 'analytics', 'reference data', 'functional specifications', 'data engineering', 'systems analysis', 'data pipelines', 'testing', 'requirements gathering', 'data analysis', 'rest', 'planning', 'agile methodologies', 'market data', 'project managers', 'escalation', 'reference']","['additions', 'environment', 'events', 'metrics', 'onboarding', 'project plans', 'design', 'client services', 'front office', 'capital markets', 'user training', 'business units', 'foreign exchange']"
609,893,Enterprise Data Engineer,"job types full time, permanent covid 19 considerations we adhere to all alberta covid 19 protocols. location calgary, ab who we are competing in a data driven world, most businesses struggle to capture real value from data and analytics. data management constraints cause mid size and large companies to miss key opportunities in the value chain. companies are left vulnerable to underwhelming performance and encroachment by competitors. a4 systems is a world class team of cyber physical system product developers, transforming quality data into primary competitive advantage. a trusted partner to industries like manufacturing, agriculture, and energy, a4 builds mission critical saas products for customers to achieve breakthrough performance. what you ll be doing this is an excellent opportunity to develop practical solutions to real world industrial data problems. the focus is on backend development implementing data pipelines in a microservices environment without relying on gcp or aws tooling. you will develop integrations with our erp platform to customise and extend functionality. who you are bachelor s degree in computer science, engineering, or equivalent this is an intermediate role for a developer with 3 5 years experience who is ready to take on new challenges. experience in the open source ecosystem is key along with proven ability to acquire new skills. a desire and capacity to learn are key. rapid implementation of solutions with a focus on delivery followed by iterations to build on success. ability to manage multiple technologies to create comprehensive backend solutions. 3 5 years of experience with the following python javascript nice to have java docker kubernetes graphql apollo apache nifi nosql, ideally cassandra postgresql odoo erp","['apacheql', 'kubernetes', 'python', 'gcp', 'data pipelines', 'postgresql', 'javascript', 'computer science', 'saas', 'analytics', 'aws', 'data management', 'erp', 'graphql', 'microservices', 'java', 'cassandra']","['kubernetes', 'python', 'gcp', 'postgresql', 'erp', 'aws', 'apachefi nosql', 'javascript', 'java', 'cassandra']","['data pipelines', 'computer science', 'saas', 'analytics', 'graphql', 'data management', 'microservices']","['agriculture', 'manufacturing', 'environment', 'functionality']"
